[
  {
    "frage": "1. Was ist der Hauptzweck von Docker in einem Data-Science-Projekt?",
    "optionen": [
      "Um die Performance von Python-Skripten zu beschleunigen.",
      "Um eine reproduzierbare und isolierte Umgebung für die Software zu schaffen.",
      "Um Jupyter Notebooks direkt in der Cloud auszuführen.",
      "Um die Größe von Datensätzen zu reduzieren."
    ],
    "loesung": 1,
    "erklaerung": "Docker packt eine Anwendung und ihre Abhängigkeiten in einen Container, der überall gleich läuft. Das löst das 'Bei mir funktioniert es aber'-Problem und sorgt für Reproduzierbarkeit.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "2. Welcher Befehl wird verwendet, um eine Streamlit-App zu starten?",
    "optionen": [
      "python run app.py",
      "streamlit start app.py",
      "streamlit run app.py",
      "start streamlit app.py"
    ],
    "loesung": 2,
    "erklaerung": "Der Befehl 'streamlit run <dateiname>.py' startet den Streamlit-Server und öffnet die App im Browser.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "3. Was ist ein Pandas DataFrame?",
    "optionen": [
      "Eine ein-dimensionale Datenstruktur für numerische Daten.",
      "Eine zweidimensionale, tabellarische Datenstruktur mit Spalten und Zeilen.",
      "Eine Bibliothek zur Erstellung von interaktiven Diagrammen.",
      "Ein Machine-Learning-Modell zur Klassifikation."
    ],
    "loesung": 1,
    "erklaerung": "Ein Pandas DataFrame ist die zentrale Datenstruktur in Pandas und ähnelt einer Excel-Tabelle oder einer SQL-Tabelle. Sie ist für die Handhabung und Analyse von strukturierten Daten optimiert.",
    "gewichtung": 1,
    "thema": "Pandas"
  },
  {
    "frage": "4. Was ist der Hauptunterschied zwischen Supervised und Unsupervised Learning?",
    "optionen": [
      "Supervised Learning benötigt mehr Rechenleistung.",
      "Unsupervised Learning wird nur für Textdaten verwendet.",
      "Supervised Learning verwendet gelabelte Daten (Input und Output), Unsupervised Learning nicht.",
      "Unsupervised Learning ist immer genauer als Supervised Learning."
    ],
    "loesung": 2,
    "erklaerung": "Der Kernunterschied ist das Vorhandensein von 'Antworten' in den Trainingsdaten. Supervised Learning lernt von Beispielen mit bekannten Ergebnissen (Labels), während Unsupervised Learning Muster in ungelabelten Daten sucht.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "5. Welcher Algorithmus gehört zum Unsupervised Learning?",
    "optionen": [
      "Decision Tree",
      "K-Nearest Neighbors (KNN)",
      "K-Means Clustering",
      "Logistic Regression"
    ],
    "loesung": 2,
    "erklaerung": "K-Means ist ein Clustering-Algorithmus, der versucht, Datenpunkte ohne vordefinierte Labels in 'k' Gruppen (Cluster) einzuteilen. Decision Tree, KNN und Logistic Regression sind Supervised-Learning-Algorithmen.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "6. Was ist der Zweck der 'Elbow-Methode'?",
    "optionen": [
      "Die optimale Anzahl der 'Nachbarn' (k) für KNN zu finden.",
      "Die optimale Anzahl der 'Cluster' (k) für K-Means zu finden.",
      "Die optimale Tiefe eines Decision Trees zu bestimmen.",
      "Die optimale Lernrate für ein Neuronales Netz zu finden."
    ],
    "loesung": 1,
    "erklaerung": "Die Elbow-Methode plottet die 'Inertia' (Summe der quadrierten Abstände zu den Cluster-Zentren) für verschiedene k-Werte. Der 'Ellenbogen' in der Kurve deutet auf ein gutes 'k' hin, bei dem eine weitere Erhöhung der Clusteranzahl nur noch geringe Verbesserungen bringt.",
    "gewichtung": 3,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "7. Was ist die Hauptfunktion einer Aktivierungsfunktion in einem Neuronalen Netz?",
    "optionen": [
      "Sie normalisiert die Eingabedaten.",
      "Sie führt Nichtlinearität in das Modell ein.",
      "Sie berechnet den Fehler des Modells.",
      "Sie initialisiert die Gewichte des Netzwerks."
    ],
    "loesung": 1,
    "erklaerung": "Ohne nichtlineare Aktivierungsfunktionen wäre ein Neuronales Netz nur eine Kaskade von linearen Operationen, was es auf die Modellierung linearer Zusammenhänge beschränken würde. Die Nichtlinearität ermöglicht das Lernen komplexer Muster.",
    "gewichtung": 2,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "8. Welche Aktivierungsfunktion wird typischerweise in der Ausgabeschicht eines Neuronalen Netzes für eine Multi-Klassen-Klassifikation verwendet?",
    "optionen": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Softmax"
    ],
    "loesung": 3,
    "erklaerung": "Die Softmax-Funktion wandelt die rohen Ausgabe-Scores (Logits) des Netzes in eine Wahrscheinlichkeitsverteilung über alle Klassen um, wobei die Summe der Wahrscheinlichkeiten 1 ergibt.",
    "gewichtung": 2,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "9. Was ist der Hauptvorteil von Convolutional Neural Networks (CNNs) gegenüber normalen Neuronalen Netzen bei der Bildverarbeitung?",
    "optionen": [
      "Sie sind schneller zu trainieren, da sie weniger Daten benötigen.",
      "Sie nutzen 'Weight Sharing' und 'Local Connectivity', um die Anzahl der Parameter drastisch zu reduzieren.",
      "Sie können nur mit Graustufenbildern arbeiten.",
      "Sie benötigen keine Aktivierungsfunktionen."
    ],
    "loesung": 1,
    "erklaerung": "CNNs verwenden Filter (Kernel), deren Gewichte über das gesamte Bild geteilt werden. Das macht sie extrem parameter-effizient und gut darin, lokale räumliche Muster zu erkennen, was für Bilder ideal ist.",
    "gewichtung": 3,
    "thema": "Computer Vision"
  },
  {
    "frage": "10. Was ist Data Augmentation?",
    "optionen": [
      "Das manuelle Hinzufügen von neuen, gelabelten Daten zum Trainingsset.",
      "Das künstliche Erzeugen neuer Trainingsdaten durch Transformationen der bestehenden Daten (z.B. Drehen, Spiegeln).",
      "Eine Methode zur Beschleunigung des Modell-Trainings.",
      "Das Entfernen von fehlerhaften Daten aus dem Datensatz."
    ],
    "loesung": 1,
    "erklaerung": "Data Augmentation ist eine Technik, um Overfitting zu reduzieren, indem man dem Modell zur Trainingszeit leicht veränderte Versionen der Bilder zeigt. Dadurch lernt das Modell, robustere und allgemeinere Merkmale zu erkennen.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "11. Was versteht man unter Transfer Learning?",
    "optionen": [
      "Das Trainieren eines Modells von Grund auf mit einem sehr großen Datensatz.",
      "Die Verwendung eines auf einer großen Aufgabe vortrainierten Modells als Ausgangspunkt für eine neue, spezifischere Aufgabe.",
      "Die Übertragung eines Modells von einer Programmiersprache in eine andere.",
      "Das Trainieren mehrerer Modelle auf verschiedenen Teilen eines Datensatzes."
    ],
    "loesung": 1,
    "erklaerung": "Beim Transfer Learning nutzt man das 'Wissen' (die gelernten Features) eines Modells, das auf einem riesigen Datensatz (z.B. ImageNet) trainiert wurde, und passt es mit einem kleineren, aufgabenspezifischen Datensatz an. Dies spart enorm viel Zeit und Daten.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "12. Was ist der Zweck des QUA³CK-Prozessmodells?",
    "optionen": [
      "Es ist ein spezifischer Machine-Learning-Algorithmus.",
      "Es ist ein Framework zur Beschleunigung von Python-Code.",
      "Es bietet eine strukturierte Vorgehensweise für Data-Science-Projekte von der Fragestellung bis zum Wissenstransfer.",
      "Es ist eine Bibliothek zur Datenvisualisierung."
    ],
    "loesung": 2,
    "erklaerung": "QUA³CK ist ein am KIT entwickeltes Prozessmodell, das die Phasen Question, Understanding, die A³-Schleife (Algorithm, Adapting, Adjusting), Conclude und Knowledge Transfer umfasst, um ML-Projekte systematisch zu bearbeiten.",
    "gewichtung": 2,
    "thema": "MLOps & Prozesse"
  },
  {
    "frage": "13. Welches Tool wird im Kurs primär für das Experiment-Tracking und die Modell-Verwaltung (Model Registry) verwendet?",
    "optionen": [
      "TensorBoard",
      "Weights & Biases",
      "MLflow",
      "DVC"
    ],
    "loesung": 2,
    "erklaerung": "MLflow wird im Kurs als zentrales MLOps-Tool verwendet, um Experimente (Parameter, Metriken) zu tracken und trainierte Modelle in einer 'Model Registry' zu versionieren und zu verwalten.",
    "gewichtung": 3,
    "thema": "MLOps & Tools"
  },
  {
    "frage": "14. Was ist der Hauptzweck einer `requirements.txt`-Datei?",
    "optionen": [
      "Sie enthält den Python-Code für die Anwendung.",
      "Sie listet alle Python-Bibliotheken und deren Versionen auf, die für ein Projekt benötigt werden.",
      "Sie beschreibt die Architektur eines Neuronalen Netzes.",
      "Sie enthält die Trainingsdaten für ein Machine-Learning-Modell."
    ],
    "loesung": 1,
    "erklaerung": "Die `requirements.txt` Datei ermöglicht es, eine Python-Umgebung mit genau den richtigen Abhängigkeiten zu reproduzieren, was für die Zusammenarbeit und das Deployment entscheidend ist. Man installiert sie mit `pip install -r requirements.txt`.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "15. Welcher Python-Befehl wird verwendet, um eine Spalte namens 'Alter' aus einem Pandas DataFrame 'df' auszuwählen?",
    "optionen": [
      "df.get('Alter')",
      "df['Alter']",
      "df.column('Alter')",
      "df.select('Alter')"
    ],
    "loesung": 1,
    "erklaerung": "Die Standardmethode, um auf eine Spalte in einem Pandas DataFrame zuzugreifen, ist die Verwendung der eckigen Klammern mit dem Spaltennamen als String: df['Alter'].",
    "gewichtung": 1,
    "thema": "Pandas"
  },
  {
    "frage": "16. Was ist der Unterschied zwischen `st.write()` und `st.dataframe()` in Streamlit?",
    "optionen": [
      "Es gibt keinen Unterschied, beide machen das Gleiche.",
      "`st.write()` kann nur Text anzeigen, `st.dataframe()` nur Tabellen.",
      "`st.write()` ist ein 'magischer' Befehl, der viele Datentypen (inkl. DataFrames) anzeigen kann, während `st.dataframe()` eine interaktive Tabelle speziell für DataFrames rendert.",
      "`st.dataframe()` ist veraltet und sollte nicht mehr verwendet werden."
    ],
    "loesung": 2,
    "erklaerung": "`st.write()` ist ein Allzweck-Befehl. Wenn man ihm einen Pandas DataFrame übergibt, zeigt er eine statische Tabelle an. `st.dataframe()` hingegen rendert eine interaktive Tabelle mit Sortier- und Filterfunktionen.",
    "gewichtung": 2,
    "thema": "Streamlit"
  },
  {
    "frage": "17. Was beschreibt der Begriff 'Overfitting' im Machine Learning?",
    "optionen": [
      "Das Modell ist zu einfach und kann die Muster in den Daten nicht lernen.",
      "Das Modell lernt die Trainingsdaten 'auswendig', inklusive des Rauschens, und generalisiert schlecht auf neue Daten.",
      "Das Training des Modells dauert zu lange.",
      "Das Modell wurde mit zu wenigen Daten trainiert."
    ],
    "loesung": 1,
    "erklaerung": "Overfitting tritt auf, wenn ein Modell zu komplex ist im Verhältnis zur Datenmenge. Es passt sich perfekt an die Trainingsdaten an, verliert aber die Fähigkeit, auf ungesehenen Daten gute Vorhersagen zu machen.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "18. Welcher der folgenden Filter wird typischerweise zur Kantenerkennung in der Bildverarbeitung verwendet?",
    "optionen": [
      "Mean-Filter (Blur)",
      "Median-Filter",
      "Gauß-Filter",
      "Sobel-Filter"
    ],
    "loesung": 3,
    "erklaerung": "Der Sobel-Filter ist ein klassischer Kantenerkennungs-Operator, der die Ableitung (den Gradienten) der Bildintensität berechnet, um Kanten hervorzuheben. Blur-Filter hingegen glätten das Bild.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "19. Was ist der Hauptvorteil der Verwendung von Transformer-Modellen (wie BERT oder GPT) gegenüber LSTMs für NLP-Aufgaben?",
    "optionen": [
      "Transformer sind einfacher zu implementieren.",
      "Transformer können stark parallelisiert werden, was das Training auf GPUs erheblich beschleunigt.",
      "Transformer benötigen weniger Speicher.",
      "Transformer können nur für Textgenerierung verwendet werden."
    ],
    "loesung": 1,
    "erklaerung": "LSTMs verarbeiten Sequenzen Wort für Wort, was die Parallelisierung erschwert. Transformer verarbeiten alle Wörter einer Sequenz gleichzeitig mithilfe des 'Attention'-Mechanismus, was sie ideal für moderne Hardware wie GPUs und TPUs macht.",
    "gewichtung": 3,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "20. Was ist der Zweck eines `Dockerfile`?",
    "optionen": [
      "Es ist ein Python-Skript zum Trainieren von ML-Modellen.",
      "Es ist eine Konfigurationsdatei für Jupyter Notebooks.",
      "Es ist eine Textdatei, die die Anweisungen zum Bauen eines Docker-Images enthält.",
      "Es ist eine Log-Datei, die alle Docker-Befehle aufzeichnet."
    ],
    "loesung": 2,
    "erklaerung": "Ein Dockerfile ist wie ein Rezept. Es listet alle Schritte auf, die notwendig sind, um eine lauffähige Umgebung für eine Anwendung zu erstellen, inklusive Basis-Image, Abhängigkeiten und Startbefehlen.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "21. Welches Argument wird bei `train_test_split` von Scikit-learn verwendet, um sicherzustellen, dass die Klassenverteilung in Trainings- und Testset gleich bleibt?",
    "optionen": [
      "shuffle=True",
      "stratify=y",
      "balance=True",
      "keep_distribution=True"
    ],
    "loesung": 1,
    "erklaerung": "Das `stratify`-Argument sorgt für eine geschichtete Aufteilung. Wenn man ihm die Label-Variable `y` übergibt, stellt es sicher, dass der prozentuale Anteil jeder Klasse in Trainings- und Testdaten dem des Gesamtdatensatzes entspricht.",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "22. Was ist der Zweck des 'Pooling'-Layers in einem CNN?",
    "optionen": [
      "Die Anzahl der Features (Filter) zu erhöhen.",
      "Die räumliche Dimension der Feature Maps zu reduzieren (Downsampling).",
      "Dem Bild Rauschen hinzuzufügen, um Overfitting zu vermeiden.",
      "Die Farben des Bildes zu normalisieren."
    ],
    "loesung": 1,
    "erklaerung": "Pooling (z.B. Max-Pooling) reduziert die Höhe und Breite der Feature Maps (Downsampling). Dies verringert die Anzahl der Parameter und den Rechenaufwand in nachfolgenden Schichten und macht das Modell robuster gegenüber kleinen Verschiebungen im Bild.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "23. Welches Python-Tool wird im Kurs verwendet, um ML-Modelle als REST API bereitzustellen?",
    "optionen": [
      "Streamlit",
      "Flask",
      "Django",
      "FastAPI"
    ],
    "loesung": 3,
    "erklaerung": "FastAPI ist ein modernes, schnelles Web-Framework für Python, das sich hervorragend für die Erstellung von performanten APIs eignet, insbesondere für das Servieren von ML-Modellen.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "24. Was ist der Unterschied zwischen `Accuracy` und `Precision` als Metrik?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "Accuracy misst den Anteil aller korrekten Vorhersagen, während Precision den Anteil der korrekten positiven Vorhersagen an allen positiven Vorhersagen misst.",
      "Precision ist immer höher als Accuracy.",
      "Accuracy wird für Regression verwendet, Precision für Klassifikation."
    ],
    "loesung": 1,
    "erklaerung": "Accuracy = (TP+TN)/(TP+TN+FP+FN). Precision = TP/(TP+FP). Precision ist wichtig, wenn die Kosten für 'False Positives' hoch sind (z.B. Spam-Filter, der wichtige E-Mails fälschlicherweise als Spam markiert).",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "25. Wie kann man in Streamlit interaktive Widgets wie Schieberegler oder Buttons in einer Seitenleiste platzieren?",
    "optionen": [
      "Man kann Widgets nicht in einer Seitenleiste platzieren.",
      "Indem man den Befehl `st.sidebar()` verwendet.",
      "Indem man den Befehlen das Präfix `st.sidebar.` voranstellt (z.B. `st.sidebar.slider(...)`).",
      "Durch die CSS-Eigenschaft `position: sidebar;`."
    ],
    "loesung": 2,
    "erklaerung": "Jeder Streamlit-Befehl, dem `st.sidebar.` vorangestellt wird, rendert das entsprechende Element in der Seitenleiste anstatt im Hauptbereich der App.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "26. Was ist ein 'Hyperparameter'?",
    "optionen": [
      "Ein Gewicht oder Bias, das während des Trainings gelernt wird.",
      "Ein Parameter, der vor dem Trainingsprozess festgelegt wird und diesen steuert (z.B. Lernrate, Anzahl der Layer).",
      "Ein Maß für die Leistung des Modells auf dem Testdatensatz.",
      "Die Ausgabe der Verlustfunktion nach einer Trainingsepoche."
    ],
    "loesung": 1,
    "erklaerung": "Hyperparameter sind die 'Stellschrauben' eines Modells, die nicht durch das Training gelernt, sondern vom Entwickler festgelegt werden. Die Suche nach den optimalen Hyperparametern ist ein wichtiger Teil des ML-Prozesses.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "27. Welcher Befehl wird in einem Dockerfile verwendet, um die notwendigen Python-Pakete zu installieren?",
    "optionen": [
      "INSTALL requirements.txt",
      "RUN pip install -r requirements.txt",
      "EXECUTE pip install -r requirements.txt",
      "ADD requirements.txt"
    ],
    "loesung": 1,
    "erklaerung": "Der `RUN`-Befehl führt Shell-Kommandos innerhalb des Docker-Images aus. `pip install -r requirements.txt` ist der Standardbefehl, um alle in der `requirements.txt`-Datei gelisteten Pakete zu installieren.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "28. Was ist der Zweck der `GlobalAveragePooling2D`-Schicht in einem CNN?",
    "optionen": [
      "Sie vergrößert die Feature Maps.",
      "Sie ersetzt die `Flatten`-Schicht und reduziert die Anzahl der Parameter drastisch, indem sie den Mittelwert jeder Feature Map berechnet.",
      "Sie führt eine Faltungsoperation über das gesamte Bild durch.",
      "Sie normalisiert die Pixelwerte des Eingabebildes."
    ],
    "loesung": 1,
    "erklaerung": "Anstatt die Feature Maps zu 'flatten' (was zu sehr vielen Parametern führt), berechnet Global Average Pooling den Durchschnitt jeder einzelnen Feature Map. Das Ergebnis ist ein Vektor, der direkt an die Dense-Layer weitergegeben werden kann, was das Modell oft robuster gegen Overfitting macht.",
    "gewichtung": 3,
    "thema": "Computer Vision"
  },
  {
    "frage": "29. Welches Problem löst der 'Attention'-Mechanismus in Transformer-Modellen?",
    "optionen": [
      "Das 'Vanishing Gradient'-Problem in tiefen Netzwerken.",
      "Die Schwierigkeit von RNNs/LSTMs, Langzeitabhängigkeiten in langen Sequenzen zu lernen.",
      "Die hohe Anzahl an Parametern in CNNs.",
      "Die Notwendigkeit, Daten vor dem Training zu normalisieren."
    ],
    "loesung": 1,
    "erklaerung": "Der Attention-Mechanismus erlaubt es dem Modell, für jedes Wort in einer Sequenz die Wichtigkeit jedes anderen Wortes zu bewerten. Dadurch kann es direkte Verbindungen zwischen weit entfernten Wörtern herstellen, ein Problem, mit dem rekurrente Architekturen (RNNs) zu kämpfen haben.",
    "gewichtung": 3,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "30. Was ist der Hauptvorteil von `docker-compose` gegenüber einzelnen `docker run`-Befehlen?",
    "optionen": [
      "`docker-compose` ist schneller im Bauen von Images.",
      "`docker-compose` kann mehrere voneinander abhängige Container (Services) mit einer einzigen Konfigurationsdatei und einem einzigen Befehl verwalten und starten.",
      "`docker-compose` benötigt weniger Speicher.",
      "`docker-compose` ist nur für Webserver geeignet."
    ],
    "loesung": 1,
    "erklaerung": "`docker-compose` ist ein Orchestrierungstool. Es ermöglicht die Definition einer Multi-Container-Anwendung (z.B. eine Web-App, eine Datenbank und ein Caching-Service) in einer `docker-compose.yml`-Datei und deren gemeinsame Verwaltung.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "31. Welche Python-Bibliothek wird hauptsächlich für die Erstellung von interaktiven Web-Dashboards im Kurs verwendet?",
    "optionen": [
      "Flask",
      "Django",
      "Streamlit",
      "Plotly"
    ],
    "loesung": 2,
    "erklaerung": "Streamlit ist das zentrale Framework im Kurs, um schnell und einfach interaktive Web-Anwendungen und Dashboards für Data-Science- und ML-Projekte zu erstellen.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "32. Was ist der Zweck der `fit()`-Methode bei einem Scikit-learn Modell?",
    "optionen": [
      "Sie macht Vorhersagen auf neuen Daten.",
      "Sie evaluiert die Genauigkeit des Modells.",
      "Sie trainiert das Modell mit den Trainingsdaten.",
      "Sie speichert das trainierte Modell auf der Festplatte."
    ],
    "loesung": 2,
    "erklaerung": "Die `fit(X_train, y_train)`-Methode ist der zentrale Schritt im Trainingsprozess, bei dem das Modell die Muster und Zusammenhänge aus den Trainingsdaten lernt.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "33. Welcher der 'Big 3' Algorithmen ist ein distanzbasierter Algorithmus?",
    "optionen": [
      "Decision Tree",
      "K-Means Clustering",
      "K-Nearest Neighbors (KNN)",
      "Random Forest"
    ],
    "loesung": 2,
    "erklaerung": "KNN klassifiziert einen neuen Datenpunkt basierend auf der Mehrheitsklasse seiner 'k' nächsten Nachbarn. Die 'Nähe' wird dabei durch ein Distanzmaß (z.B. Euklidischer Abstand) bestimmt.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "34. Was ist eine 'Feature Map' im Kontext von CNNs?",
    "optionen": [
      "Eine Landkarte, die die wichtigsten Features eines Landes zeigt.",
      "Die Ausgabe eines Filters nach der Faltungsoperation, die die Aktivierung eines bestimmten Merkmals an verschiedenen Stellen im Bild anzeigt.",
      "Eine Liste aller Features, die für das Training verwendet werden.",
      "Ein Diagramm, das die Wichtigkeit der verschiedenen Features vergleicht."
    ],
    "loesung": 1,
    "erklaerung": "Jeder Filter in einer Convolutional-Schicht erzeugt eine Feature Map. Diese Karte zeigt, wo im Bild das vom Filter gesuchte Muster (z.B. eine vertikale Kante, ein Auge) gefunden wurde.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "35. Was ist der Zweck der `requirements.cloud.txt` Datei im `07_Deployment_Portfolio` Ordner?",
    "optionen": [
      "Sie enthält spezielle Anforderungen für das Training in der Cloud.",
      "Sie listet alle Python-Pakete auf, die für das Deployment der Streamlit-Apps auf Streamlit Cloud benötigt werden.",
      "Sie ist eine Sicherungskopie der normalen `requirements.txt`.",
      "Sie enthält die Zugangsdaten für die Cloud-Plattform."
    ],
    "loesung": 1,
    "erklaerung": "Deployment-Plattformen wie Streamlit Cloud benötigen eine `requirements.txt`-Datei, um zu wissen, welche Pakete für die Ausführung der App installiert werden müssen. Die `requirements.cloud.txt` ist speziell für diesen Zweck optimiert.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "36. Welcher Datentyp wird in Python verwendet, um eine unveränderliche Liste von Elementen zu speichern?",
    "optionen": [
      "list",
      "dict",
      "set",
      "tuple"
    ],
    "loesung": 3,
    "erklaerung": "Ein Tupel (`tuple`) ist ähnlich wie eine Liste, aber seine Elemente können nach der Erstellung nicht mehr geändert, hinzugefügt oder entfernt werden. Dies macht es nützlich für Daten, die konstant bleiben sollen.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "37. Was ist der Unterschied zwischen `iloc` und `loc` in Pandas?",
    "optionen": [
      "`loc` wird für die Auswahl nach Label (Index-Name, Spalten-Name) verwendet, `iloc` für die Auswahl nach Position (Integer-Index).",
      "`iloc` ist schneller als `loc`.",
      "`loc` kann nur Zeilen auswählen, `iloc` nur Spalten.",
      "Es gibt keinen funktionalen Unterschied."
    ],
    "loesung": 0,
    "erklaerung": "`loc` ist label-basiert, z.B. `df.loc[0, 'Alter']`. `iloc` ist integer-positions-basiert, z.B. `df.iloc[0, 1]`. Die Verwendung des falschen Indexers führt oft zu Fehlern.",
    "gewichtung": 3,
    "thema": "Pandas"
  },
  {
    "frage": "38. Was ist der 'Vanishing Gradient' Problem in tiefen Neuronalen Netzen?",
    "optionen": [
      "Ein Problem, bei dem die Gradienten während der Backpropagation so groß werden, dass das Training instabil wird.",
      "Ein Problem, bei dem die Gradienten während der Backpropagation so klein werden, dass die unteren Schichten des Netzwerks kaum noch lernen.",
      "Ein Problem, bei dem das Netzwerk vergisst, was es in früheren Epochen gelernt hat.",
      "Ein Problem, bei dem die Aktivierungsfunktionen verschwinden."
    ],
    "loesung": 2,
    "erklaerung": "Bei der Backpropagation wird der Fehlergradient durch das Netzwerk zurückpropagiert. Bei tiefen Netzen und bestimmten Aktivierungsfunktionen (wie Sigmoid) kann dieser Gradient exponentiell kleiner werden, was das Update der Gewichte in den vorderen Schichten verhindert oder extrem verlangsamt.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "39. Welche Technik wird verwendet, um das 'Vanishing Gradient'-Problem zu mildern?",
    "optionen": [
      "Verwendung von `Sigmoid`-Aktivierungsfunktionen.",
      "Erhöhung der Batch-Größe.",
      "Verwendung von `ReLU`-Aktivierungsfunktionen oder Residual Connections (ResNets).",
      "Verringerung der Lernrate."
    ],
    "loesung": 2,
    "erklaerung": "Die ReLU-Aktivierungsfunktion hat für positive Eingaben eine konstante Ableitung von 1, was den Gradientenfluss erleichtert. Residual Connections (in ResNets) schaffen 'Kurzschlüsse', die es dem Gradienten ermöglichen, Schichten zu überspringen.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "40. Was ist der Zweck der Datei `.gitignore` in einem Git-Repository?",
    "optionen": [
      "Sie enthält eine Liste von Befehlen, die Git ignorieren soll.",
      "Sie listet Dateien und Verzeichnisse auf, die von der Versionskontrolle ignoriert werden sollen (z.B. Log-Dateien, temporäre Dateien).",
      "Sie ist eine Konfigurationsdatei für GitHub Actions.",
      "Sie enthält eine Liste von Git-Benutzern, die ignoriert werden sollen."
    ],
    "loesung": 1,
    "erklaerung": "Die `.gitignore`-Datei ist entscheidend, um das Repository sauber zu halten, indem man verhindert, dass generierte Dateien, Abhängigkeiten (wie `node_modules`) oder sensible Informationen versehentlich committet werden.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "41. Was ist der Unterschied zwischen einem `Conv2D`-Layer und einem `Dense`-Layer in Keras?",
    "optionen": [
      "Ein `Dense`-Layer ist nur für die Eingabeschicht, ein `Conv2D`-Layer nur für die Ausgabeschicht.",
      "In einem `Dense`-Layer ist jedes Neuron mit jedem Neuron der vorherigen Schicht verbunden, in einem `Conv2D`-Layer nur mit einer lokalen Region (rezeptives Feld).",
      "`Conv2D`-Layer haben immer mehr Parameter als `Dense`-Layer.",
      "`Dense`-Layer werden für Bilder, `Conv2D`-Layer für Text verwendet."
    ],
    "loesung": 1,
    "erklaerung": "Diese unterschiedliche Konnektivität ist der Kernunterschied. `Dense` (oder Fully-Connected) Layer lernen globale Muster, während `Conv2D`-Layer durch ihre lokalen rezeptiven Felder und das Weight Sharing lokale, räumliche Muster lernen.",
    "gewichtung": 2,
    "thema": "Deep Learning"
  },
  {
    "frage": "42. Was ist eine 'Epoche' im Kontext des Trainings von Machine-Learning-Modellen?",
    "optionen": [
      "Die Verarbeitung eines einzelnen Datenpunktes.",
      "Ein kompletter Durchlauf des Algorithmus durch den gesamten Trainingsdatensatz.",
      "Die Zeit, die für das Training eines Modells benötigt wird.",
      "Ein einzelner Schritt der Gewichtsaktualisierung."
    ],
    "loesung": 2,
    "erklaerung": "Eine Epoche ist abgeschlossen, wenn das Modell jeden Datenpunkt des Trainingsdatensatzes einmal gesehen hat. Das Training eines Modells erstreckt sich typischerweise über viele Epochen.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "43. Welches Streamlit-Kommando wird verwendet, um einen Schieberegler für Zahlen zu erstellen?",
    "optionen": [
      "st.number_input()",
      "st.slider()",
      "st.range()",
      "st.numeric_selector()"
    ],
    "loesung": 1,
    "erklaerung": "`st.slider()` ist das spezifische Widget in Streamlit, um einen interaktiven Schieberegler zu erstellen, mit dem Benutzer einen numerischen Wert aus einem definierten Bereich auswählen können.",
    "gewichtung": 1,
    "thema": "Streamlit"
  },
  {
    "frage": "44. Was ist der Zweck der `predict()`-Methode bei einem trainierten Scikit-learn Modell?",
    "optionen": [
      "Sie trainiert das Modell neu mit neuen Daten.",
      "Sie gibt die gelernten Parameter des Modells zurück.",
      "Sie wendet das gelernte Modell auf neue, ungesehene Daten an, um Vorhersagen zu treffen.",
      "Sie berechnet die Genauigkeit des Modells auf den Trainingsdaten."
    ],
    "loesung": 2,
    "erklaerung": "Nachdem ein Modell mit `fit()` trainiert wurde, wird die `predict()`-Methode verwendet, um es auf neue Daten (z.B. das Testset) anzuwenden und die entsprechenden Vorhersagen (Klassen oder Werte) zu generieren.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "45. Was ist der Hauptunterschied zwischen einem `Dockerfile` und einem `docker-compose.yml`?",
    "optionen": [
      "Ein `Dockerfile` baut ein einzelnes Image, während `docker-compose.yml` mehrere Container (Services) definiert und orchestriert.",
      "Ein `Dockerfile` ist für die Entwicklung, `docker-compose.yml` für die Produktion.",
      "Ein `Dockerfile` ist in Python geschrieben, `docker-compose.yml` in YAML.",
      "Es gibt keinen wesentlichen Unterschied."
    ],
    "loesung": 0,
    "erklaerung": "Ein `Dockerfile` ist die Bauanleitung für einen einzelnen Container. `docker-compose` ist ein Werkzeug, um Multi-Container-Anwendungen zu definieren und auszuführen, wobei jeder Container auf seinem eigenen `Dockerfile` basieren kann.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "46. Welcher der folgenden Algorithmen ist ein Ensemble-Modell?",
    "optionen": [
      "K-Nearest Neighbors (KNN)",
      "Decision Tree",
      "Random Forest",
      "Linear Regression"
    ],
    "loesung": 2,
    "erklaerung": "Ein Random Forest ist ein Ensemble-Modell, das aus vielen einzelnen Decision Trees besteht. Er trifft Vorhersagen, indem er die Vorhersagen der einzelnen Bäume aggregiert (z.B. durch Mehrheitsentscheid), was oft zu robusteren und genaueren Ergebnissen führt.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "47. Was ist der Zweck der `Flatten`-Schicht in einem CNN?",
    "optionen": [
      "Sie glättet das Eingabebild.",
      "Sie wandelt die mehrdimensionalen Feature Maps am Ende der Convolutional-Blöcke in einen eindimensionalen Vektor um.",
      "Sie reduziert die Anzahl der Farben im Bild.",
      "Sie führt eine Faltungsoperation durch."
    ],
    "loesung": 1,
    "erklaerung": "Nach den Convolutional- und Pooling-Layern liegen die Daten als mehrdimensionale Tensoren (Feature Maps) vor. Um sie an die nachfolgenden `Dense`-Layer (die einen Vektor als Input erwarten) übergeben zu können, muss dieser Tensor zu einem eindimensionalen Vektor 'geglättet' oder 'plattgedrückt' werden.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "48. Was ist ein 'REST API'?",
    "optionen": [
      "Eine spezielle Art von Machine-Learning-Modell.",
      "Eine standardisierte Schnittstelle, die es verschiedenen Softwaresystemen ermöglicht, über das HTTP-Protokoll miteinander zu kommunizieren.",
      "Ein Tool zur Versionskontrolle von Code.",
      "Eine Datenbank für große Datenmengen."
    ],
    "loesung": 2,
    "erklaerung": "REST (Representational State Transfer) ist ein Architekturstil für verteilte Systeme. Eine REST API ermöglicht es einem Client (z.B. eine Web-App), Daten von einem Server (z.B. einem ML-Modell-Server) über Standard-HTTP-Methoden (GET, POST, etc.) anzufordern.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "49. Welches Python-Keyword wird verwendet, um eine Funktion zu definieren?",
    "optionen": [
      "function",
      "def",
      "fun",
      "define"
    ],
    "loesung": 2,
    "erklaerung": "In Python wird das Keyword `def` verwendet, um eine neue Funktion zu deklarieren, gefolgt vom Funktionsnamen, den Parametern in Klammern und einem Doppelpunkt.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "50. Was ist der Zweck der `BatchNormalization`-Schicht in einem Neuronalen Netz?",
    "optionen": [
      "Sie erhöht die Anzahl der lernbaren Parameter.",
      "Sie normalisiert die Aktivierungen zwischen den Schichten, um das Training zu stabilisieren und zu beschleunigen.",
      "Sie ersetzt die Notwendigkeit von Aktivierungsfunktionen.",
      "Sie funktioniert nur in der ersten Schicht eines Netzwerks."
    ],
    "loesung": 1,
    "erklaerung": "Batch Normalization normalisiert die Ausgaben einer Schicht, bevor sie an die nächste weitergegeben werden. Dies wirkt dem Problem des 'Internal Covariate Shift' entgegen, erlaubt höhere Lernraten und macht das Training insgesamt stabiler und schneller.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "51. Welcher Befehl wird verwendet, um alle laufenden Docker-Container anzuzeigen?",
    "optionen": [
      "docker show all",
      "docker list",
      "docker ps",
      "docker containers"
    ],
    "loesung": 2,
    "erklaerung": "`docker ps` listet alle aktuell laufenden Container auf. Um auch gestoppte Container anzuzeigen, verwendet man `docker ps -a`.",
    "gewichtung": 1,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "52. Wie kann man in Streamlit eine Datei-Upload-Funktion erstellen?",
    "optionen": [
      "st.upload_file()",
      "st.file_uploader()",
      "st.input(type='file')",
      "st.load_file()"
    ],
    "loesung": 1,
    "erklaerung": "Das Widget `st.file_uploader()` erstellt eine Schaltfläche, mit der Benutzer Dateien von ihrem lokalen System in die Streamlit-App hochladen können, die dann z.B. mit Pandas verarbeitet werden können.",
    "gewichtung": 2,
    "thema": "Streamlit"
  },
  {
    "frage": "53. Was ist der Unterschied zwischen `pd.read_csv()` und `pd.read_excel()` in Pandas?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "`read_csv()` liest kommagetrennte Dateien, `read_excel()` liest Excel-Dateien (.xls, .xlsx).",
      "`read_excel()` ist schneller als `read_csv()`.",
      "`read_csv()` kann nur Textdateien lesen."
    ],
    "loesung": 1,
    "erklaerung": "Pandas bietet spezifische Funktionen für verschiedene Dateiformate. `pd.read_csv()` ist für CSV-Dateien optimiert, während `pd.read_excel()` die komplexere Struktur von Excel-Arbeitsmappen (inkl. verschiedener Blätter) handhaben kann.",
    "gewichtung": 1,
    "thema": "Pandas"
  },
  {
    "frage": "54. Was ist eine 'Confusion Matrix'?",
    "optionen": [
      "Eine Matrix, die die Korrelation zwischen verschiedenen Features zeigt.",
      "Eine Tabelle, die die Leistung eines Klassifikationsmodells visualisiert, indem sie die Anzahlen von True Positives, True Negatives, False Positives und False Negatives darstellt.",
      "Eine Methode zur Visualisierung von hochdimensionalen Daten.",
      "Eine Technik zur Hyperparameter-Optimierung."
    ],
    "loesung": 1,
    "erklaerung": "Die Confusion Matrix ist ein wichtiges Werkzeug zur Evaluation von Klassifikationsmodellen. Sie zeigt detailliert, welche Klassen das Modell gut unterscheidet und wo es zu Verwechslungen kommt.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "55. Welcher der 'Big 3' Algorithmen ist am besten für die Interpretation und Erklärung von Entscheidungen geeignet?",
    "optionen": [
      "K-Means Clustering",
      "K-Nearest Neighbors (KNN)",
      "Decision Tree",
      "Alle sind gleich gut interpretierbar."
    ],
    "loesung": 2,
    "erklaerung": "Decision Trees (Entscheidungsbäume) sind von Natur aus sehr gut interpretierbar, da ihre Struktur einer Reihe von verständlichen Ja/Nein-Fragen entspricht. Man kann den Entscheidungspfad für jede Vorhersage nachvollziehen.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "56. Was ist der Zweck der `Dropout`-Schicht in einem Neuronalen Netz?",
    "optionen": [
      "Sie beschleunigt das Training, indem sie zufällig Datenpunkte auslässt.",
      "Sie ist eine Regularisierungstechnik, die Overfitting verhindert, indem sie während des Trainings zufällig einen Teil der Neuronen 'ausschaltet'.",
      "Sie fügt dem Netzwerk zusätzliche Neuronen hinzu.",
      "Sie dient als Aktivierungsfunktion."
    ],
    "loesung": 1,
    "erklaerung": "Indem in jedem Trainingsschritt zufällig Neuronen deaktiviert werden, zwingt Dropout das Netzwerk, robustere und weniger voneinander abhängige Features zu lernen. Dies wirkt Overfitting entgegen und verbessert die Generalisierungsfähigkeit.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "57. Was ist der Unterschied zwischen 'semantischer Segmentierung' und 'Instanzensegmentierung' in der Computer Vision?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "Semantische Segmentierung klassifiziert jedes Pixel im Bild, während Instanzensegmentierung zusätzlich zwischen verschiedenen Instanzen derselben Klasse unterscheidet.",
      "Instanzensegmentierung ist einfacher als semantische Segmentierung.",
      "Semantische Segmentierung verwendet CNNs, Instanzensegmentierung nicht."
    ],
    "loesung": 1,
    "erklaerung": "Beispiel: Bei einem Bild mit zwei Katzen würde die semantische Segmentierung alle Katzenpixel als 'Katze' markieren. Die Instanzensegmentierung würde sie als 'Katze 1' und 'Katze 2' unterscheiden.",
    "gewichtung": 3,
    "thema": "Computer Vision"
  },
  {
    "frage": "58. Was ist der Zweck der `fine-tuning`-Phase beim Transfer Learning?",
    "optionen": [
      "Den vortrainierten Teil des Modells komplett neu zu trainieren.",
      "Nur den neu hinzugefügten Klassifikator zu trainieren.",
      "Die Gewichte der oberen Schichten des vortrainierten Modells mit einer sehr kleinen Lernrate leicht anzupassen, um sie besser auf die neue Aufgabe zu spezialisieren.",
      "Die Anzahl der Layer im Modell zu reduzieren."
    ],
    "loesung": 2,
    "erklaerung": "Nachdem der neue Klassifikator trainiert wurde (Feature Extraction), werden einige der oberen Schichten des Basis-Modells 'aufgetaut'. Mit einer sehr kleinen Lernrate werden diese Gewichte dann vorsichtig an die Nuancen des neuen Datensatzes angepasst, ohne das wertvolle vortrainierte Wissen zu zerstören.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "59. Welches Hugging Face Modell wird im Kurs als Beispiel für Textgenerierung verwendet?",
    "optionen": [
      "BERT",
      "T5",
      "distilgpt2",
      "RoBERTa"
    ],
    "loesung": 2,
    "erklaerung": "Im Notebook `02_NLP_und_Text_Generation.ipynb` wird `distilgpt2`, eine kleinere und schnellere Version von GPT-2, als Beispiel für eine Textgenerierungs-Pipeline mit der Hugging Face `transformers`-Bibliothek verwendet.",
    "gewichtung": 2,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "60. Was bedeutet der Begriff 'CI/CD' im Kontext von MLOps?",
    "optionen": [
      "'Continuous Integration / Continuous Deployment': Ein Satz von Praktiken zur Automatisierung des Build-, Test- und Deployment-Prozesses.",
      "'Complex Intelligence / Complex Deployment': Eine Methode für sehr komplexe Modelle.",
      "'Code Inspection / Code Delivery': Ein Werkzeug zur Code-Analyse.",
      "'Cloud Infrastructure / Cloud Database': Bezieht sich auf die verwendete Cloud-Infrastruktur."
    ],
    "loesung": 0,
    "erklaerung": "CI/CD ist ein Kernprinzip von DevOps und MLOps. Continuous Integration automatisiert das Testen bei jeder Code-Änderung, während Continuous Deployment den Prozess automatisiert, neue Versionen in die Produktion zu bringen.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "61. Welcher Datentyp in Python wird verwendet, um Schlüssel-Wert-Paare zu speichern?",
    "optionen": [
      "list",
      "tuple",
      "set",
      "dict"
    ],
    "loesung": 3,
    "erklaerung": "Ein Dictionary (`dict`) ist eine ungeordnete Sammlung von Daten in einem Schlüssel-Wert-Format. Es ist optimiert für das schnelle Nachschlagen von Werten anhand ihrer Schlüssel.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "62. Wie kann man in Pandas alle Zeilen eines DataFrames `df` anzeigen, in denen der Wert der Spalte 'Alter' größer als 30 ist?",
    "optionen": [
      "df.filter('Alter' > 30)",
      "df[df['Alter'] > 30]",
      "df.select('Alter' > 30)",
      "df.where('Alter' > 30)"
    ],
    "loesung": 1,
    "erklaerung": "Dies wird als 'boolean indexing' oder 'boolean masking' bezeichnet. `df['Alter'] > 30` erzeugt eine Serie von `True`/`False`-Werten, die dann verwendet wird, um die entsprechenden Zeilen aus dem DataFrame zu filtern.",
    "gewichtung": 2,
    "thema": "Pandas"
  },
  {
    "frage": "63. Was ist der Zweck von `st.cache_data` in Streamlit?",
    "optionen": [
      "Es speichert die gesamte App im Browser-Cache.",
      "Es ist ein Decorator, der das Ergebnis einer Funktion zwischenspeichert. Wenn die Funktion mit denselben Argumenten erneut aufgerufen wird, wird das Ergebnis aus dem Cache geholt, anstatt die Funktion erneut auszuführen.",
      "Es komprimiert die Daten, die in der App angezeigt werden.",
      "Es löscht den Cache der App."
    ],
    "loesung": 1,
    "erklaerung": "Caching ist entscheidend für die Performance von Streamlit-Apps. Langsame Operationen wie das Laden großer Datensätze oder das Trainieren von Modellen sollten mit `@st.cache_data` oder `@st.cache_resource` versehen werden, um unnötige Neuberechnungen bei jedem App-Rerun zu vermeiden.",
    "gewichtung": 3,
    "thema": "Streamlit"
  },
  {
    "frage": "64. Was ist der Unterschied zwischen Regression und Klassifikation?",
    "optionen": [
      "Regression wird für Bilder verwendet, Klassifikation für Text.",
      "Regression sagt kontinuierliche Werte voraus (z.B. Preise), Klassifikation sagt diskrete Kategorien voraus (z.B. Spam/Nicht-Spam).",
      "Regression ist immer ein Unsupervised-Learning-Problem.",
      "Klassifikation benötigt mehr Daten als Regression."
    ],
    "loesung": 1,
    "erklaerung": "Dies ist die grundlegendste Unterscheidung bei Supervised-Learning-Problemen. Die Wahl des Modells, der Verlustfunktion und der Evaluationsmetriken hängt direkt davon ab, ob man einen numerischen Wert oder eine Kategorie vorhersagen möchte.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "65. Warum ist die Skalierung von Features (z.B. mit `StandardScaler`) für den KNN-Algorithmus wichtig?",
    "optionen": [
      "Sie ist nicht wichtig für KNN.",
      "Sie wandelt alle Features in Ganzzahlen um.",
      "Da KNN auf Distanzmessungen basiert, würden Features mit großen Wertebereichen (z.B. Gehalt) die Distanzberechnung dominieren und Features mit kleinen Wertebereichen (z.B. Alter) irrelevant machen.",
      "Sie reduziert die Anzahl der Features."
    ],
    "loesung": 2,
    "erklaerung": "KNN ist ein distanzbasierter Algorithmus. Wenn die Features unterschiedliche Skalen haben, werden die Distanzen von den Features mit den größten Wertebereichen dominiert. Die Skalierung (z.B. auf einen Mittelwert von 0 und eine Standardabweichung von 1) stellt sicher, dass alle Features gleichberechtigt zur Distanzberechnung beitragen.",
    "gewichtung": 3,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "66. Was ist ein 'Autoencoder'?",
    "optionen": [
      "Ein Supervised-Learning-Modell zur Klassifikation von Bildern.",
      "Ein Neuronales Netz, das lernt, seine eigene Eingabe zu rekonstruieren, oft über eine komprimierte Repräsentation (Bottleneck).",
      "Ein Algorithmus zur automatischen Generierung von Python-Code.",
      "Ein spezieller Typ eines Reinforcement-Learning-Agenten."
    ],
    "loesung": 1,
    "erklaerung": "Ein Autoencoder besteht aus einem Encoder, der die Eingabe in einen niedrigdimensionalen Code komprimiert, und einem Decoder, der versucht, aus diesem Code die ursprüngliche Eingabe zu rekonstruieren. Er wird für Dimensionsreduktion, Feature Learning und Anomalieerkennung verwendet.",
    "gewichtung": 3,
    "thema": "Neuronale Netze"
  },
  {
    "frage": "67. Was ist der Zweck der `padding='same'`-Einstellung in einem `Conv2D`-Layer?",
    "optionen": [
      "Sie fügt dem Bild einen zufälligen Rand hinzu.",
      "Sie stellt sicher, dass die räumliche Dimension der Ausgabe (Höhe und Breite) die gleiche ist wie die der Eingabe.",
      "Sie entfernt den Rand des Bildes.",
      "Sie verdoppelt die Größe des Bildes."
    ],
    "loesung": 1,
    "erklaerung": "Ohne Padding würde die Größe der Feature Map bei jeder Faltung kleiner werden. `padding='same'` fügt dem Rand der Eingabe implizit Nullen hinzu (Zero-Padding), sodass die Ausgabe die gleiche Höhe und Breite wie die Eingabe hat. Dies ist nützlich, um sehr tiefe Netzwerke zu bauen.",
    "gewichtung": 2,
    "thema": "Computer Vision"
  },
  {
    "frage": "68. Was ist ein 'Token' im Kontext von Natural Language Processing (NLP)?",
    "optionen": [
      "Ein spezielles Zeichen, das das Ende eines Satzes markiert.",
      "Ein einzelnes Wort, ein Teil eines Wortes (Subword) oder ein Satzzeichen, in das ein Text aufgeteilt wird.",
      "Ein Synonym für ein Wort.",
      "Ein Maß für die Komplexität eines Textes."
    ],
    "loesung": 1,
    "erklaerung": "Tokenisierung ist der erste Schritt in den meisten NLP-Pipelines. Dabei wird ein Rohtext in eine Liste von Tokens zerlegt, die dann in numerische Vektoren (Embeddings) umgewandelt werden können, die das Modell verarbeiten kann.",
    "gewichtung": 2,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "69. Was ist der Zweck des `EXPOSE`-Befehls in einem Dockerfile?",
    "optionen": [
      "Er öffnet einen Port auf dem Host-System.",
      "Er teilt Docker mit, dass der Container an einem bestimmten Netzwerkport lauscht. Er veröffentlicht den Port aber nicht tatsächlich.",
      "Er installiert einen Webserver im Container.",
      "Er macht den Container im Netzwerk sichtbar."
    ],
    "loesung": 1,
    "erklaerung": "`EXPOSE` ist eine Form der Dokumentation zwischen dem Ersteller des Images und der Person, die den Container ausführt. Um den Port tatsächlich zu veröffentlichen und vom Host aus zugänglich zu machen, muss man die Option `-p` oder `-P` beim `docker run`-Befehl verwenden.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "70. Was ist der Unterschied zwischen `pip` und `conda`?",
    "optionen": [
      "`pip` ist für Python 2, `conda` für Python 3.",
      "`pip` installiert Python-Pakete in jeder Umgebung, während `conda` ein plattformübergreifender Paket- und Umgebungsmanager ist, der auch Nicht-Python-Pakete und ganze Umgebungen verwalten kann.",
      "`conda` ist schneller als `pip`.",
      "Es gibt keinen Unterschied."
    ],
    "loesung": 1,
    "erklaerung": "`pip` ist der Standard-Paketmanager für Python. `conda` ist Teil der Anaconda-Distribution und kann nicht nur Python-Pakete, sondern auch komplexe Abhängigkeiten (wie C-Bibliotheken) und isolierte Umgebungen verwalten, was es in der Data Science sehr beliebt macht.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "71. Was ist der Zweck der `groupby()`-Funktion in Pandas?",
    "optionen": [
      "Sie sortiert den DataFrame nach einer bestimmten Spalte.",
      "Sie gruppiert den DataFrame anhand einer oder mehrerer Spalten, um Aggregationsfunktionen (wie `sum()`, `mean()`) auf jede Gruppe anzuwenden.",
      "Sie wählt eine Gruppe von Zeilen aus.",
      "Sie benennt die Spalten des DataFrames um."
    ],
    "loesung": 1,
    "erklaerung": "Die `groupby()`-Operation ist ein extrem mächtiges Werkzeug für die Datenanalyse. Sie folgt dem 'Split-Apply-Combine'-Muster: Daten aufteilen, eine Funktion anwenden und die Ergebnisse wieder zusammenführen.",
    "gewichtung": 2,
    "thema": "Pandas"
  },
  {
    "frage": "72. Wie kann man in Streamlit den Inhalt auf mehrere Spalten aufteilen?",
    "optionen": [
      "Durch die Verwendung von HTML-Tabellen.",
      "Durch die Verwendung von `st.columns()`.",
      "Durch die Verwendung von `st.split()`.",
      "Das ist in Streamlit nicht möglich."
    ],
    "loesung": 1,
    "erklaerung": "Der Befehl `col1, col2 = st.columns(2)` erstellt zwei Spalten. Anschließend kann man mit `with col1:` und `with col2:` Inhalte in die jeweilige Spalte platzieren, um komplexere Layouts zu erstellen.",
    "gewichtung": 2,
    "thema": "Streamlit"
  },
  {
    "frage": "73. Was ist der Unterschied zwischen `EarlyStopping` und `ModelCheckpoint` Callbacks in Keras?",
    "optionen": [
      "Beide machen das Gleiche.",
      "`EarlyStopping` beendet das Training, wenn sich eine Metrik nicht mehr verbessert, während `ModelCheckpoint` das beste Modell während des Trainings speichert.",
      "`ModelCheckpoint` beendet das Training, `EarlyStopping` speichert das Modell.",
      "`EarlyStopping` wird für Regression verwendet, `ModelCheckpoint` für Klassifikation."
    ],
    "loesung": 1,
    "erklaerung": "Beide sind nützliche Callbacks. `EarlyStopping` verhindert Overfitting, indem es das Training abbricht, wenn z.B. der Validierungsfehler nicht mehr sinkt. `ModelCheckpoint` stellt sicher, dass man am Ende nicht ein schlechteres Modell hat, nur weil das Training zu lange lief, indem es die Version mit der besten Leistung auf dem Validierungsset speichert.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "74. Was ist der Zweck der `random_state`-Parameters in vielen Scikit-learn Funktionen?",
    "optionen": [
      "Er steuert die Zufälligkeit des Algorithmus, um die Ergebnisse reproduzierbar zu machen.",
      "Er setzt den Zustand des Modells auf einen zufälligen Wert.",
      "Er wählt zufällige Features für das Training aus.",
      "Er hat keine Funktion und wird ignoriert."
    ],
    "loesung": 0,
    "erklaerung": "Viele Algorithmen haben eine stochastische (zufällige) Komponente (z.B. die Initialisierung der Gewichte). Durch das Setzen von `random_state` auf einen festen Integer-Wert wird sichergestellt, dass der Zufallszahlengenerator immer im gleichen Zustand startet, was zu identischen Ergebnissen bei wiederholten Durchläufen führt.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "75. Welcher der folgenden ist KEIN Hyperparameter eines Decision Tree?",
    "optionen": [
      "max_depth",
      "min_samples_split",
      "feature_importance",
      "criterion (gini/entropy)"
    ],
    "loesung": 2,
    "erklaerung": "`max_depth`, `min_samples_split` und `criterion` sind alles Hyperparameter, die vor dem Training festgelegt werden, um die Struktur und das Verhalten des Baumes zu steuern. `feature_importance` ist ein Attribut des trainierten Modells, das nach dem Training berechnet wird.",
    "gewichtung": 2,
    "thema": "Machine Learning Algorithmen"
  },
  {
    "frage": "76. Was ist der Unterschied zwischen einem 'Dense' Layer und einem 'Embedding' Layer in Keras?",
    "optionen": [
      "Ein `Dense`-Layer ist für die Eingabe, ein `Embedding`-Layer für die Ausgabe.",
      "Ein `Dense`-Layer führt eine Matrix-Vektor-Multiplikation durch, während ein `Embedding`-Layer eine Nachschlagetabelle für kategoriale Eingaben (wie Wörter) ist.",
      "Ein `Embedding`-Layer hat immer mehr Parameter als ein `Dense`-Layer.",
      "Es gibt keinen funktionalen Unterschied."
    ],
    "loesung": 1,
    "erklaerung": "Ein `Embedding`-Layer ist eine effiziente Methode, um hochdimensionale, dünn besetzte kategoriale Daten (wie Wörter in einem Vokabular, die als Integer repräsentiert werden) in dichte, niedrigdimensionale Vektoren umzuwandeln. Es ist im Wesentlichen eine lernbare Nachschlagetabelle, während ein `Dense`-Layer eine vollständige lineare Transformation durchführt.",
    "gewichtung": 3,
    "thema": "Natural Language Processing"
  },
  {
    "frage": "77. Was ist ein 'Volume' in Docker?",
    "optionen": [
      "Die Größe des Docker-Images.",
      "Ein Mechanismus, um Daten persistent außerhalb des Container-Dateisystems zu speichern, sodass sie auch nach dem Löschen des Containers erhalten bleiben.",
      "Ein Netzwerk-Interface für den Container.",
      "Ein Maß für die Rechenleistung, die ein Container verbraucht."
    ],
    "loesung": 1,
    "erklaerung": "Container sind standardmäßig zustandslos ('stateless'). Wenn ein Container entfernt wird, gehen alle darin geschriebenen Daten verloren. Volumes ermöglichen es, Daten (z.B. Datenbankdateien, Logs, hochgeladene Dateien) persistent auf dem Host-System zu speichern.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "78. Welches Diagramm eignet sich am besten, um die Beziehung zwischen zwei kontinuierlichen Variablen zu visualisieren?",
    "optionen": [
      "Balkendiagramm (Bar Chart)",
      "Kreisdiagramm (Pie Chart)",
      "Histogramm",
      "Streudiagramm (Scatter Plot)"
    ],
    "loesung": 3,
    "erklaerung": "Ein Streudiagramm plottet jeden Datenpunkt als Punkt in einem 2D-Koordinatensystem, wobei die x- und y-Positionen den Werten der beiden Variablen entsprechen. Dies macht es ideal, um Korrelationen, Cluster und Ausreißer visuell zu erkennen.",
    "gewichtung": 1,
    "thema": "Datenvisualisierung"
  },
  {
    "frage": "79. Was ist der Zweck der `predict_proba()`-Methode bei vielen Scikit-learn Klassifikationsmodellen?",
    "optionen": [
      "Sie macht die gleiche Vorhersage wie `predict()`.",
      "Sie gibt die Wahrscheinlichkeit für jede Klasse zurück, anstatt nur die wahrscheinlichste Klasse.",
      "Sie berechnet die Wahrscheinlichkeit, dass das Modell korrekt ist.",
      "Sie ist nur für Regressionsmodelle verfügbar."
    ],
    "loesung": 1,
    "erklaerung": "Während `predict()` die 'harte' Klassenzuweisung (z.B. 0 oder 1) zurückgibt, gibt `predict_proba()` die 'weiche' Zuweisung in Form von Wahrscheinlichkeiten für jede Klasse zurück. Dies ist nützlich, um die Konfidenz des Modells zu bewerten oder eigene Entscheidungsschwellen zu definieren.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "80. Was ist der Hauptzweck der Phase 'K' (Knowledge Transfer) im QUA³CK-Modell?",
    "optionen": [
      "Das Sammeln von neuem Wissen über das Problem.",
      "Das Trainieren des Modells mit mehr Wissen.",
      "Die Überführung der Ergebnisse und des Modells in eine nutzbare Anwendung (z.B. eine Streamlit-App) und die Dokumentation des Projekts.",
      "Das Testen des Wissens der Entwickler."
    ],
    "loesung": 2,
    "erklaerung": "Die K-Phase schließt den Kreis, indem sie sicherstellt, dass die gewonnenen Erkenntnisse und das entwickelte Modell nicht nur in einem Notebook bleiben, sondern in eine Form gebracht werden, die für Endbenutzer oder andere Systeme von Nutzen ist und das Wissen für die Zukunft bewahrt (z.B. durch eine App oder ein Portfolio).",
    "gewichtung": 2,
    "thema": "MLOps & Prozesse"
  },
  {
    "frage": "81. Was ist der Unterschied zwischen einem Python `list` und einem `set`?",
    "optionen": [
      "Listen sind geordnet und können Duplikate enthalten, Sets sind ungeordnet und enthalten nur eindeutige Elemente.",
      "Listen können nur Zahlen enthalten, Sets nur Strings.",
      "Sets sind veränderbar, Listen nicht.",
      "Es gibt keinen Unterschied."
    ],
    "loesung": 0,
    "erklaerung": "Sets sind nützlich, wenn man schnell prüfen will, ob ein Element vorhanden ist, oder wenn man Duplikate aus einer Liste entfernen möchte. Listen behalten die Reihenfolge der Elemente bei und erlauben Duplikate.",
    "gewichtung": 1,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "82. Welcher Pandas-Befehl wird verwendet, um fehlende Werte (NaN) in einem DataFrame `df` mit dem Wert 0 zu füllen?",
    "optionen": [
      "df.replace(NaN, 0)",
      "df.remove_nan(0)",
      "df.fillna(0)",
      "df.set_nan(0)"
    ],
    "loesung": 2,
    "erklaerung": "Die `fillna()`-Methode ist das Standardwerkzeug in Pandas, um fehlende Werte zu behandeln. Man kann sie mit einem konstanten Wert, dem Mittelwert, dem Median oder anderen Strategien verwenden.",
    "gewichtung": 2,
    "thema": "Pandas"
  },
  {
    "frage": "83. Was ist der Zweck von `st.session_state` in Streamlit?",
    "optionen": [
      "Es speichert den Zustand der aktuellen Browser-Sitzung.",
      "Es ist eine Möglichkeit, Variablen über mehrere Reruns einer App hinweg zu speichern und beizubehalten.",
      "Es speichert die Konfiguration der Streamlit-App.",
      "Es ist eine veraltete Funktion."
    ],
    "loesung": 1,
    "erklaerung": "Streamlit führt das Skript bei jeder Interaktion neu aus. Um Informationen (wie Zähler, Benutzereingaben, Chat-Verläufe) zwischen diesen Reruns zu speichern, wird das `st.session_state`-Objekt verwendet, das wie ein Dictionary funktioniert.",
    "gewichtung": 3,
    "thema": "Streamlit"
  },
  {
    "frage": "84. Was ist der 'Curse of Dimensionality' (Fluch der Dimensionalität)?",
    "optionen": [
      "Das Phänomen, dass die Leistung von ML-Modellen mit zunehmender Anzahl von Features abnimmt.",
      "Die Tatsache, dass Daten in hochdimensionalen Räumen sehr spärlich werden und Distanzmaße ihre Aussagekraft verlieren.",
      "Die Notwendigkeit, bei hochdimensionalen Daten immer Deep Learning zu verwenden.",
      "Ein Fehler, der auftritt, wenn ein Datensatz mehr Spalten als Zeilen hat."
    ],
    "loesung": 1,
    "erklaerung": "In hochdimensionalen Räumen liegen die Datenpunkte tendenziell weit voneinander entfernt ('sparse'). Dies macht Algorithmen, die auf Distanzmessungen basieren (wie KNN), weniger effektiv und erfordert exponentiell mehr Daten, um den Raum abzudecken.",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "85. Was ist der Unterschied zwischen einem 'Validation Set' und einem 'Test Set'?",
    "optionen": [
      "Es gibt keinen Unterschied, die Begriffe sind austauschbar.",
      "Das Validation Set wird zum Trainieren, das Test Set zum Validieren verwendet.",
      "Das Validation Set wird zur Hyperparameter-Optimierung während der Entwicklung verwendet, das Test Set zur finalen, einmaligen Leistungsbewertung des fertigen Modells.",
      "Das Test Set ist immer größer als das Validation Set."
    ],
    "loesung": 2,
    "erklaerung": "Das Validation Set wird wiederholt während der Entwicklung verwendet, um das Modell zu justieren (z.B. für Hyperparameter-Tuning, Early Stopping). Das Test Set wird idealerweise nur ein einziges Mal am Ende verwendet, um eine unverfälschte Schätzung der Leistung des finalen Modells auf völlig neuen Daten zu erhalten.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "86. Was ist ein 'Residual Connection' (oder Skip Connection), wie sie in ResNets verwendet wird?",
    "optionen": [
      "Eine Verbindung, die die Ausgabeschicht direkt mit der Eingabeschicht verbindet.",
      "Eine Verbindung, die die Eingabe eines Blocks zur Ausgabe dieses Blocks addiert und so dem Gradienten einen 'Kurzschluss' ermöglicht.",
      "Eine Methode, um die Anzahl der Neuronen in einem Layer zu reduzieren.",
      "Eine spezielle Art von Dropout."
    ],
    "loesung": 1,
    "erklaerung": "Residual Connections ermöglichen es dem Gradienten, beim Backpropagation direkt durch einige Schichten 'hindurchzufließen'. Dies erleichtert das Training von sehr tiefen Netzwerken (z.B. mit 152 Schichten), indem es dem Vanishing-Gradient-Problem entgegenwirkt.",
    "gewichtung": 3,
    "thema": "Deep Learning"
  },
  {
    "frage": "87. Was ist der Zweck eines 'API-Keys'?",
    "optionen": [
      "Er verschlüsselt die Daten, die über die API gesendet werden.",
      "Er dient zur Authentifizierung und Autorisierung von Anfragen an eine API, um die Nutzung zu kontrollieren und zu verfolgen.",
      "Er ist der Name des Haupt-Endpoints einer API.",
      "Er beschleunigt die API-Anfragen."
    ],
    "loesung": 1,
    "erklaerung": "Viele APIs erfordern einen API-Key, um sicherzustellen, dass nur autorisierte Benutzer oder Anwendungen darauf zugreifen können. Er wird oft verwendet, um Nutzungsquoten (Rate Limiting) durchzusetzen und die Nutzung für Abrechnungszwecke zu verfolgen.",
    "gewichtung": 2,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "88. Welches Dateiformat wird oft für die Speicherung von großen, strukturierten Datensätzen empfohlen, da es spaltenorientiert und komprimiert ist?",
    "optionen": [
      "CSV",
      "JSON",
      "Parquet",
      "TXT"
    ],
    "loesung": 2,
    "erklaerung": "Parquet ist ein spaltenorientiertes Speicherformat, das für Big-Data-Workflows optimiert ist. Es ermöglicht eine sehr effiziente Kompression und Abfrage-Performance, da nur die benötigten Spalten gelesen werden müssen, was es CSV oft überlegen macht.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "89. Was ist der Hauptzweck von Reinforcement Learning (RL)?",
    "optionen": [
      "Das Finden von Mustern in ungelabelten Daten.",
      "Die Klassifikation von Daten in vordefinierte Kategorien.",
      "Das Trainieren eines Agenten, eine Sequenz von Aktionen in einer Umgebung auszuführen, um eine kumulative Belohnung zu maximieren.",
      "Die Generierung neuer, realistischer Daten."
    ],
    "loesung": 2,
    "erklaerung": "Beim RL lernt ein Agent durch Versuch und Irrtum (Trial and Error). Er interagiert mit einer Umgebung und erhält Belohnungen oder Bestrafungen für seine Aktionen, mit dem Ziel, eine Strategie (Policy) zu lernen, die die langfristige Belohnung maximiert.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "90. Was ist der 'Exploration-Exploitation Trade-off' im Reinforcement Learning?",
    "optionen": [
      "Der Kompromiss zwischen der Verwendung von viel oder wenig Speicher.",
      "Der Kompromiss zwischen dem Ausprobieren neuer, unbekannter Aktionen (Exploration) und dem Nutzen bekannter, guter Aktionen (Exploitation).",
      "Der Kompromiss zwischen einem einfachen und einem komplexen Modell.",
      "Der Kompromiss zwischen Trainingszeit und Modellgenauigkeit."
    ],
    "loesung": 1,
    "erklaerung": "Ein RL-Agent muss entscheiden, ob er eine Aktion wählt, von der er bereits weiß, dass sie gut ist (Exploitation), oder ob er eine neue, unbekannte Aktion ausprobiert, die potenziell noch besser sein könnte (Exploration). Dies ist eine zentrale Herausforderung im RL.",
    "gewichtung": 3,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "91. Was ist der Unterschied zwischen einem `list` und einem `numpy.array`?",
    "optionen": [
      "Es gibt keinen Unterschied.",
      "Ein `numpy.array` ist für homogene, numerische Daten optimiert und ermöglicht schnelle, vektorisierte mathematische Operationen. Eine Python-`list` ist flexibler, aber langsamer.",
      "Listen können nur Strings enthalten.",
      "Numpy-Arrays sind Teil der Python-Standardbibliothek."
    ],
    "loesung": 1,
    "erklaerung": "NumPy ist die Grundlage für wissenschaftliches Rechnen in Python. Seine Array-Struktur ist in C implementiert, was Operationen auf großen Datenmengen um Größenordnungen schneller macht als mit reinen Python-Listen.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "92. Welcher Plotly Express Befehl wird verwendet, um ein interaktives Streudiagramm zu erstellen?",
    "optionen": [
      "px.bar()",
      "px.line()",
      "px.scatter()",
      "px.histogram()"
    ],
    "loesung": 2,
    "erklaerung": "`plotly.express.scatter` (üblicherweise als `px.scatter` importiert) ist die High-Level-Funktion zur Erstellung von interaktiven Streudiagrammen, die Zoom, Pan und Hover-Informationen unterstützen.",
    "gewichtung": 1,
    "thema": "Datenvisualisierung"
  },
  {
    "frage": "93. Was ist der Zweck der `__init__`-Methode in einer Python-Klasse?",
    "optionen": [
      "Sie initialisiert die Klasse selbst.",
      "Sie ist der Konstruktor der Klasse und wird aufgerufen, um ein neues Objekt (eine Instanz) zu erstellen und dessen Anfangszustand zu initialisieren.",
      "Sie zerstört das Objekt, wenn es nicht mehr benötigt wird.",
      "Sie ist eine normale Methode wie jede andere auch."
    ],
    "loesung": 1,
    "erklaerung": "Die `__init__`-Methode wird automatisch aufgerufen, wenn eine neue Instanz einer Klasse erzeugt wird. Sie wird verwendet, um die Attribute des Objekts mit den übergebenen Werten zu initialisieren.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "94. Was ist ein 'Webhook' im Kontext von CI/CD und MLOps?",
    "optionen": [
      "Ein spezieller Haken, um einen Server im Rack zu befestigen.",
      "Ein Mechanismus, der es einem System ermöglicht, ein anderes System in Echtzeit über ein Ereignis zu benachrichtigen, indem es eine HTTP-Anfrage an eine vordefinierte URL sendet.",
      "Ein Sicherheitsprotokoll für APIs.",
      "Ein Werkzeug zur Code-Formatierung."
    ],
    "loesung": 1,
    "erklaerung": "Webhooks sind der 'Klebstoff' für Automatisierung. Zum Beispiel kann GitHub einen Webhook an einen CI/CD-Server senden, wenn neuer Code gepusht wird, was dann automatisch einen neuen Build und ein neues Training auslöst.",
    "gewichtung": 3,
    "thema": "MLOps & Deployment"
  },
  {
    "frage": "95. Was ist der Unterschied zwischen einem 'Dense' und einem 'Sparse' Vektor?",
    "optionen": [
      "Dense Vektoren enthalten nur Nullen, Sparse Vektoren nur Einsen.",
      "Ein Dense Vektor speichert explizit jeden Wert, während ein Sparse Vektor nur die Nicht-Null-Werte und ihre Positionen speichert.",
      "Dense Vektoren sind immer kürzer als Sparse Vektoren.",
      "Sparse Vektoren können nicht für Machine Learning verwendet werden."
    ],
    "loesung": 1,
    "erklaerung": "Sparse Vektoren sind sehr effizient für Daten mit vielen Nullen, wie z.B. bei der One-Hot-Kodierung von großen Vokabularen im NLP. Anstatt eines riesigen Vektors mit meist Nullen speichert man nur die Positionen der Einsen.",
    "gewichtung": 2,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "96. Welches der folgenden ist ein Beispiel für eine Metrik zur Evaluation von Regressionsmodellen?",
    "optionen": [
      "Accuracy",
      "F1-Score",
      "Root Mean Squared Error (RMSE)",
      "AUC-ROC"
    ],
    "loesung": 2,
    "erklaerung": "RMSE misst die durchschnittliche quadratische Abweichung zwischen den vorhergesagten und den tatsächlichen Werten. Es ist eine der gebräuchlichsten Metriken für Regressionsprobleme. Accuracy, F1-Score und AUC-ROC sind Klassifikationsmetriken.",
    "gewichtung": 1,
    "thema": "Machine Learning Grundlagen"
  },
  {
    "frage": "97. Was ist der Zweck der `self`-Variable in Python-Klassenmethoden?",
    "optionen": [
      "Sie ist eine globale Variable.",
      "Sie repräsentiert die Klasse selbst, nicht die Instanz.",
      "Sie ist eine Referenz auf die aktuelle Instanz der Klasse und ermöglicht den Zugriff auf deren Attribute und Methoden.",
      "Sie ist optional und kann weggelassen werden."
    ],
    "loesung": 2,
    "erklaerung": "`self` ist das erste Argument jeder Instanzmethode und wird von Python automatisch übergeben. Es ermöglicht der Methode, auf die Daten (Attribute) und anderen Methoden zuzugreifen, die zu diesem spezifischen Objekt gehören.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "98. Was ist der Hauptvorteil der Verwendung von `plotly.express` gegenüber `plotly.graph_objects`?",
    "optionen": [
      "`plotly.express` bietet mehr Anpassungsmöglichkeiten.",
      "`plotly.express` ist eine High-Level-Schnittstelle, die es ermöglicht, komplexe, interaktive Diagramme mit sehr wenig Code zu erstellen.",
      "`plotly.graph_objects` ist veraltet.",
      "`plotly.express` kann nur statische Bilder erzeugen."
    ],
    "loesung": 1,
    "erklaerung": "`plotly.express` (px) ist eine Wrapper-Bibliothek um `plotly.graph_objects`. Sie vereinfacht die Erstellung von gängigen Diagrammtypen erheblich. Für sehr komplexe oder benutzerdefinierte Visualisierungen kann man immer noch auf die detailliertere `graph_objects`-Syntax zurückgreifen.",
    "gewichtung": 2,
    "thema": "Datenvisualisierung"
  },
  {
    "frage": "99. Was ist ein 'Container Registry' wie Docker Hub oder GitHub Container Registry?",
    "optionen": [
      "Ein Ort, an dem man Docker-Container ausführt.",
      "Ein zentrales Repository zum Speichern, Verwalten und Verteilen von Docker-Images.",
      "Ein Werkzeug zur Überwachung von laufenden Containern.",
      "Eine Datenbank für Container-Metadaten."
    ],
    "loesung": 1,
    "erklaerung": "Eine Container Registry ist wie ein 'App Store' für Docker-Images. Man kann seine eigenen Images dorthin 'pushen' (hochladen) und Images von anderen 'pullen' (herunterladen), was die Zusammenarbeit und das Deployment vereinfacht.",
    "gewichtung": 2,
    "thema": "Grundlagen & Tools"
  },
  {
    "frage": "100. Was ist der Zweck der `main`-Block-Konstruktion `if __name__ == '__main__':` in einem Python-Skript?",
    "optionen": [
      "Sie definiert die Hauptfunktion des Skripts.",
      "Sie stellt sicher, dass der Code innerhalb des Blocks nur ausgeführt wird, wenn das Skript direkt gestartet wird, und nicht, wenn es als Modul in ein anderes Skript importiert wird.",
      "Sie ist notwendig, um globale Variablen zu deklarieren.",
      "Sie markiert den Anfang des Python-Codes."
    ],
    "loesung": 1,
    "erklaerung": "Diese Konstruktion ist eine Best Practice in Python. Sie ermöglicht es, ein Skript sowohl als eigenständiges Programm als auch als wiederverwendbares Modul zu schreiben, ohne dass beim Import sofort Code ausgeführt wird.",
    "gewichtung": 2,
    "thema": "Python Grundlagen"
  },
  {
    "frage": "101. Was ist ein grundlegendes Merkmal eines neuronalen Netzes?",
    "optionen": [
      "Es besteht aus Schichten von Neuronen, die durch gewichtete Verbindungen miteinander verknüpft sind.",
      "Es verwendet einen einzelnen Entscheidungsbaum, um Vorhersagen zu treffen.",
      "Es benötigt grundsätzlich keine Trainingsdaten, um zu funktionieren.",
      "Es kann ausschließlich lineare Regressionen durchführen."
    ],
    "loesung": 0,
    "erklaerung": "Neuronale Netze sind von der Struktur des Gehirns inspiriert und bestehen aus miteinander verbundenen Knoten (Neuronen), die in Schichten angeordnet sind. Die Stärke der Verbindungen (Gewichte) wird im Training gelernt.",
    "gewichtung": 1,
    "thema": "Grundlagen"
  },
  {
    "frage": "102. Was ist ein wesentlicher Vorteil der `ReLU`-Aktivierungsfunktion gegenüber `Sigmoid`?",
    "optionen": [
      "`ReLU` leidet weniger unter dem 'Vanishing Gradient'-Problem.",
      "`ReLU` ist über den gesamten Definitionsbereich stetig differenzierbar.",
      "`ReLU` eignet sich besser für die Ausgabeschicht bei binärer Klassifikation.",
      "`ReLU` ist rechenintensiver, aber genauer."
    ],
    "loesung": 0,
    "erklaerung": "Die Ableitung der `Sigmoid`-Funktion ist in vielen Bereichen nahe null, was bei tiefen Netzen zum 'Verschwinden' der Gradienten führen kann. `ReLU` hat für positive Eingaben eine konstante Ableitung von 1, was den Gradientenfluss erleichtert.",
    "gewichtung": 2,
    "thema": "Aktivierungsfunktionen"
  },
  {
    "frage": "103. Was beschreibt das Backpropagation-Verfahren?",
    "optionen": [
      "Die effiziente Berechnung der Gradienten des Fehlers bezüglich der Gewichte.",
      "Die zufällige Initialisierung der Gewichte vor dem ersten Trainingsschritt.",
      "Die Auswahl der optimalen Anzahl von Neuronen für ein Hidden Layer.",
      "Die schichtweise Vorwärtsausbreitung der Eingabedaten durch das Netz."
    ],
    "loesung": 0,
    "erklaerung": "`Backpropagation` ist der Algorithmus, mit dem die Gewichte eines neuronalen Netzes trainiert werden. Er propagiert den Fehler von der Ausgabeschicht rückwärts durch das Netz, um die Gradienten für die Gewichtsaktualisierung zu berechnen.",
    "gewichtung": 2,
    "thema": "Training & Optimierung"
  },
  {
    "frage": "104. Welchen Zweck erfüllt eine `Loss Function` (Verlustfunktion)?",
    "optionen": [
      "Sie quantifiziert den Fehler zwischen der Modellvorhersage und dem wahren Zielwert.",
      "Sie berechnet die optimale Anzahl der Neuronen für die gegebene Aufgabe.",
      "Sie legt die Lernrate für den Optimierungsalgorithmus fest.",
      "Sie bestimmt die maximale Anzahl der Trainingsepochen."
    ],
    "loesung": 0,
    "erklaerung": "Die Verlustfunktion ist das Signal, das der Optimierungsalgorithmus (z.B. SGD) zu minimieren versucht. Ein kleinerer Verlustwert bedeutet eine bessere Anpassung des Modells an die Trainingsdaten.",
    "gewichtung": 1,
    "thema": "Grundlagen"
  },
  {
    "frage": "105. Was ist ein Vorteil von `Stochastic Gradient Descent (SGD)`?",
    "optionen": [
      "Es ist speichereffizient und ermöglicht das Training mit sehr großen Datensätzen.",
      "Es konvergiert garantiert immer zum globalen Minimum der Verlustfunktion.",
      "Es benötigt keine manuelle Einstellung der Lernrate.",
      "Es führt im Vergleich zu anderen Methoden zu einer schnelleren Konvergenz."
    ],
    "loesung": 0,
    "erklaerung": "Da `SGD` die Gewichte nach jedem einzelnen Datenpunkt (oder einem kleinen Batch) aktualisiert, muss nicht der gesamte Datensatz im Speicher gehalten werden. Die 'rauschhaften' Updates können auch helfen, lokalen Minima zu entkommen.",
    "gewichtung": 2,
    "thema": "Training & Optimierung"
  },
  {
    "frage": "106. Welche Funktion hat ein `Hidden Layer` in einem neuronalen Netz?",
    "optionen": [
      "Es lernt hierarchische und zunehmend komplexe Merkmale aus den Eingabedaten.",
      "Es dient ausschließlich dazu, die finale Vorhersage des Netzes auszugeben.",
      "Es initialisiert die Gewichte für die Eingabeschicht.",
      "Es normalisiert die Ausgabewerte auf einen Bereich zwischen 0 und 1."
    ],
    "loesung": 0,
    "erklaerung": "Versteckte Schichten (Hidden Layers) sind die Kernkomponenten, in denen das Netzwerk lernt, aus den Rohdaten der vorherigen Schicht abstraktere und nützlichere Repräsentationen zu extrahieren.",
    "gewichtung": 1,
    "thema": "Grundlagen"
  },
  {
    "frage": "107. Was ist ein Vorteil des `Adam`-Optimierers gegenüber einfachem `SGD`?",
    "optionen": [
      "Er passt die Lernrate für jeden Parameter individuell und adaptiv an.",
      "Er benötigt keine `Backpropagation` zur Berechnung der Gradienten.",
      "Er ist speziell für sehr kleine Netzwerke mit wenigen Parametern optimiert.",
      "Er verwendet keine Gradienten, sondern einen genetischen Algorithmus."
    ],
    "loesung": 0,
    "erklaerung": "`Adam` (Adaptive Moment Estimation) kombiniert die Ideen von Momentum und RMSprop. Er pflegt eine adaptive Lernrate für jedes Gewicht, was oft zu einer schnelleren und stabileren Konvergenz führt als Standard-SGD.",
    "gewichtung": 2,
    "thema": "Training & Optimierung"
  },
  {
    "frage": "108. Warum wird die Technik des `Early Stopping` beim Training eingesetzt?",
    "optionen": [
      "Um Overfitting zu vermeiden, indem das Training beendet wird, wenn sich der Validierungsfehler nicht mehr verbessert.",
      "Um die anfängliche Lernrate dynamisch während der ersten Epochen zu erhöhen.",
      "Um die Gewichte des Netzwerks auf einen bekannten, guten Zustand zurückzusetzen.",
      "Um das Training zu stoppen, sobald eine Genauigkeit von 100% auf den Trainingsdaten erreicht ist."
    ],
    "loesung": 0,
    "erklaerung": "`Early Stopping` ist eine Form der Regularisierung, bei der die Leistung des Modells auf einem separaten Validierungsdatensatz überwacht wird. Das Training wird abgebrochen, sobald diese Leistung stagniert oder schlechter wird, um Overfitting zu verhindern.",
    "gewichtung": 2,
    "thema": "Training & Optimierung"
  },
  {
    "frage": "109. Was ist ein potenzieller Nachteil einer zu großen Lernrate?",
    "optionen": [
      "Das Training kann instabil werden, da das Optimum 'übersprungen' wird.",
      "Das Training konvergiert extrem langsam gegen ein lokales Minimum.",
      "Die Gewichte des Netzwerks werden während des Trainings nicht aktualisiert.",
      "Die Aktivierungsfunktionen in den Hidden Layers werden deaktiviert."
    ],
    "loesung": 0,
    "erklaerung": "Eine zu große Lernrate kann dazu führen, dass die Gewichtsaktualisierungen so groß sind, dass der Optimierungsprozess über das Minimum der Verlustfunktion hinwegschießt und der Fehler wieder ansteigt (Divergenz).",
    "gewichtung": 1,
    "thema": "Training & Optimierung"
  },
  {
    "frage": "110. Warum ist eine gute Gewichtsinitialisierung ('Weight Initialization') wichtig?",
    "optionen": [
      "Sie hilft, Probleme wie 'Vanishing/Exploding Gradients' zu vermeiden und beschleunigt die Konvergenz.",
      "Sie bestimmt die endgültige Anzahl der Hidden Layers im Netzwerk.",
      "Sie ersetzt die Notwendigkeit einer nichtlinearen Aktivierungsfunktion.",
      "Sie verhindert die Verwendung von Regularisierungstechniken wie `Dropout`."
    ],
    "loesung": 0,
    "erklaerung": "Eine schlechte Initialisierung (z.B. alle Gewichte auf null) kann den Lernprozess verhindern. Techniken wie Xavier/Glorot-Initialisierung sorgen für eine gute Varianz der Aktivierungen und einen stabilen Gradientenfluss zu Beginn des Trainings.",
    "gewichtung": 3,
    "thema": "Grundlagen"
  },
  {
    "frage": "111. Für welche Art von Daten sind `Recurrent Neural Networks (RNNs)` besonders geeignet?",
    "optionen": [
      "Für Sequenzdaten, bei denen die Reihenfolge der Elemente von Bedeutung ist (z.B. Text, Zeitreihen).",
      "Für gitterartige Daten ohne zeitliche Komponente wie statische Bilder.",
      "Für tabellarische Daten mit unabhängigen Zeilen wie in einer CSV-Datei.",
      "Für das Finden von Clustern in ungelabelten Datensätzen."
    ],
    "loesung": 0,
    "erklaerung": "`RNNs` besitzen interne Schleifen, die es ihnen ermöglichen, einen 'Gedächtnis'-Zustand zu pflegen. Dies macht sie ideal für Aufgaben, bei denen der Kontext aus vorherigen Schritten in einer Sequenz wichtig ist.",
    "gewichtung": 1,
    "thema": "Architekturen (RNN)"
  },
  {
    "frage": "112. Was ist ein entscheidender Vorteil von Deep Learning gegenüber klassischen ML-Algorithmen?",
    "optionen": [
      "Die Fähigkeit zum automatischen 'Feature Learning' direkt aus Rohdaten.",
      "Die Garantie, dass kein Overfitting auf den Trainingsdaten stattfindet.",
      "Die hohe Interpretierbarkeit der gelernten Modelle ('White-Box').",
      "Der geringere Bedarf an Trainingsdaten für komplexe Aufgaben."
    ],
    "loesung": 0,
    "erklaerung": "Während bei klassischen ML-Ansätzen oft aufwendiges, manuelles Feature Engineering nötig ist, können tiefe neuronale Netze eine Hierarchie von Merkmalen direkt aus den Rohdaten (z.B. Pixeln eines Bildes) lernen.",
    "gewichtung": 2,
    "thema": "Grundlagen"
  },
  {
    "frage": "113. Welche Eigenschaft von CNNs ermöglicht die Erkennung von Objekten unabhängig von ihrer Position im Bild?",
    "optionen": [
      "`Dropout`",
      "`Translation Invariance`",
      "`Dense Layer`",
      "`Batch Normalization`"
    ],
    "loesung": 1,
    "erklaerung": "Durch die Anwendung desselben Filters (Gewichtsteilung) über das gesamte Bild und die anschließende Abstraktion durch Pooling-Layer lernt ein CNN, ein Merkmal (z.B. ein Auge) zu erkennen, egal ob es links oben oder rechts unten im Bild erscheint.",
    "gewichtung": 3,
    "thema": "Architekturen (CNN)"
  },
  {
    "frage": "114. Was ist ein `Filter` (oder Kernel) in einem Convolutional Layer?",
    "optionen": [
      "Eine Methode zur Umwandlung eines Farbbildes in ein Graustufenbild.",
      "Eine kleine Matrix von Gewichten, die über das Eingabebild gefaltet wird, um Merkmale zu extrahieren.",
      "Ein Algorithmus zur Kompression der Bilddaten vor der Verarbeitung.",
      "Ein Verfahren zur künstlichen Vergrößerung des Trainingsdatensatzes (Data Augmentation)."
    ],
    "loesung": 1,
    "erklaerung": "Ein Filter ist der zentrale Baustein eines Convolutional Layers. Er fungiert als Merkmalsdetektor (z.B. für Kanten, Ecken, Texturen), dessen Gewichte während des Trainings gelernt werden.",
    "gewichtung": 1,
    "thema": "Architekturen (CNN)"
  },
  {
    "frage": "115. Was unterscheidet die Filter in CNNs von klassischen Bildverarbeitungsfiltern wie dem Sobel-Filter?",
    "optionen": [
      "Klassische Filter sind fest definiert, während die Filter in CNNs während des Trainings gelernt werden.",
      "CNN-Filter sind immer signifikant größer als klassische Filter, um globale Merkmale zu erfassen.",
      "Klassische Filter können keine Kanten oder Texturen im Bild erkennen.",
      "CNN-Filter benötigen keine nichtlineare Aktivierungsfunktion nach der Anwendung."
    ],
    "loesung": 0,
    "erklaerung": "Der entscheidende Unterschied ist, dass die Werte der Filtermatrizen in einem CNN nicht von einem Menschen entworfen, sondern durch `Backpropagation` gelernt werden. Das Netzwerk findet so selbst die optimalen Filter für die gegebene Aufgabe.",
    "gewichtung": 2,
    "thema": "Architekturen (CNN)"
  },
  {
    "frage": "116. Aus welchen zwei Hauptkomponenten besteht ein Generative Adversarial Network (GAN)?",
    "optionen": [
      "Einem Encoder und einem Decoder.",
      "Einem Generator und einem Diskriminator.",
      "Einem Convolutional Layer und einem Pooling Layer.",
      "Einem Agenten und einer Umgebung."
    ],
    "loesung": 1,
    "erklaerung": "Ein GAN besteht aus zwei neuronalen Netzen, die gegeneinander antreten: Der Generator versucht, realistische Daten zu erzeugen, während der Diskriminator versucht, echte von gefälschten Daten zu unterscheiden.",
    "gewichtung": 2,
    "thema": "Architekturen (GAN)"
  },
  {
    "frage": "117. Was ist das Ziel des Generators in einem GAN?",
    "optionen": [
      "Die Trainingsdaten möglichst exakt zu kopieren.",
      "Den Diskriminator zu täuschen, indem er Daten erzeugt, die von echten Daten nicht zu unterscheiden sind.",
      "Die Wahrscheinlichkeit zu berechnen, dass eine Eingabe echt ist.",
      "Die Dimension der Eingabedaten zu reduzieren."
    ],
    "loesung": 1,
    "erklaerung": "Das Ziel des Generators ist es, aus zufälligem Rauschen Daten zu synthetisieren, die so realistisch sind, dass der Diskriminator sie als echt klassifiziert. Er lernt dabei die zugrundeliegende Verteilung der Trainingsdaten.",
    "gewichtung": 2,
    "thema": "Architekturen (GAN)"
  },
  {
    "frage": "118. Was ist das Hauptproblem beim Training von RNNs mit langen Sequenzen?",
    "optionen": [
      "Overfitting",
      "Das Vanishing- oder Exploding-Gradient-Problem.",
      "Hoher Speicherverbrauch.",
      "Langsames Training."
    ],
    "loesung": 1,
    "erklaerung": "Bei langen Sequenzen muss der Gradient über viele Zeitschritte zurückpropagiert werden. Dabei kann er exponentiell klein (vanishing) oder groß (exploding) werden, was das Lernen von Langzeitabhängigkeiten verhindert.",
    "gewichtung": 2,
    "thema": "Architekturen (RNN)"
  },
  {
    "frage": "119. Wie lösen LSTMs das Vanishing-Gradient-Problem?",
    "optionen": [
      "Durch die Verwendung einer linearen Aktivierungsfunktion.",
      "Durch den Einsatz von 'Gates' (Input, Forget, Output), die den Informationsfluss steuern.",
      "Indem sie die Sequenzlänge auf ein Maximum von 10 Schritten begrenzen.",
      "Durch die Anwendung von Batch Normalization in jedem Zeitschritt."
    ],
    "loesung": 1,
    "erklaerung": "LSTMs besitzen einen 'Zellzustand' und spezielle 'Gates', die lernen, welche Informationen sie speichern, vergessen oder ausgeben sollen. Dies ermöglicht einen ungehinderten Gradientenfluss über lange Zeiträume.",
    "gewichtung": 3,
    "thema": "Architekturen (RNN)"
  },
  {
    "frage": "120. Was ist der Kern des Attention-Mechanismus, wie er in Transformern verwendet wird?",
    "optionen": [
      "Er fokussiert sich nur auf das letzte Wort in einem Satz.",
      "Er berechnet für jedes Wort eine gewichtete Summe aller anderen Wörter im Satz.",
      "Er verwendet einen festen Kontextvektor für den gesamten Satz.",
      "Er ersetzt alle Wörter durch ihre häufigsten Synonyme."
    ],
    "loesung": 1,
    "erklaerung": "Der Self-Attention-Mechanismus erlaubt es dem Modell, die Wichtigkeit jedes anderen Wortes in der Eingabesequenz für die Repräsentation eines bestimmten Wortes zu bewerten. Dies ermöglicht die Modellierung komplexer Abhängigkeiten unabhängig von der Distanz.",
    "gewichtung": 3,
    "thema": "Architekturen (Transformer)"
  },
  {
    "frage": "121. Was ist ein wesentlicher Vorteil von Transformern gegenüber RNNs?",
    "optionen": [
      "Sie sind einfacher zu implementieren und haben weniger Hyperparameter.",
      "Sie können aufgrund des fehlenden rekurrenten Charakters stark parallelisiert werden.",
      "Sie benötigen signifikant weniger Trainingsdaten.",
      "Sie sind von Natur aus immun gegen Overfitting."
    ],
    "loesung": 1,
    "erklaerung": "Da RNNs Sequenzen Schritt für Schritt verarbeiten müssen, ist ihre Parallelisierung schwierig. Transformer verarbeiten alle Elemente der Sequenz gleichzeitig, was das Training auf moderner Hardware (GPUs/TPUs) erheblich beschleunigt.",
    "gewichtung": 3,
    "thema": "Architekturen (Transformer)"
  },
  {
    "frage": "122. Was ist der Zweck eines Validierungsdatensatzes (Validation Set)?",
    "optionen": [
      "Er wird verwendet, um die finalen Gewichte des Modells zu trainieren.",
      "Er dient zur Abstimmung der Hyperparameter und zur Überwachung von Overfitting während des Trainings.",
      "Er wird nur einmal ganz am Ende verwendet, um die finale, unverfälschte Leistung des Modells zu bewerten.",
      "Er ist eine exakte Kopie des Trainingsdatensatzes zur Überprüfung der Konsistenz."
    ],
    "loesung": 1,
    "erklaerung": "Der Validierungsdatensatz wird während des Trainings verwendet, um die Leistung des Modells auf ungesehenen Daten zu schätzen. Dies hilft bei der Hyperparameter-Optimierung (z.B. welche Lernrate?) und beim Early Stopping.",
    "gewichtung": 2,
    "thema": "Training & Optimierung"
  },
  {
    "frage": "123. Was ist der Unterschied zwischen 'Padding' und 'Stride' in einem CNN?",
    "optionen": [
      "Padding fügt Nullen am Rand des Bildes hinzu, Stride bestimmt die Schrittweite des Filters.",
      "Padding bestimmt die Schrittweite, Stride fügt Nullen hinzu.",
      "Beide Begriffe beschreiben die Größe des Filters.",
      "Padding wird vor, Stride nach der Faltungsoperation angewendet."
    ],
    "loesung": 0,
    "erklaerung": "Padding wird verwendet, um die räumliche Größe der Ausgabe zu steuern (z.B. 'same' padding, um die Größe zu erhalten). Stride (Schrittweite) gibt an, um wie viele Pixel der Filter bei jeder Bewegung verschoben wird.",
    "gewichtung": 2,
    "thema": "Architekturen (CNN)"
  },
  {
    "frage": "124. Was ist die 'Cross-Entropy Loss'?",
    "optionen": [
      "Eine Verlustfunktion, die typischerweise für Regressionsprobleme verwendet wird.",
      "Eine Verlustfunktion, die für Klassifikationsprobleme verwendet wird und den Unterschied zwischen zwei Wahrscheinlichkeitsverteilungen misst.",
      "Eine Metrik zur Messung der Ähnlichkeit zwischen zwei Bildern.",
      "Ein Regularisierungsterm, der zur Vermeidung von Overfitting dient."
    ],
    "loesung": 1,
    "erklaerung": "Die Kreuzentropie ist die Standard-Verlustfunktion für Klassifikationsaufgaben. Sie misst, wie gut die vom Modell vorhergesagte Wahrscheinlichkeitsverteilung (nach Softmax) mit der wahren Verteilung (One-Hot-Encoding) übereinstimmt.",
    "gewichtung": 2,
    "thema": "Grundlagen"
  },
  {
    "frage": "125. Was ist ein 'One-Hot-Encoding'?",
    "optionen": [
      "Eine Methode zur Normalisierung von numerischen Daten.",
      "Eine Technik zur Darstellung von kategorialen Variablen als binärer Vektor.",
      "Ein Algorithmus zur Kompression von Bilddaten.",
      "Eine spezielle Art der Gewichtsinitialisierung."
    ],
    "loesung": 1,
    "erklaerung": "Beim One-Hot-Encoding wird eine kategoriale Variable mit N Kategorien in einen Vektor der Länge N umgewandelt, der an der Stelle der jeweiligen Kategorie eine 1 und an allen anderen Stellen Nullen enthält. Dies ist die Standarddarstellung für Zielvariablen in der Klassifikation.",
    "gewichtung": 1,
    "thema": "Grundlagen"
  },
  {
    "frage": "126. Was ist der Hauptzweck eines 'Embeddings' im NLP-Kontext?",
    "optionen": [
      "Die Darstellung von Wörtern oder Sätzen als dichte, niedrigdimensionale Vektoren.",
      "Die Zählung der Häufigkeit jedes Wortes in einem Text.",
      "Die Korrektur von Rechtschreibfehlern in einem Text.",
      "Die Übersetzung eines Textes in eine andere Sprache."
    ],
    "loesung": 0,
    "erklaerung": "Word Embeddings (wie Word2Vec oder GloVe) lernen, Wörter in einem Vektorraum so darzustellen, dass Wörter mit ähnlicher Bedeutung nahe beieinander liegen. Diese dichten Vektoren sind eine weitaus reichhaltigere Repräsentation als z.B. One-Hot-Encoding.",
    "gewichtung": 2,
    "thema": "Anwendungen (NLP)"
  },
  {
    "frage": "127. Was ist ein 'Gradient' in Bezug auf eine Verlustfunktion?",
    "optionen": [
      "Der maximale Wert, den die Verlustfunktion annehmen kann.",
      "Ein Vektor, der in die Richtung des steilsten Anstiegs der Verlustfunktion zeigt.",
      "Ein Hyperparameter, der die Komplexität des Modells steuert.",
      "Die Anzahl der Trainingsbeispiele in einem Batch."
    ],
    "loesung": 1,
    "erklaerung": "Der Gradient ist die Verallgemeinerung der Ableitung für mehrdimensionale Funktionen. Beim Gradientenabstieg (Gradient Descent) bewegt man sich in die entgegengesetzte Richtung des Gradienten, um das Minimum der Verlustfunktion zu finden.",
    "gewichtung": 2,
    "thema": "Grundlagen"
  },
  {
    "frage": "128. Was ist der Hauptvorteil von Docker im Kontext von Data Science?",
    "optionen": [
      "Eine schnellere Datenverarbeitung durch optimierte Container.",
      "Die Erstellung reproduzierbarer und isolierter Projektumgebungen.",
      "Eine automatische Bereinigung von inkonsistenten Datensätzen.",
      "Die direkte GPU-Nutzung ohne spezielle Treiberkonfiguration."
    ],
    "loesung": 1,
    "erklaerung": "Docker kapselt Anwendungen und ihre Abhängigkeiten in Container. Dies garantiert, dass alle Teammitglieder mit einer identischen, reproduzierbaren Umgebung arbeiten, was Fehler durch unterschiedliche Systemkonfigurationen vermeidet.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "129. Welcher Befehl wandelt eine Zelle in einem Jupyter Notebook in eine Code-Zelle um?",
    "optionen": [
      "Die Taste `M` im Command Mode",
      "Die Taste `Y` im Command Mode",
      "Die Tastenkombination `Shift+Enter`",
      "Die Taste `A` im Command Mode"
    ],
    "loesung": 1,
    "erklaerung": "Im Command Mode (erreichbar durch Drücken von `Esc`) wandelt die Taste `Y` eine Zelle in eine ausführbare Code-Zelle um. `M` wandelt sie in eine Markdown-Zelle um.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "130. Was ist der fundamentale Unterschied zwischen einem Docker-Image und einem Docker-Container?",
    "optionen": [
      "Ein Image ist eine laufende Instanz, während ein Container eine schreibgeschützte Vorlage ist.",
      "Ein Container ist eine laufende, beschreibbare Instanz, die aus einem schreibgeschützten Image erstellt wird.",
      "Es gibt keinen fundamentalen Unterschied; die Begriffe sind austauschbar.",
      "Ein Image enthält nur den Anwendungscode, ein Container enthält zusätzlich die Daten."
    ],
    "loesung": 1,
    "erklaerung": "Ein Image ist eine unveränderliche Vorlage (Blueprint), die alles Nötige für eine Anwendung enthält. Ein Container ist eine aktive, laufende Instanz dieses Images.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "131. Was ist der primäre Zweck einer `docker-compose.yml`-Datei?",
    "optionen": [
      "Die Verwaltung von Python-Paketabhängigkeiten ähnlich einer `requirements.txt`.",
      "Die Definition und Orchestrierung einer Multi-Container-Anwendung.",
      "Die Konfiguration der Docker-Engine auf dem Host-System.",
      "Die automatische Formatierung von Code innerhalb eines Containers."
    ],
    "loesung": 1,
    "erklaerung": "`Docker Compose` ist ein Werkzeug zur Definition und Ausführung von Anwendungen, die aus mehreren Containern bestehen. Die `docker-compose.yml` beschreibt die Services, Netzwerke und Volumes.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "132. Was ist das Kernziel der Q-Phase im QUA³CK-Modell?",
    "optionen": [
      "Die Bereinigung und Vorverarbeitung der Rohdaten.",
      "Die präzise Formulierung der geschäftlichen Fragestellung und der Projektziele.",
      "Die Auswahl und das Training des finalen Machine-Learning-Algorithmus.",
      "Die Visualisierung und Präsentation der finalen Ergebnisse."
    ],
    "loesung": 1,
    "erklaerung": "Die Q-Phase (Question) legt das Fundament des Projekts. Hier werden die genaue Fragestellung, die Ziele und die Erfolgskriterien in Absprache mit den Stakeholdern definiert.",
    "gewichtung": 2,
    "thema": "QUA³CK & MLOps"
  },
  {
    "frage": "133. Welcher Fehler tritt typischerweise auf, wenn man in `pandas` auf eine nicht existierende Spalte zugreift?",
    "optionen": [
      "Ein `KeyError`",
      "Ein `SyntaxError`",
      "Ein `ValueError`",
      "Ein `ImportError`"
    ],
    "loesung": 0,
    "erklaerung": "Ein `KeyError` wird ausgelöst, wenn versucht wird, auf einen Spalten- oder Zeilen-Index zuzugreifen, der im DataFrame nicht existiert. Dies geschieht oft durch Tippfehler im Spaltennamen.",
    "gewichtung": 2,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "134. Was ist ein zentraler Vorteil von Jupyter Notebooks für die explorative Datenanalyse?",
    "optionen": [
      "Sie erzwingen eine strikt lineare Ausführung des gesamten Codes.",
      "Sie ermöglichen die interaktive Ausführung von Code in Zellen, kombiniert mit Text und Visualisierungen.",
      "Sie sind ausschließlich für die Programmiersprache R optimiert.",
      "Sie laufen nativ als hochperformante Desktop-Anwendungen."
    ],
    "loesung": 1,
    "erklaerung": "Jupyter Notebooks sind ideal für die explorative Analyse, da sie es erlauben, Code in kleinen, isolierten Blöcken auszuführen, die Ergebnisse sofort zu inspizieren und den Prozess mit Markdown zu dokumentieren.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "135. Was ist der primäre Anwendungsfall für Streamlit im Data-Science-Kontext?",
    "optionen": [
      "Das Training von neuronalen Netzen direkt im Browser.",
      "Die Erstellung interaktiver Web-Anwendungen zur Visualisierung von Analysen und Modellen.",
      "Die Verwaltung von Python-Umgebungen ähnlich wie `conda`.",
      "Die direkte Ausführung von SQL-Abfragen auf Big-Data-Clustern."
    ],
    "loesung": 1,
    "erklaerung": "`Streamlit` ist ein Framework, das es ermöglicht, aus Datenanalyse-Skripten mit wenigen Zeilen Python-Code interaktive und ansprechende Web-Anwendungen zu erstellen.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "136. Was unterscheidet eine Python-Liste fundamental von einem Dictionary?",
    "optionen": [
      "Listen speichern Schlüssel-Wert-Paare, Dictionaries nur geordnete Werte.",
      "Listen sind geordnete Sammlungen mit numerischem Index, Dictionaries speichern ungeordnete Schlüssel-Wert-Paare.",
      "Listen können nur Elemente des gleichen Datentyps enthalten, Dictionaries beliebige.",
      "Dictionaries sind in ihrer Größe beschränkt, während Listen dynamisch wachsen können."
    ],
    "loesung": 1,
    "erklaerung": "Eine Liste ist eine geordnete Sequenz, auf die über einen Integer-Index zugegriffen wird. Ein Dictionary ist eine ungeordnete Sammlung von Paaren aus einem eindeutigen Schlüssel und einem Wert.",
    "gewichtung": 1,
    "thema": "Pandas & Python Basics"
  },
  {
    "frage": "137. Welcher Fehler tritt auf, wenn man versucht, ein nicht installiertes Python-Modul zu importieren?",
    "optionen": [
      "`ModuleNotFoundError`",
      "`ValueError`",
      "`KeyError`",
      "`TypeError`"
    ],
    "loesung": 0,
    "erklaerung": "Ein `ModuleNotFoundError` (in älteren Python-Versionen `ImportError`) wird ausgelöst, wenn der Python-Interpreter ein importiertes Modul nicht in den konfigurierten Pfaden finden kann, meist weil es nicht installiert ist.",
    "gewichtung": 1,
    "thema": "Pandas & Python Basics"
  },
  {
    "frage": "138. Was ist der Unterschied zwischen den Docker-Befehlen `ps` und `images`?",
    "optionen": [
      "`docker ps` zeigt alle laufenden Container an, während `docker images` alle lokal verfügbaren Images auflistet.",
      "`docker ps` listet alle Images auf, während `docker images` alle gestoppten Container anzeigt.",
      "`docker images` startet einen Container, während `docker ps` dessen Status prüft.",
      "Beide Befehle zeigen die gleiche Liste aller laufenden und gestoppten Container an."
    ],
    "loesung": 0,
    "erklaerung": "Mit `docker ps` (process status) inspiziert man die laufenden Container. Mit `docker images` verwaltet man die lokal heruntergeladenen Image-Vorlagen.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "139. Wofür wird das `st.sidebar`-Objekt in Streamlit primär verwendet?",
    "optionen": [
      "Um kritische Fehlermeldungen und Warnungen anzuzeigen.",
      "Um Steuerelemente und Navigationsoptionen in einer Seitenleiste zu platzieren.",
      "Um den `session_state` der Anwendung persistent zu speichern.",
      "Um den Hauptinhalt der Seite horizontal zu zentrieren."
    ],
    "loesung": 1,
    "erklaerung": "Mit `st.sidebar` können Widgets wie Slider, Selectboxen oder Buttons in einer separaten Leiste am linken Rand der App platziert werden, um die Hauptansicht aufgeräumt zu halten.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "140. Welche Methode wird in `pandas` verwendet, um die ersten `n` Zeilen eines DataFrames anzuzeigen?",
    "optionen": [
      "`df.show(n)`",
      "`df.head(n)`",
      "`df.top(n)`",
      "`df.first(n)`"
    ],
    "loesung": 1,
    "erklaerung": "Die Methode `df.head()` (standardmäßig n=5) ist ein unverzichtbares Werkzeug für einen ersten schnellen Blick auf die Struktur und den Inhalt eines DataFrames.",
    "gewichtung": 1,
    "thema": "Pandas & Python Basics"
  },
  {
    "frage": "141. Was ist ein wesentlicher Vorteil der Verwendung von Funktionen in der Programmierung?",
    "optionen": [
      "Sie erhöhen die Komplexität und Laufzeit des Codes.",
      "Sie fördern die Wiederverwendbarkeit von Code und die logische Strukturierung.",
      "Sie verhindern die Verwendung von lokalen Variablen innerhalb ihres Gültigkeitsbereichs.",
      "Sie sind ausschließlich für komplexe mathematische Berechnungen vorgesehen."
    ],
    "loesung": 1,
    "erklaerung": "Funktionen kapseln eine bestimmte Logik, die dann beliebig oft wiederverwendet werden kann. Dies reduziert Codeduplizierung und verbessert die Lesbarkeit und Wartbarkeit.",
    "gewichtung": 1,
    "thema": "Pandas & Python Basics"
  },
  {
    "frage": "142. Was unterscheidet die Docker-Befehle `stop` und `rm`?",
    "optionen": [
      "`docker stop` löscht einen Container permanent, während `docker rm` ihn nur anhält.",
      "`docker stop` hält einen laufenden Container an, während `docker rm` einen gestoppten Container entfernt.",
      "Beide Befehle sind Aliase und haben exakt die gleiche Funktion.",
      "`docker rm` startet einen gestoppten Container neu, während `docker stop` einen neuen erstellt."
    ],
    "loesung": 1,
    "erklaerung": "Mit `docker stop` wird ein Container ordnungsgemäß beendet, sein Zustand bleibt aber erhalten. `docker rm` löscht den Container und alle damit verbundenen Daten (außer in Volumes) endgültig.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "143. Welcher Fehlertyp ist spezifisch für die falsche Verwendung von Streamlit-Widgets?",
    "optionen": [
      "`StreamlitAPIException`",
      "`KeyError`",
      "`ValueError`",
      "`ModuleNotFoundError`"
    ],
    "loesung": 0,
    "erklaerung": "Eine `StreamlitAPIException` wird oft ausgelöst, wenn die Regeln der Streamlit-API verletzt werden, z.B. durch doppelte Widget-Keys oder das Platzieren von Elementen an der falschen Stelle.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "144. Welchen Zweck erfüllt das `st.metric`-Widget in Streamlit?",
    "optionen": [
      "Es dient zur Anzeige einer einzelnen Kennzahl (KPI) mit optionalem Vergleichswert.",
      "Es wandelt eine gegebene Metrik von imperialen in metrische Einheiten um.",
      "Es definiert die Metrik für die Bewertung eines Machine-Learning-Modells.",
      "Es misst die Performance und Ladezeit der Streamlit-Anwendung."
    ],
    "loesung": 0,
    "erklaerung": "Mit `st.metric` können wichtige Kennzahlen wie Umsätze, Fehlerraten oder Zuwächse prominent und übersichtlich in einem Dashboard dargestellt werden.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "145. Was ist ein Hauptvorteil der Verwendung von Markdown in Jupyter Notebooks?",
    "optionen": [
      "Es ermöglicht die Ausführung von Shell-Befehlen direkt im Browser.",
      "Es erlaubt die reichhaltige Formatierung von Text zur Dokumentation des Analyseprozesses.",
      "Es ersetzt die Notwendigkeit von Python-Code für die Datenmanipulation.",
      "Es wird automatisch in eine interaktive Streamlit-Anwendung umgewandelt."
    ],
    "loesung": 1,
    "erklaerung": "Markdown-Zellen sind essenziell, um den Gedankengang, die Methodik und die Schlussfolgerungen einer Datenanalyse direkt neben dem ausführenden Code zu dokumentieren.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "146. Was ist der Unterschied zwischen `import pandas as pd` und `from pandas import *`?",
    "optionen": [
      "Es gibt keinen Unterschied, beide haben das gleiche Ergebnis.",
      "`import pandas as pd` importiert die Bibliothek unter einem Alias, während `from pandas import *` alle Namen in den globalen Namensraum importiert.",
      "`from pandas import *` ist die empfohlene Standardmethode für bessere Performance.",
      "`import pandas as pd` importiert nur die DataFrame-Klasse, nicht die restlichen Funktionen."
    ],
    "loesung": 1,
    "erklaerung": "Die Verwendung eines Alias wie `pd` ist eine weit verbreitete Konvention, die den Code lesbar hält. Ein `import *` (Wildcard-Import) ist fehleranfällig, da er den Namensraum unübersichtlich macht, und sollte vermieden werden.",
    "gewichtung": 1,
    "thema": "Pandas & Python Basics"
  },
  {
    "frage": "147. Was ist der typische Anwendungsfall für `st.file_uploader` in einer Streamlit-App?",
    "optionen": [
      "Das Hochladen von Dateien durch den Benutzer zur interaktiven Analyse in der App.",
      "Das automatische Hochladen der fertigen App in die Streamlit Cloud.",
      "Die Visualisierung der Dateistruktur des Servers in der App.",
      "Der Download von Ergebnis-Dateien aus der App heraus."
    ],
    "loesung": 0,
    "erklaerung": "Das `st.file_uploader`-Widget ermöglicht es Benutzern, ihre eigenen Datendateien (z.B. CSV, Bilder) hochzuladen, die dann serverseitig von der Streamlit-App verarbeitet werden können.",
    "gewichtung": 1,
    "thema": "Werkzeuge & Ökosystem"
  },
  {
    "frage": "148. Welchen Vorteil bietet Docker für die Zusammenarbeit in einem Data-Science-Team?",
    "optionen": [
      "Jeder Entwickler kann seine bevorzugten, inkompatiblen Bibliotheksversionen verwenden.",
      "Alle Teammitglieder arbeiten in einer identischen, versionierten und portablen Umgebung.",
      "Docker erzwingt die Verwendung der Programmiersprache Java anstelle von Python.",
      "Die Notwendigkeit einer Versionskontrolle wie Git wird durch Docker ersetzt."
    ],
    "loesung": 1,
    "erklaerung": "Docker eliminiert das 'works on my machine'-Problem, indem es sicherstellt, dass die gesamte Entwicklungsumgebung (Betriebssystem, Bibliotheken, Konfiguration) für alle Teammitglieder exakt gleich ist.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "149. Was ist der Hauptvorteil eines Multi-Stage-Builds in einem `Dockerfile`?",
    "optionen": [
      "Automatisches Erstellen einer `.dockerignore`-Datei zur besseren Cache-Nutzung.",
      "Paralleles Starten von dev-, test- und prod-Containern mit einem einzigen Befehl.",
      "Reduzierung der finalen Image-Größe durch Trennung von Build- und Runtime-Abhängigkeiten.",
      "Sichere Verwaltung von Umgebungsvariablen durch Integration in den Docker-Daemon."
    ],
    "loesung": 2,
    "erklaerung": "Multi-Stage-Builds erlauben es, in einer ersten 'Build'-Stufe Pakete zu kompilieren oder zu installieren und in einer zweiten 'Final'-Stufe nur die notwendigen Artefakte zu übernehmen, was zu schlankeren und sichereren Images führt.",
    "gewichtung": 1,
    "thema": "Docker & Infrastruktur"
  },
  {
    "frage": "150. Was ist eine `Chained Assignment`-Warnung in `pandas`?",
    "optionen": [
      "Eine Warnung, die bei der Verkettung von zu vielen Methodenaufrufen (`.pipe()...`) auftritt.",
      "Ein Hinweis auf eine potenziell fehlerhafte Zuweisung auf eine Kopie statt auf die Originaldaten; `.loc` sollte verwendet werden.",
      "Eine reine Information, dass eine Zuweisung auf eine Kette von Indizes erfolgreich war.",
      "Ein Fehler, der auftritt, wenn der DataFrame-Index nicht korrekt sortiert ist."
    ],
    "loesung": 1,
    "erklaerung": "Die 'SettingWithCopyWarning' deutet darauf hin, dass eine Operation möglicherweise auf einer temporären Kopie eines DataFrames stattfindet. Um sicherzustellen, dass die Zuweisung im Original-DataFrame ankommt, sollte man `.loc` für den gleichzeitigen Zugriff und die Zuweisung verwenden.",
    "gewichtung": 1,
    "thema": "Pandas & Python Basics"
  }
]