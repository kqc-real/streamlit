{
  "meta": {
    "title": "Klassisches Machine Learning",
    "created": "23.12.2025 12:00",
    "target_audience": "Informatiker mit Grundkenntnissen in Programmierung und Statistik",
    "question_count": 10,
    "difficulty_profile": {
      "leicht": 4,
      "mittel": 4,
      "schwer": 2
    },
    "time_per_weight_minutes": {
      "1": 0.5,
      "2": 0.75,
      "3": 1.0
    },
    "test_duration_minutes": 10
  },
  "questions": [
    {
      "question": "1. Was ist der Hauptunterschied zwischen supervised und unsupervised Learning?",
      "options": [
        "Supervised verwendet gelabelte Daten, unsupervised nicht.",
        "Supervised ist schneller als unsupervised.",
        "Unsupervised erfordert mehr Rechenleistung.",
        "Supervised funktioniert nur mit Bildern."
      ],
      "answer": 0,
      "explanation": "Supervised Learning nutzt gelabelte Trainingsdaten, um Vorhersagen zu treffen. Unsupervised Learning findet Muster in ungelabelten Daten.",
      "weight": 1,
      "topic": "Grundlagen ML"
    },
    {
      "question": "2. Welches Modell wird typischerweise für binäre Klassifikation verwendet?",
      "options": [
        "Lineare Regression",
        "Logistische Regression",
        "K-Means Clustering",
        "Principal Component Analysis"
      ],
      "answer": 1,
      "explanation": "Logistische Regression ist ein klassisches Modell für binäre Klassifikation, das Wahrscheinlichkeiten ausgibt.",
      "weight": 1,
      "topic": "Supervised Learning"
    },
    {
      "question": "3. Was misst der Mean Squared Error (MSE) in der Regression?",
      "options": [
        "Die Genauigkeit der Klassifikation",
        "Den quadratischen Mittelwert der Fehler",
        "Die Anzahl der Cluster",
        "Die Dimensionalität der Daten"
      ],
      "answer": 1,
      "explanation": "MSE berechnet den Durchschnitt der quadrierten Differenzen zwischen vorhergesagten und tatsächlichen Werten.",
      "weight": 1,
      "topic": "Regression"
    },
    {
      "question": "4. Welcher Algorithmus wird für Clustering verwendet?",
      "options": [
        "Decision Tree",
        "K-Means",
        "Support Vector Machine",
        "Naive Bayes"
      ],
      "answer": 1,
      "explanation": "K-Means ist ein unsupervised Algorithmus, der Daten in k Cluster gruppiert.",
      "weight": 1,
      "topic": "Unsupervised Learning"
    },
    {
      "question": "5. Was ist Overfitting in Machine Learning?",
      "options": [
        "Das Modell lernt zu wenig von den Daten.",
        "Das Modell passt sich zu stark an die Trainingsdaten an und generalisiert schlecht.",
        "Das Modell ignoriert die Testdaten.",
        "Das Modell verwendet zu wenige Features."
      ],
      "answer": 1,
      "explanation": "Overfitting tritt auf, wenn ein Modell die Trainingsdaten zu genau lernt, aber auf neuen Daten schlecht performt.",
      "weight": 2,
      "topic": "Modellbewertung"
    },
    {
      "question": "6. Wie funktioniert der k-Nearest Neighbors (k-NN) Algorithmus?",
      "options": [
        "Er berechnet den Mittelwert der nächsten k Punkte.",
        "Er klassifiziert basierend auf den k nächsten Nachbarn in den Trainingsdaten.",
        "Er baut einen Entscheidungsbaum auf.",
        "Er verwendet neuronale Netze."
      ],
      "answer": 1,
      "explanation": "k-NN ist ein lazy Learner, der für eine Vorhersage die k ähnlichsten Trainingsbeispiele betrachtet.",
      "weight": 2,
      "topic": "Supervised Learning"
    },
    {
      "question": "7. Was ist der Zweck von Cross-Validation?",
      "options": [
        "Die Daten in Trainings- und Testsets aufzuteilen.",
        "Die Modellleistung auf verschiedenen Datenteilen zu testen, um Overfitting zu vermeiden.",
        "Die Features zu skalieren.",
        "Die Hyperparameter zu optimieren."
      ],
      "answer": 1,
      "explanation": "Cross-Validation hilft, die Generalisierungsfähigkeit des Modells zu schätzen, indem es auf mehreren Splits trainiert und getestet wird.",
      "weight": 2,
      "topic": "Modellbewertung"
    },
    {
      "question": "8. Welche Metrik ist für unausgewogene Datensätze in der Klassifikation besonders wichtig?",
      "options": [
        "Accuracy",
        "Precision und Recall",
        "Mean Squared Error",
        "R² Score"
      ],
      "answer": 1,
      "explanation": "Precision und Recall sind besser als Accuracy, wenn Klassen unausgewogen sind, da Accuracy durch die Mehrheitsklasse verzerrt wird.",
      "weight": 2,
      "topic": "Klassifikation"
    },
    {
      "question": "9. Erklären Sie den Bias-Variance Tradeoff kurz.",
      "options": [
        "Bias ist der Fehler durch zu einfache Modelle, Variance durch zu komplexe Modelle.",
        "Bias misst die Streuung, Variance den systematischen Fehler.",
        "Beide sind immer minimal in guten Modellen.",
        "Bias ist nur für Regression relevant."
      ],
      "answer": 0,
      "explanation": "Bias-Variance Tradeoff: Hoher Bias führt zu Underfitting (zu einfache Modelle), hohe Variance zu Overfitting (zu komplexe Modelle). Das optimale Modell balanciert beide.",
      "weight": 3,
      "topic": "Modelltheorie"
    },
    {
      "question": "10. Wie würde man den Support Vector Machine (SVM) Algorithmus für nicht-lineare Daten anpassen?",
      "options": [
        "Indem man den Kernel-Trick verwendet, z.B. mit RBF-Kernel.",
        "Indem man die Daten linear transformiert.",
        "Indem man mehr Features hinzufügt.",
        "SVM kann nur lineare Daten handhaben."
      ],
      "answer": 0,
      "explanation": "Der Kernel-Trick projiziert die Daten in einen höherdimensionalen Raum, um nicht-lineare Trennungen zu ermöglichen, ohne explizite Transformation.",
      "weight": 3,
      "topic": "Supervised Learning"
    }
  ]
}