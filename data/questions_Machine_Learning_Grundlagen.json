{
  "meta": {
    "title": "Machine Learning Grundlagen",
    "target_audience": "Anfänger",
    "question_count": 40,
    "difficulty_profile": {
      "leicht": 24,
      "mittel": 12,
      "schwer": 4
    },
    "time_per_weight_minutes": {
      "1": 0.5,
      "2": 0.75,
      "3": 1.0
    },
    "additional_buffer_minutes": 5,
    "test_duration_minutes": 30
  },
  "questions": [
    {
      "frage": "1. Was ist das Hauptziel von Machine Learning im Vergleich zu klassischer, explizit programmierter Software?",
      "optionen": [
        "Regeln manuell zu kodieren, damit das System deterministisch arbeitet.",
        "Aus Beispieldaten Muster zu lernen, um Vorhersagen oder Entscheidungen zu treffen.",
        "Zufallszahlen zu generieren, um alle Möglichkeiten abzudecken.",
        "Hardware schneller zu machen, damit Programme effizienter laufen.",
        "Fehlerhafte Daten zu verwerfen, bevor ein Programm startet."
      ],
      "loesung": 1,
      "erklaerung": "Machine Learning lässt Modelle **Muster aus Daten** lernen statt Regeln fest zu programmieren. Dadurch können Systeme verallgemeinern und auf neue Fälle reagieren.",
      "gewichtung": 1,
      "thema": "Grundbegriffe",
      "mini_glossary": {
        "Modell": "Formale Abbildung von Eingaben auf Ausgaben, deren Parameter aus Daten gelernt werden.",
        "Training": "Prozess, bei dem ein Algorithmus Parameter so anpasst, dass eine Zielgröße optimiert wird."
      }
    },
    {
      "frage": "2. Worin unterscheiden sich überwachtes und unüberwachtes Lernen grundlegend?",
      "optionen": [
        "Überwachtes Lernen nutzt gelabelte Daten, unüberwachtes Lernen arbeitet ohne Ziellabels.",
        "Überwachtes Lernen benötigt keine Daten, unüberwachtes Lernen benötigt viele Daten.",
        "Überwachtes Lernen ist nur für Bilder geeignet, unüberwachtes nur für Text.",
        "Überwachtes Lernen verwendet keine Metriken, unüberwachtes verwendet viele.",
        "Überwachtes Lernen ist stets genauer als unüberwachtes."
      ],
      "loesung": 0,
      "erklaerung": "Beim **überwachten Lernen** gibt es Zielwerte wie Klassen oder Zahlen; **unüberwachtes Lernen** sucht Strukturen in Daten ohne Labels.",
      "gewichtung": 1,
      "thema": "Grundbegriffe",
      "mini_glossary": {
        "Label": "Beobachtetes Zielattribut, das das Modell vorhersagen soll.",
        "Clustering": "Unüberwachtes Verfahren, das ähnliche Datenpunkte in Gruppen einteilt."
      }
    },
    {
      "frage": "3. Was beschreibt ein Datensatz im ML-Kontext am besten?",
      "optionen": [
        "Eine Liste von Quellcode-Dateien für das Modell.",
        "Eine Sammlung strukturierter oder unstrukturierter Beispiele mit Merkmalen und ggf. Zielwerten.",
        "Eine Hardware-Spezifikation für Trainingsserver.",
        "Eine Visualisierung von Fehlern nach dem Training.",
        "Eine Sammlung zufällig erzeugter Zahlenfolgen."
      ],
      "loesung": 1,
      "erklaerung": "Ein Datensatz besteht aus **Beispielen** (Zeilen, Dokumente, Bilder) und **Merkmalen**; optional enthält er Zielwerte für überwachtes Lernen.",
      "gewichtung": 1,
      "thema": "Grundbegriffe",
      "mini_glossary": {
        "Feature/Merkmal": "Messbare Eigenschaft eines Beispiels, z.B. Pixelwerte oder Textstatistiken.",
        "Beispiel/Instanz": "Ein einzelner Datenpunkt, der vom Modell verarbeitet wird."
      }
    },
    {
      "frage": "4. Welche Aussage beschreibt Generalisierung korrekt?",
      "optionen": [
        "Fähigkeit eines Modells, Trainingsdaten exakt auswendig zu lernen.",
        "Fähigkeit eines Modells, bei neuen, ähnlichen Daten gut abzuschneiden.",
        "Fähigkeit eines Modells, ohne Daten zu funktionieren.",
        "Fähigkeit eines Modells, die Trainingszeit zu halbieren.",
        "Fähigkeit eines Modells, alle Fehler im Training zu entfernen."
      ],
      "loesung": 1,
      "erklaerung": "**Generalisierung** bedeutet, dass gelernte Strukturen auf **neue Daten** übertragen werden und nicht nur das Training erklärt wird.",
      "gewichtung": 1,
      "thema": "Grundbegriffe",
      "mini_glossary": {
        "Overfitting": "Anpassung an Zufälligkeiten im Training; schwache Leistung auf neuen Daten.",
        "Underfitting": "Modell ist zu einfach und erfasst die Struktur der Daten nicht hinreichend."
      }
    },
    {
      "frage": "5. Was ist ein Feature im Sinne von Machine Learning?",
      "optionen": [
        "Eine grafische Oberfläche eines Programms.",
        "Eine messbare Eigenschaft eines Datenpunktes, die als Eingabe dient.",
        "Eine Sammlung von Fehlermeldungen.",
        "Ein proprietäres Dateiformat für Modelle.",
        "Eine zufällige Zahl zur Initialisierung."
      ],
      "loesung": 1,
      "erklaerung": "Ein **Feature** ist eine **Eingabevariable**, die das Modell nutzt, um Muster zu erkennen und Vorhersagen zu treffen.",
      "gewichtung": 1,
      "thema": "Daten & Features",
      "mini_glossary": {
        "Skalierung": "Anpassung der Größenordnung von Merkmalen, z.B. Standardisierung.",
        "Kodierung": "Transformation kategorialer Merkmale in numerische Darstellung."
      }
    },
    {
      "frage": "6. Warum wird Feature-Skalierung häufig vor dem Training durchgeführt?",
      "optionen": [
        "Damit alle Modelle deterministisch werden.",
        "Damit Distanz- und Gradienten-basierte Verfahren stabiler und schneller konvergieren.",
        "Damit Labels automatisch generiert werden.",
        "Damit die Datenmenge kleiner wird als zuvor.",
        "Damit Bilder automatisch farbig werden."
      ],
      "loesung": 1,
      "erklaerung": "Vergleichbare **Skalen** verhindern, dass einzelne Merkmale dominieren, und unterstützen **Optimierung** und Distanzberechnungen.",
      "gewichtung": 1,
      "thema": "Daten & Features",
      "mini_glossary": {
        "Standardisierung": "Zentriert Merkmale (Mittel 0) und skaliert auf Varianz 1.",
        "Min-Max-Skalierung": "Skaliert Werte in einen fixen Bereich, häufig [0, 1]."
      }
    },
    {
      "frage": "7. Welche Aussage zu One-Hot-Encoding trifft zu?",
      "optionen": [
        "Es ordnet Kategorien fortlaufende Zahlen zu und erzeugt Ranginformation.",
        "Es erzeugt binäre Spalten pro Kategorie, ohne künstliche Ordnung zu implizieren.",
        "Es wandelt Text automatisch in Bilder um.",
        "Es reduziert immer die Daten dimensional.",
        "Es ist nur für numerische Daten geeignet."
      ],
      "loesung": 1,
      "erklaerung": "**One-Hot-Encoding** bildet Kategorien auf **binäre Indikatoren** ab und vermeidet künstliche Ordnung.",
      "gewichtung": 1,
      "thema": "Daten & Features",
      "mini_glossary": {
        "Dummy-Variable": "Binäre Spalte, die anzeigt, ob eine Kategorie vorliegt.",
        "Kategoriales Merkmal": "Merkmal mit endlicher Menge diskreter Ausprägungen."
      }
    },
    {
      "frage": "8. Wann ist eine Log-Transformation eines Merkmals oft sinnvoll?",
      "optionen": [
        "Bei symmetrischen Normalverteilungen mit kleiner Varianz.",
        "Bei stark rechtsschiefen Verteilungen zur Kompression großer Wertebereiche.",
        "Bei binären Merkmalen mit Werten 0/1.",
        "Bei bereits skalierten Standardnormalmerkmalen.",
        "Bei reinen Textmerkmalen ohne Zahlen."
      ],
      "loesung": 1,
      "erklaerung": "Die **Log-Transformation** reduziert **Schiefe** und kann lineare Beziehungen und Stabilität verbessern.",
      "gewichtung": 1,
      "thema": "Daten & Features",
      "mini_glossary": {
        "Schiefe": "Asymmetrie einer Verteilung relativ zum Mittelwert.",
        "Transformation": "Funktionale Umformung von Merkmalen zur Modellierbarkeit."
      }
    },
    {
      "frage": "9. Welche Modellklasse wird typischerweise für Klassifikationsaufgaben eingesetzt?",
      "optionen": [
        "Lineare Regression ohne Modifikation.",
        "Logistische Regression zur Modellierung von Klassenwahrscheinlichkeiten.",
        "K-Means zur Minimierung von Distanzen.",
        "PCA zur Komponentenextraktion.",
        "DBSCAN zur Dichteanalyse."
      ],
      "loesung": 1,
      "erklaerung": "Die **logistische Regression** modelliert **Wahrscheinlichkeiten** für Klassen und ist ein Standardverfahren für Klassifikation.",
      "gewichtung": 1,
      "thema": "Modellarten",
      "mini_glossary": {
        "Klassifikation": "Vorhersage diskreter Klassenlabels.",
        "Sigmoid": "Funktion, die Werte auf den Bereich (0, 1) abbildet."
      }
    },
    {
      "frage": "10. Wofür werden Entscheidungsbäume im ML eingesetzt?",
      "optionen": [
        "Zur Dekomposition in Frequenzbänder.",
        "Zur schrittweisen Aufteilung von Daten anhand von Merkmalen zur Vorhersage.",
        "Zur kryptografischen Verschlüsselung von Datensätzen.",
        "Zur zufälligen Permutation von Labels.",
        "Zur reinen Datenkompression ohne Vorhersage."
      ],
      "loesung": 1,
      "erklaerung": "**Entscheidungsbäume** teilen Daten entlang von **Merkmalsregeln** und führen zu Vorhersagen in Blättern.",
      "gewichtung": 1,
      "thema": "Modellarten",
      "mini_glossary": {
        "Split": "Regelbasierte Aufteilung eines Knotens entlang eines Merkmals.",
        "Blatt": "Terminaler Knoten, der eine Vorhersage liefert."
      }
    },
    {
      "frage": "11. Was kennzeichnet k-nächste Nachbarn (k-NN) als Lernverfahren?",
      "optionen": [
        "Es lernt explizite Parameter während eines langen Trainings.",
        "Es speichert Beispiele und sagt basierend auf Nachbarschaftsmehrheit oder Mittelwert voraus.",
        "Es benötigt keine Distanzdefinition.",
        "Es ist nur für Bilder geeignet.",
        "Es erzeugt automatisch neue Merkmale während des Trainings."
      ],
      "loesung": 1,
      "erklaerung": "**k-NN** ist ein **instanzbasiertes** Verfahren: Vorhersagen ergeben sich aus lokalen Nachbarschaften im Merkmalsraum.",
      "gewichtung": 1,
      "thema": "Modellarten",
      "mini_glossary": {
        "Instanzbasiert": "Vorhersage durch Vergleich mit gespeicherten Beispielen.",
        "Distanzmaß": "Funktion zur Bewertung der Nähe zwischen Punkten."
      }
    },
    {
      "frage": "12. Wozu dient eine lineare Regression?",
      "optionen": [
        "Zur Vorhersage diskreter Klassenlabels.",
        "Zur Schätzung eines kontinuierlichen Zielwerts als lineare Funktion der Merkmale.",
        "Zur Segmentierung von Bildern in Regionen.",
        "Zur Erzeugung synthetischer Daten.",
        "Zur Verschlüsselung von Textdaten."
      ],
      "loesung": 1,
      "erklaerung": "Die **lineare Regression** sagt **kontinuierliche Zielgrößen** als lineare Kombination der Merkmale voraus.",
      "gewichtung": 1,
      "thema": "Modellarten",
      "mini_glossary": {
        "Regression": "Vorhersage kontinuierlicher Zielvariablen.",
        "Residuum": "Differenz zwischen vorhergesagtem und beobachtetem Wert."
      }
    },
    {
      "frage": "13. Welche Kennzahl ist für binäre Klassifikation ein Standardmaß neben Accuracy?",
      "optionen": [
        "Mean Squared Error ausschließlich.",
        "Precision, also der Anteil korrekter Positivvorhersagen.",
        "PSNR für Bildqualität.",
        "Silhouettenkoeffizient.",
        "K-Means-Inertie."
      ],
      "loesung": 1,
      "erklaerung": "**Precision** bewertet, wie zuverlässig Positivvorhersagen sind; zusammen mit **Recall** ergibt sich ein differenziertes Bild.",
      "gewichtung": 1,
      "thema": "Evaluation & Metriken",
      "mini_glossary": {
        "Accuracy": "Anteil korrekter Vorhersagen an allen Beispielen.",
        "Recall": "Anteil erkannter Positiver an allen tatsächlichen Positiven."
      }
    },
    {
      "frage": "14. Wann ist die ROC-AUC besonders hilfreich?",
      "optionen": [
        "Wenn ausschließlich Regressionsfehler bewertet werden.",
        "Wenn das Ranking der Scores über alle möglichen Schwellen interessiert.",
        "Wenn nur die absolute Vorhersagehöhe wichtig ist.",
        "Wenn ausschließlich negative Klassen betrachtet werden.",
        "Wenn keine Wahrscheinlichkeiten vorliegen."
      ],
      "loesung": 1,
      "erklaerung": "Die **ROC-AUC** fasst die **Trennfähigkeit** eines Modells über alle Schwellen zusammen und ist schwellenunabhängig.",
      "gewichtung": 1,
      "thema": "Evaluation & Metriken",
      "mini_glossary": {
        "ROC-Kurve": "Darstellung von True-Positive-Rate gegenüber False-Positive-Rate.",
        "AUC": "Fläche unter der Kurve als aggregiertes Maß."
      }
    },
    {
      "frage": "15. Wozu dient ein Validierungssplit während des Trainings?",
      "optionen": [
        "Zur Erzeugung zusätzlicher Labels.",
        "Zur unabhängigen Bewertung von Modellen zur Hyperparameterauswahl.",
        "Zur Beschleunigung der Hardware.",
        "Zur Reduktion der Datenqualität.",
        "Zur Ersetzung der Testmenge durch Trainingsdaten."
      ],
      "loesung": 1,
      "erklaerung": "Ein **Validierungssplit** erlaubt **Hyperparametertuning** und frühes Stoppen, ohne die Testmenge anzutasten.",
      "gewichtung": 1,
      "thema": "Evaluation & Metriken",
      "mini_glossary": {
        "Hyperparameter": "Steuergrößen des Lernverfahrens, die nicht aus den Daten gelernt werden.",
        "Frühes Stoppen": "Abbruch des Trainings, wenn sich die Validierungsleistung nicht mehr verbessert."
      }
    },
    {
      "frage": "16. Warum variiert man die Lernrate bei Gradientenverfahren?",
      "optionen": [
        "Um die Anzahl der Merkmale zu reduzieren.",
        "Um Schrittweite und Stabilität der Optimierung zu steuern.",
        "Um die Testdaten zu vergrößern.",
        "Um Labels besser zu kodieren.",
        "Um die Loss-Funktion zu ersetzen."
      ],
      "loesung": 1,
      "erklaerung": "Die **Lernrate** bestimmt die **Schrittgröße** der Updates. Zu große Werte führen zu Instabilität, zu kleine zu langsamer Konvergenz.",
      "gewichtung": 1,
      "thema": "Training & Optimierung",
      "mini_glossary": {
        "Gradientenabstieg": "Iteratives Minimierungsverfahren entlang des negativen Gradienten.",
        "Scheduler": "Regel, nach der die Lernrate im Verlauf angepasst wird."
      }
    },
    {
      "frage": "17. Was ist ein Epochendurchlauf im Training neuronaler Netze?",
      "optionen": [
        "Ein einzelnes Update eines Gewichts.",
        "Eine vollständige Verarbeitung des gesamten Trainingsdatensatzes.",
        "Ein zufälliger Shuffle der Testdaten.",
        "Eine Visualisierung der Gewichte.",
        "Eine einmalige Initialisierung der Parameter."
      ],
      "loesung": 1,
      "erklaerung": "Eine **Epoche** bedeutet, dass **alle Trainingsbeispiele** einmal für Updates herangezogen wurden.",
      "gewichtung": 1,
      "thema": "Training & Optimierung",
      "mini_glossary": {
        "Mini-Batch": "Teilmenge von Trainingsbeispielen pro Update.",
        "Iteration": "Ein einzelner Optimierungsschritt mit einem Mini-Batch."
      }
    },
    {
      "frage": "18. Welche Rolle spielt die Loss-Funktion im Training?",
      "optionen": [
        "Sie generiert automatisch neue Daten.",
        "Sie misst, wie stark Vorhersagen von Zielwerten abweichen, und leitet die Optimierung.",
        "Sie ersetzt die Lernrate.",
        "Sie bestimmt die Größe der Testmenge.",
        "Sie verhindert jegliche Fehler."
      ],
      "loesung": 1,
      "erklaerung": "Die **Loss-Funktion** quantifiziert **Fehler** und ist das Signal, das der Optimierer minimiert.",
      "gewichtung": 1,
      "thema": "Training & Optimierung",
      "mini_glossary": {
        "MSE": "Mean Squared Error, mittlerer quadratischer Fehler für Regression.",
        "Cross-Entropy": "Loss für Klassifikation basierend auf Wahrscheinlichkeiten."
      }
    },
    {
      "frage": "19. Wozu dient Batch-Normalisierung in tiefen Netzen?",
      "optionen": [
        "Zur Datenverschlüsselung in der Pipeline.",
        "Zur Stabilisierung von Aktivierungsverteilungen und schnelleren, robusteren Updates.",
        "Zur Ersetzung der Aktivierungsfunktion.",
        "Zur automatischen Etikettierung von Daten.",
        "Zur Verringerung der Anzahl an Merkmalen."
      ],
      "loesung": 1,
      "erklaerung": "**Batch-Norm** normalisiert Zwischenaktivierungen und erlaubt **stabilere** sowie oft **schnellere** Optimierung.",
      "gewichtung": 2,
      "thema": "Training & Optimierung",
      "extended_explanation": {
        "titel": "Batch-Norm in der Praxis",
        "schritte": [
          "Innerhalb eines Mini-Batches Mittelwert und Varianz schätzen und normalisieren.",
          "Gelerntes Re-Skalieren und Verschieben bewahrt Modellkapazität.",
          "Beim Inferenzieren gleitende Schätzungen verwenden."
        ]
      },
      "mini_glossary": {
        "Aktivierung": "Ausgabe einer Schicht nach linearem Schritt und Nichtlinearität.",
        "Inferenz": "Anwendung eines trainierten Modells auf neue Daten."
      }
    },
    {
      "frage": "20. Warum ist Kreuzvalidierung nützlich?",
      "optionen": [
        "Sie vergrößert die Datenmenge künstlich.",
        "Sie liefert robustere Schätzungen der Generalisierung durch wiederholte Aufteilungen.",
        "Sie ersetzt die Loss-Funktion.",
        "Sie zwingt alle Modelle zur gleichen Genauigkeit.",
        "Sie verhindert jede Varianz im Training."
      ],
      "loesung": 1,
      "erklaerung": "**Kreuzvalidierung** mittelt Ergebnisse über **mehrere Folds** und reduziert Zufallseinflüsse einzelner Splits.",
      "gewichtung": 1,
      "thema": "Validierung & Splits",
      "mini_glossary": {
        "Fold": "Teilmenge von Daten, die abwechselnd als Training/Validierung dient.",
        "Stratifizierung": "Erhaltung der Klassenverteilung in allen Folds."
      }
    },
    {
      "frage": "21. Wozu dient ein Testset im ML-Prozess?",
      "optionen": [
        "Zur Feinjustierung der Hyperparameter während des Trainings.",
        "Zur finalen, unbeeinflussten Bewertung nach Entwicklung und Tuning.",
        "Zur Datenreinigung vor dem Training.",
        "Zur automatischen Merkmalsauswahl.",
        "Zur Erzeugung zusätzlicher Trainingsbeispiele."
      ],
      "loesung": 1,
      "erklaerung": "Das **Testset** dient als **unabhängige** Referenz zur realistischen Leistungsabschätzung nach Abschluss des Modellbaus.",
      "gewichtung": 1,
      "thema": "Validierung & Splits",
      "mini_glossary": {
        "Holdout": "Abgetrennter Datensatzteil, der nicht im Training verwendet wird.",
        "Leckage": "Unzulässiger Informationsfluss zwischen Splits, der Bewertungen verzerrt."
      }
    },
    {
      "frage": "22. Warum ist Stratifizierung bei unausgewogenen Klassen wichtig?",
      "optionen": [
        "Sie macht die Daten zufälliger.",
        "Sie stellt sicher, dass jedes Teilset die Klassenverteilung widerspiegelt.",
        "Sie sortiert Merkmale nach Wichtigkeit.",
        "Sie ersetzt die Wahl geeigneter Metriken.",
        "Sie macht Oversampling überflüssig in allen Fällen."
      ],
      "loesung": 1,
      "erklaerung": "**Stratifizierung** bewahrt die **Klassenverhältnisse** in allen Splits und führt zu stabileren Kennzahlen.",
      "gewichtung": 2,
      "thema": "Validierung & Splits",
      "extended_explanation": {
        "titel": "Stratifizierte Splits erstellen",
        "schritte": [
          "Klassenverteilung im Gesamtdatensatz bestimmen.",
          "Daten so aufteilen, dass die Verhältnisse in allen Folds ähnlich bleiben.",
          "Metriken pro Fold und im Mittel berichten."
        ]
      },
      "mini_glossary": {
        "Klassendisbalance": "Ungleich verteilte Klassenhäufigkeiten im Datensatz.",
        "Sampling": "Auswahlstrategie von Beispielen für Splits oder Training."
      }
    },
    {
      "frage": "23. Welche Wirkung hat L2-Regularisierung typischerweise?",
      "optionen": [
        "Sie erhöht Varianz und reduziert Bias stark.",
        "Sie bestraft große Gewichte, reduziert Varianz und stabilisiert das Modell.",
        "Sie erzeugt automatisch neue Merkmale.",
        "Sie verhindert jede Form von Fehlern.",
        "Sie macht Datenvorverarbeitung unnötig."
      ],
      "loesung": 1,
      "erklaerung": "**L2-Regularisierung** schrumpft **Gewichte** und hilft, **Overfitting** zu mindern.",
      "gewichtung": 1,
      "thema": "Regularisierung",
      "mini_glossary": {
        "Regularisierung": "Zusatzterm oder Technik zur Kontrolle der Modellkomplexität.",
        "Gewichtsnorm": "Maß für die Größe von Modellparametern."
      }
    },
    {
      "frage": "24. Was ist der Hauptunterschied zwischen L1 und L2-Regularisierung?",
      "optionen": [
        "L1 führt oft zu spärlichen Lösungen, L2 verteilt Shrinkage gleichmäßiger.",
        "L1 erhöht immer die Genauigkeit, L2 senkt sie.",
        "L1 ist nur für Bilder, L2 nur für Text.",
        "L1 ersetzt die Loss-Funktion, L2 ersetzt die Metrik.",
        "L1 wirkt nur bei kleinen Datensätzen, L2 nur bei großen."
      ],
      "loesung": 0,
      "erklaerung": "**L1** setzt viele Gewichte auf **genau 0** (eingebaute Selektion), **L2** glättet Parameter ohne exakte Nullsetzung.",
      "gewichtung": 1,
      "thema": "Regularisierung",
      "mini_glossary": {
        "Sparsity": "Viele Parameter sind exakt 0.",
        "Shrinkage": "Verkleinerung von Parametern zur Varianzreduktion."
      }
    },
    {
      "frage": "25. Wozu dient Dropout in neuronalen Netzen?",
      "optionen": [
        "Zur zufälligen Deaktivierung von Einheiten im Training, um Ko-Adaptationen zu verringern.",
        "Zur Erhöhung der Batchgröße.",
        "Zur automatischen Label-Generierung.",
        "Zur Ersetzung von Aktivierungsfunktionen.",
        "Zur Bestimmung der optimalen Lernrate."
      ],
      "loesung": 0,
      "erklaerung": "**Dropout** verhindert **Ko-Adaptationen** und wirkt als Regularisierung, was die Generalisierung verbessert.",
      "gewichtung": 1,
      "thema": "Regularisierung",
      "mini_glossary": {
        "Ko-Adaptation": "Übermäßige Abhängigkeit von bestimmten Pfaden oder Merkmalen.",
        "Rate": "Anteil der im Training deaktivierten Einheiten."
      }
    },
    {
      "frage": "26. Welche Aussage zum überwachten Lernen ist korrekt?",
      "optionen": [
        "Es benötigt keine Zielwerte.",
        "Es nutzt Eingabe-Ausgabe-Paare, um eine Abbildung zu lernen.",
        "Es erzeugt ausschließlich Cluster.",
        "Es ignoriert die Loss-Funktion.",
        "Es kann nicht für Regression verwendet werden."
      ],
      "loesung": 1,
      "erklaerung": "**Überwachtes Lernen** basiert auf **Eingaben** und **Zielwerten** (Labels) und umfasst Klassifikation und Regression.",
      "gewichtung": 1,
      "thema": "Überwachtes Lernen",
      "mini_glossary": {
        "Klassifikation": "Vorhersage diskreter Klassen.",
        "Regression": "Vorhersage kontinuierlicher Zielwerte."
      }
    },
    {
      "frage": "27. Welche Loss-Funktion passt typischerweise zu binärer Klassifikation?",
      "optionen": [
        "Mean Absolute Error.",
        "Binäre Kreuzentropie, da sie Wahrscheinlichkeiten bewertet.",
        "Hinge-Loss ausschließlich.",
        "MSE unabhängig von der Aufgabe.",
        "Keine, da Klassifikation keine Loss braucht."
      ],
      "loesung": 1,
      "erklaerung": "Die **binäre Kreuzentropie** misst die Abweichung vorhergesagter **Wahrscheinlichkeit** vom wahren Label.",
      "gewichtung": 2,
      "thema": "Überwachtes Lernen",
      "extended_explanation": {
        "titel": "Binäre Kreuzentropie verstehen",
        "schritte": [
          "Modelle geben Scores oder Wahrscheinlichkeiten für die positive Klasse aus.",
          "Die Kreuzentropie bestraft falsche, sichere Vorhersagen stark.",
          "Kalibrierte Wahrscheinlichkeiten erleichtern Schwellenwahl und Entscheidungsfindung."
        ]
      },
      "mini_glossary": {
        "Kalibrierung": "Übereinstimmung zwischen vorhergesagten Wahrscheinlichkeiten und beobachteten Häufigkeiten.",
        "Schwellwert": "Grenze, ab der ein Score als positiv gilt."
      }
    },
    {
      "frage": "28. Warum ist die Wahl geeigneter Metriken bei unausgewogenen Klassen entscheidend?",
      "optionen": [
        "Weil Accuracy bei starker Dominanz einer Klasse irreführend hoch sein kann.",
        "Weil Accuracy immer zu niedrig ist.",
        "Weil Metriken das Training ersetzen.",
        "Weil Metriken die Daten bereinigen.",
        "Weil Metriken die Klassen automatisch ausbalancieren."
      ],
      "loesung": 0,
      "erklaerung": "Bei **Imbalance** kann ein triviales Modell hohe **Accuracy** erzielen; **Precision/Recall** und **PR-AUC** sind aussagekräftiger.",
      "gewichtung": 2,
      "thema": "Überwachtes Lernen",
      "extended_explanation": {
        "titel": "Metrikwahl bei Imbalance",
        "schritte": [
          "Verhältnisse der Klassen prüfen und baseline-Modelle vergleichen.",
          "Precision, Recall und F1 bewerten sowie PR-Kurven betrachten.",
          "Kosten/Nutzen von Fehlertypen berücksichtigen."
        ]
      },
      "mini_glossary": {
        "F1-Score": "Harmonisches Mittel aus Precision und Recall.",
        "PR-AUC": "Fläche unter der Precision-Recall-Kurve."
      }
    },
    {
      "frage": "29. Was ist ein typisches Ziel unüberwachter Lernverfahren?",
      "optionen": [
        "Vorhersage von Labels auf Testdaten.",
        "Erkennen von Strukturen oder Gruppen ohne vorgegebene Zielwerte.",
        "Maximierung der Trainingsgeschwindigkeit.",
        "Erhöhung der Bildauflösung.",
        "Erzeugung kryptografischer Schlüssel."
      ],
      "loesung": 1,
      "erklaerung": "**Unüberwachtes Lernen** sucht **Strukturen** wie Cluster oder reduziert Dimensionen ohne Zielvariable.",
      "gewichtung": 1,
      "thema": "Unüberwachtes Lernen",
      "mini_glossary": {
        "PCA": "Hauptkomponentenanalyse zur Dimensionsreduktion.",
        "Cluster": "Gruppe ähnlicher Datenpunkte im Merkmalsraum."
      }
    },
    {
      "frage": "30. Welche Aussage zu k-Means ist korrekt?",
      "optionen": [
        "Es benötigt keine Wahl von k.",
        "Es minimiert die Summe quadratischer Abstände zu Clusterzentren.",
        "Es arbeitet ohne Distanzbegriff.",
        "Es erzeugt immer perfekt runde Cluster.",
        "Es ist nur für Textdaten geeignet."
      ],
      "loesung": 1,
      "erklaerung": "**k-Means** sucht **Zentren** und minimiert die Summe quadratischer **Distanzen** innerhalb der Cluster.",
      "gewichtung": 2,
      "thema": "Unüberwachtes Lernen",
      "extended_explanation": {
        "titel": "k-Means in Kürze",
        "schritte": [
          "Anzahl der Cluster k festlegen und Zentren initialisieren.",
          "Punkte dem nächstgelegenen Zentrum zuordnen und Zentren aktualisieren.",
          "Bis zur Konvergenz wiederholen; Skalierung und Initialisierung beeinflussen Ergebnisse."
        ]
      },
      "mini_glossary": {
        "Zentroid": "Arithmetischer Mittelpunkt eines Clusters.",
        "Inertie": "Summe der quadratischen Abstände innerhalb der Cluster."
      }
    },
    {
      "frage": "31. Wozu dient die Silhouette in der Clusteranalyse?",
      "optionen": [
        "Zur Bewertung der Trennschärfe und Kompaktheit von Clustern pro Punkt.",
        "Zur Vorhersage kontinuierlicher Zielwerte.",
        "Zur Erzeugung neuer Merkmale.",
        "Zur Wahl der Lernrate.",
        "Zur Verschlüsselung der Daten."
      ],
      "loesung": 0,
      "erklaerung": "Die **Silhouette** misst **Passung zum eigenen Cluster** vs. Nähe zum nächsten fremden Cluster.",
      "gewichtung": 2,
      "thema": "Unüberwachtes Lernen",
      "extended_explanation": {
        "titel": "Silhouettenkoeffizient interpretieren",
        "schritte": [
          "Pro Punkt mittlere Intra- und Inter-Cluster-Distanzen berechnen.",
          "Werte nahe 1 deuten auf gute Trennung hin, nahe 0 auf Grenzfälle.",
          "Negative Werte können Fehlzuordnungen anzeigen."
        ]
      },
      "mini_glossary": {
        "Intra-Cluster": "Bezug auf Punkte im selben Cluster.",
        "Inter-Cluster": "Bezug auf Punkte in anderen Clustern."
      }
    },
    {
      "frage": "32. Welche Herausforderung entsteht bei hochdimensionalen Daten für Distanzbasen?",
      "optionen": [
        "Distanzen werden aussagekräftiger.",
        "Distanzen werden ähnlicher (Fluch der Dimensionalität), wodurch Nachbarschaft weniger informativ wird.",
        "Distanzen sind nicht mehr berechenbar.",
        "Distanzen hängen nicht mehr von Features ab.",
        "Distanzen eliminieren Ausreißer automatisch."
      ],
      "loesung": 1,
      "erklaerung": "Mit steigender **Dimension** nähern sich **Distanzen** an; Verfahren wie k-NN oder k-Means verlieren an Aussagekraft ohne geeignete Vorverarbeitung.",
      "gewichtung": 2,
      "thema": "Unüberwachtes Lernen",
      "extended_explanation": {
        "titel": "Fluch der Dimensionalität",
        "schritte": [
          "Skalierung und Merkmalsreduktion können Abstände wieder aussagekräftiger machen.",
          "Regelmäßige Evaluierung mit geeigneten Metriken ist notwendig.",
          "Domänenspezifische Feature-Konstruktion erhöht Signal-zu-Rausch-Verhältnis."
        ]
      },
      "mini_glossary": {
        "Dimensionsreduktion": "Verkleinerung der Anzahl von Merkmalen bei Erhalt wichtiger Information.",
        "Signal-Rausch-Verhältnis": "Verhältnis relevanter zu irrelevanter Variation."
      }
    },
    {
      "frage": "33. Welche Rolle spielt Transparenz in ML-Projekten?",
      "optionen": [
        "Sie ist optional und betrifft nur Hardware.",
        "Sie unterstützt Nachvollziehbarkeit von Daten, Modellen und Entscheidungen.",
        "Sie ersetzt die Dokumentation vollständig.",
        "Sie verhindert jede Form von Bias automatisch.",
        "Sie ist nur für Forschung relevant, nicht für Produkte."
      ],
      "loesung": 1,
      "erklaerung": "**Transparenz** ermöglicht **Nachvollziehbarkeit** und schafft Vertrauen in Modelle, insbesondere bei kritischen Anwendungen.",
      "gewichtung": 1,
      "thema": "Ethik & Praxis",
      "mini_glossary": {
        "Nachvollziehbarkeit": "Klare Dokumentation von Datenquellen, Annahmen und Modellversionen.",
        "Audit": "Systematische Prüfung von Prozessen und Ergebnissen."
      }
    },
    {
      "frage": "34. Was beschreibt Bias im Kontext ethischer Fragestellungen am treffendsten?",
      "optionen": [
        "Zufällige Schwankungen im Training.",
        "Systematische Verzerrung, die zu unfairen Ergebnissen führen kann.",
        "Eine spezielle Aktivierungsfunktion in Netzen.",
        "Eine Technik zur Regularisierung.",
        "Ein Dateiformat für Modelle."
      ],
      "loesung": 1,
      "erklaerung": "**Bias** kann aus **verzerrten Daten** oder unangemessenen Annahmen entstehen und zu **ungerechten** Entscheidungen führen.",
      "gewichtung": 1,
      "thema": "Ethik & Praxis",
      "mini_glossary": {
        "Fairness": "Eigenschaft von Modellen, Gruppen oder Individuen nicht systematisch zu benachteiligen.",
        "Datenrepräsentativität": "Ausgewogenheit der Daten im Hinblick auf relevante Gruppen."
      }
    },
    {
      "frage": "35. Welche Maßnahme gehört zu verantwortungsvollem Einsatz von ML-Systemen?",
      "optionen": [
        "Verzicht auf jede Dokumentation, um schneller zu sein.",
        "Einführung von Evaluationskriterien und Monitoring im Betrieb.",
        "Ignorieren der Nutzerbeschwerden nach dem Roll-out.",
        "Zufällige Änderung von Hyperparametern nach der Produktion.",
        "Verbot von Testdaten in allen Projekten."
      ],
      "loesung": 1,
      "erklaerung": "**Monitoring** und klare **Kriterien** helfen, Drift zu erkennen und Qualität langfristig zu sichern.",
      "gewichtung": 2,
      "thema": "Ethik & Praxis",
      "extended_explanation": {
        "titel": "ML-Systeme im Betrieb überwachen",
        "schritte": [
          "Relevante Metriken und Alarme definieren.",
          "Daten- und Konzeptdrift regelmäßig prüfen.",
          "Feedbackkanäle und Eskalationspfade etablieren."
        ]
      },
      "mini_glossary": {
        "Daten-Drift": "Änderung der Eingabeverteilung über die Zeit.",
        "Konzept-Drift": "Änderung der Beziehung zwischen Eingaben und Zielwert."
      }
    },
    {
      "frage": "36. Welche Praxis reduziert das Risiko von Datenlecks (Leakage) in ML-Pipelines?",
      "optionen": [
        "Vorverarbeitung vor dem Split auf alle Daten anwenden.",
        "Alle Schritte innerhalb von Validierungs-Folds fitten.",
        "Testdaten zum Training hinzufügen.",
        "Labels zur Skalierung verwenden.",
        "Schwellwerte anhand des Testsets wählen."
      ],
      "loesung": 1,
      "erklaerung": "**Fold-interne** Anpassungen (Skalierung, Auswahl) verhindern **Leakage** und liefern realistischere Bewertungen.",
      "gewichtung": 2,
      "thema": "Ethik & Praxis",
      "extended_explanation": {
        "titel": "Leakage vermeiden",
        "schritte": [
          "Split vor jeder datengetriebenen Transformation durchführen.",
          "Pipelines nutzen, damit Fit/Transform korrekt getrennt wird.",
          "Finale Bewertung ausschließlich auf dem Testset."
        ]
      },
      "mini_glossary": {
        "Pipeline": "Gekettete Verarbeitungsschritte mit konsistentem Fit/Transform.",
        "Validierung": "Bewertung außerhalb der zum Fit genutzten Daten."
      }
    },
    {
      "frage": "37. Welche Kennzahl ist bei stark unausgewogenen Klassen oft hilfreicher als Accuracy?",
      "optionen": [
        "PR-AUC, da sie den Fokus auf die positive Klasse und Fehlalarme legt.",
        "MSE, da es kontinuierliche Fehler misst.",
        "PSNR, da es Bildqualität bewertet.",
        "Silhouette, da sie Cluster trennt.",
        "Kappa, da es Splits erzeugt."
      ],
      "loesung": 0,
      "erklaerung": "**PR-AUC** betont **Precision** und **Recall** der positiven Klasse und ist bei Seltenheitsfällen oft informativer als Accuracy.",
      "gewichtung": 3,
      "thema": "Evaluation & Metriken",
      "extended_explanation": {
        "titel": "Warum PR-AUC bei Imbalance?",
        "schritte": [
          "Wenige Positive machen Falsch-Positive besonders relevant.",
          "PR-Kurven zeigen Leistung im relevanten Bereich besser als ROC.",
          "Schwellenwahl an Anwendungs-Kosten ausrichten."
        ]
      },
      "mini_glossary": {
        "Precision": "Anteil korrekter Positivvorhersagen an allen Positivvorhersagen.",
        "Recall": "Anteil erkannter Positiver an allen tatsächlichen Positiven."
      }
    },
    {
      "frage": "38. Welche Aussage zur Schwellenwahl bei probabilistischen Klassifikatoren trifft zu?",
      "optionen": [
        "Ein fester Standardwert ist immer optimal.",
        "Der optimale Schwellenwert hängt von Kosten, Nutzen und Metrikziel ab.",
        "Die Schwelle wird nach der Trainingszeit gewählt.",
        "Die Schwelle darf nur 0,5 sein.",
        "Die Schwelle ist bei allen Datensätzen gleich."
      ],
      "loesung": 1,
      "erklaerung": "Die **Schwelle** ist **anwendungsabhängig**; Kosten von Fehlalarmen und verpassten Treffern bestimmen die sinnvolle Wahl.",
      "gewichtung": 3,
      "thema": "Validierung & Splits",
      "extended_explanation": {
        "titel": "Schwellen systematisch bestimmen",
        "schritte": [
          "Vorhersagewahrscheinlichkeiten evaluieren statt nur harte Labels.",
          "ROC/PR und Kostenmatrix heranziehen.",
          "Schwelle anhand betrieblicher Ziele festlegen und periodisch prüfen."
        ]
      },
      "mini_glossary": {
        "Kostenmatrix": "Bewertet Fehlerarten mit unterschiedlichen Kosten.",
        "Kalibrierung": "Angleichung vorhergesagter Wahrscheinlichkeiten an Häufigkeiten."
      }
    },
    {
      "frage": "39. Welche Herausforderung beschreibt der Begriff Datenethik im ML-Kontext?",
      "optionen": [
        "Die Wahl der optimalen Lernrate.",
        "Die verantwortliche Erhebung, Nutzung und Speicherung von Daten unter Beachtung von Rechten und Werten.",
        "Die effiziente GPU-Nutzung im Training.",
        "Die Optimierung der Batchgröße.",
        "Die automatische Fehlersuche in Quellcode."
      ],
      "loesung": 1,
      "erklaerung": "**Datenethik** umfasst **Rechtmäßigkeit**, **Fairness** und **Transparenz** im Umgang mit Daten und Modellen.",
      "gewichtung": 3,
      "thema": "Ethik & Praxis",
      "extended_explanation": {
        "titel": "Dimensionen der Datenethik",
        "schritte": [
          "Rechtliche Vorgaben wie Datenschutz berücksichtigen.",
          "Verzerrungen erkennen und mitigieren.",
          "Nutzer informieren und Einspruchsrechte respektieren."
        ]
      },
      "mini_glossary": {
        "Transparenz": "Nachvollziehbarkeit von Datenflüssen und Entscheidungen.",
        "Rechtsgrundlage": "Zulässiger Grund für Erhebung und Verarbeitung von Daten."
      }
    },
    {
      "frage": "40. Welche Maßnahme unterstützt die Reproduzierbarkeit von ML-Experimenten am stärksten?",
      "optionen": [
        "Verzicht auf jede Versionierung.",
        "Festhalten von Seeds, Umgebungen, Daten- und Modellversionen in strukturierter Form.",
        "Mündliche Dokumentation im Teammeeting.",
        "Zufällige Änderungen nach dem Training.",
        "Ausschließliche Nutzung von Testdaten zum Tuning."
      ],
      "loesung": 1,
      "erklaerung": "Dokumentierte **Seeds**, **Versionen** und **Umgebungen** machen Ergebnisse **nachstellbar** und überprüfbar.",
      "gewichtung": 3,
      "thema": "Ethik & Praxis",
      "extended_explanation": {
        "titel": "Reproduzierbarkeit sicherstellen",
        "schritte": [
          "Versionierung für Daten, Code und Modelle etablieren.",
          "Zufallsquellen kontrollieren und Umgebungen fixieren.",
          "Experimente protokollieren und Artefakte archivieren."
        ]
      },
      "mini_glossary": {
        "Seed": "Startwert für Zufallsprozesse zur Reproduktion.",
        "Artefakt": "Ergebnis eines Laufs, z.B. Modelldatei oder Bericht."
      }
    }
  ]
}
