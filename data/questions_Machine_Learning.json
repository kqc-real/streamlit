{
  "meta": {
    "title": "Machine Learning",
    "created": "09.02.2026 13:08",
    "modified": "09.02.2026 13:12",
    "target_audience": "Gemischte Zielgruppe (kombinierte Machine-Learning-Sets)",
    "question_count": 186,
    "difficulty_profile": {
      "easy": 62,
      "medium": 87,
      "hard": 37
    },
    "language": "de",
    "time_per_weight_minutes": {
      "1": 0.5,
      "2": 0.75,
      "3": 1.0
    },
    "additional_buffer_minutes": 5,
    "test_duration_minutes": 140
  },
  "questions": [
    {
      "question": "1. Was ist ein grundlegendes Merkmal eines neuronalen Netzes?",
      "options": [
        "Es besteht aus Schichten von Neuronen, die durch gewichtete Verbindungen miteinander verknüpft sind.",
        "Es verwendet einen einzelnen Entscheidungsbaum, um Vorhersagen zu treffen.",
        "Es benötigt grundsätzlich keine Trainingsdaten, um zu funktionieren.",
        "Es kann ausschließlich lineare Regressionen durchführen."
      ],
      "answer": 0,
      "explanation": "Neuronale Netze sind von der Struktur des Gehirns inspiriert und bestehen aus miteinander verbundenen Knoten (Neuronen), die in Schichten angeordnet sind. Die Stärke der Verbindungen (Gewichte) wird im Training gelernt.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "2. Was ist die Hauptfunktion einer Aktivierungsfunktion in einem neuronalen Netz?",
      "options": [
        "Sie führt Nichtlinearität ein, was dem Netz ermöglicht, komplexe Muster zu lernen.",
        "Sie berechnet den Gradienten für die Backpropagation.",
        "Sie initialisiert die Gewichte der Neuronen vor dem Training.",
        "Sie normalisiert die Eingabedaten auf einen Bereich zwischen 0 und 1."
      ],
      "answer": 0,
      "explanation": "Ohne nichtlineare Aktivierungsfunktionen wäre ein neuronales Netz, egal wie viele Schichten es hat, nur in der Lage, lineare Zusammenhänge zu modellieren. Die Nichtlinearität ist entscheidend für seine Mächtigkeit.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "3. Was ist ein wesentlicher Vorteil der `ReLU`-Aktivierungsfunktion gegenüber `Sigmoid`?",
      "options": [
        "`ReLU` leidet weniger unter dem 'Vanishing Gradient'-Problem.",
        "`ReLU` ist über den gesamten Definitionsbereich stetig differenzierbar.",
        "`ReLU` eignet sich besser für die Ausgabeschicht bei binärer Klassifikation.",
        "`ReLU` ist rechenintensiver, aber genauer."
      ],
      "answer": 0,
      "explanation": "Die Ableitung der `Sigmoid`-Funktion ist in vielen Bereichen nahe null, was bei tiefen Netzen zum 'Verschwinden' der Gradienten führen kann. `ReLU` hat für positive Eingaben eine konstante Ableitung von 1, was den Gradientenfluss erleichtert.",
      "weight": 2,
      "topic": "Neuronale Netze – Grundlagen",
      "cognitive_level": "Anwendung",
      "concept": "Aktivierungsfunktionen"
    },
    {
      "question": "4. Was beschreibt das Backpropagation-Verfahren?",
      "options": [
        "Die effiziente Berechnung der Gradienten des Fehlers bezüglich der Gewichte.",
        "Die zufällige Initialisierung der Gewichte vor dem ersten Trainingsschritt.",
        "Die Auswahl der optimalen Anzahl von Neuronen für ein Hidden Layer.",
        "Die schichtweise Vorwärtsausbreitung der Eingabedaten durch das Netz."
      ],
      "answer": 0,
      "explanation": "`Backpropagation` ist der Algorithmus, mit dem die Gewichte eines neuronalen Netzes trainiert werden. Er propagiert den Fehler von der Ausgabeschicht rückwärts durch das Netz, um die Gradienten für die Gewichtsaktualisierung zu berechnen.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "5. Was ist eine typische Ursache für Overfitting bei neuronalen Netzen?",
      "options": [
        "Ein zu komplexes Modell (zu viele Parameter) im Verhältnis zu wenigen Trainingsdaten.",
        "Eine zu kleine Lernrate während des Trainings.",
        "Die Verwendung von Regularisierungstechniken wie `Dropout`.",
        "Das Fehlen einer nichtlinearen Aktivierungsfunktion in den Hidden Layers."
      ],
      "answer": 0,
      "explanation": "`Overfitting` tritt auf, wenn ein Modell so flexibel ist, dass es beginnt, das Rauschen in den Trainingsdaten auswendig zu lernen, anstatt das zugrundeliegende Muster zu generalisieren.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "cognitive_level": "Reproduktion",
      "concept": "Training & Optimierung"
    },
    {
      "question": "6. Was ist `Dropout` im Kontext von Deep Learning?",
      "options": [
        "Eine Regularisierungstechnik, bei der während des Trainings zufällig Neuronen 'ausgeschaltet' werden.",
        "Eine Methode zur Beschleunigung des Trainings durch Reduzierung der Batch-Größe.",
        "Eine spezielle Aktivierungsfunktion für die Ausgabeschicht.",
        "Ein Optimierungsalgorithmus, der die Lernrate adaptiv anpasst."
      ],
      "answer": 0,
      "explanation": "Durch das zufällige Deaktivieren von Neuronen in jedem Trainingsschritt zwingt `Dropout` das Netzwerk, robustere und weniger voneinander abhängige Features zu lernen, was Overfitting entgegenwirkt.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "7. Welchen Zweck erfüllt eine `Loss Function` (Verlustfunktion)?",
      "options": [
        "Sie quantifiziert den Fehler zwischen der Modellvorhersage und dem wahren Zielwert.",
        "Sie berechnet die optimale Anzahl der Neuronen für die gegebene Aufgabe.",
        "Sie legt die Lernrate für den Optimierungsalgorithmus fest.",
        "Sie bestimmt die maximale Anzahl der Trainingsepochen."
      ],
      "answer": 0,
      "explanation": "Die Verlustfunktion ist das Signal, das der Optimierungsalgorithmus (z.B. SGD) zu minimieren versucht. Ein kleinerer Verlustwert bedeutet eine bessere Anpassung des Modells an die Trainingsdaten.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "8. Was ist ein Hauptvorteil von `Batch Normalization`?",
      "options": [
        "Sie beschleunigt und stabilisiert den Trainingsprozess.",
        "Sie erhöht die Anzahl der lernbaren Parameter im Modell.",
        "Sie ersetzt die Notwendigkeit von Aktivierungsfunktionen.",
        "Sie funktioniert nur in der ersten Schicht eines Netzwerks."
      ],
      "answer": 0,
      "explanation": "`Batch Normalization` normalisiert die Aktivierungen zwischen den Schichten. Dies wirkt dem Problem des 'Internal Covariate Shift' entgegen, erlaubt höhere Lernraten und macht das Training insgesamt stabiler.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "cognitive_level": "Analyse",
      "concept": "Training & Optimierung"
    },
    {
      "question": "9. Was ist ein potenzielles Problem bei sehr tiefen neuronalen Netzen?",
      "options": [
        "Das Auftreten von 'Vanishing' oder 'Exploding Gradients'.",
        "Sie sind prinzipiell schneller zu trainieren als flache Netze.",
        "Sie können keine nichtlinearen Aktivierungsfunktionen verwenden.",
        "Sie sind von Natur aus robuster gegen Overfitting."
      ],
      "answer": 0,
      "explanation": "Bei der `Backpropagation` in sehr tiefen Netzen kann der Gradient, der rückwärts propagiert wird, exponentiell klein ('vanishing') oder groß ('exploding') werden, was das Lernen verhindert oder destabilisiert.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Anwendung",
      "concept": "Grundlagen"
    },
    {
      "question": "10. Für welche Art von Aufgaben sind `Convolutional Neural Networks (CNNs)` besonders gut geeignet?",
      "options": [
        "Aufgaben mit gitterartigen Daten wie Bildklassifikation und Objekterkennung.",
        "Die Verarbeitung von sequenziellen Daten wie Zeitreihen oder Text.",
        "Das Finden von Clustern in ungelabelten Datensätzen.",
        "Probleme des Reinforcement Learning in Spielumgebungen."
      ],
      "answer": 0,
      "explanation": "`CNNs` sind darauf spezialisiert, lokale räumliche Muster in Daten wie Bildern durch Faltungsoperationen (Convolutions) zu erkennen, was sie für Computer-Vision-Aufgaben prädestiniert.",
      "weight": 1,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Reproduktion",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "11. Was ist ein Vorteil von `Stochastic Gradient Descent (SGD)`?",
      "options": [
        "Es ist speichereffizient und ermöglicht das Training mit sehr großen Datensätzen.",
        "Es konvergiert garantiert immer zum globalen Minimum der Verlustfunktion.",
        "Es benötigt keine manuelle Einstellung der Lernrate.",
        "Es führt im Vergleich zu anderen Methoden zu einer schnelleren Konvergenz."
      ],
      "answer": 0,
      "explanation": "Da `SGD` die Gewichte nach jedem einzelnen Datenpunkt (oder einem kleinen Batch) aktualisiert, muss nicht der gesamte Datensatz im Speicher gehalten werden. Die 'rauschhaften' Updates können auch helfen, lokalen Minima zu entkommen.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "12. Welche Funktion hat ein `Hidden Layer` in einem neuronalen Netz?",
      "options": [
        "Es lernt hierarchische und zunehmend komplexe Merkmale aus den Eingabedaten.",
        "Es dient ausschließlich dazu, die finale Vorhersage des Netzes auszugeben.",
        "Es initialisiert die Gewichte für die Eingabeschicht.",
        "Es normalisiert die Ausgabewerte auf einen Bereich zwischen 0 und 1."
      ],
      "answer": 0,
      "explanation": "Versteckte Schichten (Hidden Layers) sind die Kernkomponenten, in denen das Netzwerk lernt, aus den Rohdaten der vorherigen Schicht abstraktere und nützlichere Repräsentationen zu extrahieren.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "13. Was ist ein Nachteil der `Sigmoid`-Aktivierungsfunktion in tiefen Netzen?",
      "options": [
        "Ihre Ableitung ist oft nahe null, was zum 'Vanishing Gradient'-Problem führt.",
        "Sie ist nicht stetig differenzierbar und kann nicht für `Backpropagation` verwendet werden.",
        "Sie kann keine nichtlinearen Zusammenhänge im Netzwerk abbilden.",
        "Sie ist ausschließlich für Regressionsprobleme mit positiven Zielwerten geeignet."
      ],
      "answer": 0,
      "explanation": "Die `Sigmoid`-Funktion 'sättigt' bei großen positiven oder negativen Eingaben, was bedeutet, dass ihre Ableitung nahe null wird. Dies verlangsamt oder stoppt den Lernprozess in den unteren Schichten tiefer Netzwerke.",
      "weight": 2,
      "topic": "Neuronale Netze – Grundlagen",
      "cognitive_level": "Anwendung",
      "concept": "Aktivierungsfunktionen"
    },
    {
      "question": "14. Was ist ein Vorteil des `Adam`-Optimierers gegenüber einfachem `SGD`?",
      "options": [
        "Er passt die Lernrate für jeden Parameter individuell und adaptiv an.",
        "Er benötigt keine `Backpropagation` zur Berechnung der Gradienten.",
        "Er ist speziell für sehr kleine Netzwerke mit wenigen Parametern optimiert.",
        "Er verwendet keine Gradienten, sondern einen genetischen Algorithmus."
      ],
      "answer": 0,
      "explanation": "`Adam` (Adaptive Moment Estimation) kombiniert die Ideen von Momentum und RMSprop. Er pflegt eine adaptive Lernrate für jedes Gewicht, was oft zu einer schnelleren und stabileren Konvergenz führt als Standard-SGD.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "15. Warum wird die Technik des `Early Stopping` beim Training eingesetzt?",
      "options": [
        "Um Overfitting zu vermeiden, indem das Training beendet wird, wenn sich der Validierungsfehler nicht mehr verbessert.",
        "Um die anfängliche Lernrate dynamisch während der ersten Epochen zu erhöhen.",
        "Um die Gewichte des Netzwerks auf einen bekannten, guten Zustand zurückzusetzen.",
        "Um das Training zu stoppen, sobald eine Genauigkeit von 100% auf den Trainingsdaten erreicht ist."
      ],
      "answer": 0,
      "explanation": "`Early Stopping` ist eine Form der Regularisierung, bei der die Leistung des Modells auf einem separaten Validierungsdatensatz überwacht wird. Das Training wird abgebrochen, sobald diese Leistung stagniert oder schlechter wird, um Overfitting zu verhindern.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "16. Welche Rolle spielt die `Softmax`-Funktion typischerweise in einem neuronalen Netz?",
      "options": [
        "Sie wandelt die Logits der Ausgabeschicht in eine Wahrscheinlichkeitsverteilung über die Klassen um.",
        "Sie dient als Regularisierungstechnik, um Overfitting in den Hidden Layers zu reduzieren.",
        "Sie ersetzt die Verlustfunktion bei Regressionsproblemen.",
        "Sie wird als Aktivierungsfunktion in den Hidden Layers von CNNs verwendet."
      ],
      "answer": 0,
      "explanation": "Die `Softmax`-Funktion ist ideal für die Ausgabeschicht bei Multi-Klassen-Klassifikationsproblemen, da sie sicherstellt, dass die Summe der Ausgaben 1 beträgt und jeder Wert als die Wahrscheinlichkeit für die jeweilige Klasse interpretiert werden kann.",
      "weight": 2,
      "topic": "Neuronale Netze – Grundlagen",
      "cognitive_level": "Anwendung",
      "concept": "Aktivierungsfunktionen"
    },
    {
      "question": "17. Was ist ein potenzieller Nachteil einer zu großen Lernrate?",
      "options": [
        "Das Training kann instabil werden, da das Optimum 'übersprungen' wird.",
        "Das Training konvergiert extrem langsam gegen ein lokales Minimum.",
        "Die Gewichte des Netzwerks werden während des Trainings nicht aktualisiert.",
        "Die Aktivierungsfunktionen in den Hidden Layers werden deaktiviert."
      ],
      "answer": 0,
      "explanation": "Eine zu große Lernrate kann dazu führen, dass die Gewichtsaktualisierungen so groß sind, dass der Optimierungsprozess über das Minimum der Verlustfunktion hinwegschießt und der Fehler wieder ansteigt (Divergenz).",
      "weight": 1,
      "topic": "Training & Optimierung",
      "cognitive_level": "Reproduktion",
      "concept": "Training & Optimierung"
    },
    {
      "question": "18. Warum ist eine gute Gewichtsinitialisierung ('Weight Initialization') wichtig?",
      "options": [
        "Sie hilft, Probleme wie 'Vanishing/Exploding Gradients' zu vermeiden und beschleunigt die Konvergenz.",
        "Sie bestimmt die endgültige Anzahl der Hidden Layers im Netzwerk.",
        "Sie ersetzt die Notwendigkeit einer nichtlinearen Aktivierungsfunktion.",
        "Sie verhindert die Verwendung von Regularisierungstechniken wie `Dropout`."
      ],
      "answer": 0,
      "explanation": "Eine schlechte Initialisierung (z.B. alle Gewichte auf null) kann den Lernprozess verhindern. Techniken wie Xavier/Glorot-Initialisierung sorgen für eine gute Varianz der Aktivierungen und einen stabilen Gradientenfluss zu Beginn des Trainings.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Analyse",
      "concept": "Grundlagen"
    },
    {
      "question": "19. Für welche Art von Daten sind `Recurrent Neural Networks (RNNs)` besonders geeignet?",
      "options": [
        "Für Sequenzdaten, bei denen die Reihenfolge der Elemente von Bedeutung ist (z.B. Text, Zeitreihen).",
        "Für gitterartige Daten ohne zeitliche Komponente wie statische Bilder.",
        "Für tabellarische Daten mit unabhängigen Zeilen wie in einer CSV-Datei.",
        "Für das Finden von Clustern in ungelabelten Datensätzen."
      ],
      "answer": 0,
      "explanation": "`RNNs` besitzen interne Schleifen, die es ihnen ermöglichen, einen 'Gedächtnis'-Zustand zu pflegen. Dies macht sie ideal für Aufgaben, bei denen der Kontext aus vorherigen Schritten in einer Sequenz wichtig ist.",
      "weight": 1,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Reproduktion",
      "concept": "Architekturen (RNN)"
    },
    {
      "question": "20. Was ist ein entscheidender Vorteil von Deep Learning gegenüber klassischen ML-Algorithmen?",
      "options": [
        "Die Fähigkeit zum automatischen 'Feature Learning' direkt aus Rohdaten.",
        "Die Garantie, dass kein Overfitting auf den Trainingsdaten stattfindet.",
        "Die hohe Interpretierbarkeit der gelernten Modelle ('White-Box').",
        "Der geringere Bedarf an Trainingsdaten für komplexe Aufgaben."
      ],
      "answer": 0,
      "explanation": "Während bei klassischen ML-Ansätzen oft aufwendiges, manuelles Feature Engineering nötig ist, können tiefe neuronale Netze eine Hierarchie von Merkmalen direkt aus den Rohdaten (z.B. Pixeln eines Bildes) lernen.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Anwendung",
      "concept": "Grundlagen"
    },
    {
      "question": "21. Was ist der Hauptvorteil von CNNs gegenüber Fully-Connected Networks bei der Bildverarbeitung?",
      "options": [
        "Sie sind unempfindlich gegenüber der Farbe der Pixel.",
        "Sie reduzieren die Anzahl der Parameter drastisch durch lokale Verbindungen und Gewichtsteilung.",
        "Sie können ausschließlich Graustufenbilder effizient verarbeiten.",
        "Sie konvergieren beim Training grundsätzlich schneller."
      ],
      "answer": 1,
      "explanation": "Ein Fully-Connected Network für ein Bild hätte für jedes Pixel eine Verbindung zu jedem Neuron der nächsten Schicht, was zu Millionen von Parametern führt. CNNs nutzen kleine Filter, deren Gewichte über das gesamte Bild geteilt werden, was rechnerisch effizienter ist.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "22. Welche Eigenschaft von CNNs ermöglicht die Erkennung von Objekten unabhängig von ihrer Position im Bild?",
      "options": [
        "`Dropout`",
        "`Translation Invariance`",
        "`Dense Layer`",
        "`Batch Normalization`"
      ],
      "answer": 1,
      "explanation": "Durch die Anwendung desselben Filters (Gewichtsteilung) über das gesamte Bild und die anschließende Abstraktion durch Pooling-Layer lernt ein CNN, ein Merkmal (z.B. ein Auge) zu erkennen, egal ob es links oben oder rechts unten im Bild erscheint.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Analyse",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "23. Was ist ein `Filter` (oder Kernel) in einem Convolutional Layer?",
      "options": [
        "Eine Methode zur Umwandlung eines Farbbildes in ein Graustufenbild.",
        "Eine kleine Matrix von Gewichten, die über das Eingabebild gefaltet wird, um Merkmale zu extrahieren.",
        "Ein Algorithmus zur Kompression der Bilddaten vor der Verarbeitung.",
        "Ein Verfahren zur künstlichen Vergrößerung des Trainingsdatensatzes (Data Augmentation)."
      ],
      "answer": 1,
      "explanation": "Ein Filter ist der zentrale Baustein eines Convolutional Layers. Er fungiert als Merkmalsdetektor (z.B. für Kanten, Ecken, Texturen), dessen Gewichte während des Trainings gelernt werden.",
      "weight": 1,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Reproduktion",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "24. Was ist der Zweck eines Pooling-Layers in einem CNN?",
      "options": [
        "Die Anzahl der Parameter im Netzwerk zu erhöhen.",
        "Die räumliche Dimension der Feature Maps zu reduzieren (Downsampling).",
        "Die Eingabebilder zu normalisieren.",
        "Eine nichtlineare Aktivierung auf die Feature Map anzuwenden."
      ],
      "answer": 1,
      "explanation": "Pooling (z.B. Max-Pooling) reduziert die Größe der Feature Maps, was die Anzahl der Parameter und den Rechenaufwand in nachfolgenden Schichten verringert. Es hilft auch, das Modell robuster gegenüber kleinen Verschiebungen im Bild zu machen.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "25. Was unterscheidet die Filter in CNNs von klassischen Bildverarbeitungsfiltern wie dem Sobel-Filter?",
      "options": [
        "Klassische Filter sind fest definiert, während die Filter in CNNs während des Trainings gelernt werden.",
        "CNN-Filter sind immer signifikant größer als klassische Filter, um globale Merkmale zu erfassen.",
        "Klassische Filter können keine Kanten oder Texturen im Bild erkennen.",
        "CNN-Filter benötigen keine nichtlineare Aktivierungsfunktion nach der Anwendung."
      ],
      "answer": 0,
      "explanation": "Der entscheidende Unterschied ist, dass die Werte der Filtermatrizen in einem CNN nicht von einem Menschen entworfen, sondern durch `Backpropagation` gelernt werden. Das Netzwerk findet so selbst die optimalen Filter für die gegebene Aufgabe.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "26. Was ist eine `Feature Map` in einem CNN?",
      "options": [
        "Eine grafische Darstellung der wichtigsten Features im Trainingsdatensatz.",
        "Die Ausgabe eines Filters nach der Faltungsoperation, die die Aktivierung eines Merkmals anzeigt.",
        "Ein spezieller Datensatz, der ausschließlich zur Bewertung der Merkmalsextraktion verwendet wird.",
        "Ein Layer, der neue Features durch die Kombination bestehender Features erzeugt."
      ],
      "answer": 1,
      "explanation": "Eine `Feature Map` ist das Ergebnis der Anwendung eines Filters auf eine Eingabe. Sie ist eine 2D-Karte, deren Werte anzeigen, wie stark das vom Filter gesuchte Merkmal an der jeweiligen Position der Eingabe vorhanden ist.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "27. Aus welchen zwei Hauptkomponenten besteht ein Generative Adversarial Network (GAN)?",
      "options": [
        "Einem Encoder und einem Decoder.",
        "Einem Generator und einem Diskriminator.",
        "Einem Convolutional Layer und einem Pooling Layer.",
        "Einem Agenten und einer Umgebung."
      ],
      "answer": 1,
      "explanation": "Ein GAN besteht aus zwei neuronalen Netzen, die gegeneinander antreten: Der Generator versucht, realistische Daten zu erzeugen, während der Diskriminator versucht, echte von gefälschten Daten zu unterscheiden.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (GAN)"
    },
    {
      "question": "28. Was ist das Ziel des Generators in einem GAN?",
      "options": [
        "Die Trainingsdaten möglichst exakt zu kopieren.",
        "Den Diskriminator zu täuschen, indem er Daten erzeugt, die von echten Daten nicht zu unterscheiden sind.",
        "Die Wahrscheinlichkeit zu berechnen, dass eine Eingabe echt ist.",
        "Die Dimension der Eingabedaten zu reduzieren."
      ],
      "answer": 1,
      "explanation": "Das Ziel des Generators ist es, aus zufälligem Rauschen Daten zu synthetisieren, die so realistisch sind, dass der Diskriminator sie als echt klassifiziert. Er lernt dabei die zugrundeliegende Verteilung der Trainingsdaten.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (GAN)"
    },
    {
      "question": "29. Was ist das Hauptproblem beim Training von RNNs mit langen Sequenzen?",
      "options": [
        "Overfitting",
        "Das Vanishing- oder Exploding-Gradient-Problem.",
        "Hoher Speicherverbrauch.",
        "Langsames Training."
      ],
      "answer": 1,
      "explanation": "Bei langen Sequenzen muss der Gradient über viele Zeitschritte zurückpropagiert werden. Dabei kann er exponentiell klein (vanishing) oder groß (exploding) werden, was das Lernen von Langzeitabhängigkeiten verhindert.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (RNN)"
    },
    {
      "question": "30. Wie lösen LSTMs das Vanishing-Gradient-Problem?",
      "options": [
        "Durch die Verwendung einer linearen Aktivierungsfunktion.",
        "Durch den Einsatz von 'Gates' (Input, Forget, Output), die den Informationsfluss steuern.",
        "Indem sie die Sequenzlänge auf ein Maximum von 10 Schritten begrenzen.",
        "Durch die Anwendung von Batch Normalization in jedem Zeitschritt."
      ],
      "answer": 1,
      "explanation": "LSTMs besitzen einen 'Zellzustand' und spezielle 'Gates', die lernen, welche Informationen sie speichern, vergessen oder ausgeben sollen. Dies ermöglicht einen ungehinderten Gradientenfluss über lange Zeiträume.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Analyse",
      "concept": "Architekturen (RNN)"
    },
    {
      "question": "31. Was ist der Kern des Attention-Mechanismus, wie er in Transformern verwendet wird?",
      "options": [
        "Er fokussiert sich nur auf das letzte Wort in einem Satz.",
        "Er berechnet für jedes Wort eine gewichtete Summe aller anderen Wörter im Satz.",
        "Er verwendet einen festen Kontextvektor für den gesamten Satz.",
        "Er ersetzt alle Wörter durch ihre häufigsten Synonyme."
      ],
      "answer": 1,
      "explanation": "Der Self-Attention-Mechanismus erlaubt es dem Modell, die Wichtigkeit jedes anderen Wortes in der Eingabesequenz für die Repräsentation eines bestimmten Wortes zu bewerten. Dies ermöglicht die Modellierung komplexer Abhängigkeiten unabhängig von der Distanz.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Analyse",
      "concept": "Architekturen (Transformer)"
    },
    {
      "question": "32. Was ist ein wesentlicher Vorteil von Transformern gegenüber RNNs?",
      "options": [
        "Sie sind einfacher zu implementieren und haben weniger Hyperparameter.",
        "Sie können aufgrund des fehlenden rekurrenten Charakters stark parallelisiert werden.",
        "Sie benötigen signifikant weniger Trainingsdaten.",
        "Sie sind von Natur aus immun gegen Overfitting."
      ],
      "answer": 1,
      "explanation": "Da RNNs Sequenzen Schritt für Schritt verarbeiten müssen, ist ihre Parallelisierung schwierig. Transformer verarbeiten alle Elemente der Sequenz gleichzeitig, was das Training auf moderner Hardware (GPUs/TPUs) erheblich beschleunigt.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Analyse",
      "concept": "Architekturen (Transformer)"
    },
    {
      "question": "33. Was ist Transfer Learning im Kontext von Deep Learning?",
      "options": [
        "Das Trainieren eines Modells von Grund auf mit einem sehr großen Datensatz.",
        "Die Verwendung eines auf einer großen Aufgabe vortrainierten Modells als Ausgangspunkt für eine neue, spezifischere Aufgabe.",
        "Die Übertragung eines Modells von einer Programmiersprache in eine andere.",
        "Das Trainieren mehrerer Modelle auf verschiedenen Teilen eines Datensatzes."
      ],
      "answer": 1,
      "explanation": "Beim Transfer Learning nutzt man das Wissen (die gelernten Features) eines Modells, das auf einem riesigen Datensatz (z.B. ImageNet) trainiert wurde, und passt es mit einem kleineren, aufgabenspezifischen Datensatz an. Dies spart enorm viel Zeit und Daten.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "34. Was ist Data Augmentation?",
      "options": [
        "Das manuelle Hinzufügen von neuen, gelabelten Daten zum Trainingsset.",
        "Eine Technik, um die Anzahl der Layer in einem neuronalen Netz zu erhöhen.",
        "Das künstliche Erzeugen neuer Trainingsdaten durch Transformationen der bestehenden Daten (z.B. Drehen, Spiegeln von Bildern).",
        "Das Entfernen von Ausreißern aus dem Datensatz."
      ],
      "answer": 2,
      "explanation": "Data Augmentation ist eine effektive Methode, um Overfitting zu reduzieren. Indem man leicht veränderte Versionen der Trainingsbilder erzeugt, 'sieht' das Modell mehr Variationen und lernt, robustere Merkmale zu erkennen.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "35. Was ist der Unterschied zwischen einem 'Dense' Layer und einem 'Convolutional' Layer?",
      "options": [
        "Ein Dense Layer ist nur für die Eingabeschicht, ein Convolutional Layer nur für die Ausgabeschicht.",
        "In einem Dense Layer ist jedes Neuron mit jedem Neuron der vorherigen Schicht verbunden, in einem Convolutional Layer nur mit einer lokalen Region.",
        "Convolutional Layer haben mehr Parameter als Dense Layer.",
        "Dense Layer werden für Bilder, Convolutional Layer für Text verwendet."
      ],
      "answer": 1,
      "explanation": "Diese unterschiedliche Konnektivität ist der Kernunterschied. Dense (oder Fully-Connected) Layer lernen globale Muster, während Convolutional Layer durch ihre lokalen rezeptiven Felder lokale, räumliche Muster lernen.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Anwendung",
      "concept": "Grundlagen"
    },
    {
      "question": "36. Was ist ein 'Hyperparameter'?",
      "options": [
        "Ein Gewicht oder Bias, das während des Trainings gelernt wird.",
        "Ein Parameter, der vor dem Trainingsprozess festgelegt wird und diesen steuert (z.B. Lernrate, Anzahl der Layer).",
        "Ein Maß für die Leistung des Modells auf dem Testdatensatz.",
        "Die Ausgabe der Verlustfunktion nach einer Trainingsepoche."
      ],
      "answer": 1,
      "explanation": "Hyperparameter sind die 'Stellschrauben' eines Modells, die nicht durch das Training gelernt, sondern vom Entwickler festgelegt werden. Die Suche nach den optimalen Hyperparametern ist ein wichtiger Teil des ML-Prozesses.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "37. Was ist der Zweck eines Validierungsdatensatzes (Validation Set)?",
      "options": [
        "Er wird verwendet, um die finalen Gewichte des Modells zu trainieren.",
        "Er dient zur Abstimmung der Hyperparameter und zur Überwachung von Overfitting während des Trainings.",
        "Er wird nur einmal ganz am Ende verwendet, um die finale, unverfälschte Leistung des Modells zu bewerten.",
        "Er ist eine exakte Kopie des Trainingsdatensatzes zur Überprüfung der Konsistenz."
      ],
      "answer": 1,
      "explanation": "Der Validierungsdatensatz wird während des Trainings verwendet, um die Leistung des Modells auf ungesehenen Daten zu schätzen. Dies hilft bei der Hyperparameter-Optimierung (z.B. welche Lernrate?) und beim Early Stopping.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "38. Was ist der 'Curse of Dimensionality' (Fluch der Dimensionalität)?",
      "options": [
        "Das Phänomen, dass die Leistung von ML-Modellen mit zunehmender Anzahl von Features abnimmt.",
        "Die Tatsache, dass Daten in hochdimensionalen Räumen sehr spärlich werden und Distanzmaße ihre Aussagekraft verlieren.",
        "Die Notwendigkeit, bei hochdimensionalen Daten immer Deep Learning zu verwenden.",
        "Ein Fehler, der auftritt, wenn ein Datensatz mehr Spalten als Zeilen hat."
      ],
      "answer": 1,
      "explanation": "In hochdimensionalen Räumen liegen die Datenpunkte tendenziell weit voneinander entfernt. Dies macht Algorithmen, die auf Distanzmessungen basieren (wie KNN), weniger effektiv und erfordert exponentiell mehr Daten, um den Raum abzudecken.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Analyse",
      "concept": "Grundlagen"
    },
    {
      "question": "39. Was ist der Unterschied zwischen 'Padding' und 'Stride' in einem CNN?",
      "options": [
        "Padding fügt Nullen am Rand des Bildes hinzu, Stride bestimmt die Schrittweite des Filters.",
        "Padding bestimmt die Schrittweite, Stride fügt Nullen hinzu.",
        "Beide Begriffe beschreiben die Größe des Filters.",
        "Padding wird vor, Stride nach der Faltungsoperation angewendet."
      ],
      "answer": 0,
      "explanation": "Padding wird verwendet, um die räumliche Größe der Ausgabe zu steuern (z.B. 'same' padding, um die Größe zu erhalten). Stride (Schrittweite) gibt an, um wie viele Pixel der Filter bei jeder Bewegung verschoben wird.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Anwendung",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "40. Was ist ein Autoencoder?",
      "options": [
        "Ein Supervised-Learning-Modell zur Klassifikation von Bildern.",
        "Ein neuronales Netz, das lernt, seine Eingabe zu rekonstruieren, oft über eine komprimierte Repräsentation.",
        "Ein Algorithmus zur automatischen Generierung von Python-Code.",
        "Ein spezieller Typ eines Reinforcement-Learning-Agenten."
      ],
      "answer": 1,
      "explanation": "Ein Autoencoder besteht aus einem Encoder, der die Eingabe in einen niedrigdimensionalen Code komprimiert, und einem Decoder, der versucht, aus diesem Code die ursprüngliche Eingabe zu rekonstruieren. Er wird für Dimensionsreduktion und Anomalieerkennung verwendet.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Analyse",
      "concept": "Architekturen (Sonstige)"
    },
    {
      "question": "41. Was ist die 'Cross-Entropy Loss'?",
      "options": [
        "Eine Verlustfunktion, die typischerweise für Regressionsprobleme verwendet wird.",
        "Eine Verlustfunktion, die für Klassifikationsprobleme verwendet wird und den Unterschied zwischen zwei Wahrscheinlichkeitsverteilungen misst.",
        "Eine Metrik zur Messung der Ähnlichkeit zwischen zwei Bildern.",
        "Ein Regularisierungsterm, der zur Vermeidung von Overfitting dient."
      ],
      "answer": 1,
      "explanation": "Die Kreuzentropie ist die Standard-Verlustfunktion für Klassifikationsaufgaben. Sie misst, wie gut die vom Modell vorhergesagte Wahrscheinlichkeitsverteilung (nach Softmax) mit der wahren Verteilung (One-Hot-Encoding) übereinstimmt.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Anwendung",
      "concept": "Grundlagen"
    },
    {
      "question": "42. Was ist ein 'One-Hot-Encoding'?",
      "options": [
        "Eine Methode zur Normalisierung von numerischen Daten.",
        "Eine Technik zur Darstellung von kategorialen Variablen als binärer Vektor.",
        "Ein Algorithmus zur Kompression von Bilddaten.",
        "Eine spezielle Art der Gewichtsinitialisierung."
      ],
      "answer": 1,
      "explanation": "Beim One-Hot-Encoding wird eine kategoriale Variable mit N Kategorien in einen Vektor der Länge N umgewandelt, der an der Stelle der jeweiligen Kategorie eine 1 und an allen anderen Stellen Nullen enthält. Dies ist die Standarddarstellung für Zielvariablen in der Klassifikation.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "43. Was ist der Hauptzweck eines 'Embeddings' im NLP-Kontext?",
      "options": [
        "Die Darstellung von Wörtern oder Sätzen als dichte, niedrigdimensionale Vektoren.",
        "Die Zählung der Häufigkeit jedes Wortes in einem Text.",
        "Die Korrektur von Rechtschreibfehlern in einem Text.",
        "Die Übersetzung eines Textes in eine andere Sprache."
      ],
      "answer": 0,
      "explanation": "Word Embeddings (wie Word2Vec oder GloVe) lernen, Wörter in einem Vektorraum so darzustellen, dass Wörter mit ähnlicher Bedeutung nahe beieinander liegen. Diese dichten Vektoren sind eine weitaus reichhaltigere Repräsentation als z.B. One-Hot-Encoding.",
      "weight": 2,
      "topic": "Anwendungen",
      "cognitive_level": "Anwendung",
      "concept": "Anwendungen (NLP)"
    },
    {
      "question": "44. Was ist ein 'Gradient' in Bezug auf eine Verlustfunktion?",
      "options": [
        "Der maximale Wert, den die Verlustfunktion annehmen kann.",
        "Ein Vektor, der in die Richtung des steilsten Anstiegs der Verlustfunktion zeigt.",
        "Ein Hyperparameter, der die Komplexität des Modells steuert.",
        "Die Anzahl der Trainingsbeispiele in einem Batch."
      ],
      "answer": 1,
      "explanation": "Der Gradient ist die Verallgemeinerung der Ableitung für mehrdimensionale Funktionen. Beim Gradientenabstieg (Gradient Descent) bewegt man sich in die entgegengesetzte Richtung des Gradienten, um das Minimum der Verlustfunktion zu finden.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Anwendung",
      "concept": "Grundlagen"
    },
    {
      "question": "45. Was ist der Unterschied zwischen einem 'Validation Set' und einem 'Test Set'?",
      "options": [
        "Es gibt keinen Unterschied, die Begriffe sind austauschbar.",
        "Das Validation Set wird zum Trainieren, das Test Set zum Validieren verwendet.",
        "Das Validation Set wird zur Hyperparameter-Optimierung, das Test Set zur finalen, einmaligen Leistungsbewertung verwendet.",
        "Das Test Set ist immer größer als das Validation Set."
      ],
      "answer": 2,
      "explanation": "Das Validation Set wird wiederholt während der Entwicklung verwendet, um das Modell zu justieren. Das Test Set wird idealerweise nur ein einziges Mal am Ende verwendet, um eine unverfälschte Schätzung der Leistung des finalen Modells auf völlig neuen Daten zu erhalten.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "46. Was ist ein 'Residual Connection' (oder Skip Connection), wie sie in ResNets verwendet wird?",
      "options": [
        "Eine Verbindung, die die Ausgabeschicht direkt mit der Eingabeschicht verbindet.",
        "Eine Verbindung, die die Eingabe eines Blocks zur Ausgabe dieses Blocks addiert.",
        "Eine Methode, um die Anzahl der Neuronen in einem Layer zu reduzieren.",
        "Eine spezielle Art von Dropout."
      ],
      "answer": 1,
      "explanation": "Residual Connections ermöglichen es dem Gradienten, beim Backpropagation direkt durch einige Schichten 'hindurchzufließen'. Dies erleichtert das Training von sehr tiefen Netzwerken, indem es dem Vanishing-Gradient-Problem entgegenwirkt.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "cognitive_level": "Analyse",
      "concept": "Architekturen (CNN)"
    },
    {
      "question": "47. Was ist der Hauptzweck von Reinforcement Learning (RL)?",
      "options": [
        "Das Finden von Mustern in ungelabelten Daten.",
        "Die Klassifikation von Daten in vordefinierte Kategorien.",
        "Das Trainieren eines Agenten, eine Sequenz von Aktionen in einer Umgebung auszuführen, um eine Belohnung zu maximieren.",
        "Die Generierung neuer, realistischer Daten."
      ],
      "answer": 2,
      "explanation": "Beim RL lernt ein Agent durch Versuch und Irrtum (Trial and Error). Er interagiert mit einer Umgebung und erhält Belohnungen oder Bestrafungen für seine Aktionen, mit dem Ziel, eine Strategie (Policy) zu lernen, die die kumulative Belohnung maximiert.",
      "weight": 2,
      "topic": "Reinforcement Learning",
      "cognitive_level": "Anwendung",
      "concept": "Reinforcement Learning"
    },
    {
      "question": "48. Was ist der 'Exploration-Exploitation Trade-off' im Reinforcement Learning?",
      "options": [
        "Der Kompromiss zwischen der Verwendung von viel oder wenig Speicher.",
        "Der Kompromiss zwischen dem Ausprobieren neuer Aktionen (Exploration) und dem Nutzen bekannter, guter Aktionen (Exploitation).",
        "Der Kompromiss zwischen einem einfachen und einem komplexen Modell.",
        "Der Kompromiss zwischen Trainingszeit und Modellgenauigkeit."
      ],
      "answer": 1,
      "explanation": "Ein RL-Agent muss entscheiden, ob er eine Aktion wählt, von der er bereits weiß, dass sie gut ist (Exploitation), oder ob er eine neue, unbekannte Aktion ausprobiert, die potenziell noch besser sein könnte (Exploration). Dies ist eine zentrale Herausforderung im RL.",
      "weight": 3,
      "topic": "Reinforcement Learning",
      "cognitive_level": "Analyse",
      "concept": "Reinforcement Learning"
    },
    {
      "question": "49. Was ist ein 'Epoch' im Deep Learning?",
      "options": [
        "Die Verarbeitung eines einzelnen Datenpunktes.",
        "Ein kompletter Durchlauf durch den gesamten Trainingsdatensatz.",
        "Die Anzahl der Layer in einem neuronalen Netz.",
        "Ein einzelner Schritt der Gewichtsaktualisierung."
      ],
      "answer": 1,
      "explanation": "Eine Epoche ist abgeschlossen, wenn das Modell jeden Datenpunkt des Trainingsdatensatzes einmal gesehen hat. Das Training eines Modells erstreckt sich typischerweise über viele Epochen.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "cognitive_level": "Reproduktion",
      "concept": "Grundlagen"
    },
    {
      "question": "50. Was ist der Unterschied zwischen einem 'Dense' Layer und einem 'Embedding' Layer?",
      "options": [
        "Ein Dense Layer ist für die Eingabe, ein Embedding Layer für die Ausgabe.",
        "Ein Dense Layer führt eine Matrix-Vektor-Multiplikation durch, während ein Embedding Layer eine Nachschlagetabelle für kategoriale Eingaben ist.",
        "Ein Embedding Layer hat immer mehr Parameter als ein Dense Layer.",
        "Es gibt keinen funktionalen Unterschied."
      ],
      "answer": 1,
      "explanation": "Ein Embedding Layer ist eine effiziente Methode, um hochdimensionale, dünn besetzte kategoriale Daten (wie Wörter in einem Vokabular) in dichte, niedrigdimensionale Vektoren umzuwandeln. Es ist im Wesentlichen eine lernbare Nachschlagetabelle, während ein Dense Layer eine vollständige lineare Transformation durchführt.",
      "weight": 3,
      "topic": "Anwendungen",
      "cognitive_level": "Analyse",
      "concept": "Anwendungen (NLP)"
    },
    {
      "question_id": "Q001",
      "question": "51. What is the primary difference between traditional machine learning and deep learning?",
      "options": [
        "Deep learning requires more computational resources",
        "Deep learning can automatically learn hierarchical features from data",
        "Deep learning works only with structured data",
        "Deep learning eliminates the need for data preprocessing"
      ],
      "answer": 1,
      "explanation": "Deep learning differs from traditional machine learning by automatically learning hierarchical features from raw data through multiple layers of neural networks, rather than requiring manual feature engineering.",
      "weight": 1,
      "topic": "Neuronale Netze – Grundlagen",
      "concept": "Feature Learning Hierarchy",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Feature Learning",
          "definition": "The process by which deep learning models automatically extract and learn relevant features from raw input data"
        },
        {
          "term": "Hierarchical Features",
          "definition": "Features that are learned at different levels of abstraction, from simple edges to complex object recognition"
        }
      ]
    },
    {
      "question_id": "Q002",
      "question": "52. Which activation function is commonly used in the output layer for binary classification tasks in deep learning?",
      "options": [
        "ReLU",
        "Sigmoid",
        "Tanh",
        "Softmax"
      ],
      "answer": 1,
      "explanation": "The sigmoid activation function outputs values between 0 and 1, making it suitable for binary classification where the output represents probability.",
      "weight": 1,
      "topic": "Neuronale Netze – Grundlagen",
      "concept": "Activation Functions",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Activation Function",
          "definition": "A mathematical function applied to the output of each neuron that introduces non-linearity into the network"
        },
        {
          "term": "Sigmoid",
          "definition": "An S-shaped activation function that maps input values to a range between 0 and 1"
        }
      ]
    },
    {
      "question_id": "Q003",
      "question": "53. What does CNN stand for in the context of deep learning?",
      "options": [
        "Central Neural Network",
        "Convolutional Neural Network",
        "Computational Neural Network",
        "Connected Neural Network"
      ],
      "answer": 1,
      "explanation": "CNN stands for Convolutional Neural Network, a specialized type of neural network designed for processing grid-like data such as images.",
      "weight": 1,
      "topic": "Netzarchitekturen",
      "concept": "CNN Architecture",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Convolutional Neural Network",
          "definition": "A deep learning architecture specifically designed for processing grid-structured data like images"
        },
        {
          "term": "Grid-like Data",
          "definition": "Data that has a spatial structure, such as pixels in an image arranged in a 2D grid"
        }
      ]
    },
    {
      "question_id": "Q004",
      "question": "54. Which optimization algorithm is most commonly used for training deep neural networks?",
      "options": [
        "Gradient Descent",
        "Adam",
        "Newton's Method",
        "Genetic Algorithms"
      ],
      "answer": 1,
      "explanation": "Adam (Adaptive Moment Estimation) is the most widely used optimization algorithm for training deep neural networks due to its adaptive learning rates and momentum.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "concept": "Optimization Methods",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Adam Optimizer",
          "definition": "An adaptive optimization algorithm that combines the benefits of AdaGrad and RMSProp"
        },
        {
          "term": "Adaptive Learning Rate",
          "definition": "A learning rate that adjusts itself during training based on the historical gradients"
        }
      ]
    },
    {
      "question_id": "Q005",
      "question": "55. What is the purpose of dropout in deep neural networks?",
      "options": [
        "To reduce training time",
        "To prevent overfitting",
        "To increase model complexity",
        "To speed up inference"
      ],
      "answer": 1,
      "explanation": "Dropout randomly deactivates neurons during training to prevent overfitting by forcing the network to learn redundant representations.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "concept": "Overfitting Prevention",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Dropout",
          "definition": "A regularization technique that randomly drops neurons during training to prevent overfitting"
        },
        {
          "term": "Overfitting",
          "definition": "When a model learns the training data too well and performs poorly on unseen data"
        }
      ]
    },
    {
      "question_id": "Q006",
      "question": "56. What does RNN stand for and what makes it different from feedforward neural networks?",
      "options": [
        "Recurrent Neural Network; it has feedback connections",
        "Recursive Neural Network; it processes hierarchical data",
        "Regional Neural Network; it focuses on local features",
        "Random Neural Network; it uses stochastic connections"
      ],
      "answer": 0,
      "explanation": "RNN stands for Recurrent Neural Network and differs from feedforward networks by having feedback connections that allow it to maintain memory of previous inputs.",
      "weight": 1,
      "topic": "Netzarchitekturen",
      "concept": "Temporal Dependencies",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Recurrent Neural Network",
          "definition": "A type of neural network designed to process sequential data by maintaining an internal state"
        },
        {
          "term": "Feedback Connections",
          "definition": "Connections that allow information to flow backwards in time within the network"
        }
      ]
    },
    {
      "question_id": "Q007",
      "question": "57. You are training a neural network and notice that the validation loss is increasing while training loss decreases. What regularization technique would you apply to address this issue?",
      "options": [
        "Increase the learning rate",
        "Add dropout layers",
        "Remove batch normalization",
        "Increase model complexity"
      ],
      "answer": 1,
      "explanation": "Adding dropout layers would help prevent overfitting, which is indicated by decreasing training loss but increasing validation loss.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "concept": "Overfitting Diagnosis",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Diagnosing and Treating Overfitting",
        "steps": [
          "Monitor both training and validation loss during training",
          "Identify overfitting when validation loss increases while training loss decreases",
          "Apply regularization techniques like dropout or L2 regularization",
          "Consider early stopping or reducing model complexity"
        ],
        "content": "Overfitting occurs when a model learns the training data too well but fails to generalize to unseen data. The gap between training and validation performance is a clear indicator."
      },
      "mini_glossary": [
        {
          "term": "Validation Loss",
          "definition": "The loss calculated on a separate validation dataset not used for training"
        },
        {
          "term": "Overfitting",
          "definition": "When a model performs well on training data but poorly on unseen data"
        }
      ]
    },
    {
      "question_id": "Q008",
      "question": "58. In a convolutional neural network, what happens during the pooling operation?",
      "options": [
        "Feature maps are combined through matrix multiplication",
        "Spatial dimensions are reduced while preserving important features",
        "New channels are added to the feature maps",
        "The network learns new convolutional filters"
      ],
      "answer": 1,
      "explanation": "Pooling operations reduce the spatial dimensions of feature maps by selecting the maximum or average value from small regions, helping to make the network more robust to small translations.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "concept": "Spatial Reduction",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Understanding Pooling in CNNs",
        "steps": [
          "Feature maps from convolution contain spatial information",
          "Pooling divides each feature map into small regions",
          "Max pooling selects the highest value, average pooling computes the mean",
          "Result is a smaller feature map that retains important features"
        ],
        "content": "Pooling helps reduce computational complexity and provides translation invariance by focusing on the most important features in local regions."
      },
      "mini_glossary": [
        {
          "term": "Pooling",
          "definition": "A downsampling operation that reduces the spatial size of feature maps"
        },
        {
          "term": "Max Pooling",
          "definition": "A pooling operation that selects the maximum value from each region"
        }
      ]
    },
    {
      "question_id": "Q009",
      "question": "59. You have a dataset with 10,000 images for training a CNN. How would you handle the vanishing gradient problem during training?",
      "options": [
        "Use only sigmoid activation functions",
        "Implement batch normalization",
        "Apply skip connections (residual learning)",
        "Reduce the learning rate to very small values"
      ],
      "answer": 2,
      "explanation": "Skip connections in residual networks allow gradients to flow directly through the network, helping to mitigate the vanishing gradient problem in deep networks.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "concept": "Gradient Flow",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Solving the Vanishing Gradient Problem",
        "steps": [
          "Understand that vanishing gradients occur in deep networks due to repeated multiplication",
          "Implement skip connections that allow direct gradient flow",
          "Use activation functions like ReLU that don't saturate",
          "Apply batch normalization to stabilize training"
        ],
        "content": "The vanishing gradient problem makes it difficult to train deep networks and were a major challenge before techniques like ReLU and residual connections."
      },
      "mini_glossary": [
        {
          "term": "Vanishing Gradient",
          "definition": "The problem where gradients become extremely small in deep networks, preventing effective learning"
        },
        {
          "term": "Skip Connections",
          "definition": "Direct connections that bypass one or more layers, allowing gradients to flow more easily"
        }
      ]
    },
    {
      "question_id": "Q010",
      "question": "60. When implementing transfer learning for image classification, which layers of a pre-trained CNN would you typically fine-tune?",
      "options": [
        "Only the input layer",
        "Only the fully connected layers at the end",
        "All layers equally",
        "Only the convolutional layers in the middle"
      ],
      "answer": 1,
      "explanation": "In transfer learning, you typically freeze the early convolutional layers (which learn general features) and fine-tune only the later fully connected layers for the specific task.",
      "weight": 2,
      "topic": "Anwendungen",
      "concept": "Layer Fine-tuning",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Transfer Learning Strategy",
        "steps": [
          "Load a pre-trained model trained on a large dataset",
          "Freeze the early layers that learn general features",
          "Replace and train the final fully connected layers",
          "Optionally fine-tune some of the later convolutional layers"
        ],
        "content": "Transfer learning leverages knowledge from pre-trained models, significantly reducing training time and data requirements for new tasks."
      },
      "mini_glossary": [
        {
          "term": "Transfer Learning",
          "definition": "Using a pre-trained model as a starting point for a different but related task"
        },
        {
          "term": "Fine-tuning",
          "definition": "The process of slightly adjusting a pre-trained model's weights for a new task"
        }
      ]
    },
    {
      "question_id": "Q011",
      "question": "61. In sequence-to-sequence models, what is the purpose of the attention mechanism?",
      "options": [
        "To reduce model size",
        "To focus on relevant parts of the input sequence",
        "To speed up training",
        "To prevent overfitting"
      ],
      "answer": 1,
      "explanation": "Attention mechanisms allow the model to focus on relevant parts of the input sequence when generating each output element, improving performance on long sequences.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "concept": "Attention Mechanism",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "How Attention Works in Seq2Seq",
        "steps": [
          "For each output position, compute attention scores with all input positions",
          "Convert scores to probabilities using softmax",
          "Weight the input representations by these probabilities",
          "Use the weighted sum as context for generating the output"
        ],
        "content": "Attention solves the bottleneck problem of fixed-length context vectors in basic seq2seq models by allowing dynamic focus on relevant input parts."
      },
      "mini_glossary": [
        {
          "term": "Attention Mechanism",
          "definition": "A technique that allows models to focus on relevant parts of the input when generating output"
        },
        {
          "term": "Sequence-to-Sequence",
          "definition": "Models that transform one sequence into another, like machine translation"
        }
      ]
    },
    {
      "question_id": "Q012",
      "question": "62. You are designing a neural network for time series prediction. Which architecture would be most appropriate?",
      "options": [
        "Convolutional Neural Network",
        "Recurrent Neural Network",
        "Feedforward Neural Network",
        "Autoencoder"
      ],
      "answer": 1,
      "explanation": "RNNs are designed to handle sequential data and maintain temporal dependencies, making them ideal for time series prediction tasks.",
      "weight": 2,
      "topic": "Netzarchitekturen",
      "concept": "Sequential Modeling",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Choosing Architecture for Time Series",
        "steps": [
          "Identify that time series data has temporal dependencies",
          "Consider RNN/LSTM/GRU for maintaining memory of past values",
          "CNNs can work for pattern recognition but lack temporal memory",
          "Feedforward networks can't handle sequences without preprocessing"
        ],
        "content": "The choice of architecture depends on the nature of temporal dependencies in your data and the prediction horizon."
      },
      "mini_glossary": [
        {
          "term": "Time Series",
          "definition": "Data points collected at regular time intervals"
        },
        {
          "term": "Temporal Dependencies",
          "definition": "Relationships between data points that depend on their time ordering"
        }
      ]
    },
    {
      "question_id": "Q013",
      "question": "63. What is the vanishing gradient problem and how does it affect training of deep networks?",
      "options": [
        "Gradients become too large, causing unstable training",
        "Gradients become too small, preventing weight updates",
        "The loss function becomes non-convex",
        "The network becomes too complex to optimize"
      ],
      "answer": 1,
      "explanation": "The vanishing gradient problem occurs when gradients become extremely small during backpropagation in deep networks, preventing effective learning in early layers.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "concept": "Gradient Issues",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Understanding Vanishing Gradients",
        "steps": [
          "During backpropagation, gradients are multiplied through many layers",
          "Activation functions like sigmoid have derivatives less than 1",
          "Repeated multiplication of small numbers leads to vanishing gradients",
          "Early layers receive tiny gradients and learn very slowly"
        ],
        "content": "Vanishing gradients make it difficult to train deep networks and were a major challenge before techniques like ReLU and residual connections."
      },
      "mini_glossary": [
        {
          "term": "Backpropagation",
          "definition": "The algorithm used to compute gradients and update weights in neural networks"
        },
        {
          "term": "Vanishing Gradient",
          "definition": "The problem where gradients become extremely small, preventing learning in deep layers"
        }
      ]
    },
    {
      "question_id": "Q014",
      "question": "64. In the context of object detection, what is the difference between Faster R-CNN and YOLO?",
      "options": [
        "Faster R-CNN is real-time, YOLO is not",
        "YOLO processes the entire image at once, Faster R-CNN uses region proposals",
        "Faster R-CNN works only with small images",
        "YOLO requires more training data"
      ],
      "answer": 1,
      "explanation": "YOLO processes the entire image in a single pass to predict bounding boxes and classes simultaneously, while Faster R-CNN uses a two-stage approach with region proposal networks.",
      "weight": 2,
      "topic": "Anwendungen",
      "concept": "Detection Architectures",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Comparing Detection Architectures",
        "steps": [
          "Faster R-CNN: Two-stage approach - propose regions, then classify",
          "YOLO: Single-stage approach - predict directly from grid cells",
          "Faster R-CNN typically more accurate but slower",
          "YOLO is faster and real-time capable but may have lower accuracy"
        ],
        "content": "The choice between architectures depends on the trade-off between speed and accuracy requirements."
      },
      "mini_glossary": [
        {
          "term": "Object Detection",
          "definition": "The task of identifying and locating objects within an image"
        },
        {
          "term": "Region Proposals",
          "definition": "Candidate regions in an image that might contain objects"
        }
      ]
    },
    {
      "question_id": "Q015",
      "question": "65. Analyze why batch normalization improves training stability in deep networks.",
      "options": [
        "It reduces the learning rate requirements",
        "It normalizes layer inputs to have zero mean and unit variance",
        "It increases the model capacity",
        "It reduces the number of parameters"
      ],
      "answer": 1,
      "explanation": "Batch normalization normalizes the inputs to each layer to have zero mean and unit variance, reducing internal covariate shift and making training more stable.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Normalization Techniques",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "How Batch Normalization Works",
        "steps": [
          "Compute mean and variance across the batch for each feature",
          "Normalize the features to zero mean and unit variance",
          "Scale and shift using learned parameters γ and β",
          "Apply the transformation to stabilize training"
        ],
        "content": "Batch normalization reduces internal covariate shift, allowing higher learning rates and more stable training by keeping layer inputs in a consistent range."
      },
      "mini_glossary": [
        {
          "term": "Batch Normalization",
          "definition": "A technique that normalizes layer inputs across a mini-batch to improve training stability"
        },
        {
          "term": "Internal Covariate Shift",
          "definition": "The change in the distribution of layer inputs during training"
        }
      ]
    },
    {
      "question_id": "Q016",
      "question": "66. Evaluate the trade-offs between using a larger batch size versus a smaller batch size in deep learning training.",
      "options": [
        "Larger batches always train faster and achieve better accuracy",
        "Smaller batches provide better generalization but may be unstable",
        "Batch size has no significant impact on training",
        "Larger batches always lead to overfitting"
      ],
      "answer": 1,
      "explanation": "Smaller batches provide better generalization by introducing noise that acts as regularization, but may be less stable. Larger batches train faster but may lead to poorer generalization.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Batch Size Optimization",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Batch Size Trade-offs Analysis",
        "steps": [
          "Larger batches: Faster training, more stable gradients, but poorer generalization",
          "Smaller batches: Slower training, noisier gradients, but better generalization",
          "Consider memory constraints and dataset size",
          "Often use larger batches during training, smaller for fine-tuning"
        ],
        "content": "The optimal batch size depends on the specific task, dataset, and computational resources available."
      },
      "mini_glossary": [
        {
          "term": "Batch Size",
          "definition": "The number of training examples processed together in one forward/backward pass"
        },
        {
          "term": "Generalization",
          "definition": "How well a trained model performs on unseen data"
        }
      ]
    },
    {
      "question_id": "Q017",
      "question": "67. Compare and contrast generative adversarial networks (GANs) with variational autoencoders (VAEs) for generative modeling.",
      "options": [
        "GANs are supervised, VAEs are unsupervised",
        "GANs learn implicitly through adversarial training, VAEs learn explicitly through reconstruction",
        "VAEs are better for image generation, GANs for text generation",
        "GANs require paired data, VAEs work with unpaired data"
      ],
      "answer": 1,
      "explanation": "GANs learn data distributions implicitly through adversarial training between generator and discriminator, while VAEs learn explicitly by reconstructing inputs through a bottleneck latent space.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "concept": "Learning Paradigms",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "GANs vs VAEs Comparison",
        "steps": [
          "GANs: Generator creates fake data, discriminator distinguishes real from fake",
          "VAEs: Encoder compresses to latent space, decoder reconstructs from latent vectors",
          "GANs often produce sharper images but can be unstable",
          "VAEs provide smoother latent spaces but may produce blurrier outputs"
        ],
        "content": "Both approaches have different strengths: GANs excel at generating high-quality samples, while VAEs provide better latent space properties for interpolation and manipulation."
      },
      "mini_glossary": [
        {
          "term": "Generative Adversarial Network",
          "definition": "A framework where two neural networks compete: generator creates fake data, discriminator detects fakes"
        },
        {
          "term": "Variational Autoencoder",
          "definition": "A generative model that learns to encode data into a latent space and decode it back"
        }
      ]
    },
    {
      "question_id": "Q018",
      "question": "68. Analyze how self-attention mechanisms in transformers differ from traditional RNN approaches for sequence processing.",
      "options": [
        "Self-attention can only process fixed-length sequences",
        "Self-attention allows parallel processing and better long-range dependencies",
        "RNNs are better at capturing local dependencies",
        "Transformers require sequential processing like RNNs"
      ],
      "answer": 1,
      "explanation": "Self-attention processes all positions simultaneously, allowing parallel computation and better modeling of long-range dependencies compared to RNNs which process sequentially.",
      "weight": 3,
      "topic": "Netzarchitekturen",
      "concept": "Parallel Processing",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Transformers vs RNNs",
        "steps": [
          "RNNs process sequences step-by-step, creating bottlenecks",
          "Self-attention computes all pairwise interactions simultaneously",
          "This allows parallel processing and better long-range modeling",
          "Transformers can capture dependencies regardless of distance"
        ],
        "content": "The shift from RNNs to transformers represents a fundamental change in how we process sequential data, enabling much more efficient and effective modeling."
      },
      "mini_glossary": [
        {
          "term": "Self-Attention",
          "definition": "A mechanism that computes relationships between all positions in a sequence simultaneously"
        },
        {
          "term": "Transformer",
          "definition": "A neural network architecture based entirely on attention mechanisms"
        }
      ]
    },
    {
      "question_id": "Q019",
      "question": "69. Evaluate the impact of different loss functions on training dynamics in deep learning models.",
      "options": [
        "All loss functions converge at the same rate",
        "MSE loss is always better than cross-entropy for classification",
        "The choice of loss function affects gradient magnitudes and convergence",
        "Loss functions only affect the final accuracy, not training dynamics"
      ],
      "answer": 2,
      "explanation": "Different loss functions produce different gradient magnitudes and landscapes, affecting convergence speed, stability, and the types of errors the model makes during training.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Optimization Dynamics",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Loss Function Impact Analysis",
        "steps": [
          "Cross-entropy provides stronger gradients for confident wrong predictions",
          "MSE can be more sensitive to outliers in regression tasks",
          "Focal loss helps with class imbalance by down-weighting easy examples",
          "Robust loss functions can improve training stability"
        ],
        "content": "The choice of loss function is crucial as it directly influences the gradient flow and learning dynamics throughout training."
      },
      "mini_glossary": [
        {
          "term": "Loss Function",
          "definition": "A mathematical function that measures how well a model's predictions match the true values"
        },
        {
          "term": "Gradient Magnitude",
          "definition": "The size of the gradient vector, which determines the step size during optimization"
        }
      ]
    },
    {
      "question_id": "Q020",
      "question": "70. Design a strategy for handling class imbalance in deep learning classification tasks.",
      "options": [
        "Always use the same batch size for all classes",
        "Implement weighted loss functions and data augmentation",
        "Remove minority class samples to balance the dataset",
        "Use only the majority class for training"
      ],
      "answer": 1,
      "explanation": "Class imbalance can be addressed through weighted loss functions that give higher importance to minority classes, data augmentation to increase minority samples, and sampling strategies.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Class Distribution",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Comprehensive Imbalance Handling Strategy",
        "steps": [
          "Assess the degree of class imbalance in your dataset",
          "Use weighted loss functions to penalize minority class errors more",
          "Apply data augmentation specifically to minority classes",
          "Consider oversampling, undersampling, or synthetic sample generation",
          "Use appropriate evaluation metrics beyond accuracy"
        ],
        "content": "Handling class imbalance requires a multi-faceted approach combining data-level techniques, algorithm-level modifications, and proper evaluation strategies."
      },
      "mini_glossary": [
        {
          "term": "Class Imbalance",
          "definition": "When some classes in a dataset have significantly fewer samples than others"
        },
        {
          "term": "Weighted Loss",
          "definition": "A loss function where different classes contribute differently to the total loss"
        }
      ]
    },
    {
      "question": "71. Was beschreibt maschinelles Lernen am treffendsten?",
      "options": [
        "Computer befolgen feste Regeln, die vollständig vorgegeben sind.",
        "Computer lernen aus Beispieldaten, statt festen Regeln zu folgen.",
        "Computer speichern Daten, ohne daraus etwas abzuleiten.",
        "Computer lösen Aufgaben nur durch Zufall und Ausprobieren."
      ],
      "answer": 1,
      "explanation": "Maschinelles Lernen bedeutet, dass ein System anhand von Daten Muster erkennt und dadurch bessere Vorhersagen oder Entscheidungen treffen kann. Es geht nicht darum, jede Regel manuell zu programmieren. Reines Speichern ohne Lernen ist keine ML-Leistung.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "concept": "Lernen aus Daten",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "MaschinellesLernen",
          "definition": "Ansatz, bei dem Computer aus Beispieldaten Muster ableiten, um Aufgaben besser zu lösen, statt nur feste Regeln auszuführen."
        },
        {
          "term": "Beispieldaten",
          "definition": "Daten, an denen ein Modell typische Zusammenhänge und Strukturen für eine Aufgabe erkennt."
        }
      ]
    },
    {
      "question": "72. Was ist im überwachten Lernen mit einem „Label“ gemeint?",
      "options": [
        "Ein zufälliger Identifikationscode, der Daten verschlüsselt.",
        "Eine vorgegebene korrekte Antwort zu einem Trainingsbeispiel.",
        "Eine Liste aller Merkmale ohne zugehörige Zielvariable.",
        "Eine Regel, die nach dem Training manuell ergänzt wird."
      ],
      "answer": 1,
      "explanation": "Labels sind die „richtigen Antworten“ in den Trainingsdaten, an denen das Modell lernt. Sie geben vor, welches Ergebnis zu den Merkmalen gehört. Ohne Labels kann ein Modell nicht auf die gleiche Weise gezielt lernen.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "concept": "Labels",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Label",
          "definition": "Vordefinierte korrekte Antwort (Zielwert) zu einem Datenbeispiel im überwachten Lernen."
        },
        {
          "term": "ÜberwachtesLernen",
          "definition": "Lernansatz, der mit gelabelten Daten arbeitet, um präzise Vorhersagen für neue Daten zu treffen."
        }
      ]
    },
    {
      "question": "73. Welche Anwendung passt typischerweise zum unüberwachten Lernen?",
      "options": [
        "Vorhersage eines Immobilienpreises als exakter Zahlenwert.",
        "Einordnung einer E-Mail in „Spam“ oder „kein Spam“.",
        "Automatisches Finden natürlicher Kundengruppen in Rohdaten.",
        "Berechnung einer Temperaturprognose für morgen als Zahl."
      ],
      "answer": 2,
      "explanation": "Unüberwachtes Lernen arbeitet ohne vorgegebene Labels und sucht eigenständig Muster oder Gruppen. Das automatische Finden von Kundensegmenten ist ein klassisches Beispiel für Clustering. Preis- und Temperaturprognosen sind dagegen typische Regressionsaufgaben im überwachten Lernen.",
      "weight": 1,
      "topic": "Unüberwachtes Lernen",
      "concept": "Clustering-Grundidee",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "UnüberwachtesLernen",
          "definition": "Lernansatz ohne Labels, der verborgene Muster, Strukturen oder Gruppen in Daten entdeckt."
        },
        {
          "term": "Clustering",
          "definition": "Methode, die ähnliche Datenpunkte zu sinnvollen Gruppen zusammenfasst, ohne dass Klassen vorgegeben sind."
        }
      ]
    },
    {
      "question": "74. Ein Spamfilter soll E-Mails in „Spam“ oder „Ham“ einordnen. Welche Aufgabe ist das?",
      "options": [
        "Klassifikation, weil Kategorien vorher feststehen.",
        "Regression, weil ein kontinuierlicher Wert vorhergesagt wird.",
        "Clustering, weil Gruppen ohne Vorgaben entdeckt werden.",
        "Anomalieerkennung, weil nur Ausreißer markiert werden."
      ],
      "answer": 0,
      "explanation": "Beim Spamfilter sind die Klassen (Spam/Ham) vorgegeben, daher handelt es sich um Klassifikation. Regression sagt numerische Werte voraus, Clustering findet Gruppen ohne Labels. Anomalieerkennung ist ein spezieller Fall, bei dem ungewöhnliche Muster im Fokus stehen.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Aufgabentyp bestimmen",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Aufgabentyp aus dem Ziel ableiten",
        "steps": [
          "Prüfen, ob das Ergebnis eine Kategorie oder ein Zahlenwert ist.",
          "Erkennen, ob Klassen vorgegeben sind (Spam/Ham).",
          "Klassifikation wählen, wenn das Ziel eine diskrete Klasse ist."
        ],
        "content": "Wenn das gewünschte Ergebnis aus festen Kategorien besteht, spricht das für Klassifikation. Ein Spamfilter ordnet jede E-Mail genau einer Klasse zu, statt einen kontinuierlichen Wert zu schätzen oder Gruppen ohne Vorgaben zu finden."
      },
      "mini_glossary": [
        {
          "term": "Klassifikation",
          "definition": "Aufgabe, bei der Datenobjekte vordefinierten Klassen oder Kategorien zugeordnet werden."
        },
        {
          "term": "Ham",
          "definition": "Bezeichnung für eine reguläre, nicht unerwünschte E-Mail im Kontext von Spamfiltern."
        }
      ]
    },
    {
      "question": "75. Ein Unternehmen will den erwarteten Umsatz im nächsten Quartal als Zahl prognostizieren. Welche Aufgabe passt am besten?",
      "options": [
        "Regression, weil ein numerischer Wert vorhergesagt wird.",
        "Klassifikation, weil Kategorien unterschieden werden sollen.",
        "Clustering, weil Kundengruppen gefunden werden sollen.",
        "Anomalieerkennung, weil Ausreißer gesucht werden."
      ],
      "answer": 0,
      "explanation": "Umsatzprognosen liefern einen kontinuierlichen Zahlenwert, daher ist Regression passend. Klassifikation würde Kategorien liefern, etwa „hoch“ oder „niedrig“. Clustering und Anomalieerkennung verfolgen andere Ziele als eine exakte Zahlenprognose.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Kontinuierliche Vorhersage",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Warum Regression hier passt",
        "steps": [
          "Zielvariable identifizieren: Umsatz als Zahlenwert.",
          "Prüfen, ob der Wert kontinuierlich ist.",
          "Regression wählen, wenn ein exakter numerischer Wert prognostiziert wird."
        ],
        "content": "Regression wird verwendet, wenn ein Modell einen numerischen Zielwert schätzt. Umsatz ist typischerweise kontinuierlich und soll möglichst präzise prognostiziert werden, weshalb Regression der passende Aufgabentyp ist."
      },
      "mini_glossary": [
        {
          "term": "Regression",
          "definition": "Aufgabe, bei der ein kontinuierlicher numerischer Wert vorhergesagt wird."
        },
        {
          "term": "Zielvariable",
          "definition": "Die Größe, die ein Modell vorhersagen soll, zum Beispiel Umsatz oder Temperatur."
        }
      ]
    },
    {
      "question": "76. Du hast Kundendaten, aber keine vorgegebenen Kundentypen. Du willst natürliche Gruppen finden. Was ist am passendsten?",
      "options": [
        "Clustering, weil Gruppen ohne Labels entdeckt werden.",
        "Klassifikation, weil Kategorien vorgegeben werden müssen.",
        "Regression, weil ein Zahlenwert im Fokus steht.",
        "Überwachtes Lernen, weil Labels zwingend erforderlich sind."
      ],
      "answer": 0,
      "explanation": "Wenn keine Labels oder vorgegebenen Klassen existieren, ist unüberwachtes Lernen geeignet. Clustering kann aus Ähnlichkeiten eigenständig Gruppen ableiten. Klassifikation und Regression setzen typischerweise gelabelte Trainingsdaten voraus.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "concept": "Kundensegmentierung",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Von Rohdaten zu Segmenten",
        "steps": [
          "Prüfen, ob Labels/Klassen vorhanden sind: nein.",
          "Ziel klären: Gruppen in Daten entdecken.",
          "Unüberwachtes Lernen wählen, typischerweise Clustering."
        ],
        "content": "Ohne Labels kann ein Modell nicht auf vorgegebene Antworten trainieren. Clustering nutzt Ähnlichkeiten zwischen Datenpunkten, um natürliche Segmente zu finden, was sich gut für Kundensegmentierung eignet."
      },
      "mini_glossary": [
        {
          "term": "Kundensegmentierung",
          "definition": "Aufteilung von Kunden in Gruppen mit ähnlichen Merkmalen oder Verhalten, um Maßnahmen gezielter auszurichten."
        },
        {
          "term": "Clustering",
          "definition": "Verfahren, das ähnliche Datenpunkte automatisch zu Gruppen zusammenfasst, ohne dass Kategorien vorgegeben sind."
        }
      ]
    },
    {
      "question": "77. Welche Information entspricht im Beispiel zur Gebrauchtwagen-Preisvorhersage dem Label?",
      "options": [
        "Der tatsächliche Verkaufspreis des Fahrzeugs.",
        "Der Kilometerstand des Fahrzeugs.",
        "Die Marke und das Modell des Fahrzeugs.",
        "Das Alter des Fahrzeugs in Jahren."
      ],
      "answer": 0,
      "explanation": "Im Regressionsbeispiel ist der Verkaufspreis der Zielwert, den das Modell lernen soll. Merkmale wie Alter, Kilometerstand oder Zustand sind Eingaben. Das Label liefert die korrekte Antwort für jedes Trainingsbeispiel.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Label vs. Merkmale",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Label im Regressionsbeispiel erkennen",
        "steps": [
          "Unterscheiden: Merkmale (Eingaben) vs. Zielwert (Ausgabe).",
          "Fragen: Was soll vorhergesagt werden?",
          "Den Zielwert als Label identifizieren."
        ],
        "content": "In überwachten Aufgaben sind Labels die bekannten Zielwerte. Bei der Gebrauchtwagenprognose soll der Preis vorhergesagt werden, daher ist der tatsächliche Verkaufspreis das Label, während die übrigen Angaben die Merkmale sind."
      },
      "mini_glossary": [
        {
          "term": "Merkmal",
          "definition": "Eingabevariable eines Modells, zum Beispiel Alter, Kilometerstand oder Besuchszeit."
        },
        {
          "term": "Label",
          "definition": "Bekannter Zielwert eines Trainingsbeispiels, an dem das Modell lernt."
        }
      ]
    },
    {
      "question": "78. Du möchtest Wetterdaten nutzen, um die Temperatur für morgen zu berechnen. Welche Kernanwendung ist das?",
      "options": [
        "Regression, weil eine kontinuierliche Zahl vorhergesagt wird.",
        "Klassifikation, weil feste Klassen zugeordnet werden.",
        "Clustering, weil Gruppen ohne Vorgaben entstehen.",
        "Anomalieerkennung, weil nur Ausreißer markiert werden."
      ],
      "answer": 0,
      "explanation": "Temperaturprognosen sind numerische Vorhersagen und damit ein typischer Regressionsfall. Klassifikation würde Kategorien liefern, etwa „warm“ oder „kalt“. Clustering und Anomalieerkennung verfolgen andere Ziele als eine konkrete Temperaturzahl.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Anwendungsbeispiel Wetter",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Temperatur als Regressionsziel",
        "steps": [
          "Zielwert bestimmen: Temperatur als Zahl.",
          "Kontinuierlichkeit prüfen: beliebige Werte möglich.",
          "Regression als passenden Aufgabentyp auswählen."
        ],
        "content": "Regression wird genutzt, wenn ein Modell einen kontinuierlichen Wert schätzt. Da Temperatur nicht auf wenige Klassen beschränkt ist, sondern als Zahl prognostiziert wird, passt Regression am besten."
      },
      "mini_glossary": [
        {
          "term": "KontinuierlicherWert",
          "definition": "Numerischer Wert, der viele mögliche Ausprägungen annehmen kann, nicht nur wenige feste Kategorien."
        },
        {
          "term": "Regression",
          "definition": "Vorhersage eines numerischen Zielwerts anhand von Merkmalen."
        }
      ]
    },
    {
      "question": "79. Welche Aussage passt am besten zur Rolle eines „Lehrers“ beim überwachten Lernen?",
      "options": [
        "Der Lehrer liefert die korrekten Antworten zu den Beispielen.",
        "Der Lehrer entfernt alle Merkmale, bis nur Labels übrig bleiben.",
        "Der Lehrer erzeugt zufällige Gruppen ohne Kategorien.",
        "Der Lehrer ersetzt das Modell durch feste Wenn-dann-Regeln."
      ],
      "answer": 0,
      "explanation": "Im überwachten Lernen sind Labels wie vorgegebene Lösungen, die den Lernprozess anleiten. Das Modell erkennt Muster, die zu diesen Antworten führen. Gruppen ohne Vorgaben sind typisch für unüberwachtes Lernen.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Lehrer-Analogie",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Analogie richtig zuordnen",
        "steps": [
          "Überwachtes Lernen mit Labels verknüpfen.",
          "Labels als „korrekte Lösungen“ interpretieren.",
          "Lehrerrolle als Anleitung durch Antworten verstehen."
        ],
        "content": "Die Lehrer-Analogie betont, dass der Lernende nicht im Unklaren gelassen wird, sondern korrekte Antworten erhält. Diese Labels ermöglichen es dem Modell, die relevanten Muster für verlässliche Vorhersagen zu lernen."
      },
      "mini_glossary": [
        {
          "term": "SupervisedLearning",
          "definition": "Überwachtes Lernen mit gelabelten Beispielen, die korrekte Antworten enthalten."
        },
        {
          "term": "Trainingsdaten",
          "definition": "Daten, mit denen ein Modell lernt, inklusive Eingabemerkmalen und oft Labels."
        }
      ]
    },
    {
      "question": "80. Eine Bank will Kreditkartenbetrug frühzeitig erkennen, indem ungewöhnliche Transaktionen markiert werden. Was passt am besten?",
      "options": [
        "Anomalieerkennung, weil Ausreißer im Verhalten gesucht werden.",
        "Regression, weil ein exakter Preis vorhergesagt werden soll.",
        "Klassifikation, weil immer feste Kategorien vorgegeben sind.",
        "Clustering, weil nur Gruppen ohne Auffälligkeiten entstehen."
      ],
      "answer": 0,
      "explanation": "Betrug ist oft selten und zeigt sich als Abweichung vom normalen Muster. Anomalieerkennung zielt genau darauf ab, ungewöhnliche Datenmuster zu finden. Regression und Clustering verfolgen andere Ziele als das Markieren auffälliger Transaktionen.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "concept": "Betrug als Ausreißer",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Warum Anomalieerkennung bei Betrug sinnvoll ist",
        "steps": [
          "Normalverhalten aus Transaktionen ableiten.",
          "Abweichungen als potenziell riskant interpretieren.",
          "Anomalieerkennung einsetzen, um Musterbrüche zu markieren."
        ],
        "content": "Anomalieerkennung konzentriert sich auf ungewöhnliche Muster statt auf häufige Standardfälle. Bei Kreditkartenbetrug geht es genau darum, Abweichungen vom typischen Nutzungsverhalten möglichst früh zu entdecken."
      },
      "mini_glossary": [
        {
          "term": "Anomalieerkennung",
          "definition": "Verfahren, das ungewöhnliche Datenmuster oder Ausreißer identifiziert, die vom Normalverhalten abweichen."
        },
        {
          "term": "Ausreißer",
          "definition": "Datenpunkt oder Muster, das deutlich von den typischen Beobachtungen abweicht."
        }
      ]
    },
    {
      "question": "81. Du hast vollständig gelabelte Trainingsdaten und brauchst präzise Vorhersagen für neue Fälle. Welche Methode ist laut Grundprinzip optimal?",
      "options": [
        "Überwachtes Lernen, weil Labels und Vorhersage im Fokus stehen.",
        "Unüberwachtes Lernen, weil keine Labels benötigt werden.",
        "Clustering, weil natürliche Gruppen immer die beste Lösung sind.",
        "Anomalieerkennung, weil jede Vorhersage ein Ausreißer ist."
      ],
      "answer": 0,
      "explanation": "Wenn Labels vorhanden sind und präzise Vorhersagen benötigt werden, passt überwacht am besten. Unüberwachtes Lernen ist geeignet, wenn Labels fehlen und Strukturen entdeckt werden sollen. Clustering und Anomalieerkennung sind spezielle Anwendungen des unüberwachten Lernens.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Wann überwacht?",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Methode anhand der Situation wählen",
        "steps": [
          "Prüfen: Sind Labels vorhanden? ja.",
          "Ziel bestimmen: präzise Vorhersage für neue Daten.",
          "Überwachtes Lernen als primäres Vorgehen auswählen."
        ],
        "content": "Die Wahl hängt davon ab, ob korrekte Antworten in den Daten vorhanden sind und ob Vorhersagegenauigkeit im Vordergrund steht. Mit gelabelten Daten kann ein Modell gezielt lernen, die gewünschten Outputs zuverlässig zu prognostizieren."
      },
      "mini_glossary": [
        {
          "term": "Vorhersage",
          "definition": "Geschätztes Ergebnis für neue, unbekannte Daten auf Basis eines gelernten Modells."
        },
        {
          "term": "GelabelteDaten",
          "definition": "Daten, die neben Merkmalen auch die korrekten Zielwerte enthalten."
        }
      ]
    },
    {
      "question": "82. Du hast keine oder nur sehr wenige Labels, möchtest aber verborgene Muster in den Daten finden. Welche Methode ist ideal?",
      "options": [
        "Unüberwachtes Lernen, weil es ohne Labels Muster entdeckt.",
        "Überwachtes Lernen, weil Labels nicht notwendig sind.",
        "Regression, weil Muster immer Zahlenwerte sind.",
        "Klassifikation, weil Kategorien automatisch entstehen."
      ],
      "answer": 0,
      "explanation": "Unüberwachtes Lernen ist dafür gemacht, ohne vorgegebene Antworten Strukturen zu finden. Überwachtes Lernen setzt typischerweise Labels voraus. Regression und Klassifikation sind Anwendungsbereiche des überwachten Lernens und brauchen meist Zielwerte.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "concept": "Wann unüberwacht?",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Labels fehlen: Muster entdecken",
        "steps": [
          "Feststellen: Es gibt kaum oder keine Labels.",
          "Ziel klären: Strukturen/Muster sichtbar machen.",
          "Unüberwachtes Lernen auswählen (z. B. Clustering)."
        ],
        "content": "Wenn die korrekten Antworten nicht vorliegen, kann ein Modell nicht direkt auf diese Zielwerte trainiert werden. Unüberwachtes Lernen analysiert die Daten stattdessen autonom, um wiederkehrende Muster oder Gruppierungen zu identifizieren."
      },
      "mini_glossary": [
        {
          "term": "Muster",
          "definition": "Wiederkehrende Struktur oder Zusammenhang in Daten, der für Erkenntnisse oder Entscheidungen nützlich ist."
        },
        {
          "term": "UnüberwachtesLernen",
          "definition": "Lernansatz, der ohne Labels Strukturen, Gruppen oder Ausreißer in Daten findet."
        }
      ]
    },
    {
      "question": "83. Ein Fitness-Tracker analysiert Schlafphasen und weckt zum optimalen Zeitpunkt. Welche ML-Idee steht dabei im Vordergrund?",
      "options": [
        "Clustering, weil ähnliche Schlafmuster gruppiert werden können.",
        "Regression, weil immer ein Preis vorhergesagt werden muss.",
        "Klassifikation, weil jede Nacht eine feste Kategorie ist.",
        "Anomalieerkennung, weil Schlaf immer ein Ausreißer ist."
      ],
      "answer": 0,
      "explanation": "Wenn Schlafphasen über Ähnlichkeit im Verhalten erkannt und gruppiert werden, passt Clustering als Idee. Regression ist für numerische Zielwerte gedacht, Klassifikation für feste Klassen. Anomalieerkennung würde ungewöhnliche Muster in den Fokus stellen, nicht typische Schlafphasen.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Clustering im Alltag",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Alltagsbeispiel auf ML-Konzept abbilden",
        "steps": [
          "Ziel verstehen: Muster in Schlafdaten erkennen.",
          "Prüfen, ob Labels nötig sind: meist nicht.",
          "Clustering als Gruppierung ähnlicher Muster zuordnen."
        ],
        "content": "Bei der Analyse von Schlafphasen geht es häufig darum, ähnliche Muster im Zeitverlauf zu erkennen und zusammenzufassen. Das entspricht dem Grundgedanken des Clusterings: natürliche Gruppierungen ohne vorgegebene Klassen zu finden."
      },
      "mini_glossary": [
        {
          "term": "Clustering",
          "definition": "Automatisches Finden von Gruppen ähnlicher Datenpunkte anhand ihrer Ähnlichkeit."
        },
        {
          "term": "Schlafphase",
          "definition": "Abschnitt im Schlaf mit typischen Mustern, der sich aus Sensordaten ableiten lässt."
        }
      ]
    },
    {
      "question": "84. Eine Navigations-App nutzt aktuelle Verkehrsdaten, um die schnellste Route vorherzusagen. Welche Kernanwendung passt am besten?",
      "options": [
        "Regression, weil eine numerische Vorhersage (z. B. Zeit) entsteht.",
        "Klassifikation, weil nur Kategorien wie „Stau“ oder „frei“ möglich sind.",
        "Clustering, weil die Route eine Gruppe von Straßen ist.",
        "Anomalieerkennung, weil jede Fahrt eine Auffälligkeit ist."
      ],
      "answer": 0,
      "explanation": "Die Vorhersage einer Fahrzeit oder optimalen Route basiert oft auf numerischen Schätzungen, was gut zu Regression passt. Klassifikation wäre eher eine Einordnung in feste Klassen. Clustering und Anomalieerkennung sind nicht der Kern einer Zeitprognose.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Regression im Alltag",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Warum Navigation oft Regression nutzt",
        "steps": [
          "Zielgröße bestimmen: Zeit/Ankunft als Zahl.",
          "Historische und aktuelle Daten als Input erkennen.",
          "Regression als numerische Prognose einordnen."
        ],
        "content": "Bei Navigation geht es häufig um das Prognostizieren von Fahrzeiten oder Reiseaufwand. Das sind kontinuierliche Werte, die aus Verkehrsdaten geschätzt werden, weshalb Regression als Grundprinzip gut passt."
      },
      "mini_glossary": [
        {
          "term": "Regression",
          "definition": "Vorhersage eines kontinuierlichen Zahlenwerts, etwa Preis, Umsatz oder Temperatur."
        },
        {
          "term": "Verkehrsdaten",
          "definition": "Informationen wie Geschwindigkeit, Stau, Dichte oder historische Fahrzeiten, die zur Prognose genutzt werden können."
        }
      ]
    },
    {
      "question": "85. Ein Online-Shop schlägt personalisierte Produkte vor, basierend auf Surf- und Kaufverhalten. Welche Idee wird dabei typischerweise genutzt?",
      "options": [
        "Produktempfehlungen, weil Präferenzen aus Verhalten abgeleitet werden.",
        "Klassifikation, weil Produkte nur in zwei Klassen fallen.",
        "Anomalieerkennung, weil Empfehlungen nur Ausreißer zeigen.",
        "Regression, weil jede Empfehlung eine Temperatur ist."
      ],
      "answer": 0,
      "explanation": "Personalisierte Empfehlungen entstehen, indem Muster im Nutzerverhalten erkannt und genutzt werden, um passende Vorschläge zu machen. Das ist eine typische Anwendung von Recommendation Systems. Die anderen Optionen passen nicht zum Ziel „ähnliche Vorlieben nutzen“.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Recommendation Systems",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Empfehlungen aus Verhalten ableiten",
        "steps": [
          "Ziel klären: passende Produkte vorschlagen.",
          "Verhalten als Datenbasis erkennen (Käufe, Klicks).",
          "Empfehlungslogik als Mustererkennung einordnen."
        ],
        "content": "Empfehlungssysteme nutzen Daten über Vorlieben und Verhalten, um relevante Vorschläge zu generieren. Im Kern steht das Ableiten von Mustern, die helfen, zukünftige Interessen besser zu treffen."
      },
      "mini_glossary": [
        {
          "term": "Produktempfehlung",
          "definition": "Automatisch erzeugter Vorschlag für Artikel, der auf dem Verhalten und den Präferenzen eines Nutzers basiert."
        },
        {
          "term": "Nutzerverhalten",
          "definition": "Beobachtbare Aktionen wie Klicks, Käufe oder Verweildauer, die Hinweise auf Präferenzen geben."
        }
      ]
    },
    {
      "question": "86. Welche Kombination aus Aufgaben gehört typischerweise zum überwachten Lernen?",
      "options": [
        "Klassifikation und Regression.",
        "Clustering und Anomalieerkennung.",
        "Clustering und Regression.",
        "Anomalieerkennung und Klassifikation."
      ],
      "answer": 0,
      "explanation": "Überwachtes Lernen arbeitet mit gelabelten Daten und wird häufig für Klassifikation und Regression genutzt. Clustering und Anomalieerkennung sind typische Anwendungen des unüberwachten Lernens. Mischkombinationen enthalten daher mindestens eine unpassende Aufgabe.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Zuordnung der Kernanwendungen",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Anwendungen den Lernarten zuordnen",
        "steps": [
          "Überwachtes Lernen mit Labels verknüpfen.",
          "Labels ermöglichen Zielwerte: Klassen oder Zahlen.",
          "Daraus folgen Klassifikation und Regression als Kernanwendungen."
        ],
        "content": "Mit Labels kann ein Modell lernen, entweder eine Klasse oder einen numerischen Zielwert vorherzusagen. Deshalb sind Klassifikation und Regression die typischen Einsatzfelder des überwachten Lernens, während unüberwachtes Lernen ohne Labels eher Gruppen oder Ausreißer findet."
      },
      "mini_glossary": [
        {
          "term": "Klassifikation",
          "definition": "Zuordnung eines Datenpunkts zu einer vordefinierten Klasse."
        },
        {
          "term": "Regression",
          "definition": "Vorhersage eines kontinuierlichen numerischen Werts."
        }
      ]
    },
    {
      "question": "87. Welche Kombination aus Aufgaben gehört typischerweise zum unüberwachten Lernen?",
      "options": [
        "Clustering und Anomalieerkennung.",
        "Klassifikation und Regression.",
        "Regression und Clustering.",
        "Klassifikation und Anomalieerkennung."
      ],
      "answer": 0,
      "explanation": "Unüberwachtes Lernen arbeitet ohne Labels und sucht Strukturen wie Gruppen oder Ausreißer. Daher passen Clustering und Anomalieerkennung. Klassifikation und Regression sind klassische Aufgaben des überwachten Lernens.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Zuordnung der Kernanwendungen",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Unüberwachte Ziele erkennen",
        "steps": [
          "Unüberwachtes Lernen: keine Labels vorhanden.",
          "Ziele: Muster, Gruppen, Auffälligkeiten entdecken.",
          "Clustering und Anomalieerkennung als typische Anwendungen auswählen."
        ],
        "content": "Ohne vorgegebene Antworten kann ein Modell nicht direkt auf Zielwerte trainieren. Stattdessen wird nach inneren Strukturen gesucht, etwa natürlichen Gruppen oder ungewöhnlichen Abweichungen, was zu Clustering und Anomalieerkennung führt."
      },
      "mini_glossary": [
        {
          "term": "Clustering",
          "definition": "Automatisches Finden natürlicher Gruppen in unstrukturierten Daten."
        },
        {
          "term": "Anomalieerkennung",
          "definition": "Identifikation ungewöhnlicher Muster oder Ausreißer im Vergleich zum Normalverhalten."
        }
      ]
    },
    {
      "question": "88. Du möchtest Blog-Besucher in sinnvolle Gruppen einteilen, ohne Besuchertypen vorzugeben. Welche Daten passen als Merkmale besonders gut?",
      "options": [
        "Alter, Besuchszeit, gelesene Artikel, Verweildauer.",
        "Nur das Label „Gruppe 1“ oder „Gruppe 2“ pro Besucher.",
        "Nur der Name des Blogs und das Veröffentlichungsdatum.",
        "Nur eine Liste zufälliger Besucher-IDs ohne Eigenschaften."
      ],
      "answer": 0,
      "explanation": "Für Clustering braucht man beschreibende Merkmale, die Ähnlichkeit abbilden, wie Alter, Zeit und Interaktion. Vorab-Labels wären gerade nicht erforderlich. Reine IDs oder Blog-Metadaten liefern kaum Informationen über Besucherverhalten.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "concept": "Merkmalsauswahl",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Merkmale für Clustering auswählen",
        "steps": [
          "Ziel klären: Besuchertypen aus Verhalten ableiten.",
          "Merkmale wählen, die Unterschiede sichtbar machen.",
          "Verhaltens- und Kontextmerkmale priorisieren (Zeit, Inhalte, Dauer)."
        ],
        "content": "Clustering basiert auf Ähnlichkeit, daher müssen die Merkmale relevante Unterschiede zwischen Besuchern abbilden. Verweildauer, gelesene Artikel und Besuchszeit liefern solche Signale und ermöglichen es, natürliche Gruppen zu erkennen."
      },
      "mini_glossary": [
        {
          "term": "Merkmalsauswahl",
          "definition": "Auswahl geeigneter Eingabevariablen, die ein ML-Modell für seine Aufgabe nutzen soll."
        },
        {
          "term": "Ähnlichkeit",
          "definition": "Maß dafür, wie vergleichbar zwei Datenpunkte anhand ihrer Merkmale sind."
        }
      ]
    },
    {
      "question": "89. Worin liegt der zentrale Unterschied zwischen Klassifikation und Regression?",
      "options": [
        "Klassifikation ordnet Klassen zu, Regression sagt Zahlenwerte voraus.",
        "Klassifikation sagt Zahlenwerte voraus, Regression ordnet Klassen zu.",
        "Klassifikation entdeckt Gruppen, Regression findet Ausreißer.",
        "Klassifikation braucht keine Daten, Regression braucht Daten."
      ],
      "answer": 0,
      "explanation": "Klassifikation liefert eine Kategorie wie „Spam“ oder „kein Spam“. Regression liefert einen kontinuierlichen numerischen Wert wie Preis oder Temperatur. Gruppen entdecken und Ausreißer finden sind typische Ziele des unüberwachten Lernens.",
      "weight": 2,
      "topic": "Anwendungen",
      "concept": "Klassifikation vs. Regression",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Output-Typ als Unterscheidungsmerkmal",
        "steps": [
          "Ausgabe betrachten: Kategorie oder Zahl?",
          "Diskrete Klassen -> Klassifikation.",
          "Kontinuierlicher Wert -> Regression."
        ],
        "content": "Die wichtigste Unterscheidung ist die Art des Ergebnisses. Klassifikation entscheidet zwischen vordefinierten Klassen, während Regression einen numerischen Zielwert schätzt, der viele Ausprägungen annehmen kann."
      },
      "mini_glossary": [
        {
          "term": "Klasse",
          "definition": "Vordefinierte Kategorie, in die ein Datenpunkt eingeordnet wird, z. B. „Spam“ oder „Ham“."
        },
        {
          "term": "Kontinuierlich",
          "definition": "Eigenschaft eines Wertes, viele mögliche Zahlenwerte annehmen zu können, nicht nur wenige Stufen."
        }
      ]
    },
    {
      "question": "90. Welche Abfolge entspricht am ehesten einem typischen ML-Vorgehen von der Idee bis zur Verbesserung?",
      "options": [
        "Problem verstehen, Daten erfassen, Methode wählen, Modell trainieren, anwenden und optimieren.",
        "Modell trainieren, Problem verstehen, Daten löschen, anwenden, Methode wählen.",
        "Daten erfassen, anwenden, Problem verstehen, Methode wählen, Training überspringen.",
        "Methode wählen, Problem ignorieren, Modell anwenden, Daten erfassen, optimieren."
      ],
      "answer": 0,
      "explanation": "Ein sinnvoller ML-Prozess startet mit dem Verständnis des Problems und der passenden Datengrundlage. Danach wird eine Methode gewählt, das Modell trainiert und schließlich angewendet. Monitoring und Optimierung sorgen dafür, dass das System über die Zeit besser wird.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Vom Problem zur Lösung",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Den ML-Prozess logisch ordnen",
        "steps": [
          "Ziel und Problemdefinition festlegen.",
          "Passende Daten beschaffen und prüfen.",
          "Methode auswählen und Modell trainieren.",
          "Modell einsetzen und kontinuierlich verbessern."
        ],
        "content": "Die Schritte bauen aufeinander auf: Ohne klares Ziel und geeignete Daten ist eine sinnvolle Methodenwahl kaum möglich. Training und Anwendung folgen danach, ergänzt durch Monitoring und Anpassung, damit die Leistung stabil bleibt oder steigt."
      },
      "mini_glossary": [
        {
          "term": "Training",
          "definition": "Phase, in der ein Modell aus Daten Muster lernt, um später Vorhersagen zu treffen."
        },
        {
          "term": "Monitoring",
          "definition": "Kontinuierliche Überwachung der Modellleistung im Betrieb, um Verschlechterungen zu erkennen."
        }
      ]
    },
    {
      "question": "91. Welche Aussage beschreibt am besten, was unüberwachtes Lernen „magisch“ macht?",
      "options": [
        "Es entdeckt selbstständig Strukturen, Gruppen und Ausreißer in Daten.",
        "Es liefert immer korrekte Antworten, weil Labels vorgegeben sind.",
        "Es ersetzt alle Daten durch feste Regeln ohne Lernprozess.",
        "Es benötigt keine Merkmale, sondern nur eine Zielvariable."
      ],
      "answer": 0,
      "explanation": "Unüberwachtes Lernen arbeitet ohne vorgegebene Labels und sucht eigenständig nach verborgenen Mustern. Genau das ermöglicht das Entdecken natürlicher Gruppierungen oder auffälliger Abweichungen. Labels und Zielvariablen sind dagegen typisch für überwachte Verfahren.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "concept": "Muster entdecken",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Kernidee des unüberwachten Lernens",
        "steps": [
          "Fehlende Labels als Ausgangspunkt erkennen.",
          "Ziel: Strukturen in Rohdaten finden.",
          "Ergebnisarten: Gruppen (Clustering) und Ausreißer (Anomalien)."
        ],
        "content": "Unüberwachtes Lernen wird eingesetzt, wenn es keine vorgegebenen Antworten gibt. Der Mehrwert liegt darin, dass das Modell eigenständig interessante Strukturen in den Daten sichtbar macht, die sonst leicht übersehen werden."
      },
      "mini_glossary": [
        {
          "term": "Rohdaten",
          "definition": "Unstrukturierte oder nur wenig vorbereitete Daten ohne vorgegebene Zielwerte oder Labels."
        },
        {
          "term": "Struktur",
          "definition": "Erkennbarer Zusammenhang oder Muster in Daten, etwa natürliche Gruppen oder wiederkehrende Verhaltensweisen."
        }
      ]
    },
    {
      "question": "92. Welcher Nutzen entsteht typischerweise, nachdem Clustering sinnvolle Besuchergruppen gefunden hat?",
      "options": [
        "Gezielte Maßnahmen, weil Inhalte und Marketing an Gruppen angepasst werden können.",
        "Sichere Vorhersagen, weil Labels automatisch korrekt entstehen.",
        "Automatische Rechtskonformität, weil Gruppen immer erlaubt sind.",
        "Stabile Temperaturen, weil Gruppen das Wetter beeinflussen."
      ],
      "answer": 0,
      "explanation": "Wenn Gruppen bekannt sind, können Unternehmen gezielter handeln, etwa durch passende Inhalte oder Marketingstrategien je Segment. Clustering liefert aber nicht automatisch „korrekte Labels“, sondern Strukturvorschläge. Rechtliche Fragen und Wetter haben damit nichts zu tun.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "concept": "Mehrwert von Segmenten",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Von Gruppen zu Entscheidungen",
        "steps": [
          "Erkannte Gruppen als Segmente interpretieren.",
          "Bedürfnisse je Segment ableiten (Interessen/Verhalten).",
          "Maßnahmen gezielt ausrichten (Inhalte, Angebote, Werbung)."
        ],
        "content": "Clustering liefert ein besseres Verständnis der Daten, indem es ähnliche Nutzer zusammenfasst. Dieses Wissen kann genutzt werden, um Entscheidungen und Maßnahmen zu personalisieren, was den Nutzen über die reine Analyse hinaus erhöht."
      },
      "mini_glossary": [
        {
          "term": "Segment",
          "definition": "Gruppe von Nutzern oder Kunden mit ähnlichen Merkmalen oder Verhalten, die gemeinsam adressiert werden kann."
        },
        {
          "term": "Personalisierung",
          "definition": "Anpassung von Angeboten, Inhalten oder Empfehlungen an individuelle oder gruppenspezifische Präferenzen."
        }
      ]
    },
    {
      "question": "93. Welche Aussage passt am besten zur „transformativen Kraft“ von ML?",
      "options": [
        "Ein trainiertes Modell kann Entscheidungen sehr skalierbar und konsistent treffen.",
        "Ein Modell arbeitet nur einmalig und wird danach nie mehr angepasst.",
        "Ein Modell vermeidet Muster und nutzt ausschließlich Zufall.",
        "Ein Modell braucht keine Daten, wenn es genug Regeln gibt."
      ],
      "answer": 0,
      "explanation": "Ein zentraler Vorteil ist Skalierbarkeit: Ein trainiertes Modell kann viele Entscheidungen schnell und konsistent treffen. Zudem können ML-Systeme aus neuen Daten lernen und sich verbessern. Die anderen Aussagen widersprechen dieser Idee.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Skalierbarkeit & Konsistenz",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "ML-Vorteile erkennen",
        "steps": [
          "Skalierbarkeit als Fähigkeit zur Massenanwendung identifizieren.",
          "Konsistenz als gleichbleibende Entscheidungsqualität verstehen.",
          "ML als Ansatz sehen, der aus Daten lernt und sich anpasst."
        ],
        "content": "ML wird besonders wertvoll, wenn viele ähnliche Entscheidungen zuverlässig getroffen werden müssen. Ein trainiertes Modell kann dies in großem Umfang und mit konsistenter Qualität leisten, während es durch neue Daten weiter verbessert werden kann."
      },
      "mini_glossary": [
        {
          "term": "Skalierbarkeit",
          "definition": "Fähigkeit, sehr viele Entscheidungen oder Vorhersagen effizient in großem Umfang zu treffen."
        },
        {
          "term": "Konsistenz",
          "definition": "Gleichbleibende, stabile Ausführung und Qualität von Entscheidungen über viele Fälle hinweg."
        }
      ]
    },
    {
      "question": "94. Was beschreibt „kontinuierliche Anpassung“ bei ML-Systemen am besten?",
      "options": [
        "Das System lernt aus neuen Daten und verbessert sich im Betrieb weiter.",
        "Das System bleibt nach dem Training unverändert und statisch.",
        "Das System ersetzt Daten durch manuelle Regeln im Nachhinein.",
        "Das System verhindert jede Änderung, um Fehler zu vermeiden."
      ],
      "answer": 0,
      "explanation": "ML-Systeme können durch neue Daten und Feedback weiter optimiert werden. Das ist besonders wichtig, wenn sich Umgebungen oder Nutzerverhalten verändern. Ein statisches System würde mit der Zeit oft an Leistung verlieren.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Kontinuierliche Optimierung",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Warum Anpassung wichtig ist",
        "steps": [
          "Veränderungen in Daten und Umfeld berücksichtigen.",
          "Modellleistung im Betrieb beobachten (Monitoring).",
          "Mit Feedback und neuen Daten nachjustieren."
        ],
        "content": "In realen Anwendungen ändern sich Muster über die Zeit. Kontinuierliche Anpassung bedeutet, dass ein ML-System nicht als einmaliges Projekt endet, sondern durch Monitoring und Updates seine Leistung stabilisiert oder verbessert."
      },
      "mini_glossary": [
        {
          "term": "Feedback",
          "definition": "Rückmeldung aus der Nutzung, die zeigt, ob Vorhersagen korrekt oder hilfreich waren."
        },
        {
          "term": "Optimierung",
          "definition": "Gezielte Verbesserung von Modellleistung durch Anpassungen, zusätzliche Daten oder veränderte Einstellungen."
        }
      ]
    },
    {
      "question": "95. Welche Beschreibung passt am besten zu Transfer Learning?",
      "options": [
        "Vorwissen aus einem Problem wird genutzt, um verwandte Aufgaben schneller zu lösen.",
        "Ein Modell wird nur mit völlig neuen Daten ohne Bezug neu gestartet.",
        "Daten werden zufällig gemischt, um Gruppen zu erzeugen.",
        "Ein Modell wird trainiert, ohne Daten zu verwenden."
      ],
      "answer": 0,
      "explanation": "Transfer Learning nutzt bereits gelerntes Wissen, um bei ähnlichen Aufgaben schneller gute Ergebnisse zu erzielen. Dadurch kann Entwicklung effizienter werden. Die anderen Optionen beschreiben kein sinnvolles Lernprinzip.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Transfer Learning",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Transfer Learning einordnen",
        "steps": [
          "Ausgangslage: Es gibt ein bereits trainiertes Modell.",
          "Ähnlichkeit zur neuen Aufgabe erkennen.",
          "Vorwissen übernehmen, statt komplett neu zu beginnen."
        ],
        "content": "Transfer Learning reduziert Aufwand, weil ein Modell nicht bei null starten muss. Wenn Aufgaben verwandt sind, können gelernte Muster weitergenutzt werden, was oft schneller zu guten Ergebnissen führt."
      },
      "mini_glossary": [
        {
          "term": "TransferLearning",
          "definition": "Nutzung von Wissen aus einem bereits gelernten Problem für eine verwandte Aufgabe, um schneller und effizienter zu lernen."
        }
      ]
    },
    {
      "question": "96. Welche Beschreibung passt am besten zu Federated Learning?",
      "options": [
        "Modelle werden trainiert, ohne sensible Daten zentral zu sammeln.",
        "Modelle werden nur mit Labels trainiert, niemals mit Merkmalen.",
        "Modelle arbeiten ohne Muster und nutzen nur Zufall.",
        "Modelle erzeugen automatisch perfekte Vorhersagen ohne Training."
      ],
      "answer": 0,
      "explanation": "Federated Learning zielt darauf ab, Modelle zu verbessern, ohne Daten zentral zusammenzuführen. Das stärkt Datenschutz und Sicherheit, weil Rohdaten lokal bleiben können. Die anderen Aussagen treffen den Kern nicht.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Federated Learning",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Datenschutzfreundliches Training",
        "steps": [
          "Problem erkennen: Daten sind sensibel oder verteilt.",
          "Training dezentral organisieren, statt Daten zu sammeln.",
          "Datenschutz und Sicherheit als Hauptvorteil einordnen."
        ],
        "content": "Federated Learning ermöglicht Zusammenarbeit beim Modelltraining, ohne dass alle Rohdaten an einem Ort liegen müssen. Dadurch können sensible Informationen besser geschützt werden, während dennoch Lernfortschritt erzielt wird."
      },
      "mini_glossary": [
        {
          "term": "FederatedLearning",
          "definition": "Ansatz, bei dem Modelle dezentral trainiert werden, sodass sensible Daten nicht zentral gesammelt werden müssen."
        },
        {
          "term": "Datenschutz",
          "definition": "Schutz personenbezogener oder sensibler Informationen vor unbefugtem Zugriff oder unnötiger Weitergabe."
        }
      ]
    },
    {
      "question": "97. Welche Beschreibung passt am besten zu AutoML?",
      "options": [
        "Automatisierung des ML-Prozesses, um Entwicklung zu beschleunigen.",
        "Manuelles Schreiben aller Regeln, um Training zu vermeiden.",
        "Zufälliges Erzeugen von Labels ohne Datenbasis.",
        "Ausschließliches Nutzen von Clustering für alle Aufgaben."
      ],
      "answer": 0,
      "explanation": "AutoML steht für die Automatisierung wesentlicher Schritte im ML-Prozess, um ihn schneller und einfacher zu machen. Es ersetzt nicht die Datenbasis, sondern unterstützt die Entwicklung. Die anderen Optionen verwechseln AutoML mit Regelprogrammierung oder Zufall.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "AutoML",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "AutoML richtig verstehen",
        "steps": [
          "Ziel erkennen: weniger manueller Aufwand im ML-Prozess.",
          "Automatisierung als Beschleuniger einordnen.",
          "AutoML nicht mit „ohne Daten“ oder „ohne Training“ verwechseln."
        ],
        "content": "AutoML soll die Entwicklung vereinfachen, indem Teile des Prozesses automatisiert werden. Dadurch können Teams schneller zu funktionierenden Modellen kommen, ohne dass jede Entscheidung vollständig manuell getroffen werden muss."
      },
      "mini_glossary": [
        {
          "term": "AutoML",
          "definition": "Automatisierung zentraler Schritte im Machine-Learning-Prozess, um Modellentwicklung zu beschleunigen und zu vereinfachen."
        },
        {
          "term": "MLProzess",
          "definition": "Ablauf von Problemdefinition über Daten und Training bis zu Einsatz und Optimierung eines Modells."
        }
      ]
    },
    {
      "question": "98. Welche Aussage beschreibt Erklärbarkeit von ML-Entscheidungen am besten?",
      "options": [
        "Entscheidungen sollen nachvollziehbar werden, um Vertrauen zu stärken.",
        "Entscheidungen sind immer geheim und dürfen nicht begründet werden.",
        "Erklärbarkeit bedeutet, dass Labels nicht mehr benötigt werden.",
        "Erklärbarkeit ist nur bei Clustering möglich, nicht bei Vorhersagen."
      ],
      "answer": 0,
      "explanation": "Erklärbarkeit zielt darauf ab, ML-Entscheidungen transparenter zu machen und so Vertrauen zu erhöhen. Das ist besonders wichtig, wenn Modelle in sensiblen Bereichen eingesetzt werden. Sie ersetzt keine Labels und ist nicht auf eine Methode beschränkt.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "concept": "Erklärbarkeit",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Warum Erklärbarkeit wichtig ist",
        "steps": [
          "Verstehen: Modelle treffen Entscheidungen auf Basis gelernter Muster.",
          "Bedarf erkennen: Menschen wollen Gründe nachvollziehen können.",
          "Transparenz als Grundlage für Vertrauen und verantwortlichen Einsatz sehen."
        ],
        "content": "Erklärbarkeit macht sichtbar, warum ein Modell zu einer Entscheidung kommt. Das erhöht Transparenz und Vertrauen und hilft, Modelle sinnvoll zu kontrollieren, insbesondere wenn die Folgen von Entscheidungen relevant sind."
      },
      "mini_glossary": [
        {
          "term": "Erklärbarkeit",
          "definition": "Eigenschaft eines ML-Systems, seine Entscheidungen so zu begründen, dass Menschen sie nachvollziehen können."
        },
        {
          "term": "Transparenz",
          "definition": "Nachvollziehbarkeit von Vorgehen und Entscheidungsgrundlagen, um Vertrauen und Kontrolle zu ermöglichen."
        }
      ]
    },
    {
      "question": "99. Ein Team möchte präzise Vorhersagen treffen, hat aber nur unstrukturierte Rohdaten ohne Labels. Welche erste Schlussfolgerung ist am sinnvollsten?",
      "options": [
        "Ohne Labels ist überwacht schwer möglich; zunächst unüberwacht Strukturen entdecken oder Labels aufbauen.",
        "Ohne Labels ist überwacht optimal geeignet; Labels werden automatisch korrekt entstehen.",
        "Unüberwacht ist ungeeignet; deshalb sollte man die Daten ignorieren.",
        "Regression ist immer möglich; Labels sind dafür nicht relevant."
      ],
      "answer": 0,
      "explanation": "Für präzise Vorhersagen wird oft überwacht gelernt, wofür Labels notwendig sind. Wenn Labels fehlen, kann man zunächst unüberwacht Muster finden oder einen Weg schaffen, Labels zu gewinnen. Es ist ein typisches Missverständnis, dass Labels „automatisch korrekt“ entstehen.",
      "weight": 3,
      "topic": "Überwachtes Lernen",
      "concept": "Labels als Voraussetzung",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Von Ziel und Daten zur Methode",
        "steps": [
          "Ziel prüfen: präzise Vorhersagen sprechen für überwacht.",
          "Daten prüfen: keine Labels vorhanden.",
          "Konsequenz ziehen: entweder Labels beschaffen oder zunächst unüberwacht explorieren.",
          "Erst danach überwachte Modelle für Vorhersagen einsetzen."
        ],
        "content": "Die Methode hängt sowohl vom Ziel als auch von der Datenlage ab. Präzise Vorhersagen benötigen häufig gelabelte Trainingsdaten; ohne Labels ist es sinnvoll, zunächst Strukturen zu entdecken oder einen Prozess zur Label-Erstellung aufzusetzen, bevor überwachte Vorhersagen realistisch sind."
      },
      "mini_glossary": [
        {
          "term": "Label",
          "definition": "Vordefinierter Zielwert in Trainingsdaten, der als korrekte Antwort für das Lernen dient."
        },
        {
          "term": "Exploration",
          "definition": "Erkundendes Analysieren von Daten, um Muster oder Strukturen zu entdecken, bevor ein konkretes Vorhersagemodell gebaut wird."
        }
      ]
    },
    {
      "question": "100. Eine Firma hat gelabelte Daten für „Kauf ja/nein“, möchte zusätzlich ungewöhnliche Bestellmuster erkennen. Welche Kombination ist am plausibelsten?",
      "options": [
        "Klassifikation für Kaufprognosen und Anomalieerkennung für ungewöhnliche Muster.",
        "Regression für Kauf ja/nein und Clustering für exakte Vorhersagen.",
        "Clustering für Kauf ja/nein und Regression für ungewöhnliche Muster.",
        "Anomalieerkennung für Kaufprognosen und Klassifikation für Ausreißer."
      ],
      "answer": 0,
      "explanation": "„Kauf ja/nein“ ist eine Klassifikationsaufgabe mit Labels. Ungewöhnliche Bestellmuster passen zur Anomalieerkennung, weil Abweichungen vom Normalverhalten gesucht werden. Die anderen Kombinationen vertauschen Zieltypen oder verfehlen die Rolle von Labels.",
      "weight": 3,
      "topic": "Anwendungen",
      "concept": "Passende Methoden kombinieren",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Zwei Ziele, zwei passende Verfahren",
        "steps": [
          "Ziel 1 identifizieren: Kauf ja/nein ist eine Kategorie -> Klassifikation.",
          "Ziel 2 identifizieren: ungewöhnliche Muster -> Anomalieerkennung.",
          "Prüfen, ob Labels vorhanden sind: ja für Klassifikation, nicht zwingend für Anomalien.",
          "Beide Verfahren als komplementär einsetzen."
        ],
        "content": "Wenn ein Unternehmen mehrere Ziele hat, kann es sinnvoll sein, Methoden zu kombinieren. Für eine kategorische Vorhersage ist Klassifikation passend, während Anomalieerkennung auf Abweichungen fokussiert und dadurch riskante oder auffällige Muster sichtbar machen kann."
      },
      "mini_glossary": [
        {
          "term": "Klassifikation",
          "definition": "Zuordnung eines Falls zu einer vordefinierten Klasse, z. B. „Kauf ja“ oder „Kauf nein“."
        },
        {
          "term": "Anomalieerkennung",
          "definition": "Erkennen von ungewöhnlichen Mustern oder Ausreißern im Vergleich zum Normalverhalten."
        }
      ]
    },
    {
      "question": "101. Welche Aussage ist die beste Begründung dafür, warum Clustering ohne vorher festgelegte Kategorien funktionieren kann?",
      "options": [
        "Es nutzt Ähnlichkeit in Merkmalen, um natürliche Gruppierungen zu finden.",
        "Es benötigt korrekte Antworten, die als Labels mitgeliefert werden.",
        "Es berechnet immer einen exakten Zielwert für jede Gruppe.",
        "Es ersetzt Merkmale durch Zufall, damit Gruppen entstehen."
      ],
      "answer": 0,
      "explanation": "Clustering beruht auf Ähnlichkeiten zwischen Datenpunkten und kann dadurch Gruppen entdecken, ohne dass Klassen vorgegeben sind. Labels sind dafür nicht nötig. Ein exakter Zielwert ist eher typisch für Regression und ist nicht das Ziel von Clustering.",
      "weight": 3,
      "topic": "Unüberwachtes Lernen",
      "concept": "Warum unüberwacht möglich",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Logik hinter Clustering",
        "steps": [
          "Klären, was fehlt: keine vorgegebenen Kategorien oder Labels.",
          "Erkennen, was genutzt wird: Ähnlichkeit anhand von Merkmalen.",
          "Schluss: Gruppen entstehen aus Struktur in den Daten, nicht aus Antworten.",
          "Bewerten: Ziel ist Erkenntnis/Segmentierung, nicht Zielwert-Prognose."
        ],
        "content": "Clustering entdeckt Gruppen, indem es Datenpunkte mit ähnlichen Eigenschaften zusammenfasst. Der Ansatz funktioniert, weil die Struktur aus den Merkmalen selbst kommt. Dadurch lassen sich natürliche Segmente finden, ohne dass jemand die Kategorien vorher definieren muss."
      },
      "mini_glossary": [
        {
          "term": "Ähnlichkeitsmaß",
          "definition": "Prinzip oder Maßzahl, die ausdrückt, wie ähnlich sich zwei Datenpunkte anhand ihrer Merkmale sind."
        },
        {
          "term": "NatürlicheGruppierung",
          "definition": "Gruppe, die sich aus der Struktur der Daten ergibt, statt vorher manuell festgelegt zu werden."
        }
      ]
    },
    {
      "question": "102. Ein Team möchte ein Modell „einmal trainieren und dann nie wieder anfassen“, obwohl sich Kundeverhalten saisonal ändert. Welche Einschätzung passt am besten?",
      "options": [
        "Riskant, weil Leistung ohne Monitoring und Anpassung mit der Zeit sinken kann.",
        "Optimal, weil Modelle nach dem Training immer stabil gleich bleiben.",
        "Unproblematisch, weil saisonale Änderungen keine Datenmuster betreffen.",
        "Vorteilhaft, weil Feedback die Modellqualität grundsätzlich verschlechtert."
      ],
      "answer": 0,
      "explanation": "Wenn sich Datenmuster verändern, kann ein Modell ohne Monitoring und Anpassung an Genauigkeit verlieren. Ein ML-Kreislauf beinhaltet deshalb Anwendung, Überwachung und Optimierung. Die Annahme, dass Modelle immer stabil bleiben, ist ein typisches Fehlkonzept.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "concept": "Monitoring & Optimierung",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Warum ML ein Kreislauf ist",
        "steps": [
          "Veränderungen im Umfeld erkennen (saisonal, Markttrends).",
          "Folge ableiten: gelernte Muster können veralten.",
          "Monitoring als Frühwarnsystem einordnen.",
          "Anpassung/Optimierung als Reaktion auf Leistungsabfall verstehen."
        ],
        "content": "ML ist kein einmaliger Schritt, weil reale Systeme in dynamischen Umgebungen laufen. Wenn sich Kundeverhalten ändert, kann ein statisches Modell schlechter werden. Kontinuierliches Monitoring und Anpassung halten die Leistung stabil und erhöhen den Nutzen."
      },
      "mini_glossary": [
        {
          "term": "Modellleistung",
          "definition": "Qualität der Vorhersagen oder Entscheidungen eines Modells, zum Beispiel Genauigkeit oder Fehler."
        },
        {
          "term": "Saisonalität",
          "definition": "Wiederkehrende Veränderungen über Zeit, etwa durch Jahreszeiten oder typische Kaufzyklen."
        }
      ]
    },
    {
      "question": "103. Welche Aussage trifft den Kernunterschied der Ziele am besten: überwacht vs. unüberwacht?",
      "options": [
        "Überwacht zielt auf präzise Vorhersagen mit Labels, unüberwacht auf Muster/Strukturen ohne Labels.",
        "Überwacht entdeckt nur Gruppen, unüberwacht sagt nur Preise voraus.",
        "Überwacht funktioniert ohne Daten, unüberwacht benötigt sehr viele Labels.",
        "Überwacht und unüberwacht unterscheiden sich nur in der Rechenzeit."
      ],
      "answer": 0,
      "explanation": "Überwachtes Lernen nutzt gelabelte Daten, um gezielt Vorhersagen zu treffen, etwa Klassen oder Zahlenwerte. Unüberwachtes Lernen sucht ohne Labels nach Strukturen wie Gruppen oder Ausreißern. Die anderen Aussagen vertauschen Ziele oder sind zu oberflächlich.",
      "weight": 3,
      "topic": "Überwachtes Lernen",
      "concept": "Zielorientierte Abgrenzung",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Ziele als klarer Trennpunkt",
        "steps": [
          "Überwacht mit Labels verknüpfen: Vorhersage ist das Ziel.",
          "Unüberwacht ohne Labels verknüpfen: Entdecken ist das Ziel.",
          "Beispiele zuordnen: Klassifikation/Regression vs. Clustering/Anomalien.",
          "Irreführende Aussagen erkennen (Vertauschung der Ziele)."
        ],
        "content": "Der sauberste Unterschied liegt im Ziel und in der Datenbeschriftung. Überwachte Verfahren lernen anhand korrekter Antworten, um neue Fälle präzise zu prognostizieren. Unüberwachte Verfahren explorieren Rohdaten, um verborgene Struktur sichtbar zu machen."
      },
      "mini_glossary": [
        {
          "term": "ÜberwachtesLernen",
          "definition": "Lernen mit gelabelten Beispielen, um Vorhersagen für neue Daten zu treffen."
        },
        {
          "term": "UnüberwachtesLernen",
          "definition": "Lernen ohne Labels, um Muster, Gruppen oder Ausreißer zu entdecken."
        }
      ]
    },
    {
      "question": "104. Ein Unternehmen möchte sensible Kundendaten nicht zentral speichern, aber dennoch Modelle verbessern. Welche Methode passt am besten zu diesem Ziel?",
      "options": [
        "Federated Learning, weil Training ohne zentrale Datensammlung möglich ist.",
        "Transfer Learning, weil Vorwissen immer Datenschutz garantiert.",
        "AutoML, weil Automatisierung zentrale Speicherung verhindert.",
        "Clustering, weil Gruppenbildung Daten automatisch anonym macht."
      ],
      "answer": 0,
      "explanation": "Federated Learning zielt genau darauf ab, Modelle zu trainieren, ohne sensible Daten zentral zusammenzuführen. Transfer Learning und AutoML haben andere Schwerpunkte. Clustering kann zwar Struktur finden, löst aber nicht automatisch das Problem der zentralen Datensammlung.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "concept": "Datenschutz & Training",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Ziel-zu-Methode-Argumentation",
        "steps": [
          "Ziel identifizieren: kein zentrales Sammeln sensibler Rohdaten.",
          "Passenden Mechanismus suchen: dezentrales Training.",
          "Federated Learning als Methode mit diesem Kernprinzip auswählen.",
          "Andere Begriffe abgrenzen (Transfer/AutoML sind nicht primär Datenschutzmechanismen)."
        ],
        "content": "Wenn Datenschutz und Sicherheit im Vordergrund stehen, ist entscheidend, wie Training organisiert wird. Federated Learning ermöglicht Lernfortschritt, ohne dass alle Rohdaten an einem zentralen Ort liegen müssen, und passt damit direkt zum beschriebenen Ziel."
      },
      "mini_glossary": [
        {
          "term": "FederatedLearning",
          "definition": "Dezentrales Training von Modellen, bei dem sensible Daten nicht zentral gesammelt werden müssen."
        },
        {
          "term": "SensibleDaten",
          "definition": "Informationen, die besonders schützenswert sind, etwa personenbezogene oder vertrauliche Unternehmensdaten."
        }
      ]
    },
    {
      "question": "105. Ein Team glaubt: „Wenn wir genug Daten haben, brauchen wir keine Labels mehr für Klassifikation.“ Welche Bewertung ist am passendsten?",
      "options": [
        "Unzutreffend, weil Klassifikation typischerweise Labels als korrekte Antworten benötigt.",
        "Zutreffend, weil Daten automatisch korrekte Klassen erzeugen.",
        "Unklar, weil Klassifikation immer unüberwacht funktioniert.",
        "Zutreffend, weil Labels nur bei Regression eine Rolle spielen."
      ],
      "answer": 0,
      "explanation": "Klassifikation im überwachten Lernen benötigt gelabelte Beispiele, damit das Modell weiß, welche Klasse korrekt ist. Viele Daten ersetzen nicht automatisch die Rolle der korrekten Antworten. Ohne Labels kann man zwar Strukturen entdecken, aber nicht gezielt auf vordefinierte Klassen trainieren.",
      "weight": 3,
      "topic": "Überwachtes Lernen",
      "concept": "Misconception: Labels",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Warum Labels bei Klassifikation zentral sind",
        "steps": [
          "Klassifikation als Zuordnung zu vordefinierten Klassen definieren.",
          "Erkennen: Vordefinierte Klassen benötigen korrekte Zuordnung im Training.",
          "Labels als Lernsignal verstehen, das „richtig“ von „falsch“ unterscheidet.",
          "Ohne Labels: höchstens unüberwachtes Entdecken, nicht gezieltes Klassentraining."
        ],
        "content": "Mehr Daten können helfen, aber sie ersetzen nicht das Lernsignal der korrekten Antworten. Für Klassifikation muss das Modell lernen, welche Klasse zu welchen Merkmalen gehört. Dieses Wissen entsteht typischerweise durch gelabelte Trainingsbeispiele."
      },
      "mini_glossary": [
        {
          "term": "Misconception",
          "definition": "Typisches Fehlkonzept oder Missverständnis, das zu falschen Schlussfolgerungen führen kann."
        },
        {
          "term": "Label",
          "definition": "Korrekte Zielantwort im Training, die dem Modell zeigt, welche Klasse oder welcher Wert richtig ist."
        }
      ]
    },
    {
      "question": "106. Du sollst entscheiden: Ein Problem erfordert präzise Preisvorhersagen, aber es gibt nur unstrukturierte Rohdaten ohne Verkaufspreise. Was ist der beste nächste Schritt?",
      "options": [
        "Zuerst eine Strategie zur Gewinnung von Labels aufbauen, bevor Regression sinnvoll trainiert werden kann.",
        "Sofort Regression trainieren, weil Labels bei Preisen nicht nötig sind.",
        "Clustering nutzen, um automatisch exakte Preise zu berechnen.",
        "Anomalieerkennung nutzen, um jeden Preis direkt vorherzusagen."
      ],
      "answer": 0,
      "explanation": "Für Regression werden Zielwerte wie Verkaufspreise als Labels benötigt. Wenn diese fehlen, muss man zuerst einen Weg finden, sie zu erhalten oder zu erstellen. Clustering und Anomalieerkennung können Strukturen liefern, ersetzen aber keine Preislabels für eine präzise Regressionsvorhersage.",
      "weight": 3,
      "topic": "Überwachtes Lernen",
      "concept": "Datenlücke erkennen",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Von Zielwerten zur Machbarkeit",
        "steps": [
          "Ziel erkennen: Preis als numerischer Zielwert -> Regression.",
          "Daten prüfen: Verkaufspreise fehlen als Labels.",
          "Konsequenz: Labels beschaffen oder erzeugen, sonst kein gezieltes Training.",
          "Erst danach Modelltraining und Bewertung durchführen."
        ],
        "content": "Ein Regressionsmodell braucht Beispiele, in denen Eingabemerkmale und der korrekte Zielwert gemeinsam vorliegen. Wenn die Zielwerte fehlen, ist die wichtigste Entscheidung, wie diese Labels gewonnen werden können. Ohne diesen Schritt bleibt die gewünschte Präzision unrealistisch."
      },
      "mini_glossary": [
        {
          "term": "LabelGewinnung",
          "definition": "Prozess, um korrekte Zielwerte für Trainingsdaten zu erhalten, etwa durch Messung, Erfassung oder Zuordnung."
        },
        {
          "term": "Regression",
          "definition": "Vorhersage eines numerischen Zielwerts, der als Label in Trainingsdaten vorhanden sein sollte."
        }
      ]
    },
    {
      "question": "107. Was ist der Hauptunterschied zwischen supervised und unsupervised Learning?",
      "options": [
        "Supervised verwendet gelabelte Daten, unsupervised nicht.",
        "Supervised ist schneller als unsupervised.",
        "Unsupervised erfordert mehr Rechenleistung.",
        "Supervised funktioniert nur mit Bildern."
      ],
      "answer": 0,
      "explanation": "Supervised Learning nutzt gelabelte Trainingsdaten, um Vorhersagen zu treffen. Unsupervised Learning findet Muster in ungelabelten Daten.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "concept": "Grundlagen ML",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "108. Welches Modell wird typischerweise für binäre Klassifikation verwendet?",
      "options": [
        "Lineare Regression",
        "Logistische Regression",
        "K-Means Clustering",
        "Principal Component Analysis"
      ],
      "answer": 1,
      "explanation": "Logistische Regression ist ein klassisches Modell für binäre Klassifikation, das Wahrscheinlichkeiten ausgibt.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "concept": "Supervised Learning",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "109. Was misst der Mean Squared Error (MSE) in der Regression?",
      "options": [
        "Die Genauigkeit der Klassifikation",
        "Den quadratischen Mittelwert der Fehler",
        "Die Anzahl der Cluster",
        "Die Dimensionalität der Daten"
      ],
      "answer": 1,
      "explanation": "MSE berechnet den Durchschnitt der quadrierten Differenzen zwischen vorhergesagten und tatsächlichen Werten.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "concept": "Regression",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "110. Welcher Algorithmus wird für Clustering verwendet?",
      "options": [
        "Decision Tree",
        "K-Means",
        "Support Vector Machine",
        "Naive Bayes"
      ],
      "answer": 1,
      "explanation": "K-Means ist ein unsupervised Algorithmus, der Daten in k Cluster gruppiert.",
      "weight": 1,
      "topic": "Unüberwachtes Lernen",
      "concept": "Unsupervised Learning",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "111. Was ist Overfitting in Machine Learning?",
      "options": [
        "Das Modell lernt zu wenig von den Daten.",
        "Das Modell passt sich zu stark an die Trainingsdaten an und generalisiert schlecht.",
        "Das Modell ignoriert die Testdaten.",
        "Das Modell verwendet zu wenige Features."
      ],
      "answer": 1,
      "explanation": "Overfitting tritt auf, wenn ein Modell die Trainingsdaten zu genau lernt, aber auf neuen Daten schlecht performt.",
      "weight": 2,
      "topic": "Modellbewertung & Validierung",
      "concept": "Modellbewertung",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "112. Wie funktioniert der k-Nearest Neighbors (k-NN) Algorithmus?",
      "options": [
        "Er berechnet den Mittelwert der nächsten k Punkte.",
        "Er klassifiziert basierend auf den k nächsten Nachbarn in den Trainingsdaten.",
        "Er baut einen Entscheidungsbaum auf.",
        "Er verwendet neuronale Netze."
      ],
      "answer": 1,
      "explanation": "k-NN ist ein lazy Learner, der für eine Vorhersage die k ähnlichsten Trainingsbeispiele betrachtet.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Supervised Learning",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "113. Was ist der Zweck von Cross-Validation?",
      "options": [
        "Die Daten in Trainings- und Testsets aufzuteilen.",
        "Die Modellleistung auf verschiedenen Datenteilen zu testen, um Overfitting zu vermeiden.",
        "Die Features zu skalieren.",
        "Die Hyperparameter zu optimieren."
      ],
      "answer": 1,
      "explanation": "Cross-Validation hilft, die Generalisierungsfähigkeit des Modells zu schätzen, indem es auf mehreren Splits trainiert und getestet wird.",
      "weight": 2,
      "topic": "Modellbewertung & Validierung",
      "concept": "Modellbewertung",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "114. Welche Metrik ist für unausgewogene Datensätze in der Klassifikation besonders wichtig?",
      "options": [
        "Accuracy",
        "Precision und Recall",
        "Mean Squared Error",
        "R² Score"
      ],
      "answer": 1,
      "explanation": "Precision und Recall sind besser als Accuracy, wenn Klassen unausgewogen sind, da Accuracy durch die Mehrheitsklasse verzerrt wird.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "concept": "Klassifikation",
      "cognitive_level": "Anwendung"
    },
    {
      "question": "115. Erklären Sie den Bias-Variance Tradeoff kurz.",
      "options": [
        "Bias ist der Fehler durch zu einfache Modelle, Variance durch zu komplexe Modelle.",
        "Bias misst die Streuung, Variance den systematischen Fehler.",
        "Beide sind immer minimal in guten Modellen.",
        "Bias ist nur für Regression relevant."
      ],
      "answer": 0,
      "explanation": "Bias-Variance Tradeoff: Hoher Bias führt zu Underfitting (zu einfache Modelle), hohe Variance zu Overfitting (zu komplexe Modelle). Das optimale Modell balanciert beide.",
      "weight": 3,
      "topic": "Überwachtes Lernen",
      "concept": "Modelltheorie",
      "cognitive_level": "Reproduktion"
    },
    {
      "question": "116. Wie würde man den Support Vector Machine (SVM) Algorithmus für nicht-lineare Daten anpassen?",
      "options": [
        "Indem man den Kernel-Trick verwendet, z.B. mit RBF-Kernel.",
        "Indem man die Daten linear transformiert.",
        "Indem man mehr Features hinzufügt.",
        "SVM kann nur lineare Daten handhaben."
      ],
      "answer": 0,
      "explanation": "Der Kernel-Trick projiziert die Daten in einen höherdimensionalen Raum, um nicht-lineare Trennungen zu ermöglichen, ohne explizite Transformation.",
      "weight": 3,
      "topic": "Überwachtes Lernen",
      "concept": "Supervised Learning",
      "cognitive_level": "Anwendung"
    },
    {
      "question": "117. Was ist das Hauptziel von Machine Learning im Vergleich zu klassischer, explizit programmierter Software?",
      "options": [
        "Regeln manuell zu kodieren, damit das System deterministisch arbeitet.",
        "Aus Beispieldaten Muster zu lernen, um Vorhersagen oder Entscheidungen zu treffen.",
        "Zufallszahlen zu generieren, um alle Möglichkeiten abzudecken.",
        "Hardware schneller zu machen, damit Programme effizienter laufen.",
        "Fehlerhafte Daten zu verwerfen, bevor ein Programm startet."
      ],
      "answer": 1,
      "explanation": "Machine Learning lässt Modelle **Muster aus Daten** lernen statt Regeln fest zu programmieren. Dadurch können Systeme verallgemeinern und auf neue Fälle reagieren.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "mini_glossary": {
        "Modell": "Formale Abbildung von Eingaben auf Ausgaben, deren Parameter aus Daten gelernt werden.",
        "Training": "Prozess, bei dem ein Algorithmus Parameter so anpasst, dass eine Zielgröße optimiert wird."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Grundbegriffe"
    },
    {
      "question": "118. Worin unterscheiden sich überwachtes und unüberwachtes Lernen grundlegend?",
      "options": [
        "Überwachtes Lernen nutzt gelabelte Daten, unüberwachtes Lernen arbeitet ohne Ziellabels.",
        "Überwachtes Lernen benötigt keine Daten, unüberwachtes Lernen benötigt viele Daten.",
        "Überwachtes Lernen ist nur für Bilder geeignet, unüberwachtes nur für Text.",
        "Überwachtes Lernen verwendet keine Metriken, unüberwachtes verwendet viele.",
        "Überwachtes Lernen ist stets genauer als unüberwachtes."
      ],
      "answer": 0,
      "explanation": "Beim **überwachten Lernen** gibt es Zielwerte wie Klassen oder Zahlen; **unüberwachtes Lernen** sucht Strukturen in Daten ohne Labels.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "mini_glossary": {
        "Label": "Beobachtetes Zielattribut, das das Modell vorhersagen soll.",
        "Clustering": "Unüberwachtes Verfahren, das ähnliche Datenpunkte in Gruppen einteilt."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Grundbegriffe"
    },
    {
      "question": "119. Was beschreibt ein Datensatz im ML-Kontext am besten?",
      "options": [
        "Eine Liste von Quellcode-Dateien für das Modell.",
        "Eine Sammlung strukturierter oder unstrukturierter Beispiele mit Merkmalen und ggf. Zielwerten.",
        "Eine Hardware-Spezifikation für Trainingsserver.",
        "Eine Visualisierung von Fehlern nach dem Training.",
        "Eine Sammlung zufällig erzeugter Zahlenfolgen."
      ],
      "answer": 1,
      "explanation": "Ein Datensatz besteht aus **Beispielen** (Zeilen, Dokumente, Bilder) und **Merkmalen**; optional enthält er Zielwerte für überwachtes Lernen.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "mini_glossary": {
        "Feature/Merkmal": "Messbare Eigenschaft eines Beispiels, z.B. Pixelwerte oder Textstatistiken.",
        "Beispiel/Instanz": "Ein einzelner Datenpunkt, der vom Modell verarbeitet wird."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Grundbegriffe"
    },
    {
      "question": "120. Welche Aussage beschreibt Generalisierung korrekt?",
      "options": [
        "Fähigkeit eines Modells, Trainingsdaten exakt auswendig zu lernen.",
        "Fähigkeit eines Modells, bei neuen, ähnlichen Daten gut abzuschneiden.",
        "Fähigkeit eines Modells, ohne Daten zu funktionieren.",
        "Fähigkeit eines Modells, die Trainingszeit zu halbieren.",
        "Fähigkeit eines Modells, alle Fehler im Training zu entfernen."
      ],
      "answer": 1,
      "explanation": "**Generalisierung** bedeutet, dass gelernte Strukturen auf **neue Daten** übertragen werden und nicht nur das Training erklärt wird.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "mini_glossary": {
        "Overfitting": "Anpassung an Zufälligkeiten im Training; schwache Leistung auf neuen Daten.",
        "Underfitting": "Modell ist zu einfach und erfasst die Struktur der Daten nicht hinreichend."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Grundbegriffe"
    },
    {
      "question": "121. Was ist ein Feature im Sinne von Machine Learning?",
      "options": [
        "Eine grafische Oberfläche eines Programms.",
        "Eine messbare Eigenschaft eines Datenpunktes, die als Eingabe dient.",
        "Eine Sammlung von Fehlermeldungen.",
        "Ein proprietäres Dateiformat für Modelle.",
        "Eine zufällige Zahl zur Initialisierung."
      ],
      "answer": 1,
      "explanation": "Ein **Feature** ist eine **Eingabevariable**, die das Modell nutzt, um Muster zu erkennen und Vorhersagen zu treffen.",
      "weight": 1,
      "topic": "Daten & Features",
      "mini_glossary": {
        "Skalierung": "Anpassung der Größenordnung von Merkmalen, z.B. Standardisierung.",
        "Kodierung": "Transformation kategorialer Merkmale in numerische Darstellung."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Daten & Features"
    },
    {
      "question": "122. Warum wird Feature-Skalierung häufig vor dem Training durchgeführt?",
      "options": [
        "Damit alle Modelle deterministisch werden.",
        "Damit Distanz- und Gradienten-basierte Verfahren stabiler und schneller konvergieren.",
        "Damit Labels automatisch generiert werden.",
        "Damit die Datenmenge kleiner wird als zuvor.",
        "Damit Bilder automatisch farbig werden."
      ],
      "answer": 1,
      "explanation": "Vergleichbare **Skalen** verhindern, dass einzelne Merkmale dominieren, und unterstützen **Optimierung** und Distanzberechnungen.",
      "weight": 1,
      "topic": "Daten & Features",
      "mini_glossary": {
        "Standardisierung": "Zentriert Merkmale (Mittel 0) und skaliert auf Varianz 1.",
        "Min-Max-Skalierung": "Skaliert Werte in einen fixen Bereich, häufig [0, 1]."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Daten & Features"
    },
    {
      "question": "123. Welche Aussage zu One-Hot-Encoding trifft zu?",
      "options": [
        "Es ordnet Kategorien fortlaufende Zahlen zu und erzeugt Ranginformation.",
        "Es erzeugt binäre Spalten pro Kategorie, ohne künstliche Ordnung zu implizieren.",
        "Es wandelt Text automatisch in Bilder um.",
        "Es reduziert immer die Daten dimensional.",
        "Es ist nur für numerische Daten geeignet."
      ],
      "answer": 1,
      "explanation": "**One-Hot-Encoding** bildet Kategorien auf **binäre Indikatoren** ab und vermeidet künstliche Ordnung.",
      "weight": 1,
      "topic": "Daten & Features",
      "mini_glossary": {
        "Dummy-Variable": "Binäre Spalte, die anzeigt, ob eine Kategorie vorliegt.",
        "Kategoriales Merkmal": "Merkmal mit endlicher Menge diskreter Ausprägungen."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Daten & Features"
    },
    {
      "question": "124. Wann ist eine Log-Transformation eines Merkmals oft sinnvoll?",
      "options": [
        "Bei symmetrischen Normalverteilungen mit kleiner Varianz.",
        "Bei stark rechtsschiefen Verteilungen zur Kompression großer Wertebereiche.",
        "Bei binären Merkmalen mit Werten 0/1.",
        "Bei bereits skalierten Standardnormalmerkmalen.",
        "Bei reinen Textmerkmalen ohne Zahlen."
      ],
      "answer": 1,
      "explanation": "Die **Log-Transformation** reduziert **Schiefe** und kann lineare Beziehungen und Stabilität verbessern.",
      "weight": 1,
      "topic": "Daten & Features",
      "mini_glossary": {
        "Schiefe": "Asymmetrie einer Verteilung relativ zum Mittelwert.",
        "Transformation": "Funktionale Umformung von Merkmalen zur Modellierbarkeit."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Daten & Features"
    },
    {
      "question": "125. Welche Modellklasse wird typischerweise für Klassifikationsaufgaben eingesetzt?",
      "options": [
        "Lineare Regression ohne Modifikation.",
        "Logistische Regression zur Modellierung von Klassenwahrscheinlichkeiten.",
        "K-Means zur Minimierung von Distanzen.",
        "PCA zur Komponentenextraktion.",
        "DBSCAN zur Dichteanalyse."
      ],
      "answer": 1,
      "explanation": "Die **logistische Regression** modelliert **Wahrscheinlichkeiten** für Klassen und ist ein Standardverfahren für Klassifikation.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "mini_glossary": {
        "Klassifikation": "Vorhersage diskreter Klassenlabels.",
        "Sigmoid": "Funktion, die Werte auf den Bereich (0, 1) abbildet."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Modellarten"
    },
    {
      "question": "126. Wofür werden Entscheidungsbäume im ML eingesetzt?",
      "options": [
        "Zur Dekomposition in Frequenzbänder.",
        "Zur schrittweisen Aufteilung von Daten anhand von Merkmalen zur Vorhersage.",
        "Zur kryptografischen Verschlüsselung von Datensätzen.",
        "Zur zufälligen Permutation von Labels.",
        "Zur reinen Datenkompression ohne Vorhersage."
      ],
      "answer": 1,
      "explanation": "**Entscheidungsbäume** teilen Daten entlang von **Merkmalsregeln** und führen zu Vorhersagen in Blättern.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "mini_glossary": {
        "Split": "Regelbasierte Aufteilung eines Knotens entlang eines Merkmals.",
        "Blatt": "Terminaler Knoten, der eine Vorhersage liefert."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Modellarten"
    },
    {
      "question": "127. Was kennzeichnet k-nächste Nachbarn (k-NN) als Lernverfahren?",
      "options": [
        "Es lernt explizite Parameter während eines langen Trainings.",
        "Es speichert Beispiele und sagt basierend auf Nachbarschaftsmehrheit oder Mittelwert voraus.",
        "Es benötigt keine Distanzdefinition.",
        "Es ist nur für Bilder geeignet.",
        "Es erzeugt automatisch neue Merkmale während des Trainings."
      ],
      "answer": 1,
      "explanation": "**k-NN** ist ein **instanzbasiertes** Verfahren: Vorhersagen ergeben sich aus lokalen Nachbarschaften im Merkmalsraum.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "mini_glossary": {
        "Instanzbasiert": "Vorhersage durch Vergleich mit gespeicherten Beispielen.",
        "Distanzmaß": "Funktion zur Bewertung der Nähe zwischen Punkten."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Modellarten"
    },
    {
      "question": "128. Wozu dient eine lineare Regression?",
      "options": [
        "Zur Vorhersage diskreter Klassenlabels.",
        "Zur Schätzung eines kontinuierlichen Zielwerts als lineare Funktion der Merkmale.",
        "Zur Segmentierung von Bildern in Regionen.",
        "Zur Erzeugung synthetischer Daten.",
        "Zur Verschlüsselung von Textdaten."
      ],
      "answer": 1,
      "explanation": "Die **lineare Regression** sagt **kontinuierliche Zielgrößen** als lineare Kombination der Merkmale voraus.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "mini_glossary": {
        "Regression": "Vorhersage kontinuierlicher Zielvariablen.",
        "Residuum": "Differenz zwischen vorhergesagtem und beobachtetem Wert."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Modellarten"
    },
    {
      "question": "129. Welche Kennzahl ist für binäre Klassifikation ein Standardmaß neben Accuracy?",
      "options": [
        "Mean Squared Error ausschließlich.",
        "Precision, also der Anteil korrekter Positivvorhersagen.",
        "PSNR für Bildqualität.",
        "Silhouettenkoeffizient.",
        "K-Means-Inertie."
      ],
      "answer": 1,
      "explanation": "**Precision** bewertet, wie zuverlässig Positivvorhersagen sind; zusammen mit **Recall** ergibt sich ein differenziertes Bild.",
      "weight": 1,
      "topic": "Modellbewertung & Validierung",
      "mini_glossary": {
        "Accuracy": "Anteil korrekter Vorhersagen an allen Beispielen.",
        "Recall": "Anteil erkannter Positiver an allen tatsächlichen Positiven."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Evaluation & Metriken"
    },
    {
      "question": "130. Wann ist die ROC-AUC besonders hilfreich?",
      "options": [
        "Wenn ausschließlich Regressionsfehler bewertet werden.",
        "Wenn das Ranking der Scores über alle möglichen Schwellen interessiert.",
        "Wenn nur die absolute Vorhersagehöhe wichtig ist.",
        "Wenn ausschließlich negative Klassen betrachtet werden.",
        "Wenn keine Wahrscheinlichkeiten vorliegen."
      ],
      "answer": 1,
      "explanation": "Die **ROC-AUC** fasst die **Trennfähigkeit** eines Modells über alle Schwellen zusammen und ist schwellenunabhängig.",
      "weight": 1,
      "topic": "Modellbewertung & Validierung",
      "mini_glossary": {
        "ROC-Kurve": "Darstellung von True-Positive-Rate gegenüber False-Positive-Rate.",
        "AUC": "Fläche unter der Kurve als aggregiertes Maß."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Evaluation & Metriken"
    },
    {
      "question": "131. Wozu dient ein Validierungssplit während des Trainings?",
      "options": [
        "Zur Erzeugung zusätzlicher Labels.",
        "Zur unabhängigen Bewertung von Modellen zur Hyperparameterauswahl.",
        "Zur Beschleunigung der Hardware.",
        "Zur Reduktion der Datenqualität.",
        "Zur Ersetzung der Testmenge durch Trainingsdaten."
      ],
      "answer": 1,
      "explanation": "Ein **Validierungssplit** erlaubt **Hyperparametertuning** und frühes Stoppen, ohne die Testmenge anzutasten.",
      "weight": 1,
      "topic": "Modellbewertung & Validierung",
      "mini_glossary": {
        "Hyperparameter": "Steuergrößen des Lernverfahrens, die nicht aus den Daten gelernt werden.",
        "Frühes Stoppen": "Abbruch des Trainings, wenn sich die Validierungsleistung nicht mehr verbessert."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Evaluation & Metriken"
    },
    {
      "question": "132. Warum variiert man die Lernrate bei Gradientenverfahren?",
      "options": [
        "Um die Anzahl der Merkmale zu reduzieren.",
        "Um Schrittweite und Stabilität der Optimierung zu steuern.",
        "Um die Testdaten zu vergrößern.",
        "Um Labels besser zu kodieren.",
        "Um die Loss-Funktion zu ersetzen."
      ],
      "answer": 1,
      "explanation": "Die **Lernrate** bestimmt die **Schrittgröße** der Updates. Zu große Werte führen zu Instabilität, zu kleine zu langsamer Konvergenz.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "mini_glossary": {
        "Gradientenabstieg": "Iteratives Minimierungsverfahren entlang des negativen Gradienten.",
        "Scheduler": "Regel, nach der die Lernrate im Verlauf angepasst wird."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Training & Optimierung"
    },
    {
      "question": "133. Was ist ein Epochendurchlauf im Training neuronaler Netze?",
      "options": [
        "Ein einzelnes Update eines Gewichts.",
        "Eine vollständige Verarbeitung des gesamten Trainingsdatensatzes.",
        "Ein zufälliger Shuffle der Testdaten.",
        "Eine Visualisierung der Gewichte.",
        "Eine einmalige Initialisierung der Parameter."
      ],
      "answer": 1,
      "explanation": "Eine **Epoche** bedeutet, dass **alle Trainingsbeispiele** einmal für Updates herangezogen wurden.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "mini_glossary": {
        "Mini-Batch": "Teilmenge von Trainingsbeispielen pro Update.",
        "Iteration": "Ein einzelner Optimierungsschritt mit einem Mini-Batch."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Training & Optimierung"
    },
    {
      "question": "134. Welche Rolle spielt die Loss-Funktion im Training?",
      "options": [
        "Sie generiert automatisch neue Daten.",
        "Sie misst, wie stark Vorhersagen von Zielwerten abweichen, und leitet die Optimierung.",
        "Sie ersetzt die Lernrate.",
        "Sie bestimmt die Größe der Testmenge.",
        "Sie verhindert jegliche Fehler."
      ],
      "answer": 1,
      "explanation": "Die **Loss-Funktion** quantifiziert **Fehler** und ist das Signal, das der Optimierer minimiert.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "mini_glossary": {
        "MSE": "Mean Squared Error, mittlerer quadratischer Fehler für Regression.",
        "Cross-Entropy": "Loss für Klassifikation basierend auf Wahrscheinlichkeiten."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Training & Optimierung"
    },
    {
      "question": "135. Wozu dient Batch-Normalisierung in tiefen Netzen?",
      "options": [
        "Zur Datenverschlüsselung in der Pipeline.",
        "Zur Stabilisierung von Aktivierungsverteilungen und schnelleren, robusteren Updates.",
        "Zur Ersetzung der Aktivierungsfunktion.",
        "Zur automatischen Etikettierung von Daten.",
        "Zur Verringerung der Anzahl an Merkmalen."
      ],
      "answer": 1,
      "explanation": "**Batch-Norm** normalisiert Zwischenaktivierungen und erlaubt **stabilere** sowie oft **schnellere** Optimierung.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "extended_explanation": {
        "titel": "Batch-Norm in der Praxis",
        "schritte": [
          "Innerhalb eines Mini-Batches Mittelwert und Varianz schätzen und normalisieren.",
          "Gelerntes Re-Skalieren und Verschieben bewahrt Modellkapazität.",
          "Beim Inferenzieren gleitende Schätzungen verwenden."
        ]
      },
      "mini_glossary": {
        "Aktivierung": "Ausgabe einer Schicht nach linearem Schritt und Nichtlinearität.",
        "Inferenz": "Anwendung eines trainierten Modells auf neue Daten."
      },
      "cognitive_level": "Anwendung",
      "concept": "Training & Optimierung"
    },
    {
      "question": "136. Warum ist Kreuzvalidierung nützlich?",
      "options": [
        "Sie vergrößert die Datenmenge künstlich.",
        "Sie liefert robustere Schätzungen der Generalisierung durch wiederholte Aufteilungen.",
        "Sie ersetzt die Loss-Funktion.",
        "Sie zwingt alle Modelle zur gleichen Genauigkeit.",
        "Sie verhindert jede Varianz im Training."
      ],
      "answer": 1,
      "explanation": "**Kreuzvalidierung** mittelt Ergebnisse über **mehrere Folds** und reduziert Zufallseinflüsse einzelner Splits.",
      "weight": 1,
      "topic": "Modellbewertung & Validierung",
      "mini_glossary": {
        "Fold": "Teilmenge von Daten, die abwechselnd als Training/Validierung dient.",
        "Stratifizierung": "Erhaltung der Klassenverteilung in allen Folds."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Validierung & Splits"
    },
    {
      "question": "137. Wozu dient ein Testset im ML-Prozess?",
      "options": [
        "Zur Feinjustierung der Hyperparameter während des Trainings.",
        "Zur finalen, unbeeinflussten Bewertung nach Entwicklung und Tuning.",
        "Zur Datenreinigung vor dem Training.",
        "Zur automatischen Merkmalsauswahl.",
        "Zur Erzeugung zusätzlicher Trainingsbeispiele."
      ],
      "answer": 1,
      "explanation": "Das **Testset** dient als **unabhängige** Referenz zur realistischen Leistungsabschätzung nach Abschluss des Modellbaus.",
      "weight": 1,
      "topic": "Modellbewertung & Validierung",
      "mini_glossary": {
        "Holdout": "Abgetrennter Datensatzteil, der nicht im Training verwendet wird.",
        "Leckage": "Unzulässiger Informationsfluss zwischen Splits, der Bewertungen verzerrt."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Validierung & Splits"
    },
    {
      "question": "138. Warum ist Stratifizierung bei unausgewogenen Klassen wichtig?",
      "options": [
        "Sie macht die Daten zufälliger.",
        "Sie stellt sicher, dass jedes Teilset die Klassenverteilung widerspiegelt.",
        "Sie sortiert Merkmale nach Wichtigkeit.",
        "Sie ersetzt die Wahl geeigneter Metriken.",
        "Sie macht Oversampling überflüssig in allen Fällen."
      ],
      "answer": 1,
      "explanation": "**Stratifizierung** bewahrt die **Klassenverhältnisse** in allen Splits und führt zu stabileren Kennzahlen.",
      "weight": 2,
      "topic": "Modellbewertung & Validierung",
      "extended_explanation": {
        "titel": "Stratifizierte Splits erstellen",
        "schritte": [
          "Klassenverteilung im Gesamtdatensatz bestimmen.",
          "Daten so aufteilen, dass die Verhältnisse in allen Folds ähnlich bleiben.",
          "Metriken pro Fold und im Mittel berichten."
        ]
      },
      "mini_glossary": {
        "Klassendisbalance": "Ungleich verteilte Klassenhäufigkeiten im Datensatz.",
        "Sampling": "Auswahlstrategie von Beispielen für Splits oder Training."
      },
      "cognitive_level": "Anwendung",
      "concept": "Validierung & Splits"
    },
    {
      "question": "139. Welche Wirkung hat L2-Regularisierung typischerweise?",
      "options": [
        "Sie erhöht Varianz und reduziert Bias stark.",
        "Sie bestraft große Gewichte, reduziert Varianz und stabilisiert das Modell.",
        "Sie erzeugt automatisch neue Merkmale.",
        "Sie verhindert jede Form von Fehlern.",
        "Sie macht Datenvorverarbeitung unnötig."
      ],
      "answer": 1,
      "explanation": "**L2-Regularisierung** schrumpft **Gewichte** und hilft, **Overfitting** zu mindern.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "mini_glossary": {
        "Regularisierung": "Zusatzterm oder Technik zur Kontrolle der Modellkomplexität.",
        "Gewichtsnorm": "Maß für die Größe von Modellparametern."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Regularisierung"
    },
    {
      "question": "140. Was ist der Hauptunterschied zwischen L1 und L2-Regularisierung?",
      "options": [
        "L1 führt oft zu spärlichen Lösungen, L2 verteilt Shrinkage gleichmäßiger.",
        "L1 erhöht immer die Genauigkeit, L2 senkt sie.",
        "L1 ist nur für Bilder, L2 nur für Text.",
        "L1 ersetzt die Loss-Funktion, L2 ersetzt die Metrik.",
        "L1 wirkt nur bei kleinen Datensätzen, L2 nur bei großen."
      ],
      "answer": 0,
      "explanation": "**L1** setzt viele Gewichte auf **genau 0** (eingebaute Selektion), **L2** glättet Parameter ohne exakte Nullsetzung.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "mini_glossary": {
        "Sparsity": "Viele Parameter sind exakt 0.",
        "Shrinkage": "Verkleinerung von Parametern zur Varianzreduktion."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Regularisierung"
    },
    {
      "question": "141. Wozu dient Dropout in neuronalen Netzen?",
      "options": [
        "Zur zufälligen Deaktivierung von Einheiten im Training, um Ko-Adaptationen zu verringern.",
        "Zur Erhöhung der Batchgröße.",
        "Zur automatischen Label-Generierung.",
        "Zur Ersetzung von Aktivierungsfunktionen.",
        "Zur Bestimmung der optimalen Lernrate."
      ],
      "answer": 0,
      "explanation": "**Dropout** verhindert **Ko-Adaptationen** und wirkt als Regularisierung, was die Generalisierung verbessert.",
      "weight": 1,
      "topic": "Training & Optimierung",
      "mini_glossary": {
        "Ko-Adaptation": "Übermäßige Abhängigkeit von bestimmten Pfaden oder Merkmalen.",
        "Rate": "Anteil der im Training deaktivierten Einheiten."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Regularisierung"
    },
    {
      "question": "142. Welche Aussage zum überwachten Lernen ist korrekt?",
      "options": [
        "Es benötigt keine Zielwerte.",
        "Es nutzt Eingabe-Ausgabe-Paare, um eine Abbildung zu lernen.",
        "Es erzeugt ausschließlich Cluster.",
        "Es ignoriert die Loss-Funktion.",
        "Es kann nicht für Regression verwendet werden."
      ],
      "answer": 1,
      "explanation": "**Überwachtes Lernen** basiert auf **Eingaben** und **Zielwerten** (Labels) und umfasst Klassifikation und Regression.",
      "weight": 1,
      "topic": "Überwachtes Lernen",
      "mini_glossary": {
        "Klassifikation": "Vorhersage diskreter Klassen.",
        "Regression": "Vorhersage kontinuierlicher Zielwerte."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Überwachtes Lernen"
    },
    {
      "question": "143. Welche Loss-Funktion passt typischerweise zu binärer Klassifikation?",
      "options": [
        "Mean Absolute Error.",
        "Binäre Kreuzentropie, da sie Wahrscheinlichkeiten bewertet.",
        "Hinge-Loss ausschließlich.",
        "MSE unabhängig von der Aufgabe.",
        "Keine, da Klassifikation keine Loss braucht."
      ],
      "answer": 1,
      "explanation": "Die **binäre Kreuzentropie** misst die Abweichung vorhergesagter **Wahrscheinlichkeit** vom wahren Label.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "extended_explanation": {
        "titel": "Binäre Kreuzentropie verstehen",
        "schritte": [
          "Modelle geben Scores oder Wahrscheinlichkeiten für die positive Klasse aus.",
          "Die Kreuzentropie bestraft falsche, sichere Vorhersagen stark.",
          "Kalibrierte Wahrscheinlichkeiten erleichtern Schwellenwahl und Entscheidungsfindung."
        ]
      },
      "mini_glossary": {
        "Kalibrierung": "Übereinstimmung zwischen vorhergesagten Wahrscheinlichkeiten und beobachteten Häufigkeiten.",
        "Schwellwert": "Grenze, ab der ein Score als positiv gilt."
      },
      "cognitive_level": "Anwendung",
      "concept": "Überwachtes Lernen"
    },
    {
      "question": "144. Warum ist die Wahl geeigneter Metriken bei unausgewogenen Klassen entscheidend?",
      "options": [
        "Weil Accuracy bei starker Dominanz einer Klasse irreführend hoch sein kann.",
        "Weil Accuracy immer zu niedrig ist.",
        "Weil Metriken das Training ersetzen.",
        "Weil Metriken die Daten bereinigen.",
        "Weil Metriken die Klassen automatisch ausbalancieren."
      ],
      "answer": 0,
      "explanation": "Bei **Imbalance** kann ein triviales Modell hohe **Accuracy** erzielen; **Precision/Recall** und **PR-AUC** sind aussagekräftiger.",
      "weight": 2,
      "topic": "Überwachtes Lernen",
      "extended_explanation": {
        "titel": "Metrikwahl bei Imbalance",
        "schritte": [
          "Verhältnisse der Klassen prüfen und baseline-Modelle vergleichen.",
          "Precision, Recall und F1 bewerten sowie PR-Kurven betrachten.",
          "Kosten/Nutzen von Fehlertypen berücksichtigen."
        ]
      },
      "mini_glossary": {
        "F1-Score": "Harmonisches Mittel aus Precision und Recall.",
        "PR-AUC": "Fläche unter der Precision-Recall-Kurve."
      },
      "cognitive_level": "Anwendung",
      "concept": "Überwachtes Lernen"
    },
    {
      "question": "145. Was ist ein typisches Ziel unüberwachter Lernverfahren?",
      "options": [
        "Vorhersage von Labels auf Testdaten.",
        "Erkennen von Strukturen oder Gruppen ohne vorgegebene Zielwerte.",
        "Maximierung der Trainingsgeschwindigkeit.",
        "Erhöhung der Bildauflösung.",
        "Erzeugung kryptografischer Schlüssel."
      ],
      "answer": 1,
      "explanation": "**Unüberwachtes Lernen** sucht **Strukturen** wie Cluster oder reduziert Dimensionen ohne Zielvariable.",
      "weight": 1,
      "topic": "Unüberwachtes Lernen",
      "mini_glossary": {
        "PCA": "Hauptkomponentenanalyse zur Dimensionsreduktion.",
        "Cluster": "Gruppe ähnlicher Datenpunkte im Merkmalsraum."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Unüberwachtes Lernen"
    },
    {
      "question": "146. Welche Aussage zu k-Means ist korrekt?",
      "options": [
        "Es benötigt keine Wahl von k.",
        "Es minimiert die Summe quadratischer Abstände zu Clusterzentren.",
        "Es arbeitet ohne Distanzbegriff.",
        "Es erzeugt immer perfekt runde Cluster.",
        "Es ist nur für Textdaten geeignet."
      ],
      "answer": 1,
      "explanation": "**k-Means** sucht **Zentren** und minimiert die Summe quadratischer **Distanzen** innerhalb der Cluster.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "extended_explanation": {
        "titel": "k-Means in Kürze",
        "schritte": [
          "Anzahl der Cluster k festlegen und Zentren initialisieren.",
          "Punkte dem nächstgelegenen Zentrum zuordnen und Zentren aktualisieren.",
          "Bis zur Konvergenz wiederholen; Skalierung und Initialisierung beeinflussen Ergebnisse."
        ]
      },
      "mini_glossary": {
        "Zentroid": "Arithmetischer Mittelpunkt eines Clusters.",
        "Inertie": "Summe der quadratischen Abstände innerhalb der Cluster."
      },
      "cognitive_level": "Anwendung",
      "concept": "Unüberwachtes Lernen"
    },
    {
      "question": "147. Wozu dient die Silhouette in der Clusteranalyse?",
      "options": [
        "Zur Bewertung der Trennschärfe und Kompaktheit von Clustern pro Punkt.",
        "Zur Vorhersage kontinuierlicher Zielwerte.",
        "Zur Erzeugung neuer Merkmale.",
        "Zur Wahl der Lernrate.",
        "Zur Verschlüsselung der Daten."
      ],
      "answer": 0,
      "explanation": "Die **Silhouette** misst **Passung zum eigenen Cluster** vs. Nähe zum nächsten fremden Cluster.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "extended_explanation": {
        "titel": "Silhouettenkoeffizient interpretieren",
        "schritte": [
          "Pro Punkt mittlere Intra- und Inter-Cluster-Distanzen berechnen.",
          "Werte nahe 1 deuten auf gute Trennung hin, nahe 0 auf Grenzfälle.",
          "Negative Werte können Fehlzuordnungen anzeigen."
        ]
      },
      "mini_glossary": {
        "Intra-Cluster": "Bezug auf Punkte im selben Cluster.",
        "Inter-Cluster": "Bezug auf Punkte in anderen Clustern."
      },
      "cognitive_level": "Anwendung",
      "concept": "Unüberwachtes Lernen"
    },
    {
      "question": "148. Welche Herausforderung entsteht bei hochdimensionalen Daten für Distanzbasen?",
      "options": [
        "Distanzen werden aussagekräftiger.",
        "Distanzen werden ähnlicher (Fluch der Dimensionalität), wodurch Nachbarschaft weniger informativ wird.",
        "Distanzen sind nicht mehr berechenbar.",
        "Distanzen hängen nicht mehr von Features ab.",
        "Distanzen eliminieren Ausreißer automatisch."
      ],
      "answer": 1,
      "explanation": "Mit steigender **Dimension** nähern sich **Distanzen** an; Verfahren wie k-NN oder k-Means verlieren an Aussagekraft ohne geeignete Vorverarbeitung.",
      "weight": 2,
      "topic": "Unüberwachtes Lernen",
      "extended_explanation": {
        "titel": "Fluch der Dimensionalität",
        "schritte": [
          "Skalierung und Merkmalsreduktion können Abstände wieder aussagekräftiger machen.",
          "Regelmäßige Evaluierung mit geeigneten Metriken ist notwendig.",
          "Domänenspezifische Feature-Konstruktion erhöht Signal-zu-Rausch-Verhältnis."
        ]
      },
      "mini_glossary": {
        "Dimensionsreduktion": "Verkleinerung der Anzahl von Merkmalen bei Erhalt wichtiger Information.",
        "Signal-Rausch-Verhältnis": "Verhältnis relevanter zu irrelevanter Variation."
      },
      "cognitive_level": "Anwendung",
      "concept": "Unüberwachtes Lernen"
    },
    {
      "question": "149. Welche Rolle spielt Transparenz in ML-Projekten?",
      "options": [
        "Sie ist optional und betrifft nur Hardware.",
        "Sie unterstützt Nachvollziehbarkeit von Daten, Modellen und Entscheidungen.",
        "Sie ersetzt die Dokumentation vollständig.",
        "Sie verhindert jede Form von Bias automatisch.",
        "Sie ist nur für Forschung relevant, nicht für Produkte."
      ],
      "answer": 1,
      "explanation": "**Transparenz** ermöglicht **Nachvollziehbarkeit** und schafft Vertrauen in Modelle, insbesondere bei kritischen Anwendungen.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "mini_glossary": {
        "Nachvollziehbarkeit": "Klare Dokumentation von Datenquellen, Annahmen und Modellversionen.",
        "Audit": "Systematische Prüfung von Prozessen und Ergebnissen."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Ethik & Praxis"
    },
    {
      "question": "150. Was beschreibt Bias im Kontext ethischer Fragestellungen am treffendsten?",
      "options": [
        "Zufällige Schwankungen im Training.",
        "Systematische Verzerrung, die zu unfairen Ergebnissen führen kann.",
        "Eine spezielle Aktivierungsfunktion in Netzen.",
        "Eine Technik zur Regularisierung.",
        "Ein Dateiformat für Modelle."
      ],
      "answer": 1,
      "explanation": "**Bias** kann aus **verzerrten Daten** oder unangemessenen Annahmen entstehen und zu **ungerechten** Entscheidungen führen.",
      "weight": 1,
      "topic": "Grundlagen & Praxis",
      "mini_glossary": {
        "Fairness": "Eigenschaft von Modellen, Gruppen oder Individuen nicht systematisch zu benachteiligen.",
        "Datenrepräsentativität": "Ausgewogenheit der Daten im Hinblick auf relevante Gruppen."
      },
      "cognitive_level": "Reproduktion",
      "concept": "Ethik & Praxis"
    },
    {
      "question": "151. Welche Maßnahme gehört zu verantwortungsvollem Einsatz von ML-Systemen?",
      "options": [
        "Verzicht auf jede Dokumentation, um schneller zu sein.",
        "Einführung von Evaluationskriterien und Monitoring im Betrieb.",
        "Ignorieren der Nutzerbeschwerden nach dem Roll-out.",
        "Zufällige Änderung von Hyperparametern nach der Produktion.",
        "Verbot von Testdaten in allen Projekten."
      ],
      "answer": 1,
      "explanation": "**Monitoring** und klare **Kriterien** helfen, Drift zu erkennen und Qualität langfristig zu sichern.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "extended_explanation": {
        "titel": "ML-Systeme im Betrieb überwachen",
        "schritte": [
          "Relevante Metriken und Alarme definieren.",
          "Daten- und Konzeptdrift regelmäßig prüfen.",
          "Feedbackkanäle und Eskalationspfade etablieren."
        ]
      },
      "mini_glossary": {
        "Daten-Drift": "Änderung der Eingabeverteilung über die Zeit.",
        "Konzept-Drift": "Änderung der Beziehung zwischen Eingaben und Zielwert."
      },
      "cognitive_level": "Anwendung",
      "concept": "Ethik & Praxis"
    },
    {
      "question": "152. Welche Praxis reduziert das Risiko von Datenlecks (Leakage) in ML-Pipelines?",
      "options": [
        "Vorverarbeitung vor dem Split auf alle Daten anwenden.",
        "Alle Schritte innerhalb von Validierungs-Folds fitten.",
        "Testdaten zum Training hinzufügen.",
        "Labels zur Skalierung verwenden.",
        "Schwellwerte anhand des Testsets wählen."
      ],
      "answer": 1,
      "explanation": "**Fold-interne** Anpassungen (Skalierung, Auswahl) verhindern **Leakage** und liefern realistischere Bewertungen.",
      "weight": 2,
      "topic": "Grundlagen & Praxis",
      "extended_explanation": {
        "titel": "Leakage vermeiden",
        "schritte": [
          "Split vor jeder datengetriebenen Transformation durchführen.",
          "Pipelines nutzen, damit Fit/Transform korrekt getrennt wird.",
          "Finale Bewertung ausschließlich auf dem Testset."
        ]
      },
      "mini_glossary": {
        "Pipeline": "Gekettete Verarbeitungsschritte mit konsistentem Fit/Transform.",
        "Validierung": "Bewertung außerhalb der zum Fit genutzten Daten."
      },
      "cognitive_level": "Anwendung",
      "concept": "Ethik & Praxis"
    },
    {
      "question": "153. Welche Kennzahl ist bei stark unausgewogenen Klassen oft hilfreicher als Accuracy?",
      "options": [
        "PR-AUC, da sie den Fokus auf die positive Klasse und Fehlalarme legt.",
        "MSE, da es kontinuierliche Fehler misst.",
        "PSNR, da es Bildqualität bewertet.",
        "Silhouette, da sie Cluster trennt.",
        "Kappa, da es Splits erzeugt."
      ],
      "answer": 0,
      "explanation": "**PR-AUC** betont **Precision** und **Recall** der positiven Klasse und ist bei Seltenheitsfällen oft informativer als Accuracy.",
      "weight": 3,
      "topic": "Modellbewertung & Validierung",
      "extended_explanation": {
        "titel": "Warum PR-AUC bei Imbalance?",
        "schritte": [
          "Wenige Positive machen Falsch-Positive besonders relevant.",
          "PR-Kurven zeigen Leistung im relevanten Bereich besser als ROC.",
          "Schwellenwahl an Anwendungs-Kosten ausrichten."
        ]
      },
      "mini_glossary": {
        "Precision": "Anteil korrekter Positivvorhersagen an allen Positivvorhersagen.",
        "Recall": "Anteil erkannter Positiver an allen tatsächlichen Positiven."
      },
      "cognitive_level": "Analyse",
      "concept": "Evaluation & Metriken"
    },
    {
      "question": "154. Welche Aussage zur Schwellenwahl bei probabilistischen Klassifikatoren trifft zu?",
      "options": [
        "Ein fester Standardwert ist immer optimal.",
        "Der optimale Schwellenwert hängt von Kosten, Nutzen und Metrikziel ab.",
        "Die Schwelle wird nach der Trainingszeit gewählt.",
        "Die Schwelle darf nur 0,5 sein.",
        "Die Schwelle ist bei allen Datensätzen gleich."
      ],
      "answer": 1,
      "explanation": "Die **Schwelle** ist **anwendungsabhängig**; Kosten von Fehlalarmen und verpassten Treffern bestimmen die sinnvolle Wahl.",
      "weight": 3,
      "topic": "Modellbewertung & Validierung",
      "extended_explanation": {
        "titel": "Schwellen systematisch bestimmen",
        "schritte": [
          "Vorhersagewahrscheinlichkeiten evaluieren statt nur harte Labels.",
          "ROC/PR und Kostenmatrix heranziehen.",
          "Schwelle anhand betrieblicher Ziele festlegen und periodisch prüfen."
        ]
      },
      "mini_glossary": {
        "Kostenmatrix": "Bewertet Fehlerarten mit unterschiedlichen Kosten.",
        "Kalibrierung": "Angleichung vorhergesagter Wahrscheinlichkeiten an Häufigkeiten."
      },
      "cognitive_level": "Analyse",
      "concept": "Validierung & Splits"
    },
    {
      "question": "155. Welche Herausforderung beschreibt der Begriff Datenethik im ML-Kontext?",
      "options": [
        "Die Wahl der optimalen Lernrate.",
        "Die verantwortliche Erhebung, Nutzung und Speicherung von Daten unter Beachtung von Rechten und Werten.",
        "Die effiziente GPU-Nutzung im Training.",
        "Die Optimierung der Batchgröße.",
        "Die automatische Fehlersuche in Quellcode."
      ],
      "answer": 1,
      "explanation": "**Datenethik** umfasst **Rechtmäßigkeit**, **Fairness** und **Transparenz** im Umgang mit Daten und Modellen.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "extended_explanation": {
        "titel": "Dimensionen der Datenethik",
        "schritte": [
          "Rechtliche Vorgaben wie Datenschutz berücksichtigen.",
          "Verzerrungen erkennen und mitigieren.",
          "Nutzer informieren und Einspruchsrechte respektieren."
        ]
      },
      "mini_glossary": {
        "Transparenz": "Nachvollziehbarkeit von Datenflüssen und Entscheidungen.",
        "Rechtsgrundlage": "Zulässiger Grund für Erhebung und Verarbeitung von Daten."
      },
      "cognitive_level": "Analyse",
      "concept": "Ethik & Praxis"
    },
    {
      "question": "156. Welche Maßnahme unterstützt die Reproduzierbarkeit von ML-Experimenten am stärksten?",
      "options": [
        "Verzicht auf jede Versionierung.",
        "Festhalten von Seeds, Umgebungen, Daten- und Modellversionen in strukturierter Form.",
        "Mündliche Dokumentation im Teammeeting.",
        "Zufällige Änderungen nach dem Training.",
        "Ausschließliche Nutzung von Testdaten zum Tuning."
      ],
      "answer": 1,
      "explanation": "Dokumentierte **Seeds**, **Versionen** und **Umgebungen** machen Ergebnisse **nachstellbar** und überprüfbar.",
      "weight": 3,
      "topic": "Grundlagen & Praxis",
      "extended_explanation": {
        "titel": "Reproduzierbarkeit sicherstellen",
        "schritte": [
          "Versionierung für Daten, Code und Modelle etablieren.",
          "Zufallsquellen kontrollieren und Umgebungen fixieren.",
          "Experimente protokollieren und Artefakte archivieren."
        ]
      },
      "mini_glossary": {
        "Seed": "Startwert für Zufallsprozesse zur Reproduktion.",
        "Artefakt": "Ergebnis eines Laufs, z.B. Modelldatei oder Bericht."
      },
      "cognitive_level": "Analyse",
      "concept": "Ethik & Praxis"
    },
    {
      "question": "157. Gegeben ist eine Matrix $A \\in \\mathbb{R}^{m \\times n}$ und eine Matrix $B \\in \\mathbb{R}^{n \\times k}$. Welche Dimensionen hat das Produkt $C = A \\cdot B$?",
      "options": [
        "$m \\times k$",
        "$n \\times n$",
        "$k \\times m$",
        "$m \\times n$"
      ],
      "answer": 0,
      "explanation": "Bei der Matrixmultiplikation muss die Spaltenanzahl der ersten Matrix ($n$) mit der Zeilenanzahl der zweiten Matrix ($n$) übereinstimmen. Das Ergebnis erbt die Zeilen von $A$ ($m$) und die Spalten von $B$ ($k$).",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Matrix-Multiplikation",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Dimension",
          "definition": "Größe einer Matrix (Zeilen x Spalten)."
        }
      ]
    },
    {
      "question": "158. Was beschreibt der Gradient $\\nabla f(x)$ einer skalaren Funktion $f: \\mathbb{R}^n \\to \\mathbb{R}$ an der Stelle $x$?",
      "options": [
        "Die Richtung des steilsten Abstiegs.",
        "Die Richtung des steilsten Anstiegs.",
        "Den Wert des globalen Minimums.",
        "Die Krümmung der Funktion."
      ],
      "answer": 1,
      "explanation": "Der Gradient ist ein Vektor, der in Richtung der größten Steigung der Funktion zeigt. Für Minimierungsprobleme (wie Gradient Descent) geht man daher in die *negative* Gradientenrichtung.",
      "weight": 1,
      "topic": "Modellbewertung & Validierung",
      "concept": "Gradient",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Gradient",
          "definition": "Vektor der partiellen Ableitungen erster Ordnung."
        }
      ]
    },
    {
      "question": "159. Welche Eigenschaft muss eine symmetrische Matrix $A$ haben, damit die quadratische Form $x^T A x$ streng konvex ist (d.h. ein eindeutiges Minimum bei 0 hat)?",
      "options": [
        "Sie muss orthogonal sein.",
        "Sie muss positiv definit sein (alle Eigenwerte $> 0$).",
        "Sie muss singulär sein.",
        "Sie muss invertierbar sein."
      ],
      "answer": 1,
      "explanation": "Eine Matrix ist positiv definit, wenn für alle $x \\neq 0$ gilt: $x^T A x > 0$. Geometrisch bedeutet dies, dass die Funktion in alle Richtungen nach oben gekrümmt ist (wie eine Schüssel).",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "Positive Definitheit",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Konvexität und Matrizen",
        "steps": [
          "Quadratische Form: $f(x) = x^T A x$.",
          "Eigenwerte: Bestimmen die Krümmung entlang der Eigenvektoren.",
          "Positiv Definit: Alle Eigenwerte positiv -> Krümmung überall positiv -> Konvex."
        ],
        "content": "Dies ist entscheidend für die Analyse von Kostenfunktionen und deren Minima."
      },
      "mini_glossary": [
        {
          "term": "Eigenwert",
          "definition": "Skalar $\\lambda$, für den $Av = \\lambda v$ gilt."
        }
      ]
    },
    {
      "question": "160. Sie wollen die L2-Norm (Euklidische Norm) eines Vektors berechnen. Welcher NumPy-Befehl fehlt?\n\n```python\n1: import numpy as np\n2: v = np.array([3, 4])\n3: norm = np.linalg.__________(v)\n4: # Ergebnis sollte 5.0 sein\n```",
      "options": [
        "abs",
        "norm",
        "dist",
        "length"
      ],
      "answer": 1,
      "explanation": "`np.linalg.norm(x)` berechnet standardmäßig die L2-Norm (Wurzel aus der Summe der Quadrate). $\\sqrt{3^2 + 4^2} = \\sqrt{9+16} = 5$.",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Vektor-Normen",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "L2-Norm",
          "definition": "Euklidische Länge eines Vektors."
        }
      ]
    },
    {
      "question": "161. Gegeben ist $f(x, y) = x^2 + 3y$. Was ist der partielle Ableitungsvektor (Gradient) $\\nabla f$?",
      "options": [
        "$\\begin{pmatrix} 2x \\\\ 3 \\end{pmatrix}$",
        "$\\begin{pmatrix} 2x \\\\ 3y \\end{pmatrix}$",
        "$\\begin{pmatrix} x \\\\ 3 \\end{pmatrix}$",
        "$2x + 3$"
      ],
      "answer": 0,
      "explanation": "Die partielle Ableitung nach $x$ ist $2x$ ($y$ wird als Konstante betrachtet, fällt weg). Die partielle Ableitung nach $y$ ist $3$ ($x^2$ fällt weg). Zusammen ergibt das den Vektor $(2x, 3)^T$.",
      "weight": 2,
      "topic": "Modellbewertung & Validierung",
      "concept": "Partielle Ableitung",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Berechnung partieller Ableitungen",
        "steps": [
          "Nach x ableiten: $x^2 \\to 2x$, $3y \\to 0$.",
          "Nach y ableiten: $x^2 \\to 0$, $3y \\to 3$.",
          "Zusammenfügen: Vektor aus den Ergebnissen."
        ],
        "content": "Im Machine Learning ist dies der Grundbaustein für Backpropagation."
      },
      "mini_glossary": [
        {
          "term": "Partielle Ableitung",
          "definition": "Ableitung einer Funktion mehrerer Variablen nach einer einzigen Variablen."
        }
      ]
    },
    {
      "question": "162. Wofür wird die Singulärwertzerlegung (SVD) im Machine Learning häufig verwendet?",
      "options": [
        "Um die Ableitung einer Funktion zu finden.",
        "Zur Dimensionsreduktion (z.B. in PCA oder Latent Semantic Analysis).",
        "Um Overfitting durch mehr Parameter zu erzwingen.",
        "Zur Erhöhung der Datenkomplexität."
      ],
      "answer": 1,
      "explanation": "SVD zerlegt eine Matrix in Komponenten, die nach Wichtigkeit (Singulärwerten) sortiert sind. Durch Weglassen der kleinen Singulärwerte kann man Daten komprimieren oder Rauschen entfernen (Low-Rank Approximation).",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "SVD / PCA",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "SVD Anwendung",
        "steps": [
          "Zerlegung: $A = U \\Sigma V^T$.",
          "$\\Sigma$: Diagonalmatrix mit Singulärwerten (Wichtigkeit).",
          "Reduktion: Behalte nur die größten $k$ Werte in $\\Sigma$.",
          "Resultat: Matrix bester Annäherung mit niedrigerem Rang."
        ],
        "content": "Dies ist der mathematische Kern der Principal Component Analysis (PCA)."
      },
      "mini_glossary": [
        {
          "term": "PCA",
          "definition": "Hauptkomponentenanalyse; Verfahren zur Dimensionsreduktion."
        }
      ]
    },
    {
      "question": "163. Was besagt der Satz von Bayes $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$?",
      "options": [
        "Er erlaubt die Berechnung der Wahrscheinlichkeit von A, gegeben B, basierend auf der Likelihood und dem Prior.",
        "Er besagt, dass A und B unabhängig sind.",
        "Er definiert den Erwartungswert einer Verteilung.",
        "Er dient zur Berechnung der Matrix-Inverse."
      ],
      "answer": 0,
      "explanation": "Der Satz von Bayes ist fundamental für 'Bayesian Inference'. Er aktualisiert die Wahrscheinlichkeit einer Hypothese $A$ (Posterior), nachdem Beweise $B$ beobachtet wurden.",
      "weight": 1,
      "topic": "Statistik & Wahrscheinlichkeit",
      "concept": "Satz von Bayes",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Posterior",
          "definition": "Wahrscheinlichkeit nach Berücksichtigung neuer Daten ($P(A|B)$)."
        },
        {
          "term": "Prior",
          "definition": "Vorwissen/A-priori-Wahrscheinlichkeit ($P(A)$)."
        }
      ]
    },
    {
      "question": "164. Sie haben zwei Vektoren $a, b \\in \\mathbb{R}^n$. Wenn das Skalarprodukt $a^T b = 0$ ist, was bedeutet das geometrisch?",
      "options": [
        "Die Vektoren sind parallel.",
        "Die Vektoren sind orthogonal (stehen senkrecht aufeinander).",
        "Die Vektoren sind identisch.",
        "Die Länge beider Vektoren ist 0."
      ],
      "answer": 1,
      "explanation": "Das Skalarprodukt ist definiert als $||a|| \\cdot ||b|| \\cdot \\cos(\\theta)$. Wenn es 0 ist, muss $\\cos(\\theta) = 0$ sein (sofern $a,b \\neq 0$), was einem Winkel von $90^\\circ$ entspricht.",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "Orthogonalität",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Skalarprodukt und Winkel",
        "steps": [
          "Formel: $a \\cdot b = \\sum a_i b_i$.",
          "Geometrie: $a \\cdot b = |a| |b| \\cos(\\alpha)$.",
          "Nullstelle: $\\cos(90^\\circ) = 0$.",
          "Schlussfolgerung: Orthogonalität."
        ],
        "content": "Orthogonalität ist wichtig für unkorrelierte Features und Basiswechsel."
      },
      "mini_glossary": [
        {
          "term": "Skalarprodukt",
          "definition": "Inneres Produkt zweier Vektoren, ergibt eine Zahl."
        }
      ]
    },
    {
      "question": "165. Berechnen Sie das Matrix-Vektor-Produkt:\n$$ \\begin{pmatrix} 1 & 2 \\\\ 0 & 3 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} $$",
      "options": [
        "$\\begin{pmatrix} 4 \\\\ 3 \\end{pmatrix}$",
        "$\\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$",
        "$\\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix}$",
        "$\\begin{pmatrix} 5 \\\\ 3 \\end{pmatrix}$"
      ],
      "answer": 0,
      "explanation": "Zeile 1 mal Vektor: $1\\cdot2 + 2\\cdot1 = 4$. Zeile 2 mal Vektor: $0\\cdot2 + 3\\cdot1 = 3$. Ergebnis: $(4, 3)^T$.",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "Matrix-Rechnung",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Rechenweg",
        "steps": [
          "1. Komponente: Zeile 1 ($1, 2$) dot Spalte ($2, 1$) -> $1*2 + 2*1 = 4$.",
          "2. Komponente: Zeile 2 ($0, 3$) dot Spalte ($2, 1$) -> $0*2 + 3*1 = 3$."
        ],
        "content": "Dies ist die Basisoperation in jedem Neural Network Layer ($W \\cdot x$)."
      },
      "mini_glossary": [
        {
          "term": "Dot Product",
          "definition": "Skalarprodukt von Zeilenvektor und Spaltenvektor."
        }
      ]
    },
    {
      "question": "166. In der Optimierung (z.B. Training neuronaler Netze) suchen wir $x$, sodass $\\nabla f(x) = 0$. Die Hesse-Matrix $H_f(x)$ ist an dieser Stelle positiv definit. Was liegt vor?",
      "options": [
        "Ein lokales Maximum.",
        "Ein Sattelpunkt.",
        "Ein lokales Minimum.",
        "Ein Wendepunkt ohne Extremum."
      ],
      "answer": 2,
      "explanation": "Wenn der Gradient 0 ist (kritischer Punkt) und die Hesse-Matrix (zweite Ableitung) positiv definit ist (positive Krümmung), handelt es sich um ein lokales Minimum.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Hesse-Matrix & Extrema",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Kriterien zweiter Ordnung",
        "steps": [
          "Notwendig: $\\nabla f(x) = 0$.",
          "Hinreichend: Prüfe Eigenwerte von $H_f(x)$.",
          "Alle Eigenwerte > 0 (Positiv Definit): Minimum.",
          "Alle Eigenwerte < 0 (Negativ Definit): Maximum.",
          "Gemischt: Sattelpunkt."
        ],
        "content": "In hochdimensionalen Räumen (Deep Learning) sind Sattelpunkte ein größeres Problem als lokale Minima."
      },
      "mini_glossary": [
        {
          "term": "Hesse-Matrix",
          "definition": "Matrix der zweiten partiellen Ableitungen."
        }
      ]
    },
    {
      "question": "167. Welcher Python-Code berechnet den Erwartungswert eines Arrays `x` mit Wahrscheinlichkeiten `p`?",
      "options": [
        "`np.sum(x * p)`",
        "`np.mean(x)`",
        "`np.sum(x) / len(x)`",
        "`np.dot(x, x)`"
      ],
      "answer": 0,
      "explanation": "Der Erwartungswert $E[X]$ ist definiert als $\\sum x_i \\cdot P(x_i)$. Dies entspricht dem Skalarprodukt der Werte und ihrer Wahrscheinlichkeiten. `np.mean(x)` wäre nur korrekt, wenn alle `p` gleich wären (uniform).",
      "weight": 2,
      "topic": "Statistik & Wahrscheinlichkeit",
      "concept": "Erwartungswert",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Gewichteter Mittelwert",
        "steps": [
          "Formel: $E[X] = \\sum x_i p_i$.",
          "Code: `x * p` multipliziert elementweise.",
          "Code: `np.sum(...)` summiert die Ergebnisse.",
          "Bedingung: `sum(p)` muss 1 sein."
        ],
        "content": "Der Erwartungswert ist das theoretische Mittel einer Zufallsvariablen."
      },
      "mini_glossary": [
        {
          "term": "Erwartungswert",
          "definition": "Mittelwert einer Zufallsvariablen gewichtet nach Wahrscheinlichkeit."
        }
      ]
    },
    {
      "question": "168. Was ist der Rang (Rank) einer Matrix?",
      "options": [
        "Die Anzahl der Elemente in der Matrix.",
        "Die Dimension der Matrix.",
        "Die maximale Anzahl linear unabhängiger Zeilen- oder Spaltenvektoren.",
        "Die Summe der Diagonalelemente."
      ],
      "answer": 2,
      "explanation": "Der Rang gibt an, wie viele Dimensionen der durch die Matrix aufgespannte Raum tatsächlich hat. Eine $3 \\times 3$ Matrix mit Rang 2 projiziert den Raum auf eine Ebene.",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Matrix-Rang",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Lineare Unabhängigkeit",
          "definition": "Ein Vektor lässt sich nicht als Linearkombination der anderen darstellen."
        }
      ]
    },
    {
      "question": "169. Wenn zwei Zufallsvariablen $X$ und $Y$ unabhängig sind, was gilt für ihre Kovarianz $Cov(X, Y)$?",
      "options": [
        "Sie ist 1.",
        "Sie ist 0.",
        "Sie ist unendlich.",
        "Sie ist gleich der Varianz von X."
      ],
      "answer": 1,
      "explanation": "Unabhängigkeit impliziert Unkorreliertheit. Wenn kein linearer Zusammenhang besteht, ist die Kovarianz 0. (Achtung: Kovarianz 0 impliziert nicht zwingend Unabhängigkeit, außer bei Normalverteilungen).",
      "weight": 1,
      "topic": "Statistik & Wahrscheinlichkeit",
      "concept": "Kovarianz",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Kovarianz",
          "definition": "Maß für den gemeinsamen linearen Zusammenhang zweier Variablen."
        }
      ]
    },
    {
      "question": "170. Warum verwenden wir im Machine Learning oft die Log-Likelihood $\\ln(L(\\theta))$ statt der Likelihood $L(\\theta)$ zur Maximierung?",
      "options": [
        "Weil der Logarithmus monotone Produkte in Summen umwandelt, was numerisch stabiler ist und die Ableitung vereinfacht.",
        "Weil der Logarithmus das Vorzeichen ändert und wir immer minimieren wollen.",
        "Weil die Likelihood-Funktion sonst negativ wäre.",
        "Weil Computer keine Multiplikationen können."
      ],
      "answer": 0,
      "explanation": "Likelihoods sind oft Produkte vieler kleiner Wahrscheinlichkeiten ($P(x_1) \\cdot P(x_2) \\dots$). Das führt zu numerischem Underflow. Der Logarithmus macht daraus eine Summe $\\sum \\ln P(x_i)$, und da $\\ln$ streng monoton steigend ist, bleibt die Position des Maximums gleich.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Log-Likelihood",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Log-Trick",
        "steps": [
          "Problem: $L = \\prod p_i$. Wenn $p_i < 1$, geht $L \\to 0$ (Underflow).",
          "Lösung: $\\ln(L) = \\ln(\\prod p_i) = \\sum \\ln(p_i)$.",
          "Eigenschaft: $\\text{argmax}_x f(x) = \\text{argmax}_x \\ln(f(x))$ (Monotonie).",
          "Vorteil: Summen sind einfacher abzuleiten als Produkte."
        ],
        "content": "Standardpraxis bei Maximum Likelihood Estimation (MLE) und Cross-Entropy Loss."
      },
      "mini_glossary": [
        {
          "term": "Underflow",
          "definition": "Zahl ist zu klein, um im Computer präzise dargestellt zu werden, wird zu 0."
        }
      ]
    },
    {
      "question": "171. Welche NumPy-Funktion fehlt, um zwei Matrizen `A` und `B` korrekt zu multiplizieren (Matrixprodukt)?\n\n```python\n1: A = np.eye(3)\n2: B = np.ones((3, 1))\n3: C = A.__________(B)\n```",
      "options": [
        "multiply",
        "dot",
        "times",
        "prod"
      ],
      "answer": 1,
      "explanation": "`A.dot(B)` oder `np.dot(A, B)` (oder der `@` Operator) führt die Matrixmultiplikation aus. `multiply` würde eine elementweise Multiplikation durchführen.",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "NumPy Syntax",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Elementweise vs. Matrix-Multiplikation",
        "steps": [
          "Elementweise (`*` oder `multiply`): $C_{ij} = A_{ij} \\cdot B_{ij}$. Benötigt gleiche Shape.",
          "Matrix (`@` oder `dot`): Zeile mal Spalte. Benötigt kompatible Shapes ($(n,k), (k,m)$)."
        ],
        "content": "Der häufigste Fehler in Python-ML-Code ist die Verwechslung dieser beiden Operationen."
      },
      "mini_glossary": [
        {
          "term": "Broadcasting",
          "definition": "NumPy-Mechanismus, um Arrays unterschiedlicher Größe elementweise zu verknüpfen."
        }
      ]
    },
    {
      "question": "172. Was ist die Spur (Trace) einer quadratischen Matrix?",
      "options": [
        "Das Produkt der Eigenwerte.",
        "Die Summe der Diagonalelemente.",
        "Die Determinante.",
        "Der größte Eintrag der Matrix."
      ],
      "answer": 1,
      "explanation": "Die Spur ist definiert als die Summe der Elemente auf der Hauptdiagonalen: $Tr(A) = \\sum A_{ii}$. Interessanterweise ist sie auch gleich der Summe der Eigenwerte.",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Matrix-Spur",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Trace",
          "definition": "Summe der Diagonalelemente."
        }
      ]
    },
    {
      "question": "173. Eine Funktion $f: \\mathbb{R}^n \\to \\mathbb{R}$ heißt konvex, wenn für alle $x, y$ und $\\lambda \\in [0, 1]$ gilt:",
      "options": [
        "$f(\\lambda x + (1-\\lambda)y) \\leq \\lambda f(x) + (1-\\lambda)f(y)$",
        "$f(\\lambda x + (1-\\lambda)y) \\geq \\lambda f(x) + (1-\\lambda)f(y)$",
        "$f(x+y) = f(x) + f(y)$",
        "$\\nabla f(x) = 0$"
      ],
      "answer": 0,
      "explanation": "Geometrisch bedeutet dies: Die Verbindungsstrecke (Sekante) zwischen zwei beliebigen Punkten auf dem Funktionsgraphen liegt immer *oberhalb* oder auf dem Graphen selbst. Dies garantiert, dass jedes lokale Minimum auch ein globales Minimum ist.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "concept": "Konvexität",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Konvexitäts-Ungleichung",
        "steps": [
          "Linke Seite: Funktionswert an einer Stelle zwischen x und y.",
          "Rechte Seite: Gewichteter Durchschnitt der Funktionswerte von x und y (Gerade).",
          "Bedingung: Funktion liegt 'unter' der Geraden.",
          "Wichtigkeit: Konvexe Probleme sind effizient lösbar."
        ],
        "content": "Lineare Regression und SVMs basieren auf konvexen Optimierungsproblemen."
      },
      "mini_glossary": [
        {
          "term": "Globales Minimum",
          "definition": "Tiefster Punkt der gesamten Funktion, nicht nur einer Umgebung."
        }
      ]
    },
    {
      "question": "174. Für welche Matrixoperation wird die Determinante benötigt, um die Existenz zu prüfen?",
      "options": [
        "Matrixaddition",
        "Transposition",
        "Inversion",
        "Multiplikation"
      ],
      "answer": 2,
      "explanation": "Eine quadratische Matrix ist genau dann invertierbar, wenn ihre Determinante ungleich 0 ist. Wenn $\\det(A) = 0$, ist die Matrix singulär.",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Determinante",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Singulär",
          "definition": "Nicht invertierbare Matrix ($\\det = 0$)."
        }
      ]
    },
    {
      "question": "175. Welcher Begriff beschreibt den Prozess des Findens der optimalen Parameter $\\theta$, die die Wahrscheinlichkeit der beobachteten Daten maximieren?",
      "options": [
        "Gradient Descent",
        "Maximum Likelihood Estimation (MLE)",
        "Bayesian Inference",
        "Principal Component Analysis"
      ],
      "answer": 1,
      "explanation": "MLE ist das statistische Prinzip, Parameter so zu wählen, dass die Daten unter dem Modell am wahrscheinlichsten erscheinen. Gradient Descent ist oft der *Algorithmus*, um dieses Maximum numerisch zu finden.",
      "weight": 2,
      "topic": "Statistik & Wahrscheinlichkeit",
      "concept": "MLE",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "MLE Prinzip",
        "steps": [
          "Gegeben: Daten $X$.",
          "Modell: Wahrscheinlichkeit $P(X|\\theta)$.",
          "Ziel: Finde $\\theta$, das $P(X|\\theta)$ maximiert.",
          "Methode: Leite Likelihood nach $\\theta$ ab und setze 0."
        ],
        "content": "Die Methode der kleinsten Quadrate (Least Squares) ist ein Spezialfall von MLE unter Annahme normalverteilter Fehler."
      },
      "mini_glossary": [
        {
          "term": "Likelihood",
          "definition": "Wahrscheinlichkeit der Daten als Funktion der Parameter."
        }
      ]
    },
    {
      "question": "176. Welche Aussage über Eigenvektoren $v$ und Eigenwerte $\\lambda$ einer Matrix $A$ ist korrekt?",
      "options": [
        "$Av = \\lambda v$",
        "$Av = v + \\lambda$",
        "$A\\lambda = v$",
        "$v^T A = \\lambda$"
      ],
      "answer": 0,
      "explanation": "Ein Eigenvektor ist ein Vektor, dessen Richtung sich durch die Anwendung der linearen Abbildung $A$ nicht ändert, sondern nur skaliert wird. Der Skalierungsfaktor ist der Eigenwert $\\lambda$.",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Eigenwert-Gleichung",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Lineare Abbildung",
          "definition": "Funktion zwischen Vektorräumen, die Addition und Skalarmultiplikation erhält."
        }
      ]
    },
    {
      "question": "177. Sie nutzen die Kettenregel, um den Gradienten in einem tiefen neuronalen Netz zu berechnen. Wenn $f(x) = g(h(x))$, was ist $f'(x)$?",
      "options": [
        "$g'(h(x)) \\cdot h'(x)$",
        "$g'(x) \\cdot h'(x)$",
        "$g'(h'(x))$",
        "$g(x) + h(x)$"
      ],
      "answer": 0,
      "explanation": "Die Kettenregel besagt: Äußere Ableitung (an der Stelle der inneren Funktion) mal innere Ableitung. Dies ist das fundamentale Prinzip von Backpropagation.",
      "weight": 2,
      "topic": "Modellbewertung & Validierung",
      "concept": "Kettenregel",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Backpropagation",
        "steps": [
          "Forward Pass: Berechne $z = h(x)$ und $y = g(z)$.",
          "Backward Pass: Wir wollen Änderung von y bezüglich x.",
          "Kettenregel: $\\frac{dy}{dx} = \\frac{dy}{dz} \\cdot \\frac{dz}{dx}$.",
          "Layer für Layer: Multiplikation der lokalen Gradienten."
        ],
        "content": "Ohne die Kettenregel könnten wir keine tiefen Netze trainieren."
      },
      "mini_glossary": [
        {
          "term": "Backpropagation",
          "definition": "Algorithmus zur effizienten Berechnung von Gradienten in Graphen/Netzen."
        }
      ]
    },
    {
      "question": "178. Welche Norm führt bei der Regularisierung (Lasso) dazu, dass viele Parameter exakt 0 werden (Sparsity)?",
      "options": [
        "L2-Norm ($||w||_2$)",
        "L1-Norm ($||w||_1$)",
        "L-Unendlich Norm",
        "Frobenius-Norm"
      ],
      "answer": 1,
      "explanation": "Die L1-Norm (Summe der Beträge) hat spitze Ecken im Parameterraum (Geometrie eines Oktaeders/Raute). Bei der Optimierung trifft man die Level-Sets der Kostenfunktion oft genau auf den Achsen, wo Parameter 0 sind.",
      "weight": 3,
      "topic": "Training & Optimierung",
      "concept": "Regularisierung & Normen",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "L1 vs L2 Geometrie",
        "steps": [
          "Constraint: Beschränkung der Parametergröße.",
          "L2 (Ridge): Kreisform. Berührungspunkt meist nicht auf Achse -> kleine Werte, aber nicht 0.",
          "L1 (Lasso): Rautenform. Ecken auf den Achsen. Berührungspunkt oft Ecke -> exakte 0.",
          "Nutzen: Feature Selection."
        ],
        "content": "L1 erzeugt 'Sparsity' (dünnbesetzte Vektoren), L2 verhindert nur extrem große Werte."
      },
      "mini_glossary": [
        {
          "term": "Sparsity",
          "definition": "Eigenschaft, dass viele Einträge eines Vektors null sind."
        }
      ]
    },
    {
      "question": "179. Was passiert mit der Determinante einer Matrix, wenn man zwei Zeilen vertauscht?",
      "options": [
        "Sie bleibt gleich.",
        "Sie ändert das Vorzeichen.",
        "Sie wird 0.",
        "Sie wird invertiert ($1/det$)."
      ],
      "answer": 1,
      "explanation": "Die Determinante ist eine alternierende Form. Das Vertauschen zweier Zeilen (oder Spalten) multipliziert den Wert mit -1.",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "Determinanten-Eigenschaften",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Determinante und Orientierung",
        "steps": [
          "Geometrie: Determinante misst Volumenänderung und Orientierung.",
          "Zeilentausch: Spiegelt das Koordinatensystem (z.B. x und y Achse tauschen).",
          "Effekt: Orientierung dreht sich um (Rechte-Hand-Regel wird Linke-Hand-Regel) -> Vorzeichenwechsel."
        ],
        "content": "Dies ist relevant beim Verständnis von Permutationsmatrizen."
      },
      "mini_glossary": [
        {
          "term": "Permutation",
          "definition": "Vertauschung von Elementen/Reihenfolgen."
        }
      ]
    },
    {
      "question": "180. Ein Vektor $v$ wird als Eigenvektor einer Matrix $A$ bezeichnet, wenn $v$ nicht der Nullvektor ist. Warum schließen wir den Nullvektor aus?",
      "options": [
        "Weil $A \\cdot 0 = \\lambda \\cdot 0$ für jedes beliebige $\\lambda$ wahr ist und der Eigenwert somit nicht eindeutig definiert wäre.",
        "Weil man durch 0 nicht teilen darf.",
        "Weil die Länge 0 Probleme bei der Normierung macht.",
        "Das ist nur Konvention ohne tieferen Grund."
      ],
      "answer": 0,
      "explanation": "Die Gleichung $A0 = 0$ gilt immer, egal welches $\\lambda$ man wählt. Der Nullvektor enthält keine Information über die Richtungs-Eigenschaften der Matrix.",
      "weight": 3,
      "topic": "Lineare Algebra",
      "concept": "Eigenvektor-Definition",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Triviale Lösung",
        "steps": [
          "Gleichung: $Av = \\lambda v$.",
          "Setze v=0: $A0 = 0$ und $\\lambda 0 = 0$.",
          "Ergebnis: $0=0$ ist immer wahr.",
          "Problem: Wir suchen spezifische Richtungen, 0 hat keine Richtung."
        ],
        "content": "Mathematische Definitionen schließen triviale Fälle oft aus, um Eindeutigkeit zu wahren."
      },
      "mini_glossary": [
        {
          "term": "Trivial",
          "definition": "Offensichtlich, einfach, oder ohne Informationsgehalt (wie die Lösung x=0)."
        }
      ]
    },
    {
      "question": "181. Wie berechnet man in NumPy die Inverse einer Matrix `A` (sofern sie existiert)?",
      "options": [
        "`np.inv(A)`",
        "`A ** -1`",
        "`np.linalg.inv(A)`",
        "`1 / A`"
      ],
      "answer": 2,
      "explanation": "Die Funktion liegt im Submodul `linalg`. `1/A` oder `A**-1` würde versuchen, die Operation elementweise durchzuführen, was mathematisch falsch ist für die Matrix-Inverse.",
      "weight": 1,
      "topic": "Lineare Algebra",
      "concept": "Inverse Matrix",
      "cognitive_level": "Reproduction",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Inverse Matrix",
          "definition": "Matrix $A^{-1}$, für die gilt $A A^{-1} = I$."
        }
      ]
    },
    {
      "question": "182. Die Taylor-Reihe wird genutzt, um Funktionen anzunähern. Wie lautet die Approximation erster Ordnung (Linearisierung) einer Funktion $f(x)$ an der Stelle $a$?",
      "options": [
        "$f(a) + f'(a)(x-a)$",
        "$f(a) + f'(a)$",
        "$f(a) + \\frac{1}{2}f''(a)(x-a)^2$",
        "$f'(a)(x-a)$"
      ],
      "answer": 0,
      "explanation": "Dies ist die Gleichung der Tangente an der Stelle $a$. Sie besteht aus dem Stützwert $f(a)$ und der Steigung $f'(a)$ multipliziert mit dem Abstand $(x-a)$.",
      "weight": 2,
      "topic": "Modellbewertung & Validierung",
      "concept": "Taylor-Reihe",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Lokale Approximation",
        "steps": [
          "Idee: Ersetze komplexe Kurve durch Gerade.",
          "Startpunkt: $f(a)$.",
          "Richtung: $f'(a)$.",
          "Schrittweite: $(x-a)$.",
          "Gradient Descent: Basiert auf genau dieser Approximation erster Ordnung."
        ],
        "content": "Newton-Verfahren nutzt zusätzlich die Approximation zweiter Ordnung (Hesse-Matrix)."
      },
      "mini_glossary": [
        {
          "term": "Linearisierung",
          "definition": "Annäherung einer nicht-linearen Funktion durch eine lineare Funktion."
        }
      ]
    },
    {
      "question": "183. Sie haben eine Matrix $X$ (Daten) der Größe $N \\times D$. Um die Kovarianzmatrix der Features zu berechnen (nach Zentrierung), welche Operation führen Sie aus?",
      "options": [
        "$\\frac{1}{N-1} X^T X$",
        "$\\frac{1}{N-1} X X^T$",
        "$X + X^T$",
        "$\\det(X)$"
      ],
      "answer": 0,
      "explanation": "$X^T X$ berechnet die Skalarprodukte zwischen den Spalten (Features). Das Ergebnis ist eine $D \\times D$ Matrix. $X X^T$ wäre $N \\times N$ (Ähnlichkeit zwischen Samples).",
      "weight": 3,
      "topic": "Statistik & Wahrscheinlichkeit",
      "concept": "Kovarianzmatrix Berechnung",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Datenmatrix Geometrie",
        "steps": [
          "X: Zeilen=Samples, Spalten=Features.",
          "Zentriert: Mittelwert jeder Spalte ist 0.",
          "Kovarianz: $E[(x-\\mu)(y-\\mu)]$.",
          "Matrix-Form: Summe über alle Samples entspricht Skalarprodukt der Spaltenvektoren -> $X^T X$."
        ],
        "content": "Dies ist der erste Schritt der PCA."
      },
      "mini_glossary": [
        {
          "term": "Sample",
          "definition": "Ein Datenpunkt/Beobachtung (Zeile)."
        },
        {
          "term": "Feature",
          "definition": "Merkmal/Eigenschaft (Spalte)."
        }
      ]
    },
    {
      "question": "184. Was bedeutet es, wenn ein Optimierungsproblem 'constrained' (nebenbedingungsbehaftet) ist? Welches mathematische Werkzeug hilft hier?",
      "options": [
        "Man nutzt Lagrange-Multiplikatoren, um die Nebenbedingungen in die Zielfunktion zu integrieren.",
        "Man ignoriert die Nebenbedingungen und prüft am Ende.",
        "Man setzt den Gradienten auf unendlich.",
        "Man kann das Problem nicht lösen."
      ],
      "answer": 0,
      "explanation": "Lagrange-Multiplikatoren erweitern die Zielfunktion $L(x, \\lambda) = f(x) - \\lambda g(x)$. Dies erlaubt das Finden von Extrema unter der Bedingung $g(x)=0$.",
      "weight": 2,
      "topic": "Training & Optimierung",
      "concept": "Lagrange-Multiplikatoren",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Lagrange Funktion",
        "steps": [
          "Original: Minimiere $f(x)$ unter $g(x)=0$.",
          "Idee: Gradienten von $f$ und $g$ müssen parallel sein.",
          "Lagrange: $\\nabla f = \\lambda \\nabla g$.",
          "Lösung: Suche stationäre Punkte von $L(x, \\lambda)$."
        ],
        "content": "Grundlage für Support Vector Machines (SVM) und viele Regularisierungsverfahren."
      },
      "mini_glossary": [
        {
          "term": "Constraint",
          "definition": "Einschränkung/Nebenbedingung, die die Lösung erfüllen muss."
        }
      ]
    },
    {
      "question": "185. Ein neuronaler Layer führt die Operation $y = \\sigma(Wx + b)$ aus. Wenn $x$ Dimension $d$ hat und der Layer $k$ Neuronen besitzt, welche Dimension hat der Bias-Vektor $b$?",
      "options": [
        "$d$",
        "$k$",
        "$d \\times k$",
        "$1$"
      ],
      "answer": 1,
      "explanation": "Jedes der $k$ Neuronen hat seinen eigenen Bias-Wert (Schwellenwert). Der Output $y$ hat Dimension $k$, daher muss auch $b$ Dimension $k$ haben, damit die Vektoraddition $Wx + b$ funktioniert.",
      "weight": 2,
      "topic": "Lineare Algebra",
      "concept": "Dimensionen in NN",
      "cognitive_level": "Application",
      "extended_explanation": {
        "title": "Layer Dimensionen",
        "steps": [
          "Input x: Vektor der Länge d.",
          "Gewichte W: Matrix $k \\times d$.",
          "Produkt Wx: Vektor der Länge k.",
          "Bias b: Muss zum Addieren Länge k haben."
        ],
        "content": "Broadcasting in Python erlaubt manchmal b als Skalar, aber mathematisch ist es ein Vektor."
      },
      "mini_glossary": [
        {
          "term": "Bias",
          "definition": "Verschiebungsparameter (Intercept) in einem linearen Modell."
        }
      ]
    },
    {
      "question": "186. Warum ist die Sigmoid-Funktion $\\sigma(x) = \\frac{1}{1+e^{-x}}$ für sehr große oder sehr kleine x problematisch für das Training (Gradient Descent)?",
      "options": [
        "Sie ist dort nicht definiert.",
        "Ihre Ableitung (Gradient) geht gegen 0 (Vanishing Gradient), wodurch das Lernen stoppt.",
        "Sie wird unendlich groß.",
        "Sie wird negativ."
      ],
      "answer": 1,
      "explanation": "Die Sigmoid-Funktion flacht für große Beträge von $x$ ab (Sättigung). Die Tangente wird waagerecht, die Ableitung somit nahe 0. Da Gradient Descent die Ableitung zum Update nutzt, ändern sich die Gewichte kaum noch.",
      "weight": 3,
      "topic": "Modellbewertung & Validierung",
      "concept": "Vanishing Gradient",
      "cognitive_level": "Analysis",
      "extended_explanation": {
        "title": "Sättigung von Aktivierungsfunktionen",
        "steps": [
          "Sigmoid Ableitung: $\\sigma'(x) = \\sigma(x)(1-\\sigma(x))$.",
          "Grenzwerte: Für $x \\to \\pm \\infty$ geht $\\sigma'$ gegen 0.",
          "Kettenregel: Viele kleine Zahlen multipliziert ergeben fast 0.",
          "Folge: Tiefe Netze lernen nicht."
        ],
        "content": "Dies führte zur Popularität von ReLU (Rectified Linear Unit), deren Ableitung 1 ist (für x>0)."
      },
      "mini_glossary": [
        {
          "term": "Sättigung",
          "definition": "Bereich einer Funktion, in dem sie sich kaum noch ändert."
        }
      ]
    }
  ]
}