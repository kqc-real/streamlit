{
  "meta": {
    "title": "Machine Learning Kapitel 1: Die ML-Umgebung",
    "created": "05.02.2026 12:50",
    "target_audience": "Informatikstudierende",
    "question_count": 20,
    "difficulty_profile": {
      "easy": 4,
      "medium": 10,
      "hard": 6
    },
    "language": "de",
    "time_per_weight_minutes": {
      "1": 0.5,
      "2": 0.75,
      "3": 1.0
    },
    "additional_buffer_minutes": 5,
    "test_duration_minutes": 25
  },
  "questions": [
    {
      "question": "1. In der Definition von Tom Mitchell lernt ein Programm aus Erfahrung $E$ bezüglich einer Aufgabe $T$ und einem Leistungsmaß $P$. Wenn Sie einen Spamfilter entwickeln, was stellt die 'Erfahrung $E$' dar?",
      "options": [
        "Der Trainingsdatensatz markierter Mails.",
        "Die Klassifikationsrate neuer E-Mails.",
        "Der zugrunde liegende Lernalgorithmus.",
        "Die Hardware, auf der das Modell läuft."
      ],
      "answer": 0,
      "explanation": "Laut Mitchell ist die Erfahrung $E$ die Datenquelle, aus der das System lernt. Beim Spamfilter sind dies die bereits vom Nutzer als Spam oder Ham markierten E-Mails im Trainingsdatensatz.",
      "weight": 1,
      "topic": "Grundlagen",
      "concept": "Erfahrung E",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        { "term": "Erfahrung E", "definition": "Die Daten oder Beispiele, aus denen ein ML-System lernt." },
        { "term": "Aufgabe T", "definition": "Die spezifische Problemstellung, die das System lösen soll." },
        { "term": "Leistungsmaß P", "definition": "Metrik zur Bewertung der Qualität der Problemlösung." },
        { "term": "Spamfilter", "definition": "Ein System zur automatischen Aussortierung unerwünschter Nachrichten." },
        { "term": "Trainingsdatensatz", "definition": "Sammlung von Beispielen für den Lernprozess." },
        { "term": "Tom Mitchell", "definition": "Informatiker, bekannt für seine präzise Definition von ML." }
      ]
    },
    {
      "question": "2. Worin besteht der terminologische Hauptunterschied zwischen den Begriffen 'Target' und 'Label' im Kontext des überwachten Lernens?",
      "options": [
        "Targets werden nur beim unüberwachten Lernen genutzt.",
        "Labels beschreiben Merkmale, Targets die Hyperparameter.",
        "Es gibt keinen Unterschied, sie sind absolut synonym.",
        "Target bei Regression, Label bei Klassifikation üblich."
      ],
      "answer": 3,
      "explanation": "Obwohl beide Begriffe oft synonym für die 'richtige Antwort' verwendet werden, ist 'Target' in der Regressionsanalyse (numerische Werte) gebräuchlicher, während 'Label' meist bei Klassifikationsaufgaben verwendet wird.",
      "weight": 1,
      "topic": "Lernparadigmen",
      "concept": "Fachjargon Target vs. Label",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        { "term": "Target", "definition": "Die Zielvariable in einer Regressionsaufgabe." },
        { "term": "Label", "definition": "Die Klassenzugehörigkeit in einer Klassifikationsaufgabe." },
        { "term": "Regression", "definition": "Vorhersage eines kontinuierlichen numerischen Wertes." },
        { "term": "Klassifikation", "definition": "Zuordnung einer Instanz zu einer diskreten Kategorie." },
        { "term": "Überwachtes Lernen", "definition": "Lernen mit Beispielen, die die Lösung bereits enthalten." },
        { "term": "Instanz", "definition": "Ein einzelner Datenpunkt im Datensatz." }
      ]
    },
    {
      "question": "3. Wie definiert das Lehrbuch den Prozess des 'Data Mining' im Verhältnis zum Machine Learning?",
      "options": [
        "Das reine Speichern großer Mengen von Webdaten.",
        "Mustererkennung in großen Mengen durch ML.",
        "Das Löschen von Duplikaten in Datenbanken.",
        "Das manuelle Markieren von Trainingsdaten."
      ],
      "answer": 1,
      "explanation": "Data Mining nutzt Machine-Learning-Techniken, um in großen Datenmengen Muster zu entdecken, die nicht unmittelbar ersichtlich sind. Dies hilft Menschen, komplexe Aufgaben besser zu verstehen.",
      "weight": 1,
      "topic": "Grundlagen",
      "concept": "Data Mining",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        { "term": "Data Mining", "definition": "Untersuchung großer Datenmengen zur Entdeckung von Mustern." },
        { "term": "Mustererkennung", "definition": "Fähigkeit eines Systems, Regelmäßigkeiten in Daten zu finden." },
        { "term": "Korrelation", "definition": "Statistischer Zusammenhang zwischen zwei Variablen." },
        { "term": "Einsicht", "definition": "Gewinnung von Verständnis aus einer Datenanalyse." },
        { "term": "Skalierbarkeit", "definition": "Fähigkeit eines Systems, mit wachsenden Datenmengen umzugehen." },
        { "term": "Analyse", "definition": "Systematische Untersuchung von Datenbestandteilen." }
      ]
    },
    {
      "question": "4. Welcher Begriff bezeichnet im Reinforcement Learning die Strategie, die festlegt, welche Aktion ein Agent in einer gegebenen Situation wählt?",
      "options": [
        "Kostenfunktion",
        "Prädiktor",
        "Policy",
        "Label"
      ],
      "answer": 2,
      "explanation": "Die Policy ist das Herzstück eines Reinforcement-Learning-Agenten. Sie fungiert als Vorschrift oder Strategie, die Beobachtungen der Umwelt in Aktionen übersetzt.",
      "weight": 1,
      "topic": "Lernparadigmen",
      "concept": "Policy",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        { "term": "Policy", "definition": "Strategie eines Agenten zur Wahl der nächsten Aktion." },
        { "term": "Agent", "definition": "Das Lernsystem in einer Reinforcement-Learning-Umgebung." },
        { "term": "Belohnung", "definition": "Positives Feedback für eine vorteilhafte Aktion." },
        { "term": "Umwelt", "definition": "Der Kontext, in dem der Agent agiert und beobachtet." },
        { "term": "Aktion", "definition": "Ein Eingriff des Agenten in seine Umgebung." },
        { "term": "Lernschritt", "definition": "Anpassung der Policy basierend auf Belohnungen." }
      ]
    },
    {
      "question": "5. Sie möchten den zukünftigen Umsatz Ihres Unternehmens basierend auf Werbeausgaben und Saisonalität vorhersagen. Welchem Aufgabentyp entspricht dies?",
      "options": [
        "Regression",
        "Klassifikation",
        "Clustering"
      ],
      "answer": 0,
      "explanation": "Da der Umsatz ein kontinuierlicher numerischer Wert ist, handelt es sich um eine Regressionsaufgabe. Klassifikation würde stattdessen Kategorien (z.B. 'Umsatz hoch'/'niedrig') vorhersagen.",
      "weight": 2,
      "topic": "Lernparadigmen",
      "concept": "Regression vs. Klassifikation",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Unterscheidung von Vorhersagetypen",
        "steps": [
          "Identifikation des Zielwerts (Umsatz).",
          "Prüfung des Datentyps (kontinuierliche Zahl).",
          "Zuordnung zum Regressionsmodell."
        ],
        "content": "Wenn das Ziel ein Zahlenwert auf einer Skala ist, wird Regression verwendet. Wäre das Ziel eine Gruppenzuordnung ohne numerische Bedeutung, wäre es Klassifikation."
      },
      "mini_glossary": [
        { "term": "Umsatz", "definition": "In diesem Kontext die kontinuierliche Zielvariable (Target)." },
        { "term": "Saisonalität", "definition": "Ein zeitabhängiges Merkmal (Feature) in den Daten." },
        { "term": "Kontinuierlich", "definition": "Werte, die jeden beliebigen Wert in einem Intervall annehmen können." },
        { "term": "Numerisch", "definition": "Auf Zahlen basierend und für mathematische Operationen geeignet." },
        { "term": "Vorhersage", "definition": "Schätzung eines unbekannten Wertes durch ein Modell." },
        { "term": "Modelltyp", "definition": "Die Wahl zwischen Regression, Klassifikation oder Clustering." }
      ]
    },
    {
      "question": "6. Ein Algorithmus gruppiert Besucher Ihres Blogs automatisch in 'Jugendliche Comic-Fans' und 'Erwachsene Sci-Fi-Fans'. Welcher Lernkategorie entspricht das?",
      "options": [
        "Überwachtes Lernen",
        "Teilüberwachtes Lernen",
        "Unüberwachtes Lernen"
      ],
      "answer": 2,
      "explanation": "Da das System die Gruppen ohne vorherige Labels (Vorgaben durch Menschen) selbstständig aufgrund von Ähnlichkeiten findet, handelt es sich um Clustering (unüberwachtes Lernen).",
      "weight": 2,
      "topic": "Lernparadigmen",
      "concept": "Clustering",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Merkmale des unüberwachten Lernens",
        "steps": [
          "Fehlen von Labels im Trainingsdatensatz feststellen.",
          "Suche nach inhärenten Strukturen (Clustern) durchführen.",
          "Gruppierung basierend auf Merkmalsähnlichkeit abschließen."
        ],
        "content": "Unüberwachtes Lernen benötigt keine Zielvorgaben. Es analysiert die statistische Verteilung der Merkmale, um natürliche Gruppen in den Daten zu identifizieren."
      },
      "mini_glossary": [
        { "term": "Clustering", "definition": "Automatische Gruppierung ähnlicher Datenpunkte." },
        { "term": "Unüberwacht", "definition": "Lernen ohne Zielvorgaben oder menschliche Korrektur." },
        { "term": "Ähnlichkeit", "definition": "Maß für die Übereinstimmung von Datenpunkten." },
        { "term": "Struktur", "definition": "Inhärente Ordnung oder Verteilung in einem Datensatz." },
        { "term": "Blogbesucher", "definition": "Die Instanzen, die im Beispiel gruppiert werden." },
        { "term": "Merkmal", "definition": "Eigenschaft einer Instanz (z. B. gelesene Artikel)." }
      ]
    },
    {
      "question": "7. Warum wird die Dimensionsreduktion (z. B. Zusammenfassen von Alter und Kilometerstand eines Autos) oft vor dem eigentlichen Training durchgeführt?",
      "options": [
        "Um die Anzahl der Trainingsinstanzen künstlich zu erhöhen.",
        "Um sicherzustellen, dass das Modell komplexer wird.",
        "Um das Rauschen in den Daten absichtlich zu verstärken.",
        "Spart Speicherplatz und verkürzt die Rechenzeit."
      ],
      "answer": 3,
      "explanation": "Dimensionsreduktion vereinfacht die Daten, indem korrelierende Merkmale kombiniert werden. Dies reduziert den Rechenaufwand, spart Speicher und verbessert oft die Performance des Modells.",
      "weight": 2,
      "topic": "Lernparadigmen",
      "concept": "Dimensionsreduktion",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Vorteile der Merkmalsvereinfachung",
        "steps": [
          "Erkennen von Korrelationen zwischen Merkmalen.",
          "Zusammenfassen zu einem neuen, aussagekräftigen Merkmal.",
          "Reduktion der Eingabedimensionen für den Lernalgorithmus."
        ],
        "content": "Weniger Eingabevariablen bedeuten weniger Parameter im Modell. Dies führt zu schnellerer Inferenz und reduziert die Gefahr, dass das Modell sich in irrelevanten Details verliert."
      },
      "mini_glossary": [
        { "term": "Dimensionsreduktion", "definition": "Verringerung der Anzahl der Eingabemerkmale." },
        { "term": "Korrelation", "definition": "Zusammenhang, bei dem Merkmale ähnliche Information tragen." },
        { "term": "Rechenzeit", "definition": "Dauer, die ein Algorithmus für das Training benötigt." },
        { "term": "Inferenz", "definition": "Anwendung des fertigen Modells auf neue Daten." },
        { "term": "Speichereffizienz", "definition": "Sparsame Nutzung von RAM und Festplatte." },
        { "term": "Feature Extraction", "definition": "Erzeugen neuer Merkmale aus vorhandenen Daten." }
      ]
    },
    {
      "question": "8. Ein System zur Anomalieerkennung wird mit normalen Transaktionen trainiert. Wie reagiert es auf eine völlig neuartige betrügerische Transaktion?",
      "options": [
        "Stuft sie als Anomalie ein, da sie vom Gelernten abweicht.",
        "Es ignoriert sie, da es sie im Training nicht gesehen hat.",
        "Es ordnet sie dem größten Cluster normaler Daten zu.",
        "Es bittet den Nutzer sofort um ein neues Label."
      ],
      "answer": 0,
      "explanation": "Anomalieerkennung lernt, wie 'normale' Daten aussehen. Jeder neue Punkt, der statistisch signifikant von diesem Muster abweicht, wird automatisch als Anomalie oder Ausreißer markiert.",
      "weight": 2,
      "topic": "Lernparadigmen",
      "concept": "Anomalieerkennung",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Funktionsweise der Ausreißererkennung",
        "steps": [
          "Modellierung des 'Normalzustands' während des Trainings.",
          "Vergleich einer neuen Instanz mit dem Normalmodell.",
          "Abweichungsprüfung über einen Schwellenwert."
        ],
        "content": "Das System muss den Betrug nicht kennen. Es reicht aus, dass der Betrug anders aussieht als die legitimen Transaktionen, um einen Alarm auszulösen."
      },
      "mini_glossary": [
        { "term": "Anomalie", "definition": "Ein Datenpunkt, der stark vom Erwartungswert abweicht." },
        { "term": "Normalzustand", "definition": "Die Mehrheit der Daten, die das System als Referenz nutzt." },
        { "term": "Ausreißer", "definition": "Einzelner Datenpunkt mit extremen Werten." },
        { "term": "Schwellenwert", "definition": "Grenze, ab der eine Abweichung als Anomalie gilt." },
        { "term": "Transaktion", "definition": "Ein einzelner Vorgang (z. B. Kauf), der geprüft wird." },
        { "term": "Fehlalarm", "definition": "Fälschliche Einstufung einer normalen Instanz als Anomalie." }
      ]
    },
    {
      "question": "9. Google Photos gruppiert Gesichter (unüberwacht) und fragt Sie dann nach dem Namen. Welcher Lernkategorie entspricht dieser kombinierte Prozess?",
      "options": [
        "Reinforcement Learning",
        "Teilüberwachtes Lernen",
        "Batch-Learning",
        "Instanzbasiertes Lernen"
      ],
      "answer": 1,
      "explanation": "Teilüberwachtes Lernen kombiniert viele ungelabelte Daten (Bilder) mit wenigen gelabelten Beispielen (Ihre Namenszuweisung), um die Effizienz des Labelings zu steigern.",
      "weight": 2,
      "topic": "Lernparadigmen",
      "concept": "Teilüberwachtes Lernen",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Effizienz durch Datenkombination",
        "steps": [
          "Clustering der ungelabelten Bilder nach Ähnlichkeit.",
          "Abfrage eines Labels für einen Repräsentanten der Gruppe.",
          "Propagierung des Labels auf die gesamte Gruppe."
        ],
        "content": "Dieser Ansatz spart Zeit und Kosten, da nicht jedes einzelne Foto manuell benannt werden muss, sondern das System die Struktur der Daten vorab erkennt."
      },
      "mini_glossary": [
        { "term": "Teilüberwacht", "definition": "Mix aus wenigen gelabelten und vielen ungelabelten Daten." },
        { "term": "Label-Propagierung", "definition": "Übertragung eines Labels auf ähnliche Datenpunkte." },
        { "term": "Effizienz", "definition": "Erreichen eines Ziels mit minimalem Aufwand (hier Labeling)." },
        { "term": "Fotodienst", "definition": "Anwendungsbeispiel für Gesichtserkennung." },
        { "term": "Kombination", "definition": "Zusammenführung von überwachten und unüberwachten Techniken." },
        { "term": "Repräsentant", "definition": "Ein typisches Beispiel für einen Cluster." }
      ]
    },
    {
      "question": "10. Ein Modell lernt erst, beschädigte Bilder zu reparieren (ohne Labels) und wird dann für die Tiererkennung feingetuned. Wie nennt man das Übertragen dieses Wissens?",
      "options": [
        "Deep Learning",
        "Online-Learning",
        "Data Mining",
        "Transfer Learning"
      ],
      "answer": 3,
      "explanation": "Transfer Learning bezeichnet das Nutzen eines Modells, das für eine Aufgabe trainiert wurde, als Startpunkt für eine neue, verwandte Aufgabe.",
      "weight": 2,
      "topic": "Grundlagen",
      "concept": "Transfer Learning",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Wissensrecycling in neuronalen Netzen",
        "steps": [
          "Vortraining auf einer allgemeinen Aufgabe (z. B. Bildreparatur).",
          "Anpassung der letzten Schichten für die Zielaufgabe (z. B. Katzen).",
          "Feintuning mit einem kleinen, spezifischen Datensatz."
        ],
        "content": "Da das Modell bereits Grundformen und Farben aus der Bildreparatur kennt, benötigt es viel weniger spezifische Tierfotos, um eine hohe Genauigkeit zu erreichen."
      },
      "mini_glossary": [
        { "term": "Transfer Learning", "definition": "Wiederverwendung von gelerntem Wissen für neue Aufgaben." },
        { "term": "Vortraining", "definition": "Erster Lernschritt auf einem großen, oft ungelabelten Datensatz." },
        { "term": "Feintuning", "definition": "Letzte Anpassung des Modells an die spezifische Zielaufgabe." },
        { "term": "Bildreparatur", "definition": "Beispiel für eine selbstüberwachte Voraufgabe." },
        { "term": "Neuronales Netz", "definition": "Architektur, die sich besonders gut für Transfer Learning eignet." },
        { "term": "Spezifisch", "definition": "Auf eine eng begrenzte Aufgabe bezogen." }
      ]
    },
    {
      "question": "11. Warum ist Online-Learning für Systeme wie Aktienkurs-Vorhersagen besser geeignet als Batch-Learning?",
      "options": [
        "Passt sich inkrementell an fluktuierende Datenströme an.",
        "Es verbraucht immer weniger CPU-Leistung insgesamt.",
        "Batch-Learning kann keine numerischen Werte vorhersagen.",
        "Online-Learning benötigt keine Validierung der Daten."
      ],
      "answer": 0,
      "explanation": "Online-Learning kann Daten stückweise verarbeiten und sich sofort an neue Trends anpassen. Batch-Learning müsste bei jeder Änderung zeitaufwendig mit dem gesamten Datensatz neu trainiert werden.",
      "weight": 2,
      "topic": "Training & Anpassung",
      "concept": "Inkrementelles Lernen",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Anpassung an dynamische Märkte",
        "steps": [
          "Empfangen neuer Datenpunkte in Echtzeit.",
          "Durchführung eines schnellen Updates des Modells.",
          "Berücksichtigung neuester Markttrends ohne Neustart."
        ],
        "content": "In Umgebungen mit hoher Volatilität veralten Batch-Modelle zu schnell. Online-Modelle bleiben durch ständige kleine Lernschritte aktuell."
      },
      "mini_glossary": [
        { "term": "Inkrementell", "definition": "Schrittweises Hinzufügen von Wissen." },
        { "term": "Fluktuierend", "definition": "Sich schnell und unvorhersehbar ändernd." },
        { "term": "Aktienkurs", "definition": "Beispiel für Zeitreihendaten mit hoher Dynamik." },
        { "term": "Online-Learning", "definition": "Lernform, die kontinuierliche Datenströme verarbeitet." },
        { "term": "Batch-Learning", "definition": "Lernform, die Daten in einem geschlossenen Block trainiert." },
        { "term": "Datenstrom", "definition": "Ununterbrochene Abfolge eintreffender Informationen." }
      ]
    },
    {
      "question": "12. Welches Problem wird primär durch 'Out-of-Core-Lernen' gelöst?",
      "options": [
        "Fehlende Internetverbindung beim Training.",
        "Die Notwendigkeit, ohne CPU-Kerne zu rechnen.",
        "Datensätze, die nicht in den Hauptspeicher passen.",
        "Das automatische Löschen veralteter Modelle."
      ],
      "answer": 2,
      "explanation": "Wenn ein Datensatz nicht in den RAM passt, zerlegt Out-of-Core-Lernen ihn in Stücke. Ein Online-Learning-Algorithmus verarbeitet diese Stücke dann nacheinander.",
      "weight": 2,
      "topic": "Training & Anpassung",
      "concept": "Out-of-Core-Lernen",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Umgang mit Big Data Hardware-Limits",
        "steps": [
          "Laden eines Teilstücks des Datensatzes von der Festplatte.",
          "Durchführung des Trainingsschritts auf diesem Stück.",
          "Wiederholen des Vorgangs für alle weiteren Stücke."
        ],
        "content": "Diese Technik ermöglicht es, riesige Datenmengen auf Standard-Hardware zu verarbeiten, indem der RAM-Bedarf pro Schritt gering gehalten wird."
      },
      "mini_glossary": [
        { "term": "Out-of-Core", "definition": "Lernprozess für Daten, die nicht in den RAM passen." },
        { "term": "Hauptspeicher (RAM)", "definition": "Begrenzter Arbeitsspeicher des Computers." },
        { "term": "Festplatte", "definition": "Speichermedium für große, persistente Datenmengen." },
        { "term": "Chunk", "definition": "Ein Teilstück eines großen Datensatzes." },
        { "term": "Hardware-Limit", "definition": "Physische Grenze der Rechenressourcen." },
        { "term": "Datenmenge", "definition": "Gesamtes Volumen der verfügbaren Informationen." }
      ]
    },
    {
      "question": "13. In der Formel $y = \\theta_0 + \\theta_1 \\times x$ sind $\\theta_0$ und $\\theta_1$ Parameter. Was geschieht beim 'Trainieren' dieses Modells?",
      "options": [
        "Der Nutzer rät die Werte für $\\theta$ manuell.",
        "Ein Algorithmus findet $\\theta$, die Fehler minimieren.",
        "Das Modell löscht alle $\\theta$, die negativ sind.",
        "Die Parameter werden nach jedem Test zufällig gewürfelt."
      ],
      "answer": 1,
      "explanation": "Training ist ein Optimierungsprozess. Ein Algorithmus (wie die lineare Regression) sucht systematisch nach den Parameterwerten, bei denen die Kostenfunktion (der Fehler) am kleinsten ist.",
      "weight": 2,
      "topic": "Training & Anpassung",
      "concept": "Parameteroptimierung",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Optimierung durch Fehlerrechnung",
        "steps": [
          "Definition einer Kostenfunktion (Abweichung Modell zu Daten).",
          "Anpassung der Parameter $\\theta$ durch den Lernalgorithmus.",
          "Erreichen des globalen oder lokalen Minimums des Fehlers."
        ],
        "content": "Das Ziel ist die beste Anpassung an die Trainingsdaten, damit das Modell das zugrunde liegende Muster (z. B. eine Gerade) korrekt wiedergibt."
      },
      "mini_glossary": [
        { "term": "Modellparameter", "definition": "Interne Variablen des Modells, die gelernt werden." },
        { "term": "Kostenfunktion", "definition": "Mathematische Funktion, die den Fehler des Modells misst." },
        { "term": "Optimierung", "definition": "Suche nach dem besten Zustand (hier: minimaler Fehler)." },
        { "term": "Lineare Regression", "definition": "Verfahren zum Finden einer Geraden durch Datenpunkte." },
        { "term": "Theta (\\theta)", "definition": "Griechischer Buchstabe, oft Symbol für Parameter." },
        { "term": "Minimierung", "definition": "Prozess der Verringerung einer Größe (hier: Kosten)." }
      ]
    },
    {
      "question": "14. Ein System vergleicht neue E-Mails direkt mit gespeicherten Spam-Mails über die Anzahl gemeinsamer Wörter. Wie nennt man diesen Verallgemeinerungsansatz?",
      "options": [
        "Modellbasiertes Lernen",
        "Reinforcement Learning",
        "Instanzbasiertes Lernen"
      ],
      "answer": 2,
      "explanation": "Instanzbasiertes Lernen nutzt kein abstraktes Modell wie eine Formel. Es speichert Beispiele (Instanzen) auswendig und klassifiziert neue Daten basierend auf ihrer Ähnlichkeit zu diesen Beispielen.",
      "weight": 2,
      "topic": "Training & Anpassung",
      "concept": "Instanzbasiertes Lernen",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Lernen durch Ähnlichkeitsvergleich",
        "steps": [
          "Speichern aller Trainingsinstanzen im System.",
          "Berechnung der Distanz/Ähnlichkeit zu einem neuen Punkt.",
          "Mehrheitsentscheidung der ähnlichsten Nachbarn nutzen."
        ],
        "content": "Dieses Verfahren ist sehr flexibel, kann aber bei großen Datenmengen langsam werden, da für jede Vorhersage viele Vergleiche nötig sind."
      },
      "mini_glossary": [
        { "term": "Instanzbasiert", "definition": "Lernen durch direktes Speichern von Beispielen." },
        { "term": "Ähnlichkeitsmaß", "definition": "Metrik zum Vergleich zweier Datenpunkte." },
        { "term": "Auswendiglernen", "definition": "Triviale Form des Wissenserwerbs ohne Abstraktion." },
        { "term": "k-Nächste-Nachbarn", "definition": "Klassischer instanzbasierter Algorithmus." },
        { "term": "Verallgemeinerung", "definition": "Fähigkeit, auf neuen Daten korrekt zu reagieren." },
        { "term": "Speicheraufwand", "definition": "Bedarf an Platz für alle gelernten Instanzen." }
      ]
    },
    {
      "question": "15. Warum lieferte die Literary-Digest-Umfrage von 1936 trotz 2,4 Millionen Antworten eine völlig falsche Vorhersage für die US-Wahl?",
      "options": [
        "Daten waren durch Stichprobenverzerrung nicht repräsentativ.",
        "Die Stichprobe war zu klein für statistische Signifikanz.",
        "Das Modell litt unter extremem Overfitting auf die Kandidaten.",
        "Es wurde versehentlich ein unüberwachtes Verfahren genutzt."
      ],
      "answer": 0,
      "explanation": "Trotz der Masse waren die Daten verzerrt, da vor allem wohlhabende Personen (Telefonbesitzer/Klubmitglieder) befragt wurden. Große Datenmengen heilen keine methodischen Fehler bei der Datenerhebung.",
      "weight": 3,
      "topic": "Herausforderungen & Validierung",
      "concept": "Stichprobenverzerrung",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Analyse systematischer Fehler",
        "steps": [
          "Untersuchung der Erhebungsmethode (Telefonbücher/Listen).",
          "Identifikation der sozialen Schieflage der Stichprobe.",
          "Bewertung der Nicht-Repräsentativität für die Gesamtbevölkerung."
        ],
        "content": "Die Stichprobenverzerrung (Sampling Bias) führt dazu, dass ein Modell eine Realität lernt, die nicht der Zielpopulation entspricht. Qualität der Daten schlägt Quantität."
      },
      "mini_glossary": [
        { "term": "Stichprobenverzerrung", "definition": "Systematischer Fehler bei der Auswahl der Datenpunkte." },
        { "term": "Repräsentativität", "definition": "Eigenschaft einer Stichprobe, die Grundgesamtheit korrekt abzubilden." },
        { "term": "Sampling Bias", "definition": "Englischer Fachbegriff für Stichprobenverzerrung." },
        { "term": "Grundgesamtheit", "definition": "Die gesamte Gruppe, über die eine Aussage getroffen werden soll." },
        { "term": "Literary Digest", "definition": "Historisches Beispiel für gescheiterte Vorhersagen." },
        { "term": "Schweigeverzerrung", "definition": "Verzerrung durch selektive Teilnahme an Umfragen." }
      ]
    },
    {
      "question": "16. Ein Modell zur Zufriedenheit nutzt den Namen des Landes als Merkmal und lernt: 'Alle Länder mit einem w im Namen sind glücklich'. Welches Problem liegt hier vor?",
      "options": [
        "Underfitting durch zu einfache Merkmale.",
        "Datenmangel, da zu wenig Länder ein w enthalten.",
        "Overfitting durch Lernen von Mustern im Rauschen.",
        "Stichprobenrauschen durch zu große Datensätze."
      ],
      "answer": 2,
      "explanation": "Das Modell ist zu komplex relativ zur Datenmenge und lernt zufällige Korrelationen (Rauschen), die nicht verallgemeinerbar sind. Solche Scheinmuster führen zu schlechter Qualität bei neuen Daten.",
      "weight": 3,
      "topic": "Herausforderungen & Validierung",
      "concept": "Overfitting auf Rauschen",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Mustererkennung vs. Zufall",
        "steps": [
          "Einbeziehung irrelevanter Merkmale (Ländername).",
          "Erkennung einer zufälligen Übereinstimmung (Buchstabe 'w').",
          "Fehlinterpretation als kausaler oder stabiler Trend."
        ],
        "content": "Komplexe Modelle neigen dazu, jedes Detail der Trainingsdaten 'auswendig' zu lernen. Ohne Regularisierung unterscheiden sie nicht zwischen echtem Signal und zufälligem Rauschen."
      },
      "mini_glossary": [
        { "term": "Overfitting", "definition": "Überanpassung des Modells an die Trainingsdaten." },
        { "term": "Rauschen", "definition": "Zufällige, nicht aussagekräftige Anteile in den Daten." },
        { "term": "Scheinmuster", "definition": "Korrelation ohne tatsächliche Grundlage in der Realität." },
        { "term": "Regularisierung", "definition": "Technik zur Vereinfachung von Modellen gegen Overfitting." },
        { "term": "Kausalität", "definition": "Echter Ursache-Wirkungs-Zusammenhang." },
        { "term": "Generalisierungsfehler", "definition": "Abweichung des Modells bei neuen, unbekannten Daten." }
      ]
    },
    {
      "question": "17. Wenn Sie die Regularisierung eines linearen Modells verstärken (z. B. $\\theta_1$ nahe 0 zwingen), welchen Effekt hat dies auf die Modellflexibilität?",
      "options": [
        "Das Modell erhält mehr Freiheitsgrade.",
        "Die Anzahl der Freiheitsgrade wird reduziert.",
        "Die Gefahr für Underfitting sinkt drastisch.",
        "Das Modell passt sich besser an Ausreißer an."
      ],
      "answer": 1,
      "explanation": "Regularisierung schränkt das Modell ein. Weniger Freiheitsgrade machen das Modell 'starrer', was Overfitting verhindert, aber das Risiko für Underfitting erhöht.",
      "weight": 3,
      "topic": "Herausforderungen & Validierung",
      "concept": "Freiheitsgrade und Regularisierung",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Steuerung der Modellkomplexität",
        "steps": [
          "Einführung von Restriktionen für die Parameter $\\theta$.",
          "Reduktion der mathematischen Flexibilität der Kurve.",
          "Erzwingen einer glatteren, einfacheren Modellfunktion."
        ],
        "content": "Ein Modell mit nur einem Freiheitsgrad kann nur die Höhe ändern. Ein Modell mit zwei kann auch die Steigung anpassen. Regularisierung findet den Mittelweg."
      },
      "mini_glossary": [
        { "term": "Freiheitsgrad", "definition": "Anzahl der unabhängig veränderbaren Parameter." },
        { "term": "Starrheit", "definition": "Unfähigkeit eines Modells, komplexe Muster abzubilden." },
        { "term": "Hyperparameter", "definition": "Stellschraube des Lernalgorithmus (z. B. Grad der Regularisierung)." },
        { "term": "Bias-Variance Tradeoff", "definition": "Abwägung zwischen Einfachheit und Flexibilität." },
        { "term": "Restriktion", "definition": "Einschränkung der erlaubten Werte für Parameter." },
        { "term": "Fitten", "definition": "Anpassen der Modellfunktion an die Datenpunkte." }
      ]
    },
    {
      "question": "18. Ihr Blumen-Erkennungsmodell funktioniert super auf Web-Bildern (Trainingsdaten), aber schlecht auf Handy-Fotos (Validierungsdaten). Wie nutzen Sie ein 'Train-Dev-Set', um die Ursache zu finden?",
      "options": [
        "Es dient dazu, mehr Handy-Fotos künstlich zu generieren.",
        "Es ersetzt den Testdatensatz komplett zur Sicherheit.",
        "Man mischt Web- und Handybilder darin für ein Chaos.",
        "Prüfung auf Overfitting vs. Datendiskrepanz."
      ],
      "answer": 3,
      "explanation": "Das Train-Dev-Set besteht aus Web-Bildern, die nicht zum Training genutzt wurden. Funktioniert das Modell dort auch schlecht, liegt Overfitting vor. Funktioniert es dort gut, liegt eine Datendiskrepanz vor.",
      "weight": 3,
      "topic": "Herausforderungen & Validierung",
      "concept": "Train-Dev-Set Diagnose",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Fehlerdiagnose bei unterschiedlichen Datenquellen",
        "steps": [
          "Vergleich Fehlerquote Training vs. Train-Dev (Overfitting Check).",
          "Vergleich Fehlerquote Train-Dev vs. Validation (Mismatch Check).",
          "Ableitung der Optimierungsstrategie (Datenaufbereitung vs. Modellvereinfachung)."
        ],
        "content": "Ohne Train-Dev-Set weiß man nicht, ob das Modell zu komplex ist oder ob Handy-Fotos einfach physikalisch zu anders sind (Licht, Schärfe) als Web-Bilder."
      },
      "mini_glossary": [
        { "term": "Train-Dev-Set", "definition": "Teilmenge der Trainingsdaten zur Overfitting-Diagnose." },
        { "term": "Datendiskrepanz", "definition": "Unterschied in der Verteilung von Trainings- und Produktivdaten." },
        { "term": "Mismatch", "definition": "Nichtübereinstimmung der Datencharakteristika." },
        { "term": "Validierung", "definition": "Prüfung des Modells auf repräsentativen Daten." },
        { "term": "Datenquelle", "definition": "Herkunft der Bilder (z. B. Web vs. Smartphone-Kamera)." },
        { "term": "Fehlerquote", "definition": "Anteil falsch klassifizierter Instanzen." }
      ]
    },
    {
      "question": "19. Das 'No-Free-Lunch-Theorem' besagt, dass kein Modell a priori besser ist als ein anderes. Welche praktische Konsequenz ergibt sich daraus für einen Data Scientist?",
      "options": [
        "Man muss mehrere Modelle evaluieren und vergleichen.",
        "Man sollte immer nur das komplexeste Modell wählen.",
        "Mathematische Beweise sind im ML völlig wertlos.",
        "Modelle müssen ohne jede Annahme trainiert werden."
      ],
      "answer": 0,
      "explanation": "Da kein Modell universell überlegen ist, müssen für jede Aufgabe verschiedene Kandidaten (z. B. Linear vs. Neuronal) getestet werden. Annahmen über die Daten helfen, die Auswahl sinnvoll einzugrenzen.",
      "weight": 3,
      "topic": "Herausforderungen & Validierung",
      "concept": "No-Free-Lunch-Theorem",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Implikationen der Modellblindheit",
        "steps": [
          "Verzicht auf die Suche nach dem 'einen wahren' Algorithmus.",
          "Durchführung systematischer Vergleichstests (Benchmark).",
          "Nutzung von Domänenwissen zur Einschränkung des Suchraums."
        ],
        "content": "Das NFL-Theorem zwingt zur Empirie. Da man nicht alles testen kann, trifft man begründete Annahmen, bleibt aber bereit, das Modell bei schlechter Performance zu wechseln."
      },
      "mini_glossary": [
        { "term": "No-Free-Lunch-Theorem", "definition": "Theorem: Kein Modell ist ohne Annahmen überlegen." },
        { "term": "A priori", "definition": "Im Vorhinein, ohne empirische Prüfung." },
        { "term": "Empirie", "definition": "Erkenntnisgewinnung durch Beobachtung und Experiment." },
        { "term": "Domänenwissen", "definition": "Fachwissen über den spezifischen Anwendungsbereich." },
        { "term": "Modellauswahl", "definition": "Entscheidung für eine bestimmte Algorithmenfamilie." },
        { "term": "Benchmark", "definition": "Vergleichstest unter standardisierten Bedingungen." }
      ]
    },
    {
      "question": "20. Was passiert, wenn Sie Hyperparameter wiederholt direkt am Testdatensatz optimieren, anstatt einen Validierungsdatensatz zu nutzen?",
      "options": [
        "Das Modell wird mathematisch instabil und stürzt ab.",
        "Die Trainingszeit pro Epoche verlängert sich exponentiell.",
        "Geschätzter Verallgemeinerungsfehler wird zu optimistisch.",
        "Es gibt keinen Effekt, das ist ein übliches Vorgehen."
      ],
      "answer": 2,
      "explanation": "Wenn Hyperparameter auf den Testdatensatz 'gefittet' werden, 'leckt' Information des Tests in das Modell. Der Test ist dann nicht mehr unabhängig und liefert geschönte, unrealistische Ergebnisse.",
      "weight": 3,
      "topic": "Herausforderungen & Validierung",
      "concept": "Data Leakage / Overfitting on Test Set",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Verlust der Test-Unabhängigkeit",
        "steps": [
          "Anpassung der Modellkonfiguration an Testergebnisse.",
          "Indirektes Lernen der Testcharakteristika durch das Modell.",
          "Scheinbare Fehlerminimierung ohne echte Generalisierung."
        ],
        "content": "Der Testdatensatz darf erst ganz am Ende angefasst werden. Nutzt man ihn zur Optimierung, wird er Teil des Trainingsprozesses und verliert seine Funktion als objektive Erfolgskontrolle."
      },
      "mini_glossary": [
        { "term": "Verallgemeinerungsfehler", "definition": "Fehler bei völlig neuen Datenpunkten." },
        { "term": "Validierungsdatensatz", "definition": "Puffer-Set zur Abstimmung der Hyperparameter." },
        { "term": "Optimistisch", "definition": "Hier: Fälschlicherweise zu gut bewertet." },
        { "term": "Data Leakage", "definition": "Unerwünschtes Einfließen von Testwissen in das Training." },
        { "term": "Hold-out-Validierung", "definition": "Zurückhalten von Daten zur neutralen Bewertung." },
        { "term": "Unabhängigkeit", "definition": "Fehlen gegenseitiger Beeinflussung von Datensätzen." }
      ]
    }
  ]
}
