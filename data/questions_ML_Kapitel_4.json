{
  "questions": [
    {
      "question": "1. Welcher mathematische Ansatz berechnet die Modellparameter $\\theta$ einer linearen Regression direkt in geschlossener Form, um den MSE zu minimieren?",
      "options": [
        "Die Normalengleichung",
        "Das Gradientenverfahren",
        "Die logistische Funktion",
        "Das Simulated Annealing"
      ],
      "answer": 0,
      "explanation": "Die Normalengleichung ermöglicht die direkte Berechnung der optimalen Parameter mittels einer mathematischen Formel ohne iterative Schritte. Sie minimiert die Kostenfunktion direkt über den gesamten Datensatz.",
      "weight": 1,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Normalengleichung",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Normalengleichung",
          "definition": "Mathematische Formel zur direkten Berechnung optimaler Modellparameter."
        },
        {
          "term": "MSE",
          "definition": "Mean Squared Error; Maß für die durchschnittliche quadratische Abweichung."
        }
      ]
    },
    {
      "question": "2. Wie wird eine vollständige Iteration über den gesamten Trainingsdatensatz im Kontext von Gradientenverfahren bezeichnet?",
      "options": [
        "Ein Batch-Lauf",
        "Eine Epoche",
        "Ein Lernschritt",
        "Eine Konvergenz"
      ],
      "answer": 1,
      "explanation": "Eine Epoche beschreibt den Prozess, bei dem der Algorithmus jedes Beispiel im Trainingsdatensatz genau einmal verarbeitet hat. Dies ist die zentrale Maßeinheit für den Trainingsfortschritt.",
      "weight": 1,
      "topic": "Gradientenverfahren",
      "concept": "Epoche",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Epoche",
          "definition": "Ein vollständiger Durchlauf durch alle verfügbaren Trainingsdaten."
        },
        {
          "term": "Iteration",
          "definition": "Ein einzelner Update-Schritt der Modellparameter."
        }
      ]
    },
    {
      "question": "3. Welcher Hyperparameter steuert maßgeblich die Schrittweite bei der Anpassung der Modellparameter im Gradientenverfahren?",
      "options": [
        "Die Epochenanzahl",
        "Der Bias-Term $\\theta_0$",
        "Die Lernrate $\\eta$",
        "Die Toleranz $\\epsilon$"
      ],
      "answer": 2,
      "explanation": "Die Lernrate $\\eta$ bestimmt die Größe der Korrekturschritte entlang des negativen Gradienten. Eine falsche Wahl kann zu langsamer Konvergenz oder Divergenz führen.",
      "weight": 1,
      "topic": "Gradientenverfahren",
      "concept": "Lernrate",
      "cognitive_level": "Reproduktion",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Lernrate",
          "definition": "Skalierungsfaktor für die Parameteränderung pro Trainingsschritt."
        },
        {
          "term": "Hyperparameter",
          "definition": "Vom Nutzer gesetzte Konfiguration, die nicht vom Modell gelernt wird."
        }
      ]
    },
    {
      "question": "4. Sie berechnen eine Vorhersage für ein lineares Modell mit $\\theta = [4, 3]^T$ und dem Merkmalsvektor $x = [1, 2]^T$ (mit $x_0=1$). Welchen Wert liefert die Hypothese $\\hat{y} = \\theta \\cdot x$?",
      "options": [
        "Der Wert beträgt 7,0",
        "Der Wert beträgt 10,0",
        "Der Wert beträgt 11,0",
        "Der Wert beträgt 12,0"
      ],
      "answer": 1,
      "explanation": "Die Vorhersage wird über das Skalarprodukt berechnet: $4 \\cdot 1 + 3 \\cdot 2 = 4 + 6 = 10$. Hierbei repräsentiert die 4 den Bias-Term $\\theta_0$.",
      "weight": 2,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Hypothesenfunktion",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Berechnung des Skalarprodukts",
        "content": "Das lineare Modell bildet die Vorhersage als gewichtete Summe der Merkmale ab. In Vektorschreibweise entspricht dies dem Skalarprodukt.",
        "steps": [
          "Identifikation: $\\theta_0=4, \\theta_1=3$ und $x_0=1, x_1=2$.",
          "Anwendung: $\\hat{y} = \\theta_0 x_0 + \\theta_1 x_1$.",
          "Berechnung: $4 \\cdot 1 + 3 \\cdot 2 = 10$."
        ]
      },
      "mini_glossary": [
        {
          "term": "Skalarprodukt",
          "definition": "Summe der Produkte entsprechender Komponenten zweier Vektoren."
        },
        {
          "term": "Bias-Term",
          "definition": "Konstanter Achsenabschnitt eines linearen Modells."
        }
      ]
    },
    {
      "question": "5. Gegeben ist folgender Python-Code zur Implementierung eines Gradientenschritts: ```python\n1: gradients = 2 / m * X_b.T @ (X_b @ theta - y)\n2: theta = theta - eta * gradients\n``` Welche Variante wird hier implementiert, wenn `X_b` alle Trainingsdaten enthält?",
      "options": [
        "Batch-Gradientenverfahren",
        "Stochastisches Verfahren",
        "Mini-Batch-Verfahren",
        "Polynomielle Regression"
      ],
      "answer": 0,
      "explanation": "Da der Gradient über die gesamte Matrix `X_b` (alle m Instanzen) berechnet wird, handelt es sich um das Batch-Verfahren. Dies nutzt alle Daten für einen einzigen Schritt.",
      "weight": 2,
      "topic": "Gradientenverfahren",
      "concept": "Batch-Update",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Analyse des Matrix-Updates",
        "content": "In dieser Implementierung wird der Gradient für alle Datenpunkte gleichzeitig bestimmt, was stabil aber speicherintensiv ist.",
        "steps": [
          "Matrix `X_b` umfasst den gesamten Datensatz.",
          "Der Gradient wird gemittelt über alle m Instanzen berechnet.",
          "Dies charakterisiert das Batch-Verfahren gegenüber SGD."
        ]
      },
      "mini_glossary": [
        {
          "term": "Vektorisierung",
          "definition": "Gleichzeitige Berechnung mehrerer Datenpunkte mittels Matrixoperationen."
        }
      ]
    },
    {
      "question": "6. Fehlerkurven für Training und Validierung liegen nah beieinander, erreichen aber ein Plateau auf einem insgesamt hohen Fehler-Niveau. Welche Diagnose stellen Sie?",
      "options": [
        "Es liegt Overfitting vor",
        "Es liegt Underfitting vor",
        "Modellkomplexität ist ideal",
        "Daten-Skalierung ist falsch"
      ],
      "answer": 1,
      "explanation": "Wenn beide Fehler hoch sind und zusätzliche Daten nicht helfen, ist das Modell zu einfach für die Datenstruktur (hoher Bias/Underfitting).",
      "weight": 2,
      "topic": "Lernkurven",
      "concept": "Underfitting",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Interpretation von Plateaus",
        "content": "Lernkurven zeigen bei Underfitting, dass das Modell die Komplexität der Daten nicht erfassen kann, unabhängig von der Datenmenge.",
        "steps": [
          "Beobachtung: Hoher Fehler in Training und Validierung.",
          "Analyse: Kurven haben sich bereits angenähert.",
          "Schlussfolgerung: Modellkapazität reicht nicht aus."
        ]
      },
      "mini_glossary": [
        {
          "term": "Underfitting",
          "definition": "Zustand, in dem ein Modell zu einfach ist, um Muster in den Daten zu lernen."
        }
      ]
    },
    {
      "question": "7. Warum ist die Skalierung der Merkmale beim Gradientenverfahren kritisch, wenn Features unterschiedliche Wertebereiche haben?",
      "options": [
        "Kostenfunktion wird länglich",
        "MSE wird mathematisch komplex",
        "Bias kann nicht gelernt werden",
        "SVD funktioniert nur skaliert"
      ],
      "answer": 0,
      "explanation": "Unterschiedliche Skalen strecken die Kostenfunktion zu einer länglichen Ellipse. Der Gradient zeigt dann nicht mehr direkt zum Minimum, was die Konvergenz extrem verlangsamt.",
      "weight": 2,
      "topic": "Gradientenverfahren",
      "concept": "Merkmalsskalierung",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Geometrie der Fehlerlandschaft",
        "content": "Standardisierung sorgt für kreisförmige Konturen, wodurch der Gradient direkt zum Zentrum weist.",
        "steps": [
          "Skalierung beeinflusst die Form der Niveaulinien.",
          "Ungleiche Skalen führen zu schmalen Tälern.",
          "Das Verfahren 'zick-zackt' zum Minimum."
        ]
      },
      "mini_glossary": [
        {
          "term": "Standardisierung",
          "definition": "Transformation von Merkmalen auf Mittelwert 0 und Varianz 1."
        }
      ]
    },
    {
      "question": "8. Welcher Regularisierungs-Term wird zur Kostenfunktion addiert, um eine Ridge-Regression (L2) durchzuführen?",
      "options": [
        "$\\frac{\\alpha}{m} \\sum_{i=1}^{n} \\theta_i^2$",
        "$\\alpha \\sum_{i=1}^{n} |\\theta_i|$",
        "$r \\cdot L1 + (1-r) \\cdot L2$",
        "$\\frac{1}{m} \\sum (\\hat{y} - y)^2$"
      ],
      "answer": 0,
      "explanation": "Ridge nutzt das Quadrat der Gewichte. Dies bestraft besonders große Koeffizienten und führt zu einer glatteren Modellfunktion.",
      "weight": 2,
      "topic": "Regularisierte lineare Modelle",
      "concept": "L2-Regularisierung",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "Ridge-Strafterm",
        "content": "Die L2-Regularisierung reduziert die Varianz des Modells, indem sie extreme Parameterwerte unterdrückt.",
        "steps": [
          "Addition der quadrierten Parameter $\\theta_i$.",
          "Wichtung durch Hyperparameter $\\alpha$.",
          "Ausschluss des Bias-Terms $\\theta_0$."
        ]
      },
      "mini_glossary": [
        {
          "term": "Regularisierung",
          "definition": "Verfahren zur Vermeidung von Overfitting durch Zusatzstrafen."
        }
      ]
    },
    {
      "question": "9. Welche spezifische Eigenschaft unterscheidet die Lasso-Regression (L1) von der Ridge-Regression?",
      "options": [
        "Automatische Merkmalsauswahl",
        "Robustheit gegen Ausreißer",
        "Nutzung der Pseudoinversen",
        "Immer geschlossene Lösung"
      ],
      "answer": 0,
      "explanation": "Lasso eliminiert die Gewichte der unwichtigsten Merkmale vollständig, indem es sie auf Null setzt. Dadurch fungiert es gleichzeitig als Methode zur Merkmalsauswahl.",
      "weight": 2,
      "topic": "Regularisierte lineare Modelle",
      "concept": "Lasso-Regression",
      "cognitive_level": "Anwendung",
      "extended_explanation": {
        "title": "L1-Effekt",
        "content": "Lasso erzeugt spärliche Modelle, was bei Datensätzen mit vielen irrelevanten Merkmalen vorteilhaft ist.",
        "steps": [
          "L1-Norm hat Ecken auf den Achsen.",
          "Optimierung trifft oft diese Ecken.",
          "Resultat: Gewichte werden exakt Null."
        ]
      },
      "mini_glossary": [
        {
          "term": "Spärliches Modell",
          "definition": "Modell, bei dem viele Parameter exakt den Wert Null haben."
        }
      ]
    },
    {
      "question": "10. In Scikit-Learn implementiert `SGDRegressor` das stochastische Gradientenverfahren. Welcher Parameter aktiviert Ridge-Regularisierung?",
      "options": [
        "penalty='l2'",
        "regularization='ridge'",
        "loss='squared_error'",
        "alpha=0"
      ],
      "answer": 0,
      "explanation": "Der Parameter `penalty` legt den Typ fest. 'l2' entspricht der Ridge-Bestrafung basierend auf der quadrierten Norm.",
      "weight": 2,
      "topic": "Regularisierte lineare Modelle",
      "concept": "Scikit-Learn API",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Penalty",
          "definition": "Strafterm in der Kostenfunktion zur Regularisierung."
        }
      ]
    },
    {
      "question": "11. Wie skaliert die Berechnungs-Komplexität bezüglich der Merkmale $n$ beim SVD-Ansatz von Scikit-Learn im Vergleich zur Normalengleichung?",
      "options": [
        "SVD $O(n^2)$, Normalengl. $O(n^3)$",
        "SVD $O(n^3)$, Normalengl. $O(n)$",
        "Beide skalieren mit $O(n^2)$",
        "SVD ist nur für große m gut"
      ],
      "answer": 0,
      "explanation": "Die Normalengleichung erfordert eine Matrizeninversion ($O(n^3)$), während der SVD-Ansatz (Singulärwertzerlegung) etwa $O(n^2)$ benötigt und somit besser skaliert.",
      "weight": 3,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Laufzeitkomplexität",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Rechenaufwand",
        "content": "SVD ist nicht nur schneller bei vielen Merkmalen, sondern auch numerisch stabiler als die direkte Inversion.",
        "steps": [
          "Inversion skaliert kubisch mit der Merkmalszahl.",
          "SVD zerlegt die Matrix effizienter.",
          "Unterschied wird bei großen n massiv."
        ]
      },
      "mini_glossary": [
        {
          "term": "SVD",
          "definition": "Singular Value Decomposition; Verfahren zur Matrixzerlegung."
        }
      ]
    },
    {
      "question": "12. Warum konvergiert das Batch-Gradientenverfahren im Gegensatz zum stochastischen Verfahren (SGD) ohne 'Sprünge' zum Minimum?",
      "options": [
        "Exakter Gradient über alle Daten",
        "Künstliche Glättung der Kurve",
        "Nutzung einer geschlossenen Form",
        "Verwendung der Pseudoinversen"
      ],
      "answer": 0,
      "explanation": "Batch-GD nutzt den Mittelwert der Gradienten aller Datenpunkte. Dies liefert eine stabile Richtung, während SGD pro Schritt nur einen verrauschten Schätzwert nutzt.",
      "weight": 2,
      "topic": "Gradientenverfahren",
      "concept": "Konvergenzstabilität",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Deterministisch",
          "definition": "Verfahren, das bei gleichen Eingaben immer das gleiche Ergebnis liefert."
        }
      ]
    },
    {
      "question": "13. Welches Problem droht bei SGD, wenn ein Datensatz nach Klassen sortiert ist (z. B. erst alle Hunde, dann Katzen)?",
      "options": [
        "Parameter 'wandern' einseitig",
        "MSE wird mathematisch negativ",
        "Matrix $X^{\\top}X$ wird singulär",
        "SGD shuffelt Daten automatisch"
      ],
      "answer": 0,
      "explanation": "SGD passt die Parameter an die aktuell gesehenen Daten an. Ohne Durchmischung optimiert es erst für eine Klasse und 'vergisst' das Gelernte beim Wechsel zur nächsten.",
      "weight": 3,
      "topic": "Gradientenverfahren",
      "concept": "IID-Annahme",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": {
        "title": "Datenverteilung",
        "content": "Durchmischung (Shuffling) ist essenziell, damit der Gradient im Mittel in die richtige Richtung zeigt.",
        "steps": [
          "SGD lernt lokal von einzelnen Instanzen.",
          "Sortierung verletzt die IID-Annahme.",
          "Modell findet kein globales Gleichgewicht."
        ]
      },
      "mini_glossary": [
        {
          "term": "IID",
          "definition": "Independent and Identically Distributed; Kernannahme für stabiles Lernen."
        }
      ]
    },
    {
      "question": "14. Was ist der Hauptvorteil von Mini-Batch-Verfahren gegenüber reinem SGD?",
      "options": [
        "Hardware-Nutzung durch Matrizen",
        "Konvergenz in nur einer Epoche",
        "Keine Regularisierung nötig",
        "Keine Lernrate erforderlich"
      ],
      "answer": 0,
      "explanation": "Mini-Batches erlauben Vektoroperationen auf GPUs. Dies ist deutlich schneller als die Einzelverarbeitung bei reinem SGD.",
      "weight": 2,
      "topic": "Gradientenverfahren",
      "concept": "Hardware-Beschleunigung",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "GPU",
          "definition": "Graphics Processing Unit; optimiert für parallele Matrixrechnungen."
        }
      ]
    },
    {
      "question": "15. Wie verändert sich die Anzahl der Merkmale bei `PolynomialFeatures(degree=2)` mit den Basismerkmalen $x_1, x_2$?",
      "options": [
        "Es entstehen 5 Merkmale",
        "Es entstehen 4 Merkmale",
        "Es entstehen 2 Merkmale",
        "Es entstehen 6 Merkmale"
      ],
      "answer": 0,
      "explanation": "Zusätzlich zu $x_1$ und $x_2$ entstehen die Quadrate $x_1^2, x_2^2$ sowie das Produkt $x_1x_2$.",
      "weight": 2,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Feature Engineering",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Interaktionsterm",
          "definition": "Produkt zweier Merkmale zur Modellierung von Wechselwirkungen."
        }
      ]
    },
    {
      "question": "16. Welche Funktion transformiert bei der logistischen Regression den linearen Score in eine Wahrscheinlichkeit zwischen 0 und 1?",
      "options": [
        "Die Sigmoid-Funktion",
        "Die Logit-Funktion",
        "Der Mittelwert von y",
        "Die Pseudoinverse"
      ],
      "answer": 0,
      "explanation": "Die Sigmoid-Funktion (oder logistische Funktion) bildet beliebige Werte auf das Intervall (0, 1) ab, was eine Interpretation als Wahrscheinlichkeit erlaubt.",
      "weight": 2,
      "topic": "Logistische Regression",
      "concept": "Sigmoid-Funktion",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Aktivierungsfunktion",
          "definition": "Funktion, die den Output eines Knotens bestimmt."
        }
      ]
    },
    {
      "question": "17. Was gilt für die Summe der Wahrscheinlichkeiten bei der Softmax-Regression für eine Instanz?",
      "options": [
        "Summe ergibt genau 1,0",
        "Summe hängt von n ab",
        "Summe ist immer &lt; 1,0",
        "Summe entspricht Logits"
      ],
      "answer": 0,
      "explanation": "Softmax normalisiert die Scores über alle Klassen. Dadurch entsteht eine valide Wahrscheinlichkeitsverteilung, deren Summe stets 100% (1,0) beträgt.",
      "weight": 2,
      "topic": "Logistische Regression",
      "concept": "Wahrscheinlichkeitsverteilung",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Normalisierung",
          "definition": "Anpassung von Werten, sodass sie in einem bestimmten Verhältnis stehen."
        }
      ]
    },
    {
      "question": "18. Welcher Fehlertyp entsteht durch die Annahme eines linearen Modells für eigentlich quadratische Daten?",
      "options": [
        "Bias (Verzerrung)",
        "Varianz",
        "Nicht reduzierbarer Fehler",
        "Overfitting-Fehler"
      ],
      "answer": 0,
      "explanation": "Bias resultiert aus falschen Annahmen über die Datenform. Ein zu einfaches Modell 'verfehlt' die wahre Struktur systematisch.",
      "weight": 2,
      "topic": "Lernkurven",
      "concept": "Bias",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Verzerrung",
          "definition": "Systematische Abweichung des Modellschätzwerts vom wahren Wert."
        }
      ]
    },
    {
      "question": "19. Wann unterbricht die Technik 'Early Stopping' das Training eines iterativen Algorithmus?",
      "options": [
        "Minimum des Validierungsfehlers",
        "Minimum des Trainingsfehlers",
        "Nach einer festen Zeit",
        "Wenn Gradient exakt Null ist"
      ],
      "answer": 0,
      "explanation": "Das Training wird gestoppt, sobald der Fehler auf den Validierungsdaten wieder ansteigt, da dies ein Einsetzen von Overfitting signalisiert.",
      "weight": 2,
      "topic": "Regularisierte lineare Modelle",
      "concept": "Regularisierung",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Validierung",
          "definition": "Testen des Modells auf Daten, die nicht zum Lernen genutzt wurden."
        }
      ]
    },
    {
      "question": "20. Welche Kostenfunktion wird standardmäßig bei der logistischen Regression minimiert?",
      "options": [
        "Log Loss (Kreuzentropie)",
        "Mean Squared Error (MSE)",
        "Root Mean Squared Error",
        "Absolute Abweichung"
      ],
      "answer": 0,
      "explanation": "Der Log Loss bestraft falsche Vorhersagen mit hoher Wahrscheinlichkeit extrem stark. Dies ist für Klassifikationsaufgaben besser geeignet als MSE.",
      "weight": 2,
      "topic": "Logistische Regression",
      "concept": "Log Loss",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Kreuzentropie",
          "definition": "Maß für die Differenz zwischen zwei Wahrscheinlichkeitsverteilungen."
        }
      ]
    },
    {
      "question": "21. Training-RMSE ist 0,1, Validierungs-RMSE ist 2,5. Welche Maßnahme ist am besten geeignet?",
      "options": [
        "Erhöhung der Regularisierung",
        "Mehr Merkmale hinzufügen",
        "Trainingsdaten reduzieren",
        "Bias-Term entfernen"
      ],
      "answer": 0,
      "explanation": "Die große Lücke (Gap) deutet auf Overfitting hin. Stärkere Regularisierung hilft, das Modell zu vereinfachen und die Generalisierung zu verbessern.",
      "weight": 3,
      "topic": "Lernkurven",
      "concept": "Overfitting-Korrektur",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Generalisierung",
          "definition": "Fähigkeit eines Modells, korrekte Vorhersagen für neue Daten zu treffen."
        }
      ]
    },
    {
      "question": "22. Warum bevorzugt man oft Elastic Net gegenüber reinem Lasso bei korrelierten Merkmalen?",
      "options": [
        "Lasso eliminiert zufällig",
        "Elastic Net ist schneller",
        "Keine Skalierung nötig",
        "Lasso nur für kleine n"
      ],
      "answer": 0,
      "explanation": "Bei starker Korrelation wählt Lasso oft willkürlich ein Merkmal aus und setzt andere auf Null. Elastic Net ist hier stabiler durch die Kombination von L1 und L2.",
      "weight": 3,
      "topic": "Regularisierte lineare Modelle",
      "concept": "Elastic Net",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Multikollinearität",
          "definition": "Starke Korrelation zwischen mehreren erklärenden Variablen."
        }
      ]
    },
    {
      "question": "23. Welchen Zweck erfüllt das Hinzufügen des künstlichen Merkmals $x_0 = 1$?",
      "options": [
        "Integration des Bias-Terms",
        "Vermeidung von Singularität",
        "Voraussetzung für SVD",
        "RMSE wird positiv"
      ],
      "answer": 0,
      "explanation": "Durch $x_0=1$ wird der Achsenabschnitt $\\theta_0$ Teil des Skalarprodukts, was einheitliche Matrixberechnungen erlaubt.",
      "weight": 2,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Bias-Kompensation",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Vektorisierung",
          "definition": "Kompakte mathematische Darstellung von Datenblöcken."
        }
      ]
    },
    {
      "question": "24. Wie erzwingt man echte Konvergenz bei SGD, statt nur 'nahe' ans Minimum zu kommen?",
      "options": [
        "Nutze Learning Schedule",
        "Batch-Size auf m setzen",
        "Nutze Normalengleichung",
        "Wechsle zu Log Loss"
      ],
      "answer": 0,
      "explanation": "Durch schrittweises Senken der Lernrate werden die Sprünge zum Ende hin immer kleiner, sodass der Algorithmus am Minimum 'einfriert'.",
      "weight": 3,
      "topic": "Gradientenverfahren",
      "concept": "Learning Schedule",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Simulated Annealing",
          "definition": "Optimierungsverfahren durch langsames Absenken der Schrittweite."
        }
      ]
    },
    {
      "question": "25. Welcher Zusammenhang besteht zwischen der logistischen Funktion und der Logit-Funktion?",
      "options": [
        "Logit ist die Inverse",
        "Logit ist die Ableitung",
        "Kein Zusammenhang",
        "Logit ist das Quadrat"
      ],
      "answer": 0,
      "explanation": "Die Logit-Funktion transformiert Wahrscheinlichkeiten zurück in Scores und ist damit die mathematische Umkehrfunktion.",
      "weight": 2,
      "topic": "Logistische Regression",
      "concept": "Logit vs. Sigmoid",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Inverse",
          "definition": "Funktion, die eine andere Funktion rückgängig macht."
        }
      ]
    },
    {
      "question": "26. Warum scheitert die Normalengleichung eventuell, wenn Merkmale $n$ zahlreicher als Instanzen $m$ sind?",
      "options": [
        "Matrix ist singulär",
        "MSE wird immer Null",
        "Rechenzeit ist zu hoch",
        "Sigmoid ist zwingend"
      ],
      "answer": 0,
      "explanation": "Bei $n > m$ ist die Matrix nicht invertierbar. In solchen Fällen ist das System unterbestimmt und die Normalengleichung mathematisch nicht direkt lösbar.",
      "weight": 3,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Singularität",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Singulär",
          "definition": "Eigenschaft einer Matrix, die keine Inverse besitzt."
        }
      ]
    },
    {
      "question": "27. Entscheidungsgrenze liegt bei 1,65 cm. Was sagt das Modell für eine Blüte mit 1,7 cm vorher?",
      "options": [
        "Iris virginica (Wahr)",
        "Nicht virginica (Falsch)",
        "Iris versicolor",
        "Nicht entscheidbar"
      ],
      "answer": 0,
      "explanation": "Werte oberhalb der Grenze führen zu einer Wahrscheinlichkeit $> 50\\%$ für die positive Klasse.",
      "weight": 2,
      "topic": "Logistische Regression",
      "concept": "Entscheidungsgrenze",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Schwellenwert",
          "definition": "Grenzwert für die Klassenzuordnung."
        }
      ]
    },
    {
      "question": "28. Einfluss einer Erhöhung von $\\alpha$ bei Ridge-Regression auf das Bias-Varianz-Gleichgewicht?",
      "options": [
        "Bias steigt, Varianz sinkt",
        "Bias sinkt, Varianz steigt",
        "Beide Werte sinken",
        "Nur Bias steigt"
      ],
      "answer": 0,
      "explanation": "Stärkere Regularisierung vereinfacht das Modell. Das macht es robuster gegen Rauschen (weniger Varianz), aber ungenauer in der Anpassung (mehr Bias).",
      "weight": 3,
      "topic": "Regularisierte lineare Modelle",
      "concept": "Bias-Varianz-Tradeoff",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Tradeoff",
          "definition": "Gegensätzlicher Zusammenhang zweier erstrebenswerter Eigenschaften."
        }
      ]
    },
    {
      "question": "29. Warum wird der Bias-Term $\\theta_0$ in der Kostenfunktion üblicherweise nicht mit bestraft?",
      "options": [
        "Beeinflusst Varianz nicht",
        "Verschiebt Daten unnötig",
        "Technisch kein Parameter",
        "Historisches Relikt"
      ],
      "answer": 0,
      "explanation": "Der Achsenabschnitt trägt nicht zur 'Kurvigkeit' oder Komplexität bei. Ihn zu bestrafen würde das Modell ohne Generalisierungsvorteil Richtung Null zwingen.",
      "weight": 3,
      "topic": "Regularisierte lineare Modelle",
      "concept": "Bias-Regularisierung",
      "cognitive_level": "Strukturelle Analyse",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Generalisierung",
          "definition": "Übertragbarkeit auf neue Daten."
        }
      ]
    },
    {
      "question": "30. Welches Gütekriterium wird häufig zur Evaluierung genutzt, obwohl zum Training MSE optimiert wurde?",
      "options": [
        "RMSE (Root Mean Squared Error)",
        "Log Loss (Kreuzentropie)",
        "Precision und Recall",
        "Singuläre Werte"
      ],
      "answer": 0,
      "explanation": "RMSE hat dieselbe Einheit wie die Zielvariable y und ist daher für Menschen deutlich besser zu interpretieren.",
      "weight": 2,
      "topic": "Grundkonzepte der Linearen Regression",
      "concept": "Performancemetriken",
      "cognitive_level": "Anwendung",
      "extended_explanation": null,
      "mini_glossary": [
        {
          "term": "Metrik",
          "definition": "Maßzahl zur objektiven Bewertung der Modellleistung."
        }
      ]
    }
  ],
  "meta": {
    "title": "Machine Learning: Kapitel 4",
    "created": "09.02.2026 07:15",
    "updated": "2026-02-09",
    "target_audience": "Informatikstudierende",
    "question_count": 30,
    "difficulty_profile": {
      "leicht": 3,
      "mittel": 19,
      "schwer": 8
    },
    "language": "de",
    "time_per_weight_minutes": {
      "1": 0.5,
      "2": 0.75,
      "3": 1.0
    },
    "additional_buffer_minutes": 5,
    "test_duration_minutes": 30,
    "computed_test_duration_minutes": 30
  }
}