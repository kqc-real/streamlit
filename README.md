# ğŸ“ MC-Test Streamlit App

[![CI](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml/badge.svg?bâ”œâ”€main)](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml)

Eine interaktive Multiple-Choice-Lern- und Selbsttest-App.
Sie bietet schnelles Feedback, Fortschrittsverfolgung und aggregierte Ergebnisse fÃ¼r verschiedene Fragensets.
Die App ist modular aufgebaut und nutzt eine SQLite-Datenbank zur persistenten Speicherung von Testergebnissen.
Die App verfÃ¼gt Ã¼ber ein integriertes Feedback-System, das es Nutzern ermÃ¶glicht, Probleme mit Fragen zu melden, und Admins, dieses Feedback zu verwalten.

---

## ğŸš€ Schnellstart

**ğŸ“– Installationsanleitungen fÃ¼r Einsteiger/innen**
- https://github.com/kqc-real/streamlit/blob/main/INSTALLATION_MAC_ANLEITUNG.md
- https://github.com/kqc-real/streamlit/blob/main/INSTALLATION_WINDOWS_ANLEITUNG.md
- https://github.com/kqc-real/streamlit/blob/main/INSTALLATION_VS-CODE_SSH-AUTHENTIFIZIERUNG.md

Diese Schritt-fÃ¼r-Schritt-Anleitungen erklÃ¤ren alles von Grund auf:
- Python & Git installieren (Windows & Mac)
- App herunterladen und starten
- HÃ¤ufige Probleme und LÃ¶sungen
- **Perfekt fÃ¼r BWL-Studierende ohne IT-Kenntnisse!**

**Admin-Panel lokal testen?**
â†’ **[ğŸ” Admin-Panel Anleitung fÃ¼r Kursteilnehmer/innen](ADMIN_PANEL_ANLEITUNG.md)**

Diese Anleitung zeigt dir:
- Wie du als "Albert Einstein" Admin-Rechte erhÃ¤ltst
- Was du im Admin-Panel alles tun kannst (Analytics, Itemanalyse, Feedback)
- Wie Itemanalyse und Distraktor-Analyse funktionieren
- **Perfekt fÃ¼r Projektmitglieder, die alle Features verstehen wollen!**

---

## ğŸš€ Ãœbersicht

Diese App ist ein vollstÃ¤ndiger MC-Test fÃ¼r Kursinhalte, entwickelt mit Streamlit.
Sie ermÃ¶glicht anonyme Tests mit Pseudonymen, zufÃ¤lliger Fragenreihenfolge, Zeitlimit und einem integrierten Feedback-System zur kontinuierlichen Verbesserung der Fragen.
Perfekt fÃ¼r Bildungsumgebungen, Selbstlernphasen oder zur PrÃ¼fungsvorbereitung.

### Hauptfunktionen

| Kategorie      | Funktion                                                                                      |
|----------------|-----------------------------------------------------------------------------------------------|
| Zugang         | Pseudonym-Login (anonym, keine Registrierung)                                                 |
| Fragen         | ZufÃ¤llige Reihenfolge, Gewichtung je Frage, strikte Trennung nach Fragenset                   |
| Fragenset      | Dynamische Auswahl verschiedener Fragensets (`questions_*.json`)                               |
| Scoring-Modi   | "Nur +Punkte" (falsch = 0) oder "+/- Punkte" (falsch = -Gewichtung)                            |
| Feedback       | Sofortiges Ergebnis mit optionalen, detaillierten ErklÃ¤rungen zu Theorie und Herleitung       |
| Navigation     | Fragen kÃ¶nnen markiert und Ã¼bersprungen werden, mit direkter Navigation Ã¼ber die Seitenleiste |
| Fortschritt    | Fortschritt wird pro Pseudonym und Fragenset in einer SQLite-Datenbank gespeichert            |
| Zeitlimit      | Optionales 60-Minuten-Fenster                                                                 |
| Feedback       | Nutzer kÃ¶nnen Probleme mit Fragen melden (inhaltlich, technisch etc.)                         |
| Leaderboard    | Ã–ffentliches Topâ€‘10 (pro Fragenset); vollstÃ¤ndige Ansicht fÃ¼r Admin                           |
| Analyse & Wartung | Itemanalyse, Distraktor-Analyse, Verwaltung von gemeldetem Feedback                         |
| PDF-Export     | Professioneller Report mit LaTeX-Rendering, Durchschnittsvergleich, Mini-Glossar, Bookmarks   |
| Export         | CSV-Download aller Antworten und SQL-Dump der Datenbank Ã¼ber Admin-Panel                      |
| Admin-Panel    | PasswortgeschÃ¼tzter Bereich fÃ¼r Analyse, Feedback-Management, Export und Systemeinstellungen  |

### Neuere Features (seit v1.2)

- MusterlÃ¶sung (PDF): Admins kÃ¶nnen jetzt eine formatierte MusterlÃ¶sung mit allen korrekten Antworten, ausfÃ¼hrlichen ErklÃ¤rungen und angehÃ¤ngtem Mini-Glossar erzeugen. Die MusterlÃ¶sung rendert LaTeX-Formeln als hochwertige PNGs und hebt korrekte Optionen hervor.
- Nutzer-Download: Nach Abschluss eines Tests steht den Nutzer/innen ebenfalls eine MusterlÃ¶sung zum Download zur VerfÃ¼gung (sinnvollerweise nur zum Lernen). Die UI zeigt eine Kurzinfo, dass die MusterlÃ¶sung prÃ¼fungsrelevant ist und nicht geteilt werden sollte.
- Robustere Formel-Rendering-Pipeline: Formeln werden parallel gerendert (ThreadPool) mit einem konfigurierbaren Gesamt-Timeout; ausgefallene oder zu langsame Renderings werden durch Platzhalter ersetzt, damit ein Export nicht ewig hÃ¤ngt.
- Per-User Export-Cache: Um wiederholte Anfragen schnell zu bedienen, werden erzeugte MusterlÃ¶sungen temporÃ¤r im Session-Cache (`st.session_state`) zwischengespeichert und beim erneuten Download sofort ausgeliefert.
- ZeitabschÃ¤tzung & Probe-Rendering: Bei PDF-Exporten mit Formeln wird optional ein Probe-Rendering durchgefÃ¼hrt, um die voraussichtliche Gesamtdauer anzugeben.

### Formel-Cache (Disk) & automatische Eviction

Die App cached gerenderte LaTeX-Formel-Bilder als PNG-Dateien auf der lokalen Festplatte, um Netzwerkaufrufe zur Remote-Render-API zu reduzieren und Exporte zu beschleunigen. Damit der Cache auf Hosts mit begrenztem oder ephemerem Speicher (z. B. Streamlit Community Cloud) nicht unkontrolliert wÃ¤chst, gibt es automatische Eviction-Mechanismen.

Konfigurierbare Umgebungsvariablen:

- FORMULA_CACHE_DIR: Pfad zum Cache-Verzeichnis (Standard: ./var/formula_cache)
- FORMULA_CACHE_MAX_FILES: Maximale Anzahl Dateien im Cache (Standard: 200)
- FORMULA_CACHE_MAX_MB: Maximale GesamtgrÃ¶ÃŸe des Caches in MiB (Standard: 200)
- FORMULA_CACHE_TTL_DAYS: Lebensdauer von Cache-Dateien in Tagen (Standard: 7)

Verhalten:

- Vor jedem Schreiben einer neuen Formeldatei wird die Eviction-Routine ausgefÃ¼hrt: Dateien Ã¤lter als TTL werden zuerst entfernt; danach werden die Ã¤ltesten Dateien gelÃ¶scht, bis sowohl Dateianzahl als auch GesamtgrÃ¶ÃŸe innerhalb der Grenzwerte liegen.
- Auf schreibgeschÃ¼tzten oder nicht verfÃ¼gbaren Dateisystemen werden Schreibfehler ignoriert und die In-Memory-Fallback-Strategie verwendet. Das verhindert AbstÃ¼rze auf restriktiven Plattformen.

Empfehlung: Setze konservative Limits fÃ¼r Cloud-Deploys (z. B. FORMULA_CACHE_MAX_MB=50, FORMULA_CACHE_MAX_FILES=100) und Ã¼berwache die Nutzung in Logs.


---

## ï¿½ Security Features

Die MC-Test-App implementiert **Enterprise-Grade Security** Ã¼ber drei aufeinander aufbauende Phasen:

### Phase 1: Quick Wins (v1.1.0)
- âš ï¸ **Empty Admin-Key Warnings**: Warnung bei unsicherem Admin-Passwort
- ğŸ”„ **Re-Authentication**: Passwortabfrage vor kritischen Operationen (LÃ¶schen, Export)

### Phase 2: Server-Side Session Validation (v1.2.0)
- ğŸ” **Cryptographic Tokens**: Sichere Session-Tokens mit `secrets.token_urlsafe(32)`
- ğŸ”’ **SHA-256 Hashing**: Keine Klartext-PasswÃ¶rter im Session State
- â±ï¸ **Session Timeouts**: Automatische Abmeldung nach 2 Stunden InaktivitÃ¤t
- ğŸ§µ **Thread-Safe**: Sichere Concurrent-Access mit Threading-Locks

### Phase 3: Audit-Logging & Rate-Limiting (v1.3.0) â­ **NEU**
- ğŸ“Š **SQLite-Based Audit-Logging**: Alle Admin-Aktionen persistent geloggt
  - Login-Versuche (erfolg/fehlgeschlagen)
  - Delete-Operationen (User-Daten, Global)
  - CSV-Exports
  - CRITICAL Actions markiert
- ğŸš« **Rate-Limiting**: Brute-Force-Schutz
  - 3 fehlgeschlagene Login-Versuche â†’ 5 Minuten Sperre
  - Automatisches Reset nach erfolgreichem Login
  - Anzeige der Sperr-Zeit
- ğŸ“ˆ **Admin Dashboard**: Neuer "ğŸ”’ Audit-Log" Tab
  - Statistiken: Gesamt-Aktionen, Success/Fail-Raten
  - Filter: User, Action-Typ, Erfolg-Status, Limit
  - CSV-Export fÃ¼r forensische Analyse
- ğŸ—‘ï¸ **DSGVO-Compliance**: Automatische LÃ¶schung nach 90 Tagen
- ğŸŒ **IP-Tracking**: Optional Client-IP-Logging (wenn verfÃ¼gbar)

**Security Level:** ğŸ›¡ï¸ **VERY HIGH (Enterprise-Grade)**

**Dokumentation:**
- ğŸ“˜ [SECURITY_PHASE3_SUMMARY.md](SECURITY_PHASE3_SUMMARY.md) - Technische Details
- ğŸ“‹ [CHANGELOG_SECURITY_PHASE3.md](CHANGELOG_SECURITY_PHASE3.md) - VollstÃ¤ndiger Changelog
- ğŸ“„ [PHASE3_ABSCHLUSS.md](PHASE3_ABSCHLUSS.md) - User-Guide

---

## ï¿½ğŸ“‹ Voraussetzungen

- **Python:** Version 3.9 oder hÃ¶her.
- **AbhÃ¤ngigkeiten:** Installiere via `pip install -r requirements.txt`.

---

## ğŸ› ï¸ Installation und Start

### Lokaler Start

1.  Klone das Repository.
2.  Installiere die AbhÃ¤ngigkeiten:
    ```bash
    pip install -r requirements.txt
    ```
3.  Starte die App:
    ```bash
    streamlit run app.py
    ```
4.  Ã–ffne [http://localhost:8501](http://localhost:8501) im Browser.

### Deployment (z.B. Streamlit Cloud)

1.  Verbinde dein GitHub-Repository mit deinem Streamlit-Cloud-Konto.
2.  Deploye die App.
3.  Konfiguriere die Secrets (siehe nÃ¤chster Abschnitt) im Dashboard deiner Streamlit-Cloud-App.

---

## âš™ï¸ Konfiguration

### Umgebungsvariablen / Secrets

Die App wird Ã¼ber Umgebungsvariablen (fÃ¼r sensible Daten) und eine Konfigurationsdatei (fÃ¼r nicht-sensible Daten) konfiguriert.

FÃ¼r die lokale Entwicklung kannst du eine `.env`-Datei erstellen. FÃ¼r das Deployment auf Streamlit Cloud mÃ¼ssen diese Variablen als "Secrets" im Dashboard der App hinterlegt werden.

```env
# Beispiel fÃ¼r .env oder Streamlit Cloud Secrets
MC_TEST_ADMIN_USER="dein_admin_user"
MC_TEST_ADMIN_KEY="dein_geheimes_passwort"
MC_TEST_MIN_SECONDS_BETWEEN="2"
APP_URL="https://ihre-streamlit-app.streamlit.app"
```


- **`MC_TEST_ADMIN_USER`**: Der Benutzername, der fÃ¼r den Admin-Login erforderlich ist.
- **`MC_TEST_ADMIN_KEY`**: Das Passwort fÃ¼r den Admin-Login.
- **`MC_TEST_MIN_SECONDS_BETWEEN`**: Die Mindestanzahl an Sekunden, die zwischen zwei Antworten vergehen muss. Verhindert Spam. Ein Wert von `0` deaktiviert das Limit. (Default: `3`)
- **`APP_URL`**: Die URL der Streamlit-App fÃ¼r den QR-Code im PDF-Export. (Default: `https://mc-test-amalea.streamlit.app`)

---

## ğŸ“ Projektstruktur

```
.
â”œâ”€â”€ .github/                # GitHub Actions Workflows (CI/CD)
â”œâ”€â”€ .streamlit/             # Streamlit-Konfiguration (z.B. Themes)
â”œâ”€â”€ data/                   # EnthÃ¤lt JSON-Dateien (Fragensets, Pseudonyme)
â”œâ”€â”€ db/                     # Speichert die SQLite-Datenbankdatei
â”œâ”€â”€ tests/                  # Pytest-Tests fÃ¼r die Anwendungslogik
â”œâ”€â”€ .env.example            # Beispiel fÃ¼r Umgebungsvariablen
â”œâ”€â”€ admin_panel.py          # Logik fÃ¼r das Admin-Panel
â”œâ”€â”€ app.py                  # Haupt-Anwendungsskript
â”œâ”€â”€ auth.py                 # Authentifizierung und Session-Management
â”œâ”€â”€ components.py           # Wiederverwendbare UI-Komponenten
â”œâ”€â”€ config.py               # Laden der Konfiguration und Fragensets
â”œâ”€â”€ database.py             # Datenbankinteraktionen (SQLite)
â”œâ”€â”€ helpers.py              # Kleine Hilfsfunktionen
â”œâ”€â”€ logic.py                # Kernlogik der App (Scoring, etc.)
â”œâ”€â”€ main_view.py            # UI-Logik fÃ¼r die Hauptansichten
â”œâ”€â”€ pdf_export.py           # PDF-Report-Generierung mit LaTeX & Mini-Glossar
â”œâ”€â”€ requirements.txt        # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ AI_QUESTION_GENERATOR_PLAN.md      # Plan fÃ¼r KI-basierte Fragenset-Generierung
â”œâ”€â”€ DEPLOYMENT_FEASIBILITY_STUDY.md    # Infrastruktur & Kostenanalyse (Streamlit/Cloudflare)
â”œâ”€â”€ GLOSSARY_SCHEMA.md                 # Dokumentation fÃ¼r Mini-Glossar in Fragensets
â”œâ”€â”€ VISION_RELEASE_2.0.md              # Strategische Vision & Feature-Roadmap Release 2.0
â””â”€â”€ README.md                          # Diese Dokumentation

## ğŸ§° Developer tools (local)

Es gibt kleine Hilfs-Skripte zum Testen und Benchmarking im Ordner `tools/`:

- `tools/test_evict.py` â€” Erzeugt Dummy-Dateien im Cache (`var/formula_cache`) und testet die Eviction-Routine.
- `tools/run_export_test.py` â€” FÃ¼hrt einen einzelnen MusterlÃ¶sungs-Export durch und schreibt das PDF nach `exports/`.
- `tools/benchmark_exports.py` â€” FÃ¼hre N Exporte hintereinander aus (Standard N=5) und schreibe eine `exports/benchmark_summary.txt`.

Beispiele:

```bash
# Eviction smoke test
PYTHONPATH=. python3 tools/test_evict.py

# Single export (shows progress)
PYTHONPATH=. python3 tools/run_export_test.py

# Benchmark with 5 runs
BENCH_EXPORTS_N=5 PYTHONPATH=. python3 tools/benchmark_exports.py
```

---

## ğŸ§­ Hinweise zum Prompting (fÃ¼r AI / Textâ€‘Generierung)

Kleine, aber wichtige Regel fÃ¼r alle Prompts, die in diese App (oder in Templates) eingespeist werden:

- Verwende echte Leerzeilen / AbsÃ¤tze. Gib niemals die zwei Zeichen Backslash + n (`"\\n"`) als Ersatz fÃ¼r einen Zeilenumbruch aus.
- Korrekt: eine echte leere Zeile zwischen zwei AbsÃ¤tzen.
- Nicht verwenden: der Literalâ€‘String `"\\n"` (Backslash + n).

Beispiel (nicht so):

```
Ergebnis:\n\n- Punkt 1\n- Punkt 2
```

Beispiel (richtig):

```
Ergebnis:

- Punkt 1
- Punkt 2
```

Warum das wichtig ist:
- Manche Modelle liefern `"\\n"` anstelle echter ZeilenumbrÃ¼che â€” das bricht Markdown/HTMLâ€‘Rendering und macht die Ausgabe schwer lesbar.
- Eine kurze Nachbearbeitung der Modellâ€‘Antworten (Sanitizer) ist zusÃ¤tzlich empfehlenswert, siehe `helpers.py`.

Short note (EN): Use real blank lines, not the literal string "\\n". This avoids escaped newline artifacts in Markdown/HTML output.


Hinweis: Die generierten Artefakte landen in `exports/` und werden in `.gitignore` ausgeschlossen, damit sie nicht versehentlich in Git landen.
```

---

## ï¿½ğŸ› ï¸ Administration & Wartung

### Admin-Bereich

- **Zugang:**
    1. WÃ¤hle auf der Startseite das in den Secrets (`MC_TEST_ADMIN_USER`) definierte Admin-Pseudonym aus.
    2. Nach dem Start des Tests erscheint in der Seitenleiste der Bereich "ğŸ” Admin Panel".
    3. Gib dort das Admin-Passwort (`MC_TEST_ADMIN_KEY`) ein, um vollen Zugriff zu erhalten.
- **Funktionen:** Das Panel bietet detaillierte Analysen (Item- & Distraktoranalyse), eine Ãœbersicht und Verwaltung fÃ¼r gemeldetes Feedback, Datenexport (CSV, SQL-Dump, **PDF-Export**) und Systemeinstellungen (Scoring-Modus, ZurÃ¼cksetzen der Testdaten).

### Tests ausfÃ¼hren

```bash
pip install -r requirements.txt
PYTHONPATH=. pytest
```

---

## ğŸ› Troubleshooting

-   **App startet nicht:** Stelle sicher, dass alle AbhÃ¤ngigkeiten aus `requirements.txt` installiert sind.

---

## ğŸ¤ Contributing


BeitrÃ¤ge sind willkommen! Forke das Repository, erstelle einen Branch und Ã¶ffne einen Pull Request.

---
