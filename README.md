# üìù MC-Test Streamlit App

[![CI](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml)

Eine interaktive Multiple-Choice-Lern- und Selbsttest-App f√ºr Kursteilnehmer.
Bietet schnelles Feedback, Fortschrittsverfolgung und aggregierte Ergebnisse
f√ºr Data Science-Themen.

---

## üöÄ √úbersicht

Diese App ist ein vollst√§ndiger MC-Test f√ºr Data Analytics, entwickelt mit Streamlit.
Sie erm√∂glicht anonyme Tests mit Pseudonymen, zuf√§lliger Fragenreihenfolge und Zeitlimit.
Perfekt f√ºr Bildungsumgebungen oder Selbstlernphasen.

### Hauptfunktionen

- **Benutzerverwaltung:** Anmeldung mit Pseudonym; Fortschritt wird gespeichert.
- **Testdurchf√ºhrung:** 100 zuf√§llig gemischte Fragen aus JSON-Datei,
  mit Erkl√§rungen und Review-Modus.
- **Zeitmanagement:** 60-Minuten-Limit mit Countdown und Warnungen.
- **Feedback & Analyse:** Motivationales Feedback, Leaderboard (Top 5),
  Admin-Bereich f√ºr Logs.
- **Datenschutz:** SHA-256-Hashing f√ºr Anonymit√§t; lokale Speicherung.
- **Zus√§tze:** Dark-Mode, Accessibility-Optionen, CSV-Exporte, Docker-Unterst√ºtzung.

---

## üìã Voraussetzungen

- **Python:** Version 3.8 oder h√∂her.
- **Abh√§ngigkeiten:** Installiere via `pip install -r requirements.txt`.
- **Optionale Tools:** Docker f√ºr Container-Deployment; Git f√ºr Versionierung.

---

## üõ†Ô∏è Installation und Start

### Lokaler Start (Empfohlen f√ºr Entwicklung)

1. Klone das Repository oder navigiere zum `mc_test_app/`-Ordner.
2. Installiere Abh√§ngigkeiten:

   ```bash
   pip install -r requirements.txt
   ```

3. Starte die App:

   ```bash
   streamlit run mc_test_app.py
   ```

4. √ñffne [http://localhost:8501](http://localhost:8501) im Browser.

### Docker-Start

```bash
docker compose up -d streamlit-slim
```

F√ºr den vollen Stack (mit Jupyter, MLflow):

```bash
docker compose up -d
```

### Deployment (z.B. Streamlit Cloud)

1. Pushe nur den `mc_test_app/`-Ordner in ein separates Repo.
2. Verwende `git subtree` f√ºr saubere Trennung:

   ```bash
   git subtree push --prefix mc_test_app github main
   ```

3. Deploye auf Streamlit Cloud oder √§hnlichen Plattformen.

---

## ‚öôÔ∏è Konfiguration

### Umgebungsvariablen (`.env`-Datei)

Erstelle eine `.env`-Datei basierend auf `.env.example`:

```env
MC_TEST_ADMIN_USER=dein_admin_pseudonym  # Optional: Beschr√§nkt Admin-Zugang
MC_TEST_ADMIN_KEY=dein_geheimes_passwort  # Erforderlich f√ºr Admin-Features
MC_TEST_MIN_SECONDS_BETWEEN=5  # Optional: Mindestsekunden zwischen Antworten
```

- **Admin-Zugang:** Ohne `MC_TEST_ADMIN_KEY` reicht ein beliebiges Passwort;
  mit Key muss es exakt passen.
- **Rate-Limiting:** Verhindert Spam; Standard: 0 (kein Limit).

### Streamlit-Secrets (`.streamlit/secrets.toml`)

F√ºr Produktion:

```toml
MC_TEST_ADMIN_USER = "admin"
MC_TEST_ADMIN_KEY = "secret123"
MC_TEST_MIN_SECONDS_BETWEEN = 5
```

### Datenpersistenz (CSV)

- **Datei:** `mc_test_answers.csv` (wird automatisch erstellt).
- **Schema (ab August 2025):**

  ```csv
  user_id_hash,user_id_display,user_id_plain,frage_nr,frage,antwort,richtig,zeit
  ```

- **Felder:**

  - `user_id_hash`: SHA-256-Hash des Pseudonyms (f√ºr Anonymit√§t).
  - `user_id_display`: Gek√ºrzter Hash (z.B. erste 10 Zeichen).
  - `user_id_plain`: Eingetragenes Pseudonym (f√ºr Leaderboard).
  - `frage_nr`: Fragenummer.
  - `frage`: Vollst√§ndiger Fragetext.
  - `antwort`: Ausgew√§hlte Option.
  - `richtig`: 1 (richtig) oder -1 (falsch).
  - `zeit`: ISO8601-Zeitstempel.

- **Eigenschaften:** Append-only, Pandas-kompatibel, leicht zu sichern.

---

## üìÅ Projektstruktur

```
mc_test_app/
‚îú‚îÄ‚îÄ README.md                 # Diese Dokumentation
‚îú‚îÄ‚îÄ mc_test_app.py            # Hauptapp (UI + kombinierte Logik ‚Äì wird schrittweise entschlackt)
‚îú‚îÄ‚îÄ core.py                   # Speicher/Hash/CSV-Basisfunktionen
‚îú‚îÄ‚îÄ scoring.py                # (Neu) Zentrale Score-/Leaderboard-Berechnung (Top-5 Abbildung)
‚îú‚îÄ‚îÄ questions.json            # Fragenkatalog (JSON)
‚îú‚îÄ‚îÄ requirements.txt          # Abh√§ngigkeiten
‚îú‚îÄ‚îÄ mc_test_answers.csv       # Antwort-Logs (auto-generiert)
‚îú‚îÄ‚îÄ .env / .env.example       # ENV-Konfiguration
‚îú‚îÄ‚îÄ __init__.py               # Paket-Marker
‚îú‚îÄ‚îÄ .devcontainer/
‚îÇ   ‚îî‚îÄ‚îÄ devcontainer.json     # Dev-Container-Konfiguration
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ mc_test_app_ci.yml # Subtree-spezifischer CI-Workflow
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îú‚îÄ‚îÄ config.toml           # Streamlit-Konfiguration
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml          # Secrets (f√ºr Produktion)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_core.py          # Kern-/App-Tests (Import-fallback)
‚îÇ   ‚îú‚îÄ‚îÄ test_edge_cases.py    # Edge Cases (Duplicate Guard, Leaderboard leer usw.)
‚îÇ   ‚îú‚îÄ‚îÄ test_storage.py       # File-Locking & Parallel-Append
‚îÇ   ‚îî‚îÄ‚îÄ test_ui.py            # UI-Sanity via streamlit.testing
‚îî‚îÄ‚îÄ __pycache__/              # App-Cache
```

### Aktueller Modularisierungsstand

| Modul | Zweck | Status |
|-------|-------|--------|
| `core.py` | CSV-Persistenz, Locking, Hashing, Fragenladen | Stabil |
| `scoring.py` | Score-Berechnung, Max-/Ist-Punkte, Leaderboard (abstrakt) | Neu (eingebunden) |
| `mc_test_app.py` | UI, Session-State, Admin, Review, Frageanzeige | Wird weiter zerlegt |
| `leaderboard.py` | (Geplant) Admin-Ansicht + Aggregationen (`calculate_leaderboard_all`) | Ausstehend |
| `review.py` | (Geplant) Final Summary + Review-Filterlogik | Ausstehend |

Nach jeder Auslagerung werden Wrapper im Hauptmodul belassen, um vorhandene Tests & externe Nutzer nicht zu brechen (Backward Compatibility Layer).

### Warum Auslagerung?

- Reduziert Komplexit√§t im Hauptfile (>1000 Zeilen ‚Üí besser wartbar)
- Erleichtert gezieltes Testen (kleinere Oberfl√§chen / klarere Verantwortlichkeiten)
- Vorbereitung f√ºr m√∂gliche Wiederverwendung (z.B. Headless-Auswertung, API)

### Integration der neuen `scoring`-Funktionen

`mc_test_app.py` verwendet jetzt interne Wrapper, die auf `scoring.max_score`, `scoring.current_score`, `scoring.percentage` sowie `scoring.leaderboard_completed` delegieren. Tests behalten ihre bestehenden Aufrufe (`calculate_leaderboard()`) bei.

Fallback-Strategie: Falls Import im Sonderlayout (z.B. direktes Skript) scheitert, l√§uft weiterhin die fr√ºhere Inline-Logik (defensiver Pfad, sollte aber selten aktiv sein).

### Geplante n√§chste Schritte

1. Extrahieren: `calculate_leaderboard_all` + `admin_view` ‚Üí `leaderboard.py`
2. Extrahieren: `display_final_summary` + Review-Filter ‚Üí `review.py`
3. Entfernen veralteter Duplikat-Logik nach stabiler CI-Phase
4. README-Update (diese Sektion entsprechend pflegen)

> Hinweis: Falls du nur den Subtree `mc_test_app` in ein eigenes Repo pushst, bleiben die Modul-Pfade stabil.

---

## üîí Datenschutz & Sicherheit

- **Anonymit√§t:** Pseudonyme werden gehasht; nur Admins sehen Plaintext-Pseudonyme.
- **Lokale Speicherung:** Keine externen Server; Daten bleiben auf dem Ger√§t.
- **Admin-Schutz:** Gesch√ºtzt durch ENV-Variablen; kein Zugriff ohne Key.
- **Rate-Limiting:** Verhindert Missbrauch (konfigurierbar).
- **Backup:** Sichere die CSV regelm√§√üig (z.B. via Git oder Cron).

**Hinweis:** Bei sensiblen Daten teste in isolierter Umgebung.

---

## üõ†Ô∏è Admin & Wartung

### Admin-Bereich

- Zugang: Sidebar > Management > Key eingeben.
- Funktionen: Leaderboard anzeigen, Scoring-Modus √§ndern,
  alle Daten l√∂schen (mit Best√§tigung).
- CSV-Reset: L√∂sche `mc_test_answers.csv` manuell (wird neu erstellt).

### Tests ausf√ºhren

```bash
pip install -r requirements.txt
PYTHONPATH=. pytest tests/ -q
```

### CI / Qualit√§t

- Automatische Tests via GitHub Actions.
- Schutz gegen fehlerhafte CSV-Zeilen.
- Retry-Logik bei Schreibfehlern.

---

## üé® Accessibility & UX

- **Optionen:** Hoher Kontrast, gro√üe Schrift, reduzierte Animationen.
- **Navigation:** Sticky Progress-Bar, Live-Countdown, Review-Modus.
- **Feedback:** Motivationales Design, Erkl√§rungen zu jeder Frage.

---

## üêõ Troubleshooting

### H√§ufige Probleme

- **App startet nicht:** Pr√ºfe Python-Version und Abh√§ngigkeiten
  (`pip install -r requirements.txt`).
- **Fragen laden nicht:** Stelle sicher, dass `questions.json`
  vorhanden und g√ºltig ist.
- **CSV-Fehler:** L√∂sche `mc_test_answers.csv` und starte neu (Daten gehen verloren).
- **Admin-Zugang fehlt:** Pr√ºfe `.env` oder `secrets.toml` auf korrekte Werte.
- **Zeitlimit √ºberschritten:** Test ohne Zeitdruck neu starten (Pseudonym √§ndern).

### Logs pr√ºfen

- Streamlit-Logs: In der Konsole bei `streamlit run`.
- CSV-Logs: √ñffne `mc_test_answers.csv` mit Excel/Pandas.

### Hilfe

- √ñffne ein Issue auf GitHub oder kontaktiere den Entwickler.

---

## üöÄ Erweiterungsideen

- **Dynamische Fragen:** YAML-Quellen oder Rotation.
- **Mehrsprachigkeit:** Englische √úbersetzung.
- **Erweiterte Analyse:** ML-basierte Schwierigkeitsanalyse.
- **Integration:** Mit Jupyter f√ºr Datenanalyse kombinieren.

---

## üìù Changelog

- **2025-09-20:** Scoring modularisiert (`scoring.py`), CI-Workflow (`mc_test_app_ci.yml`) erg√§nzt, README-Modularchitektur hinzugef√ºgt.
- **2025-09-19:** README optimiert (Struktur, Klarheit, Troubleshooting hinzugef√ºgt).
- **2025-08-16:** Tests und README aktualisiert; Privacy-√Ñnderungen.
- **Fr√ºher:** Grundfunktionen, Docker-Unterst√ºtzung.

---

## ü§ù Contributing

Beitr√§ge willkommen! Forke das Repo, erstelle einen Branch und √∂ffne einen Pull Request.
F√ºr gr√∂√üere √Ñnderungen: Issue erstellen.

**Letzte Aktualisierung:** 2025-09-19
