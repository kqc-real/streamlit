# üìù MC-Test Streamlit App

[![CI](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml)

Eine interaktive Multiple-Choice-Lern- und Selbsttest-App f√ºr Kursteilnehmer/innen.
Bietet schnelles Feedback, Fortschrittsverfolgung und aggregierte Ergebnisse
f√ºr diverse Fragensets.

---

## üöÄ √úbersicht

Diese App ist ein vollst√§ndiger MC-Test f√ºr Kursinhalte, entwickelt mit Streamlit.
Sie erm√∂glicht anonyme Tests mit Pseudonymen, zuf√§lliger Fragenreihenfolge und Zeitlimit.
Perfekt f√ºr Bildungsumgebungen oder Selbstlernphasen.


### Hauptfunktionen (Stand 2025-09-24, verifiziert)

| Kategorie      | Funktion (verifiziert)                                                                                 |
|---------------|--------------------------------------------------------------------------------------------------------|
| Zugang        | Pseudonym-Login (anonymisiert via Hash)                                                                |
| Fragen        | Zuf√§llige Reihenfolge, Gewichtung je Frage, Erkl√§rungen, **strikte Trennung nach Fragenset**           |
| Fragenset     | Auswahl & Persistenz des Fragensets (Fragenpool) auf Startseite, Query-Param-Sync, keine Vermischung   |
| Scoring-Modi  | "Nur +Punkte" (falsch = 0) ¬∑ "+/- Punkte" (falsch = -Gewichtung, ab 2025-09-22 volle Gewichtung)     |
| Feedback      | Sofortiges Ergebnis + Erkl√§rung, dynamische Motivation                                                 |
| Fortschritt   | Persistenz pro Pseudonym (Session lokal, pro Fragenset getrennt)                                       |
| Zeitlimit     | Optionales 60-Minuten-Fenster (abschaltbar durch Code-Anpassung)                                      |
| Leaderboard   | √ñffentliches Top‚Äë5 vor Login; vollst√§ndige Ansicht f√ºr Admin                                           |
| Analyse       | Itemanalyse (p, r_pb, Distraktor, Verteilungen)                                                        |
| Export        | CSV-Download √ºber Admin-Panel, **normiertes Schema**                                                   |
| Reset         | Globaler CSV-Reset mit Hinweisbanner & Best√§tigungsdialog (System-Tab, Admin)                         |
| Admin-Panel   | Sichtbar & funktionsf√§hig nach Login, Session-Handling, keine doppelten Widget-Keys                    |
| Sicherheit    | Hashing + Admin-Key + Rate-Limit (optional), DEV-Fallback                                              |
| Accessibility | Reduzierte Animationen, hoher Kontrast                                                                |

**Neu (2025-09-22 bis 2025-09-24, verifiziert):**

- Strikte Trennung & Persistenz der Antworten, Bookmarks und Exporte pro Fragenset (kein Pool-Mix mehr m√∂glich)
- Admin-Panel: Sichtbarkeit, Session-Handling und Reset-Button mit Best√§tigung verbessert
- CSV-Export: Spaltenreihenfolge und Schema sind jetzt immer konsistent
- Fragenset-Auswahl: Persistenz via Query-Param und Session, keine Vermischung nach Wechsel
- Bugfixes: Keine doppelten Widget-Keys, keine unerw√ºnschten Titel im Admin-Panel, keine Frage-Mischung

Alle Features wurden am 2025-09-24 getestet und funktionieren wie dokumentiert.

---

## üë®‚Äçüíª Entwickler-Info: Session State Variablen

Die App verwendet `st.session_state` intensiv zur Steuerung von UI, Fortschritt, Authentifizierung und Pool-Logik. Nachfolgend eine √úbersicht der wichtigsten Session-Variablen und ihrer Bedeutung (Stand 2025-09-24):

| Variable                  | Typ         | Bedeutung                                                                                 |
|---------------------------|-------------|------------------------------------------------------------------------------------------|
| user_id                   | str         | Aktuelles Pseudonym (Plaintext, f√ºr Leaderboard & Anzeige)                               |
| user_id_hash              | str         | SHA-256-Hash des Pseudonyms (f√ºr Anonymit√§t, als Key f√ºr Antworten)                      |
| user_id_display           | str         | Gek√ºrzter Hash (z.B. erste 10 Zeichen, f√ºr Leaderboard)                                  |
| selected_questions_file   | str         | Aktuell gew√§hltes Fragenset (Dateiname, z.B. `questions_Data_Science.json`)              |
| beantwortet               | list[bool]  | Liste, ob jede Frage beantwortet wurde (Index = Frage)                                   |
| frage_indices             | list[int]   | Reihenfolge der Fragen (zuf√§llig permutiert)                                             |
| optionen_shuffled         | list[list]  | F√ºr jede Frage: zuf√§llig permutierte Antwortoptionen                                     |
| answers_text              | list[str]   | Vom User gew√§hlte Antworttexte (Index = Frage)                                           |
| answer_outcomes           | list[int]   | Punktwert pro Frage (Index = Frage)                                                      |
| celebrated_questions      | set/int     | IDs der Fragen, f√ºr die bereits ein Motivationsbanner gezeigt wurde                      |
| start_zeit                | str/dt      | ISO8601-Startzeit des Tests (f√ºr Zeitlimit)                                              |
| test_time_expired         | bool        | True, wenn Zeitlimit √ºberschritten                                                       |
| bookmarks                 | set/int     | Vom User markierte Fragen (Bookmark-Feature)                                             |
| admin_auth_ok             | bool        | True, wenn Admin-Login erfolgreich                                                       |
| show_admin_panel          | bool        | True, wenn Admin-Panel angezeigt werden soll                                              |
| admin_view                | str         | Aktueller Tab im Admin-Panel (z.B. "Leaderboard", "Analyse", "System")               |
| __selected_pool_tmp       | str         | Zwischenspeicher f√ºr Fragenset-Auswahl (Selectbox)                                       |
| __admin_reset_confirm     | bool        | True, wenn Admin-Reset best√§tigt wurde                                                   |
| __admin_reset_pending     | bool        | True, wenn Admin-Reset-Dialog angezeigt wird                                             |
| __admin_reset_done        | bool        | True, wenn Admin-Reset durchgef√ºhrt wurde                                                |

Weitere tempor√§re oder Feature-spezifische Variablen k√∂nnen im Code erg√§nzt werden. Die wichtigsten States werden beim Fragenset-Wechsel und beim globalen Reset gezielt gel√∂scht oder neu initialisiert.

**Hinweis:** Die Session-State-Keys sind bewusst sprechend gew√§hlt und k√∂nnen sich bei neuen Features erweitern. F√ºr robuste Feature-Entwicklung empfiehlt sich die Nutzung von `st.session_state.get("key")` mit Defaultwerten.
# üìù MC-Test Streamlit App

[![CI](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/kqc-real/streamlit/actions/workflows/ci.yml)

Eine interaktive Multiple-Choice-Lern- und Selbsttest-App f√ºr Kursteilnehmer.
Bietet schnelles Feedback, Fortschrittsverfolgung und aggregierte Ergebnisse
f√ºr Data Science-Themen.

---

## üöÄ √úbersicht

Diese App ist ein vollst√§ndiger MC-Test f√ºr Data Analytics, entwickelt mit Streamlit.
Sie erm√∂glicht anonyme Tests mit Pseudonymen, zuf√§lliger Fragenreihenfolge und Zeitlimit.
Perfekt f√ºr Bildungsumgebungen oder Selbstlernphasen.


### Hauptfunktionen (Stand 2025-09-24, verifiziert)

| Kategorie      | Funktion (verifiziert)                                                                                 |
|---------------|--------------------------------------------------------------------------------------------------------|
| Zugang        | Pseudonym-Login (anonymisiert via Hash)                                                                |
| Fragen        | Zuf√§llige Reihenfolge, Gewichtung je Frage, Erkl√§rungen, **strikte Trennung nach Fragenset**           |
| Fragenset     | Auswahl & Persistenz des Fragensets (Fragenpool) auf Startseite, Query-Param-Sync, keine Vermischung   |
| Scoring-Modi  | "Nur +Punkte" (falsch = 0) ¬∑ "+/- Punkte" (falsch = -Gewichtung, ab 2025-09-22 volle Gewichtung)     |
| Feedback      | Sofortiges Ergebnis + Erkl√§rung, dynamische Motivation                                                 |
| Fortschritt   | Persistenz pro Pseudonym (Session lokal, pro Fragenset getrennt)                                       |
| Zeitlimit     | Optionales 60-Minuten-Fenster (abschaltbar durch Code-Anpassung)                                      |
| Leaderboard   | √ñffentliches Top‚Äë5 vor Login; vollst√§ndige Ansicht f√ºr Admin                                           |
| Analyse       | Itemanalyse (p, r_pb, Distraktor, Verteilungen)                                                        |
| Export        | CSV-Download √ºber Admin-Panel, **normiertes Schema**                                                   |
| Reset         | Globaler CSV-Reset mit Hinweisbanner & Best√§tigungsdialog (System-Tab, Admin)                         |
| Admin-Panel   | Sichtbar & funktionsf√§hig nach Login, Session-Handling, keine doppelten Widget-Keys                    |
| Sicherheit    | Hashing + Admin-Key + Rate-Limit (optional), DEV-Fallback                                              |
| Accessibility | Reduzierte Animationen, hoher Kontrast                                                                |

**Neu (2025-09-22 bis 2025-09-24, verifiziert):**

- Strikte Trennung & Persistenz der Antworten, Bookmarks und Exporte pro Fragenset (kein Pool-Mix mehr m√∂glich)
- Admin-Panel: Sichtbarkeit, Session-Handling und Reset-Button mit Best√§tigung verbessert
- CSV-Export: Spaltenreihenfolge und Schema sind jetzt immer konsistent
- Fragenset-Auswahl: Persistenz via Query-Param und Session, keine Vermischung nach Wechsel
- Bugfixes: Keine doppelten Widget-Keys, keine unerw√ºnschten Titel im Admin-Panel, keine Frage-Mischung

Alle Features wurden am 2025-09-24 getestet und funktionieren wie dokumentiert.

---

## üìã Voraussetzungen

- **Python:** Version 3.8 oder h√∂her.
- **Abh√§ngigkeiten:** Installiere via `pip install -r requirements.txt`.
- **Optionale Tools:** Docker f√ºr Container-Deployment; Git f√ºr Versionierung.

---

## üõ†Ô∏è Installation und Start

### Lokaler Start (Empfohlen f√ºr Entwicklung)

1. Klone das Repository oder navigiere zum `mc_test_app/`-Ordner.
2. Installiere Abh√§ngigkeiten:

   ```bash
   pip install -r requirements.txt
   ```

3. Starte die App:

   ```bash
   streamlit run mc_test_app.py
   ```

4. √ñffne [http://localhost:8501](http://localhost:8501) im Browser.

### Docker-Start

```bash
docker compose up -d streamlit-slim
```

F√ºr den vollen Stack (mit Jupyter, MLflow):

```bash
docker compose up -d
```

### Deployment (z.B. Streamlit Cloud)

1. Pushe nur den `mc_test_app/`-Ordner in ein separates Repo.
2. Verwende `git subtree` f√ºr saubere Trennung:

   ```bash
   git subtree push --prefix mc_test_app github main
   ```

3. Deploye auf Streamlit Cloud oder √§hnlichen Plattformen.

---

## ‚öôÔ∏è Konfiguration

### Umgebungsvariablen (`.env`-Datei)

Erstelle eine `.env`-Datei basierend auf `.env.example`:

```env
MC_TEST_ADMIN_USER=dein_admin_pseudonym  # Optional: Beschr√§nkt Admin-Zugang
MC_TEST_ADMIN_KEY=dein_geheimes_passwort  # Erforderlich f√ºr Admin-Features
MC_TEST_MIN_SECONDS_BETWEEN=5  # Optional: Mindestsekunden zwischen Antworten
```

- **Admin-Zugang:** Ohne `MC_TEST_ADMIN_KEY` reicht ein beliebiges Passwort;
  mit Key muss es exakt passen.
- **Rate-Limiting:** Verhindert Spam; Standard: 0 (kein Limit).

### Streamlit-Secrets (`.streamlit/secrets.toml`)

F√ºr Produktion:

```toml
"MC_TEST_ADMIN_USER" = "admin"
"MC_TEST_ADMIN_KEY" = "secret123"
"MC_TEST_MIN_SECONDS_BETWEEN" = 5
```

Hinweise (Streamlit Cloud / TOML Parser):

- Schl√ºssel UND Werte als Strings konsequent quoten (robusteste Variante): `"KEY" = "wert"`.
- Numerische Werte (z.B. `5`) k√∂nnen ohne Quotes, d√ºrfen aber auch mit `"5"` ‚Äì intern wird gecastet.
- Keine `.env`-Syntax (`KEY=value` ohne Leerzeichen) in `secrets.toml` verwenden ‚Äì immer `KEY = VALUE` mit Leerzeichen.
- Pro Zeile genau ein Key. Keine Inline-Kommentare direkt hinter dem Wert.
- Unsichtbare Sonderzeichen vermeiden (non-breaking space, typogr. Bindestrich) ‚Äì bei Copy/Paste ggf. s√§ubern.
- Bei "invalid TOML": Quotes, `=` Abst√§nde und Tabs (verboten) pr√ºfen.

Minimalvariante (alle Strings explizit in Quotes):

```toml
"MC_TEST_ADMIN_USER" = "Admin"
"MC_TEST_ADMIN_KEY" = "Admin"
"MC_TEST_MIN_SECONDS_BETWEEN" = 1
```

### Datenpersistenz (CSV)

- **Datei:** `mc_test_answers.csv` (automatische Erstellung).
- **Schema (seit Sept 2025, kompatibel r√ºckw√§rts):**

  ```csv
  user_id_hash,user_id_display,user_id_plain,frage_nr,frage,antwort,richtig,zeit,markiert,questions_file
  ```

- **Felder:**

  - `user_id_hash`: SHA-256-Hash des Pseudonyms (f√ºr Anonymit√§t).
  - `user_id_display`: Gek√ºrzter Hash (z.B. erste 10 Zeichen).
  - `user_id_plain`: Eingetragenes Pseudonym (f√ºr Leaderboard).
  - `frage_nr`: Fragenummer.
  - `frage`: Vollst√§ndiger Fragetext.
  - `antwort`: Ausgew√§hlte Option.
  - `richtig`: Punktwert der Antwort. `positive_only`: +Gewichtung oder 0. `+/-`: +Gewichtung oder -Gewichtung.
  - `zeit`: ISO8601-Zeitstempel.

- **Eigenschaften:** Append-only, Pandas-kompatibel, leicht zu sichern.

---

## üìÅ Projektstruktur

```
mc_test_app/
‚îú‚îÄ‚îÄ README.md                 # Diese Dokumentation
‚îú‚îÄ‚îÄ mc_test_app.py            # Hauptapp (UI + kombinierte Logik ‚Äì wird schrittweise entschlackt)
‚îú‚îÄ‚îÄ core.py                   # Speicher/Hash/CSV-Basisfunktionen
‚îú‚îÄ‚îÄ scoring.py                # (Neu) Zentrale Score-/Leaderboard-Berechnung (Top-5 Abbildung)
‚îú‚îÄ‚îÄ questions.json            # Fragenkatalog (JSON)
‚îú‚îÄ‚îÄ requirements.txt          # Abh√§ngigkeiten
‚îú‚îÄ‚îÄ mc_test_answers.csv       # Antwort-Logs (auto-generiert)
‚îú‚îÄ‚îÄ .env / .env.example       # ENV-Konfiguration
‚îú‚îÄ‚îÄ __init__.py               # Paket-Marker
‚îú‚îÄ‚îÄ .devcontainer/
‚îÇ   ‚îî‚îÄ‚îÄ devcontainer.json     # Dev-Container-Konfiguration
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ mc_test_app_ci.yml # Subtree-spezifischer CI-Workflow
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îú‚îÄ‚îÄ config.toml           # Streamlit-Konfiguration
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml          # Secrets (f√ºr Produktion)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_core.py          # Kern-/App-Tests (Import-fallback)
‚îÇ   ‚îú‚îÄ‚îÄ test_edge_cases.py    # Edge Cases (Duplicate Guard, Leaderboard leer usw.)
‚îÇ   ‚îú‚îÄ‚îÄ test_storage.py       # File-Locking & Parallel-Append
‚îÇ   ‚îî‚îÄ‚îÄ test_ui.py            # UI-Sanity via streamlit.testing
‚îî‚îÄ‚îÄ __pycache__/              # App-Cache
```

### Modularisierungsstand (Stand 2025‚Äë09‚Äë21)

| Modul | Zweck | Status |
|-------|-------|--------|
| `core.py` | CSV-Persistenz, Locking, Hashing, Fragenladen | Stabil |
| `scoring.py` | Punktestand, Prozent, abstrahiertes Leaderboard | Aktiv |
| `leaderboard.py` | Aggregationen, Leaderboard, Log-Ansicht (Admin) | Aktiv |
| `review.py` | Itemanalyse (Analyse / Export / System / Glossar Tabs) | Aktiv |
| `mc_test_app.py` | UI-Orchestrierung + Wrapper | Schlank |
| `gamification.py` | Badges, Streak, Motivation | Geplant |

Backward Compatibility: Wrapper-Funktionen im Hauptmodul behalten alte Namen
(`calculate_leaderboard`, `display_admin_panel` etc.), damit bestehende Tests
& externe Automationen nicht brechen.

### Warum Auslagerung?

- Geringere Komplexit√§t (maintainable, testbar, klarere Verantwortlichkeiten)
- Saubere Trennung: UI vs. Analyse-/Aggregationslogik
- Wiederverwendbarkeit (sp√§ter ggf. Headless-Auswertung / API / Batch Reports)
- Besseres Onboarding neuer Contributor (kleinere Module)

### Neue / Erweiterte Funktionen seit Modularisierung

| Bereich | √Ñnderung | Nutzen |
|---------|----------|-------|
| Admin Auth | USER + KEY Pflicht (konstante Zeit) | Schutz |
| DEV Fallback | Auto-Credentials bei fehlender ENV | Schnelles Testen |
| Itemanalyse | p, r_pb, Qualit√§tslabel | Transparenz |
| Distraktor-Analyse | Dominanter Distraktor %, h√§ufigste falsche | Diagnose |
| Detail-Ansicht | Verlauf + Verteilung pro Option | Item-Diagnose |
| System-Metriken | Nutzer, aktiv <10m, √ò Antworten, Accuracy | Monitoring |
| Export-Tab | CSV-Download + Spaltenliste | Weiterverarb. |
| Glossar-Tab | Definitionen + Formeln | Kontext |
| Struktur | Module + Wrapper | Klarheit |

Geplante Erg√§nzung: Auslagerung von Streak/Badges/Motivationslogik nach `gamification.py`.

### Scoring & Gewichtung

| Modus | Richtig | Falsch | Motivation |
|-------|---------|--------|------------|
| Nur +Punkte | +Gewichtung | 0 | Risikoarmes √úben |
| +/- Punkte | +Gewichtung | -Gewichtung | F√∂rdert sorgf√§ltiges Antworten |

Hinweise:
- Gewichtung fehlt? ‚Üí Standard = 1.
- Prozentanzeige = aktueller Score / Summe aller Gewichtungen.
- Negative Gesamtwerte sind erlaubt (kein Floor). Optional konfigurierbar (Code-Anpassung in `current_score`).
- Vorschau-Abz√ºge (Vorwarnung) k√∂nnen leicht erg√§nzt werden (siehe Developer Guide Roadmap).

### Admin-Panel √úbersicht

Zwei Ebenen der Verwaltung:

Analyse-/Review (`review.py`):
- üìä Analyse: Itemanalyse (p, r_pb, Distraktor, Verteilung)
- üì§ Export: CSV-Download + Spaltenliste
- üõ† System: Teilnehmer, Aktivit√§t (<10m), √ò Antworten, Accuracy
- üìö Glossar: Definitionen, Hinweise, Formeln

Leaderboard (Admin):
- ü•á Top 5: Abgeschlossene Teilnahmen (Top 3 mit Icons)
- üë• Alle Teilnahmen: √úbersicht aller Nutzer
- üìÑ Rohdaten: Basis-Log

√ñffentlich (nicht angemeldet) sichtbar: Eine kompakte Top‚Äë5 Liste (ohne Detail-Logs).

Glossar-Formeln: p, r_pb, Dominanter Distraktor %.
Hinweis: Kleine Stichproben (<20) vorsichtig interpretieren.

### Integration der modularen Funktionen

`mc_test_app.py` delegiert via Wrapper an `scoring`, `leaderboard`, `review`.
Fehlschlagende Importe (Spezialumgebung) aktivieren Fallbacks.

---

## üîí Datenschutz & Sicherheit

- **Anonymit√§t:** Pseudonyme werden gehasht; nur Admins sehen Plaintext-Pseudonyme.
- **Lokale Speicherung:** Keine externen Server; Daten bleiben auf dem Ger√§t.
- **Admin-Schutz:** Gesch√ºtzt durch ENV-Variablen; kein Zugriff ohne Key.
- **Rate-Limiting:** Verhindert Missbrauch (konfigurierbar).
- **Backup:** Sichere die CSV regelm√§√üig (z.B. via Git oder Cron).

**Hinweis:** Bei sensiblen Daten teste in isolierter Umgebung.

---

## üõ†Ô∏è Admin & Wartung

### Admin-Bereich

- Zugang: Sidebar > Management > Key eingeben
  (nur spezifizierter Admin-User sieht das Eingabefeld).
- Tabs: Leaderboard (Top / Alle / Rohdaten), Analyse (Itemanalyse),
  Export (CSV), System (Status/KPIs), Glossar.
- Scoring-Modus-Umschaltung & globaler CSV-Reset (System-Tab > *Globaler Reset*).
  Falls Button fehlt: Datei manuell l√∂schen (`mc_test_answers.csv`).

### Tests ausf√ºhren

```bash
pip install -r requirements.txt
# Haupt-App Tests (empfohlen):
PYTHONPATH=. pytest mc_test_app/tests -q
```

Hinweise:

- Haupttests: `mc_test_app/tests` (Core, Edge, Storage, UI).
- Deaktivierter UI-Test: `test_sidebar_leaderboard.py` (Skip).
- Legacy Root-`tests/` ggf. ignorieren.

### CI / Qualit√§t

- Automatische Tests via GitHub Actions.
- Schutz gegen fehlerhafte CSV-Zeilen.
- Retry-Logik bei Schreibfehlern.

---

## üé® Accessibility & UX

- **Optionen:** Hoher Kontrast, gro√üe Schrift, reduzierte Animationen.
- **Navigation:** Sticky Progress-Bar, Live-Countdown, Review-Modus.
- **Feedback:** Motivationales Design, Erkl√§rungen zu jeder Frage.

---

## üêõ Troubleshooting

### H√§ufige Probleme

- **App startet nicht:** Pr√ºfe Python-Version und Abh√§ngigkeiten
  (`pip install -r requirements.txt`).
- **Fragen laden nicht:** Stelle sicher, dass `questions.json`
  vorhanden und g√ºltig ist.
- **CSV-Fehler:** L√∂sche `mc_test_answers.csv` und starte neu (Daten gehen verloren).
- **Admin-Zugang fehlt:** Pr√ºfe `.env` oder `secrets.toml` auf korrekte Werte.
- **Zeitlimit √ºberschritten:** Test ohne Zeitdruck neu starten (Pseudonym √§ndern).

### Logs pr√ºfen

- Streamlit-Logs: In der Konsole bei `streamlit run`.
- CSV-Logs: √ñffne `mc_test_answers.csv` mit Excel/Pandas.

### Hilfe

- √ñffne ein Issue auf GitHub oder kontaktiere den Entwickler.

---

## üöÄ Erweiterungsideen

- **Dynamische Fragen:** YAML-Quellen oder Rotation.
- **Mehrsprachigkeit:** Englische √úbersetzung.
- **Erweiterte Analyse:** ML-basierte Schwierigkeitsanalyse.
- **Integration:** Mit Jupyter f√ºr Datenanalyse kombinieren.

---

## üìù Changelog

- **2025-09-22:** Scoring √ºberarbeitet (Abzug = volle Gewichtung), README restrukturiert (Feature-Tabelle, Scoring-Abschnitt erg√§nzt).
- **2025-09-22:** Aufr√§umarbeiten: Entfernte veraltete "Highscore"-Texte,
  README aktualisiert (vereinheitlichte Admin-Bereich Beschreibung,
  klare Trennung √∂ffentliche Ansicht vs. Admin-Tabs).
- **2025-09-21:** Module `leaderboard.py`, `review.py`; Analyse-/Glossar-Tabs;
  System-KPIs; Itemanalyse (p, r_pb, Distraktor %, Verteilungen);
  DEV-Fallback; h√§rteres Admin-Auth; UI: Rang-Icons (ü•áü•àü•â) f√ºr Top 3;
  leerer minimaler Leaderboard-Placeholder.
- **2025-09-20:** Scoring modularisiert (`scoring.py`), CI-Workflow
  (`mc_test_app_ci.yml`) erg√§nzt, Modularchitektur dokumentiert.
- **2025-09-19:** README optimiert (Struktur, Klarheit, Troubleshooting hinzugef√ºgt).
- **2025-08-16:** Tests und README aktualisiert; Privacy-√Ñnderungen.
- **Fr√ºher:** Grundfunktionen, Docker-Unterst√ºtzung.

---

## ü§ù Contributing

Beitr√§ge willkommen! Forke das Repo, erstelle einen Branch und √∂ffne einen Pull Request.
F√ºr gr√∂√üere √Ñnderungen: Issue erstellen.

**Letzte Aktualisierung:** 2025-09-21
