{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Wir trainieren nur bergab? "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Das Problem der Regression\n", "Bei der Regressionsanalyse muss eine Modellfunktion gefunden werden, die zu einem gegebenen Satz von Datenpunkten N m\u00f6glichst **genau** passt. Ein h\u00e4ufig verwendetes Ma\u00df f\u00fcr die Genauigkeit der Approximation ist die **Methode der kleinsten Quadrate** (engl. least squares approach). Der vertikale Abstand zwischen jedem Datenpunkt $(x_n,y_n)$ und der Ausgabe der Modellfunktion $m(x_n)$ wird durch Subtraktion der y-Werte der Datenpunkte von den vorhergesagten y-Werten der Modellfunktion berechnet (3).\n", "\n", "\\begin{align}\n", "d_n & = m(x_n)-y_n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;        (3)\n", "\\end{align}\n", "\n", "Diese Abst\u00e4nde werden dann quadriert und aufsummiert. Da wir die Qualit\u00e4t einer Approximation mit anderen Approximationen vergleichen wollen, die m\u00f6glicherweise eine andere Anzahl von Datenpunkten haben, teilen wir die Summe noch durch die Gesamtzahl der Datenpunkte (**mittlerer quadratischer Fehler**). So erhalten wir unsere **Verlust**-Funktion (4). Unser Ziel ist es, diese Metrik so niedrig wie m\u00f6glich zu halten, denn je niedriger der Verlust, desto besser die Approximation. Hier haben die Begriffe \"Verlust\" und \"Fehler\" die gleiche Bedeutung. Ein anderer h\u00e4ufig verwendeter Begriff ist \"Kosten\".\n", "\n", "\\begin{align}\n", "Verlust & = \\frac{1}{N} \\sum_{n=0}^{N-1} {[m(x_n)-y_n]}^2 \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (4)\n", "\\end{align}\n", "\n", "\n", "<div class=\"alert alert-block alert-info\">\n", "<b>Hinweis:</b> Beachten Sie, dass in Gl.(4) $x_0$ kein Merkmal wie in Gl.(1) aus W4V2 ist, sondern ein Datenpunkt des Datensatzes.   \n", "\n", "</div>\n", "\n", "\n", "\n", "\n", "Wenn wir eine genaue Regression erreicht haben, k\u00f6nnen wir damit **Vorhersagen** machen. Wir werden unsere Neuronen auf einen gegebenen Satz von Punkten trainieren und sie dann verwenden, um neue Punkte vorherzusagen. Dazu werden wir dem trainierten Neuron neue x-Werte geben, zu denen es die y-Werte vorhersagen soll.\n", "\n", "\n", "<img src=\"images/least_squares_explanation.png\" />\n", "<p style=\"text-align: center;\">\n", "    Abb. 3 - Visualisierung des Abstands zur Modellfunktion\n", "</p>\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# do not change\n", "class SimpleNeuron:\n", "    def __init__(self, plot):\n", "        self.plot = plot #I am assigned the following plot\n", "        self.plot.register_neuron(self) #hey plot, remember me\n", "        \n", "    def set_values(self, weight:float, bias:float):\n", "        self.weight = weight\n", "        self.bias = bias\n", "        self.plot.update() #hey plot, I have changed, redraw my output\n", "        \n", "    def get_weight(self) -> float:\n", "        return self.weight\n", "    \n", "    def get_bias(self) -> float:\n", "        return self.bias\n", "\n", "    def compute(self, x:float) -> float:\n", "        self.activation = self.weight * x + self.bias\n", "        return self.activation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wir werden eine Funktion \"loss\" erstellen, die die Operation in Gleichung (4) durchf\u00fchrt. Als Argumente wird sie dazu ein Neuron-Objekt und einen Satz von Punkten erhalten.\n", "- F\u00fcr jeden Punkt, den wir ihr geben, trennt sie zun\u00e4chst x- und y-Werte. \n", "- Dann \u00fcbergibt sie dem Neuron einen x-Wert und bittet das Neuron, eine Vorhersage f\u00fcr den y-Wert zu berechnen. (siehe $m(x_n)$) \n", "- Dann subtrahiert sie den realen y-Wert von dem vorhergesagten y-Wert, wie in Gleichung (3), und erh\u00e4lt einen Abstand\n", "- Anschlie\u00dfend quadriert sie den Abstand und summiert die quadrierten Abst\u00e4nde.  \n", "- Im letzten Schritt wird die Summe der quadrierten Abst\u00e4nde durch die Anzahl der verglichenen Punkte dividiert."]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fchren Sie die nachfolgende Zelle aus, um eine Verlustfunktion zu definieren."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# do not change\n", "def loss(neuron:SimpleNeuron, points:dict) -> float:\n", "    sum_squared_dist = 0\n", "\n", "    for point_x, point_y in zip(points[\"x\"], points[\"y\"]):  # zip merges both points[\"x\"] and points[\"y\"]\n", "\n", "        predicted_point_y = neuron.compute(point_x)\n", "        dist = point_y - predicted_point_y\n", "        squared_dist = dist ** 2\n", "        sum_squared_dist += squared_dist\n", "\n", "    loss = sum_squared_dist / len(points[\"y\"])\n", "    return loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Vorbereiten eines interaktiven Plots\n", "\n", "Nachdem wir die notwendigen Bibliotheken importiert haben, werden wir nun eine interaktive Plot-Klasse einrichten. Diese soll die Ausgabe eines Neurons zeichnen, indem sie es auffordert, einen Satz von x-Werten zu berechnen. Das f\u00fchrt zu einem Satz von vorhergesagten y-Werten, die auf einer Ebene gezeichnet werden k\u00f6nnen. Wenn das Gewicht oder der Bias eines Neurons ge\u00e4ndert wird, ruft das Neuron die \"redraw\"-Methode seines Plots auf, um ihn zu aktualisieren. Der Plot kann auch feste Punkte zeichnen. Interaktive Schieberegler werden verwendet, um die Gewichte und den Bias der Neuronenobjekten direkt zu \u00e4ndern.\n", "\n", "\n", "<div class=\"alert alert-block alert-info\">\n", "<b>Hinweis:</b> Die Plot-Klassen sind nicht Teil des Lernstoffs f\u00fcr dieses Praktikum.  \n", "\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fchren Sie die nachfolgenden Zellen aus, um die Bibliotheken zu importieren und einen interaktiven Plot zu definieren."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-info\">\n", "<b>Hinweis:</b> Wechseln Sie in die tf1-Umgebung. Wenn Sie einen eigenen Rechner verwenden oder diese Environment kein Plotly enth\u00e4lt, <a href=\"https://anaconda.org/plotly/plotly\">installieren</a> Sie es. Dazu \u00f6ffnen Sie das Terminal in tf1 und verwenden conda install ...\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# do not change\n", "import numpy as np\n", "import plotly.offline as plotly\n", "import plotly.graph_objs as go\n", "from ipywidgets import interact, Layout, HBox, FloatSlider\n", "import time\n", "import threading"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# do not change\n", "# an Interactive Plot monitors the activation of a neuron or a neural network\n", "class Interactive2DPlot:\n", "    def __init__(self, points:dict, ranges:dict, width:int=800, height:int=400, margin:dict=dict(t=0, l=170), draw_time:float=0.05):\n", "        self.idle = True\n", "        self.points = points\n", "        self.x = np.arange(ranges[\"x\"][0], ranges[\"x\"][1], 0.1)\n", "        self.y = np.arange(ranges[\"y\"][0], ranges[\"y\"][1], 0.1)\n", "        self.draw_time = draw_time\n", "        self.layout = go.Layout(\n", "            xaxis=dict(title=\"Input: x\", range=ranges[\"x\"], fixedrange=True),\n", "            yaxis=dict(title=\"Output: y\", range=ranges[\"y\"], fixedrange=True),\n", "            width=width,\n", "            height=height,\n", "            showlegend=False,\n", "            autosize=False,\n", "            margin=margin,\n", "        )\n", "        self.trace = go.Scatter(x=self.x, y=self.y)\n", "        self.plot_points = go.Scatter(x=points[\"x\"], y=points[\"y\"], mode=\"markers\")\n", "        self.data = [self.trace, self.plot_points]\n", "        self.plot = go.FigureWidget(self.data, self.layout)\n", "        # self.plot = plotly.iplot(self.data, self.layout,config={\"displayModeBar\": False})\n", "\n", "    def register_neuron(self, neuron:SimpleNeuron):\n", "        self.neuron = neuron\n", "\n", "    def redraw(self):\n", "        self.idle = False\n", "        time.sleep(self.draw_time)\n", "        self.plot.data[0].y = self.neuron.compute(self.x)\n", "        self.idle = True\n", "\n", "    def update(self):\n", "        print(\"Loss: {:0.2f}\".format(loss(self.neuron, self.points)))\n", "        if self.idle:\n", "            thread = threading.Thread(target=self.redraw)\n", "            thread.start()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 4.2.1:</b> Das Neuron trainieren\n", "<ul>\n", "<li>Sie erhalten einen Satz mit 3 Punkten und ein Neuron, um eine Kurvenanpassung durchzuf\u00fchren. F\u00fchren Sie die folgende Zelle aus.\n", "<li> <b>Ver\u00e4ndern Sie das Gewicht und den Bias des Neurons mit den Schiebereglern, um den Verlust zu minimieren.</b>\n", "    <li><b>Tipp:</b> Sie k\u00f6nnen die Schieberegler auch mit den Pfeiltasten auf Ihrer Tastatur ver\u00e4ndern, nachdem Sie auf den Schieberegler geklickt haben.\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# do not change\n", "points_linreg = dict(x=[1, 2, 3], y=[1.5, 0.7, 1.2])\n", "ranges_linreg = dict(x=[-4, 4], y=[-4, 4])\n", "\n", "linreg_plot = Interactive2DPlot(points_linreg, ranges_linreg)\n", "simple_neuron = SimpleNeuron(linreg_plot)\n", "\n", "slider_layout = Layout(width=\"90%\")\n", "\n", "interact(\n", "    simple_neuron.set_values, \n", "    weight=FloatSlider(min=-3, max=3, step=0.1, value = 0, layout=slider_layout),\n", "    bias=FloatSlider(min=-3, max=3, step=0.1, value = 0, layout=slider_layout)\n", ")\n", "\n", "linreg_plot.plot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.2:</b> Was ist die optimale Kombination aus Gewicht und Bias? \n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Vorbereiten des 3D-Plots\n", "Wir sehen, dass die Suche nach dem geringsten Verlust ein **Parameteroptimierungsproblem** ist. Bisher k\u00f6nnen wir das Problem manuell l\u00f6sen. Wollen wir aber neuronale Netze zur L\u00f6sung komplexerer Probleme verwenden, m\u00fcssen wir einen Weg finden, diesen Prozess zu automatisieren.\n", "\n", "Die Verlustfunktion wird sowohl mit dem festgelegten Gewicht als auch mit dem festgelegten Bias ge\u00e4ndert. Diese Beziehung kann dreidimensional visualisiert werden, was uns weitere Einblicke geben kann, um einen Algorithmus zu konstruieren, der das Optimierungsproblem l\u00f6st. \n", "In dieser 3D-Ansicht werden logarithmische Skalen verwendet, um die Topographie hervorzuheben. Wir werden eine neue Funktion definieren, um den logarithmischen Verlust f\u00fcr einen Satz von Punkten zu berechnen.\n", "\n", "Der Plot wird wie folgt definiert:\n", "- Die **X-Achse** stellt die Gewichte dar. \n", "- Die **Y-Achse** stellt den Bias dar.\n", "- Die **Z-Achse** (H\u00f6he) stellt den entsprechenden Verlustwert bei einer gegebenen Gewicht/Bias-Konfiguration dar. Zur besseren Verst\u00e4ndlichkeit wird der Logarithmus des MSE-Verlusts angezeigt.\n", "- Die **schwarze Kugel** stellt die aktuelle Gewicht/Bias-Konfiguration. Seine H\u00f6he zeigt den Verlust dieser Konfiguration an."]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fchren Sie die folgenden Zellen aus."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# do not change\n", "def log_mse(neuron:SimpleNeuron, points:dict) -> float:\n", "    least_squares_loss = loss(neuron, points)\n", "    return np.log10(least_squares_loss)"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# do not change\n", "class Interactive3DPlot:\n", "    def __init__(self, points:dict, ranges:dict, width:int=600, height:int=600, draw_time:int=0.1):\n", "        self.idle = True\n", "        self.points = points\n", "        self.draw_time = draw_time\n", "        self.threading = threading\n", "\n", "        self.range_weights = np.arange(  # Array with all possible weight values in the given range\n", "            ranges[\"x\"][0], ranges[\"x\"][1], 0.1\n", "        )\n", "        self.range_biases = np.arange(  # Array with all possible bias values in the given range\n", "            ranges[\"y\"][0], ranges[\"y\"][1], 0.1\n", "        )\n", "        self.range_biases_t = self.range_biases[:, np.newaxis]  # Bias array transposed\n", "        self.range_losses = []  # initialize z axis for 3D surface\n", "\n", "        self.ball = go.Scatter3d(  # initialize ball\n", "            x=[], y=[], z=[], hoverinfo=\"none\", mode=\"markers\", marker=dict(size=12, color=\"black\")\n", "        )\n", "\n", "        self.layout = go.Layout(\n", "            width=width,\n", "            height=height,\n", "            showlegend=False,\n", "            autosize=False,\n", "            margin=dict(t=0, l=0),\n", "            scene=dict(\n", "                xaxis=dict(title=\"Weight\", range=ranges[\"x\"], autorange=False, showticklabels=True),\n", "                yaxis=dict(title=\"Bias\", range=ranges[\"y\"], autorange=False, showticklabels=True),\n", "                zaxis=dict(title=\"Loss: log(MSE)\", range=ranges[\"z\"], autorange=True, showticklabels=False),\n", "            ),\n", "        )\n", "\n", "        self.data = [\n", "            go.Surface(\n", "                z=self.range_losses,\n", "                x=self.range_weights,\n", "                y=self.range_biases,\n", "                colorscale=\"Viridis\",\n", "                opacity=0.9,\n", "                showscale=False,\n", "                hoverinfo=\"none\",\n", "            ),\n", "            self.ball,\n", "        ]\n", "\n", "        self.plot = go.FigureWidget(self.data, self.layout)\n", "\n", "    def register_neuron(self, neuron:SimpleNeuron):\n", "        self.neuron = neuron\n", "        self.calc_surface()\n", "\n", "        # height of 3d surface represents loss of weight/bias combination\n", "        # In the 2D plot, x is an array from e.g. -4 to +4. But the weights and biases only have a single value\n", "        # Here x will be the points to do regression and to calculate the loss on. \n", "        # The surface is spanned by the arrays of weight and bias.\n", "        \n", "    def calc_surface(self):  \n", "                \n", "        self.neuron.weight = (  #instead of 1 weight and 1 bias, let Neuron have an array of all weights and biases\n", "            self.range_weights\n", "        )\n", "        self.neuron.bias = self.range_biases_t\n", "        self.range_losses = log_mse(  # result: matrix of losses of all weight/bias combinations in the given range\n", "            self.neuron, self.points\n", "        )\n", "        self.plot.data[0].z = self.range_losses\n", "\n", "    def update(self):\n", "        if self.idle:\n", "            thread = threading.Thread(target=self.redraw)\n", "            thread.start()\n", "\n", "    def redraw(self):  # when updating, only the ball is redrawn\n", "        self.idle = False\n", "        time.sleep(self.draw_time)\n", "        self.ball.x = [self.neuron.weight]\n", "        self.ball.y = [self.neuron.bias]\n", "        self.ball.z = [log_mse(self.neuron, self.points)]\n", "        self.plot.data[1].x = self.ball.x\n", "        self.plot.data[1].y = self.ball.y\n", "        self.plot.data[1].z = self.ball.z\n", "        self.idle = True"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# do not change\n", "class DualPlot:\n", "    def __init__(self, points:dict, ranges_3d:dict, ranges_2d:dict):\n", "        self.plot_3d = Interactive3DPlot(points, ranges_3d)\n", "        self.plot_2d = Interactive2DPlot(points, ranges_2d, width=400, height=500, margin=dict(t=200, l=30))\n", "\n", "    def register_neuron(self, neuron:SimpleNeuron):\n", "        self.plot_3d.register_neuron(neuron)\n", "        self.plot_2d.register_neuron(neuron)\n", "\n", "    def update(self):\n", "        self.plot_3d.update()\n", "        self.plot_2d.update()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 4.2.3:</b> Das Neuron trainieren\n", "<ul>\n", "<li> Sie erhalten den gleiche Satz von 3 Datenpunkten und erneut ein Neuron, um eine Kurvenanpassung durchzuf\u00fchren. F\u00fchren Sie die folgende Zelle aus.\n", "<li> <b>Ver\u00e4ndern Sie das Gewicht und den Bias des Neurons mit den Schiebereglern, um den Verlust zu minimieren.</b>\n", "<li> <b>Beobachten Sie alle \u00c4nderungen.</b>\n", "    </li>\n", "\n", "</ul>\n", "\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-info\">\n", "<b>Hinweis:</b> Sie k\u00f6nnen den 3D-Plot drehen, indem Sie auf ihn klicken und den Cursor bewegen. Dabei m\u00fcssen Sie mit dem Cursor innerhalb des Widgets bleiben. \n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# do not change\n", "ranges_3d = dict(x=[-2.5, 2.5], y=[-2.5, 2.5], z=[-1, 2.5])  # set up ranges for the 3d plot\n", "plot_task2 = DualPlot(points_linreg, ranges_3d, ranges_linreg)  # create a DualPlot object to mange plotting on two plots\n", "neuron_task2 = SimpleNeuron(plot_task2)  # create a new neuron for this task\n", "\n", "interact(\n", "    neuron_task2.set_values,\n", "    weight=FloatSlider(min=-2, max=2, step=0.2, layout=slider_layout),\n", "    bias=FloatSlider(min=-2, max=2, step=0.2, layout=slider_layout),\n", ")\n", "\n", "HBox((plot_task2.plot_3d.plot, plot_task2.plot_2d.plot))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.4:</b> Wo liegt im Allgemeinen die optimale Kombination aus Gewicht und Bias im 3D-Plot?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.5:</b> Wie steil ist das Tal an der Stelle der optimalen Gewichts- und Bias Kombination?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "## Aktivierungsfunktionen\n", "Bis jetzt ist unser Neuronenmodell, das aus Gewichten und Bias besteht, nur in der Lage, lineare Funktionen zu imitieren. Folglich k\u00f6nnen wir damit nur lineare Regression durchf\u00fchren. Aktivierungsfunktionen erweitern unsere M\u00f6glichkeiten, indem sie dem Neuron eine zus\u00e4tzliche Nichtlinearit\u00e4t hinzuf\u00fcgen. Mit ihnen k\u00f6nnen wir komplexere Funktionen modellieren. Die heutzutage am h\u00e4ufigsten verwendete Aktivierungsfunktion ist die Rectified Linear Unit, auch **ReLU** genannt. Sie gibt nur den Eingabewert aus, solange er gr\u00f6\u00dfer als 0 ist. Ist er kleiner als 0, gibt sie 0 aus. Wir k\u00f6nnen diese Funktion bequem beschreiben, indem wir das Maximum des Eingabewertes und 0 nehmen. Der gr\u00f6\u00dfere Wert von beiden wird als Ausgabe gew\u00e4hlt (5).\n", "\n", "\\begin{align}\n", "f_{relu}(x) & = max(0,x) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (5)\n", "\\end{align}\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fchren Sie die folgende Zelle aus, um die ReLU Funktion zu definieren."]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# do not change\n", "def relu(input_val:float) -> float:\n", "    return np.where(input_val > 0, input_val, 0.0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wir k\u00f6nnen ein Neuron mit einer ReLU-Aktivierungsfunktion folgenderma\u00dfen zeichnen:\n", "<img src=\"images/single_neuron_relu.png\" />\n", "<p style=\"text-align: center;\">\n", "    Abb. 5 - Neuron mit ReLU-Aktivierungsfunktion visualisiert\n", "</p>\n", "Lassen Sie uns eine neue Klasse erstellen, um dieses Neuron in Python zu implementieren. Wir werden alle Eigenschaften eines Neurons von SimpleNeuron erben.\n", "Wir \u00e4ndern nur die Ausgabe, indem wir sie zun\u00e4chst durch unsere ReLU-Funktion f\u00fchren:\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 4.2.6:</b> Implementieren Sie ein komplettes k\u00fcnstlichen Neurons mit ReLU-Aktivierungsfunktion\n", "<ul>\n", "<li> Vervollst\u00e4ndigen Sie den folgenden Code eines k\u00fcnstliches Neuron, indem Sie die ReLU-Funktion von oben verwenden, um seine Aktivierung zu berechnen (wie in Abbildung 5). </li>\n", "<li>Schauen Sie sich die <a href=\"#simple_neuron\">einfache Neuronenklasse</a> an und schreiben Sie eine \u00e4hnliche Berechnungsfunktion</li>\n", "<li>Sie brauchen die relu-Funktion nicht neu zu implementieren und sollten nicht mehr als 1 Zeile hinzuf\u00fcgen m\u00fcssen. </li>\n", "\n", "</ul>\n", "</div>"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["class ReluNeuron(SimpleNeuron): #inherit from SimpleNeuron class\n", "    \n", "    def compute(self, inputs:list) -> float:\n", "        # STUDENT CODE HERE\n", "\n", "        # STUDENT CODE until HERE\n", "        return self.activation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "### Aufgabe: Nichtlineare Klimaregelung\n", "\n", "Sie finden sich als Ingenieur bei der Firma \"ClimaTronics\" wieder. Ihre Firma m\u00f6chte KI-Technologie implementieren, um ihr neues Klimasystem \"Perfect Climate 9000\" zu regeln. Obwohl das Problem leicht mit konventioneller Programmierung gel\u00f6st werden kann, m\u00f6chte die Gesch\u00e4ftsleitung, dass Sie KI implementieren, um Investoren zu gewinnen. Sie m\u00fcssen die folgenden Anforderungen erf\u00fcllen, die im Datenblattauszug visualisiert sind:\n", "\n", "\n", "`Bei Temperaturen unter 25\u00b0C soll die Klimasteuerung ausgeschaltet bleiben. Bei einer Temperatur von 30\u00b0C soll sie 10% ihrer K\u00fchlleistung erreichen. Zwischen 30\u00b0C und 40\u00b0C soll die K\u00fchlleistung quadratisch mit der Temperatur ansteigen. Die K\u00fchlleistung soll bei 40\u00b0C ihr Maximum erreichen.`\n", "<img src=\"images/datasheet.png\" />\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fchren Sie die nachfolgende Zelle aus, um ein interaktives Diagramm anzuzeigen."]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["# do not change\n", "points_climate = dict(x=[25.0, 27.5, 30.0, 32.5, 35, 37.5, 40.0], y=[0.0, 2.0, 10.0, 23.7, 43, 68.7, 100.0])\n", "\n", "ranges_climate = dict(x=[-4, 45], y=[-4, 105])\n", "climate_plot = Interactive2DPlot(points_climate, ranges_climate)\n", "our_relu_neuron = ReluNeuron(climate_plot)\n", "\n", "interact(\n", "    our_relu_neuron.set_values,\n", "    weight=FloatSlider(min=-10, max=10, step=0.1, value=0, layout=slider_layout),\n", "    bias=FloatSlider(min=-200.0, max=200.0, step=1, value=0, layout=slider_layout),\n", ")\n", "\n", "climate_plot.plot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.7:</b> Wie wirkt sich eine \u00c4nderung des Gewichts auf die Ausgabefunktion aus, wenn der Bias auf 0,00 gesetzt wird? \n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.8:</b> Wie wirkt sich die \u00c4nderung des Bias auf die Ausgangsfunktion aus? \n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.9:</b> Bei welcher Temperatur beginnt die Klimatisierung, wenn sie das Gewicht auf 1,00 und den Bias auf -10, setzen? \n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.10:</b> Bei welcher Temperatur beginnt die Klimatisierung, wenn Sie das Gewicht auf 1,00 und den Bias auf -20 setzen?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.11:</b> Bei welcher Temperatur beginnt die Klimatisierung, wenn Sie das Gewicht auf 2,00 und des Bias auf -20 setzen?\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.12:</b> Was ist die beste Gewicht/Bias-Konfiguration, die Sie finden konnten?\n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Schlussfolgerung\n", "Mit nur einem Neuron k\u00f6nnen wir den Einfluss von Gewicht und Bias leicht verstehen und nachvollziehen.\n", "Aber unsere Ein-Neuron-Approximation reicht nicht aus, um die ben\u00f6tigte quadratische Beziehung genau zu approximieren."]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "## Neuronale Netze\n", "\n", "Die Approximation kann durch die Verwendung mehrerer Neuronen verbessert werden. Anstatt nur ein Neuron f\u00fcr unsere Approximation zu verwenden, konstruieren wir ein neuronales Netzwerk. Wir werden zwei ReLU-Neuronen und ein Ausgangsneuron verwenden, das ebenfalls Gewichte hat. Nun k\u00f6nnen wir entscheiden, wie wir das Ergebnis der beiden ReLU-Neuronen in der Mitte gewichten wollen.\n", "\n", "### Versteckte Schichten (engl. Hidden Layers)\n", "In dem nachfolgenden neuronalen Netzwerk stellen die beiden Neuronen in der Mitte eine **versteckte Schicht** dar.\n", "\n", "In der letzten Aufgabe hatten das Gewicht und der Bias einen leicht nachvollziehbaren Einfluss auf die Ausgabe.\n", "Durch das Hinzuf\u00fcgen weiterer Neuronen wird die Beziehung zwischen den einzelnen Gewichten und Bias und der Ausgabe jedoch weniger nachvollziehbar.\n", "Wir erhalten die Gewichte und Bias, indem wir sie einfach solange anpassen, bis das Ergebnis stimmt. Bei diesem Vorgang verlieren wir schnell den \u00dcberblick dar\u00fcber, was wir eigentlich genau berechnen. Daher ist es schwierig, ein einzelnes Neuron aus diesem Netz zu isolieren und seine Verantwortung im System zu beschreiben.\n", "\n", "Der Eingabewert wird mit den ersten Gewichten multipliziert und nach dem Hinzuf\u00fcgen der Bias auf eine Aktivierungsfunktion gegeben. Anschlie\u00dfend wird dieser Ausgang mit den zweiten Gewichten multipliziert. Versteckte Schichten k\u00f6nnen mehrfach hintereinander gestapelt werden. Dies gibt Raum f\u00fcr mehrere Berechnungsschritte und erm\u00f6glicht die Approximation komplexerer Funktionen.\n", "\n", "Neuronale Netze, die mindestens eine versteckte Schicht verwenden, haben eine interessante Eigenschaft: Sie k\u00f6nnen zur Approximation einer beliebigen stetigen Funktion verwendet werden. _(Siehe \"Weiterf\u00fchrende Literatur\")_\n", "\n", "<img src=\"images/hidden_layer.png\" />\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wir werden eine Klasse f\u00fcr neuronale Netze erstellen. Das Netzwerk wird vier Gewichte und zwei Bias haben."]}, {"cell_type": "markdown", "metadata": {}, "source": ["</div>\n", "\n", "<div class=\"alert alert-block alert-info\">\n", "<b>Hinweis:</b> Der Einfachheit halber und zur Wiederverwendbarkeit des Codes werden wir neuronale Netze so behandeln, wie wir einzelne Neuronen in den bisherigen Beispielen behandelt haben. Denken Sie daran, dass ein k\u00fcnstliches Neuron nur eine mathematische Funktion ist. Ein ganzes neuronales Netzwerk kann auch vollst\u00e4ndig durch eine einzelne Funktion beschrieben werden, wie es auch bei der Berechnung der Aktivierung geschieht. Die Neuronen m\u00fcssen nicht die konkrete Form von einzelnen Datenobjekten annehmen.\n", "\n", "</div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["F\u00fchren Sie die folgende Zelle aus, um ein neuronales Netzwerk zu definieren."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["# do not change\n", "class NeuralNetwork:\n", "    def __init__(self, plot):\n", "        self.plot = plot #I am assigned the following plot\n", "        self.plot.register_neuron(self) #hey plot, remember me\n", "        \n", "    def set_config(self, w_i1:float, w_o1:float, b1:float, w_i2:float, w_o2:float, b2:float):\n", "        self.w_i1 = w_i1\n", "        self.w_o1 = w_o1\n", "        self.b1 = b1\n", "        self.w_i2 = w_i2\n", "        self.w_o2 = w_o2\n", "        self.b2 = b2\n", "        self.show_config()\n", "        self.plot.update()  # please redraw my output\n", "\n", "    def show_config(self):\n", "        print(\"w_i1:\", self.w_i1, \"\\t| \", \"w_o1:\", self.w_o1,\"\\n\")\n", "        print(\"b1:\", self.b1, \"\\t| \", \"w_i2:\", self.w_i2,\"\\n\")\n", "        print(\"w_o2:\", self.w_o2, \"\\t| \", \"b2:\", self.b2,\"\\n\")\n", "\n", "    def compute(self, x:float)->float:\n", "        self.prediction = (relu(self.w_i1 * x + self.b1) * self.w_o1\n", "                         + relu(self.w_i2 * x + self.b2) * self.w_o2)\n", "        return self.prediction"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "### Aufgabe: Nichtlineare Klimaregelung mit einem neuronalen Netzwerk\n", "\n", "F\u00fchren Sie die folgende Zelle aus und passen Sie Gewichte und Bias an, um eine bessere Ann\u00e4herung an die gew\u00fcnschte Kurve als in der vorherigen Aufgabe zu erreichen."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["# do not change\n", "climate_plot_adv = Interactive2DPlot(points_climate, ranges_climate)\n", "our_neural_net = NeuralNetwork(climate_plot_adv)\n", "\n", "interact(\n", "    our_neural_net.set_config,\n", "    w_i1=FloatSlider(min=-10, max=10, step=0.1, layout=slider_layout),\n", "    w_o1=FloatSlider(min=-10, max=10, step=0.1,  layout=slider_layout),\n", "    b1=FloatSlider(min=-200.0, max=200.0, step=1,  layout=slider_layout),\n", "    w_i2=FloatSlider(min=-10, max=10, step=0.1, layout=slider_layout),\n", "    w_o2=FloatSlider(min=-10, max=10, step=0.1,  layout=slider_layout),\n", "    b2=FloatSlider(min=-200.0, max=200.0, step=1,layout=slider_layout),\n", ")\n", "climate_plot_adv.plot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.13:</b> Was ist die beste Konfiguration, die Sie finden konnten? (Kopie von oberhalb des Plots)\n", "</div>\n", "\n", "<div class=\"alert block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Schlussfolgerung\n", "Wir stellen fest, dass die quadratische Beziehung durch die Verwendung zus\u00e4tzlicher Gewichte und Bias besser angen\u00e4hert werden kann. Mit zwei ReLU Neuronen k\u00f6nnen wir eine Funktion mit zwei Knicken erstellen.\n", "Die Komplexit\u00e4t der Suche nach den optimalen Gewichten/Biases nimmt jedoch mit jeder Variablen drastisch zu. Je leistungsf\u00e4higer unsere neuronalen Netze sein sollen, desto schwieriger wird die Optimierung."]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "## Backpropagation\n", "\n", "Die L\u00f6sung f\u00fcr unser Optimierungsproblem lautet Backpropagation. Mit ihr k\u00f6nnen wir den Prozess der Anpassung von Gewichten und Bias automatisieren. In diesem Beispiel werden wir zu den Grundlagen zur\u00fcckkehren und ein einfaches Neuron ohne Aktivierungsfunktion betrachten. Backpropagation funktioniert unter Hinzunahme der partiellen Ableitungen der Verlustfunktion in Bezug auf jedes Gewicht und jeden Bias im Netz. Diese k\u00f6nnen mit Hilfe der Kettenregel der Infinitesimalrechnung berechnet werden. Die Ausgabe des Netzwerks $\\hat{y} = \\hat{f}(x,\\theta )$\n", "(wenn $\\hat{y}$ den vom neuronalen Netz vorhergesagten y-Wert bezeichnet) wird in der Forwardpropagation unter Anwendung der gegebenen Rechenregeln (Multiplizieren mit Gewichten, Summieren mit Bias und Aktivierungsfunktion, bis Sie den Ausgang erreichen) berechnet. Der Verlust wird dann aus dem vorhergesagten und dem Ground-Truth-Wert (tats\u00e4chlichem Wert) mit der Verlustfunktion berechnet. Mit diesem Verlust k\u00f6nnen Sie einfach die partiellen Ableitungen in der so genannten Backpropagation berechnen. Siehe zum Beispiel: [BackpropagationExample](https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html) \n", "\n", "An jedem Punkt zeigen der Bias- und der Gewichtsgradient in die Richtung des h\u00f6heren Verlustes. Die Gr\u00f6\u00dfe des Gradienten repr\u00e4sentiert den Betrag der Verlustzunahme. \n", "\n", "Angenommen, wir w\u00fcrden den Verlust in Abb. 6 __maximieren__: Alles, was wir tun m\u00fcssen, ist, den partiellen Ableitungen zu folgen, indem wir sie zu unserem aktuellen Gewicht/Bias-Punkt addieren. In diesem Beispiel bedeutet das, dass wir das Gewicht stark verringern (siehe die Achsen in Abb. 6) und den Bias um einen geringen Betrag verringern (da seine partielle Ableitung eine geringere Gr\u00f6\u00dfe hat).\n", "\n", "Da wir aber mit dem Verlust nach unten gehen wollen, _subtrahieren_ wir den Gradienten von unserem aktuellen Punkt. Dadurch n\u00e4hern wir uns dem Minimum entgegen. Im n\u00e4chsten Schritt sind wir so weiter unten und nahe dem Tiefpunkt. Da wir dann aber immer noch nicht nah genug am Tiefpunkt sind, wiederholen wir diese Schritte einfach, bis wir das Minimum erreicht haben.\n", "\n", "Das Gute an neuronalen Netzwerken ist, dass wir den Gradienten **analytisch** f\u00fcr alle m\u00f6glichen Datenpunkte bestimmen k\u00f6nnen. Wir m\u00fcssen ihn nicht durch numerische Methoden sch\u00e4tzen, wie z. B. durch die Berechnung des Verlusts zweier Gewicht/Bias-Kombinationen dividiert durch den \"Schrittabstand\" (\"Euler-Methode\"). Dieses Vorwissen \u00fcber den Gradienten macht die Backpropagation vergleichsweise schnell. Leider k\u00f6nnen wir aber nicht analytisch die Gewicht/Bias-Kombination bestimmen, die die Verlustfunktion auf ihr Minimum bringt. Wir m\u00fcssen sie immer noch iterativ \u00fcber viele Schritte finden.\n", "\n", "Jeder Schritt, den wir machen, wird eine **Epoche** genannt. (In diesem Fall sind _Trainingsschritte_ und _Epochen_ gleichwertig). Da es schwierig ist, festzustellen, ob das Minimum erreicht ist, geben wir die Anzahl der Epochen vor unserem Abstieg an und lassen das Programm dann einfach laufen.\n", "\n", "Ist die Gr\u00f6\u00dfe der Gradienten zu gro\u00df, werden wir nie ein Minimum erreichen. Das liegt daran, dass unser Algorithmus die Kugel (also den aktuellen Punkt) bei jedem Schritt zu stark bewegen will. Er wird um das Minimum oszillieren, aber nie dort ankommen. Im Extremfall kann die Bewegung sogar bis in die Unendlichkeit oszillieren. Um die Kontrolle \u00fcber die Gr\u00f6\u00dfe der Bewegung zu haben, wird der Gradient mit einem Faktor multipliziert, der **Lernrate** (engl. learning rate) genannt wird (auch \"Schrittgr\u00f6\u00dfe\" genannt im Gradientenabstieg). Indem wir die Lernrate auf einen optimalen Wert einstellen, k\u00f6nnen wir Oszillationen verhindern. Ist die Lernrate allerdings zu klein, wird das Netzwerk sehr lange brauchen, um zu \"lernen\", da sich dann die Gewichte und Bias nur sehr langsam \u00e4ndern.\n", "\n", "Die Anzahl der Epochen sowie die Lernrate sind so genannte **Hyperparameter**. Sie beeinflussen den Trainingsprozess, sind aber nicht Teil des Netzwerks selbst.\n", "\n", "\n", "\n", "<img src=\"images/backprop.png\" />\n", "<p style=\"text-align: center;\">\n", "    Abb. 6 - Partielle Ableitungen der Verlustfunktion\n", "</p>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Backpropagation-Plot vorbereiten\n", "Wir werden ein neues 3D-Diagramm erstellen, das die vergangenen Gewichts-/Bias-/Verlustwerte darstellt, w\u00e4hrend wir versuchen, den Verlust Schritt f\u00fcr Schritt zu optimieren. Die schwarze Kugel hinterl\u00e4sst eine Spur ihrer vergangenen Werte. F\u00fchren Sie die nachfolgende Zelle aus, um das Plotten der Backpropagation-Schritte zu aktivieren."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# do not change\n", "plot_backprop = DualPlot(points_linreg, ranges_3d, ranges_linreg)\n", "trace_to_plot = go.Scatter3d(x=[], y=[], z=[], hoverinfo=\"none\", mode=\"lines\", line=dict(width=10, color=\"grey\"))\n", "\n", "plot_backprop.plot_3d.data.append(trace_to_plot)  # Expand 3D Plot to also plot traces\n", "plot_backprop.plot_3d.plot = go.FigureWidget(plot_backprop.plot_3d.data, plot_backprop.plot_3d.layout)\n", "plot_backprop.plot_3d.draw_time = 0\n", "\n", "\n", "def redraw_with_traces(plot_to_update:DualPlot, neuron:SimpleNeuron, trace_list:dict, points:dict):  # executed every update step\n", "    plot_to_update.plot_3d.plot.data[2].x = trace_list[\"x\"]\n", "    plot_to_update.plot_3d.plot.data[2].y = trace_list[\"y\"]\n", "    plot_to_update.plot_3d.plot.data[2].z = trace_list[\"z\"]\n", "    plot_to_update.plot_3d.plot.data[1].x = [neuron.weight]\n", "    plot_to_update.plot_3d.plot.data[1].y = [neuron.bias]\n", "    plot_to_update.plot_3d.plot.data[1].z = [log_mse(neuron, points)]\n", "    plot_to_update.update()\n", "\n", "\n", "def add_traces(neuron:SimpleNeuron, points:dict, trace_list:dict):  # executed every epoch\n", "    trace_list[\"x\"].extend([neuron.weight])\n", "    trace_list[\"y\"].extend([neuron.bias])\n", "    trace_list[\"z\"].extend([log_mse(neuron, points)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "## DIY Backpropagation\n", "\n", "Um Backpropagation durchzuf\u00fchren, m\u00fcssen Sie zun\u00e4chst die partiellen Ableitungen der Verlustfunktion des \"einfachen Neurons\" in Abh\u00e4ngigkeit von Gewicht und Bias bestimmen. Danach m\u00fcssen Sie herausfinden, wie Sie die Gewichte und Bias richtig an den auf die Lernrate skalierten Gradienten anpassen.\n", "Am Ende dieser \u00dcbung k\u00f6nnen Sie Ihre Ergebnisse durch Training verifizieren. Wenn Sie die erwartete Leistung (Benchmark) erreichen, ist Ihr Algorithmus korrekt.\n", "\n", "Der Algorithmus arbeitet mit einem Dictionary von Punkten mit der Form von: [points_linreg](#points_linreg)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 4.2.14:</b> Bestimmen Sie die Steigung <b>analytisch!!</b>\n", "<ul>\n", "<li> <b>Vervollst\u00e4ndigen Sie die folgende Funktion selbst.</b>\n", "<li>Es gibt mehrere L\u00f6sungen, Ihr Algorithmus kann das Gewicht und den Bias in die richtige Richtung anpassen, obwohl die Berechnung des Gradienten falsch ist.\n", "<li> <b>Benchmark:</b> Wenn Sie nach 100 Epochen und mit einer Lernrate von 0,03 einen Verlust von 0,22 erreichen k\u00f6nnen, ist Ihre L\u00f6sung richtig\n", "    </li>\n", "\n", "</ul>\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["def simple_neuron_loss_gradient(neuron:SimpleNeuron, points:dict)->dict:\n", "\n", "    gradient_sum = dict(weight=0, bias=0) # contains the sum of the weight and bias gradient\n", "    for point_x, point_y in zip(points[\"x\"], points[\"y\"]):  # for each point\n", "            # Hint: point_x and point_y are the current point values\n", "\n", "        gradient_sum[\"weight\"] += ( # sum up the gradient for each point\n", "            \n", "            # STUDENT CODE HERE\n", "\n", "            # STUDENT CODE until HERE\n", "        )\n", "\n", "        gradient_sum[\"bias\"] += (\n", "            # STUDENT CODE HERE\n", "\n", "            # STUDENT CODE until HERE\n", "        )\n", "\n", "    gradient = dict(weight=gradient_sum[\"weight\"] / len(points[\"x\"]), bias=gradient_sum[\"bias\"] / len(points[\"x\"]))\n", "    return gradient"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 4.2.15:</b> Das Neuron anpassen\n", "<ul>\n", "\n", "<li>Nachdem Sie den Gradienten ermittelt haben, m\u00fcssen Sie das Gewicht und den Bias des Neurons basierend auf den partiellen Ableitungen und der Lernrate anpassen. Sie sollten Ihre Ergebnisse \u00fcberpr\u00fcfen, indem Sie das Netz unten trainieren.\n", "<li> <b>Vervollst\u00e4ndigen Sie die nachfolgende Funktion selbst.</b>\n", "    </li>\n", "\n", "</ul>\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["def adjust_neuron(neuron:SimpleNeuron, gradient:dict, learning_rate:float):\n", "    # STUDENT CODE HERE\n", "\n", "    # STUDENT CODE until HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Trainingsprozess definieren\n"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# do not change\n", "def train(neuron:SimpleNeuron, points:dict, epochs:int, learning_rate:float, redraw_step:int, trace_list:dict):\n", "    redraw_with_traces(neuron.plot, neuron, trace_list, points)\n", "    for i in range(1, epochs + 1):  # first Epoch is Epoch no.1\n", "        add_traces(neuron, points, trace_list)\n", "        gradient = simple_neuron_loss_gradient(neuron, points)\n", "        adjust_neuron(neuron, gradient, learning_rate)\n", "\n", "        if i % redraw_step == 0:\n", "            print(\"Epoch:{} \\t\".format(i), end=\"\")\n", "            redraw_with_traces(neuron.plot, neuron_backprop, trace_list, points)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Aufgabe 4.2.16:</b> Hyperparameter w\u00e4hlen und trainieren\n", "<ul>\n", "\n", "<li>W\u00e4hlen Sie eine optimale Lernrate und Anzahl der Epochen, indem Sie verschiedene Werte einstellen und die beiden nachfolgenden Zellen ausf\u00fchren.</li>\n", "\n", "</ul>\n", "\n", "</div>"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["learning_rate = 0.03 #keep this for benchmarking, change to play around\n", "epochs = 100 # keep this for benchmarking, change to play around\n", "redraw_step = 10 # update plot every n'th epoch. too slow? set this to a higher value (e.g. 100)\n", "\n", "# these values are taken as parameters by the train function below\n", "\n", "neuron_backprop = SimpleNeuron(plot_backprop)\n", "HBox((plot_backprop.plot_3d.plot, plot_backprop.plot_2d.plot))"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["#run this cell to test algorithm\n", "\n", "np.random.seed(4) # keep this for benchmarking, remove to play around # TODO: Use np.RandomState !!!!!\n", "\n", "neuron_backprop.set_values(  # set weight and bias randomly\n", "    (5 * np.random.random() - 2.5), (5 * np.random.random() - 2.5)\n", ")\n", "trace_list1 = dict(x=[], y=[], z=[])\n", "\n", "train(neuron_backprop, points_linreg, epochs, learning_rate, redraw_step, trace_list1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Benchmark:** Wenn Sie nach 100 Epochen und einer Lernrate von 0,03 einen Verlust von 0,22 erreichen k\u00f6nnen, ist Ihre L\u00f6sung korrekt."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Beantworten Sie diese Fragen erst, wenn Ihr Algorithmus den Benchmark erreicht hat**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.17:</b> Was passiert, wenn Sie die Lernrate auf 0,18 setzen? Erkl\u00e4ren Sie dieses Verhalten.\n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-success\">\n", "<b>Frage 4.2.18:</b> Welche Lernrate f\u00fchrt zu dem geringsten Verlust nach 100 Epochen mit lr=0,03? \n", "</div>\n", "\n", "<div class=\"alert alert-block alert-success\">\n", "<b>Ihre Antwort:</b></div>", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Machine/Deep Learning Notation\n", "\n", "Wir haben bereits die Lernrate, die Hyperparameter sowie die Epoche kennengelernt. Nun sollen einige weitere Begriffe eingef\u00fchrt werden.\n", "\n", "Betrachten Sie einen Trainingssatz, den Sie an Ihr neuronales Netzwerk geben und dessen Gewichte Sie mit Hilfe von Backpropagation anpassen wollen. Wenn Sie Gewichte und Bias mit jeden Datenpunkt, der in einem Vorw\u00e4rts- und R\u00fcckw\u00e4rtsdurchlauf verwendet wurde, aktualisieren, spricht man von **Stochastischem Gradientenabstieg** (engl. Stochastic Gradient Descent) oder Online-Lernen. Wie Sie sich vielleicht schon denken k\u00f6nen, k\u00f6nnen Sie auch die Fehler mehrer Datenpunkte zu Gruppen einer definierten **Stapelgr\u00f6\u00dfe** (engl. batch size) zusammen addieren. Auf diese Weise k\u00f6nnen Sie mehrere R\u00fcckw\u00e4rtsdurchl\u00e4ufe mit diesen gr\u00f6\u00dferen Teilmengen von Trainingsdaten durchf\u00fchren. Dieses Verfahren wird **Batch Gradient Descent** genannt. Bei einer korrekten Berechnung w\u00fcrden Sie den gesamten Satz von Trainingsdatenpunkten f\u00fcr Ihre Vorw\u00e4rtsdurchl\u00e4ufe verwenden und Fehler speichern, um ein Update zu berechnen (= regul\u00e4rer Gradient Descent). Mit zunehmender Anzahl an Datenpunkten ist dies aber oft nicht mehr praktikabel, sodass hier Batch Gradient Descent und Stochastic Gradient Descent hilfreich sein k\u00f6nnen. Allerdings zeigen beide Verfahren w\u00e4hrend des Trainings unterschiedliche Auswirkungen auf das Modell.\n", "\n", "Egal, welche Variante des Gradientenabstiegs Sie verwenden: Eine **Epoche** ist dann abgelaufen, wenn Ihre Trainingsdaten einmal vollst\u00e4ndig zum Aktualisieren der Gewichte (in Teilmengen oder als Ganzes) verwendet wurden.\n", "\n", "Wie Sie bereits im Abschnitt zur Performannz Evaluierung gelernt haben, kann ein Modell in Abh\u00e4ngigkeit von der Komplexit\u00e4t des Problems/Modells und der Menge der verf\u00fcgbaren Daten over- oder underfitten. Overfitting kann in neuronalen Netzen mit **Regularisierung** behoben werden. In der kommenden Einheit zu Convolutional Neural Networks werden Sie einige dieser Techniken unter Zuhilfenahme der Deeplearning-Bibliothek Keras anwenden m\u00fcssen. Die g\u00e4ngigsten Methoden sind neben der Reduzierung der Modellkomplexit\u00e4t oder der Vergr\u00f6\u00dferung des Datensatzes die **L1/L2-Regularisierung** oder **Dropout**.\n", "\n", "Wenn Sie Ihr Modell nicht richtig trainieren k\u00f6nnen, k\u00f6nnte dies daran liegen, dass Ihr Modell mit **Explodierenden oder verschwindenden Gradienten** (engl. Exploding or Vanishing Gradients) zu k\u00e4mpfen hat. Betrachten Sie ein sehr tiefes Modell, das mehrere versteckte Schichten enth\u00e4lt. Durch Verwenden des Verlustes am Ausgang sollen die Parameter des gesamten Netzwerks aktualisiert werden. Da Werte $>1$, die rekursiv multipliziert werden, zu gr\u00f6\u00dferen Updates f\u00fchren, kann das Verhalten w\u00e4hrend des Trainings instabil werden. Das Training wird die Gewichte in fr\u00fcheren Schichten nicht aktualisieren, wenn partielle Ableitungen $<1$ sind und \u00fcber viele Schichten multipliziert werden (Vanishing Gradient). Um den letzten Fall zu verhindern, der beim regul\u00e4ren Training und beim Verwenden von Sigmoid-Funktionen h\u00e4ufiger auftritt, wird die ReLU-Aktivierungsfunktion heutzutage standardm\u00e4\u00dfig in den versteckten Schichten verwendet. Desweiteren k\u00f6nnen auch fortgeschrittenere Methoden verwendet werden, wie z. B. **Residual/Skip-Verbindungen**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "### Weiterf\u00fchrende Lekt\u00fcre: Neuronale Netze sind universelle Funktionsapproximatoren\n", "\n", "Mathematisch kann bewiesen werden, dass neuronale Netze jede kontinuierliche Funktion approximieren k\u00f6nnen, solange sie mindestens eine versteckte Schicht aufweisen, nichtlineare Aktivierungsfunktionen verwenden und eine ausreichende (aber endliche) Zahl von Neuronen der versteckten Schicht verwenden. \n", "\n", "https://www.sciencedirect.com/science/article/pii/089360809190009T?via%3Dihub\n", "\n", "Kurt Hornik,\\\n", "Approximation capabilities of multilayer feedforward networks,\\\n", "Neural Networks,\\\n", "Band 4, Ausgabe 2,\\\n", "1991,\\\n", "Seiten 251-257"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python-amalea"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 4}
