{"cells":[{"cell_type":"markdown","source":["# Classification: Softmax-Eis für einen one-hot day"],"metadata":{}},{"cell_type":"markdown","source":["## Klassifizierung mit neuronalen Netzen\n","In diesem Kapitel werden Sie die Funktionsweise eines Klassifizierers kennenlernen und einen solchen Klassifizierer manuell trainieren, der mit einem einzelnen Wert arbeitet. Sie werden den Klassifikator Schritt für Schritt verbessern und dabei grundlegende Konzepte der Klassifizierung verstehen.\n","Anschließend werden Sie mit Hilfe der automatischen Backpropagation ein mehrschichtiges neuronales Netz trainieren, das ein logisches Gatter nachahmt."],"metadata":{}},{"cell_type":"markdown","source":["### Einführung\n","Beim maschinellen Lernen und in der Statistik ist die Klassifizierung das Problem. Hierzu wird eine Beobachtung einem Satz von Kategorien (Unterpopulationen) zugeordnet, und zwar auf der Grundlage eines Trainingssatzes von Daten, die Beobachtungen (oder Instanzen) enthalten und deren Kategorie-Zugehörigkeit bekannt ist. Beispiele hierfür sind die Zuordnung einer gegebenen E-Mail zur Klasse \"Spam\" oder \"Nicht-Spam\" oder die Diagnosevergabe an einen Patienten auf der Grundlage von beobachteten Merkmalen des Patienten (Geschlecht, Blutdruck, Vorhandensein oder Fehlen bestimmter Symptome usw.). [1]\n","\n","Ein Klassifizierungsprozess erfordert einen Datensatz, der in verschiedene Kategorien unterteilt ist. Ein Klassifikator kann mit diesem Datensatz trainiert werden, indem er die Beziehung zwischen bestimmten Eigenschaften der Eingabedaten und der zugehörigen Kategorien erlernt. \n","Der Prozess zur Klassifizierung neuer Daten ist dabei ähnlich wie der im Kapitel \"Regression\" vorgestellt, jedoch können je nach Anwendung zusätzliche Rechenschritte hinzugefügt werden.\n","Ein bekanntes Klassifizierungsproblem, das mit neuronalen Netzen gelöst werden kann, ist die Bilderkennung (siehe Abbildung 1).\n","\n","\n","\n","<img src=\"images/neural_network_classification.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 1 - Bilderkennung durch ein neuronales Netz\n","</p>"],"metadata":{}},{"cell_type":"markdown","source":["Führen Sie die folgenden Zellen aus, um die erforderlichen Bibliotheken zu importieren und eine ReLU-, MSE-Verlustfunktion und eine SimpleNeuron-Klasse zu definieren."],"metadata":{}},{"cell_type":"markdown","source":["Wenn Sie Ihren eigenen Computer verwenden, müssen Sie wahrscheinlich die Bibliothek <code>plotly</code> installieren.\n","Dies können Sie mit <code>conda install plotly</code> in der Befehlszeile von Anaconda  erledigen."],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# do not change\n","import numpy as np\n","from ipywidgets import interact, Layout, FloatSlider\n","import plotly.offline as plotly\n","import plotly.graph_objs as go\n","import time\n","import threading"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["# do not change\n","def relu(input_val:float)->float:\n","    return np.where(input_val > 0, input_val, 0.0)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["# do not change\n","def mean_squared_loss(predictions:list, solutions:list)->float:\n","    total_squared_loss = np.sum(np.subtract(predictions, solutions)**2) #np allows to handle both values and lists\n","    mean_squared_loss = total_squared_loss/len(predictions)\n","    return mean_squared_loss"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["# do not change\n","class SimpleNeuron:\n","    def __init__(self, plot):\n","        self.plot = plot\n","        self.plot.register_neuron(self) #hey plot, remember me\n","\n","    def set_values(self, weight:float, bias:float):\n","        self.weight = weight\n","        self.bias = bias\n","        self.plot.update() #hey plot, I have changed, redraw my output\n","        \n","    def get_weight(self) -> float:\n","        return self.weight\n","    \n","    def get_bias(self)->float:\n","        return self.bias\n","\n","    def compute(self, x:float)->float:\n","        self.activation = np.dot(self.weight, x) + self.bias\n","        return self.activation"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["# do not change\n","# an Interactive Plot monitors the activation of a neuron or a neural network\n","class Interactive2DPlot:\n","    def __init__(\n","        self, points_red, points_blue, ranges, loss_function=mean_squared_loss, loss_string=\"Loss\", width=800, height=400, margin=dict(t=0, l=170),\n","        draw_time=0.1\n","    ):\n","        self.idle = True\n","        self.points_red = points_red\n","        self.points_blue = points_blue\n","        self.draw_time = draw_time\n","        self.loss_function = loss_function\n","        self.loss_string = loss_string\n","\n","        self.x = np.arange(ranges[\"x\"][0], ranges[\"x\"][1], 0.01)\n","        self.y = np.arange(ranges[\"y\"][0], ranges[\"y\"][1], 0.01)\n","\n","        self.layout = go.Layout(\n","            xaxis=dict(title=\"Neck height in m\", range=ranges[\"x\"]),\n","            yaxis=dict(title=\"y\", range=ranges[\"y\"]),\n","            width=width,\n","            height=height,\n","            showlegend=False,\n","            margin=margin,\n","        )\n","        self.trace = go.Scatter(x=self.x, y=self.y)\n","\n","        self.plot_points_red = go.Scatter(\n","            x=points_red[\"x\"], y=points_red[\"y\"], mode=\"markers\", marker=dict(color='rgb(255, 0, 0)', size=10)\n","        )\n","        self.plot_points_blue = go.Scatter(\n","            x=points_blue[\"x\"],\n","            y=points_blue[\"y\"],\n","            mode=\"markers\",\n","            marker=dict(color='rgb(0, 0, 255)', size=10, symbol=\"square\"),\n","        )\n","\n","        self.plot_point_new = go.Scatter(\n","            x=[], y=[], mode=\"markers\", marker=dict(size=20, symbol=\"star\", color='rgb(0,0,0)')\n","        )\n","\n","        self.data = [self.trace, self.plot_points_red, self.plot_points_blue, self.plot_point_new]\n","        self.plot = go.FigureWidget(self.data, self.layout)\n","\n","    def register_neuron(self, neuron):\n","        self.neuron = neuron\n","\n","    def redraw(self):\n","        self.idle = False\n","        time.sleep(self.draw_time)\n","        self.plot.data[0].y = self.neuron.compute(self.x)\n","        self.idle = True\n","\n","    def update(self):\n","        loss_red = self.loss_function(self.neuron.compute(self.points_red[\"x\"]), self.points_red[\"y\"])\n","        loss_blue = self.loss_function(self.neuron.compute(self.points_blue[\"x\"]), self.points_blue[\"y\"])\n","        print(self.loss_string,\": {:0.3f}\".format((loss_red + loss_blue) / 2))\n","\n","        if self.idle:\n","            thread = threading.Thread(target=self.redraw)\n","            thread.start()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Von der Regression zur Klassifikation\n","\n","### Lineare Regression\n","\n","Sie arbeiten auf einem Bauernhof mit Schafen und Lamas, die in getrennten Gehegen grasen. Letzte Nacht hat der Schäfer jedoch vergessen, das Tor zwischen den beiden Gehegen zu schließen. Die Lamas und Schafe sind nun vermischt und müssen wieder getrennt werden. Sie denken sich sofort eine auf maschinellem Lernen basierende Lösung aus, um die Schafe wieder von den Lamas zu trennen: Sie gehen davon aus, dass Lamas von Schafen unterschieden werden können, indem Sie den Abstand von der Oberseite des Kopfes bis zur Wirbelsäule messen. Da Lamas deutlich längere Hälse aufweisen. Mit einem LIDAR-Scanner wird die Halshöhe autonom gemessen und die Tiere werden mit einem Futterköder und einem elektronischen Drehkreuz, das nur Lamas durchlässt, getrennt.\n","\n","\n","<img src=\"images/neck_heights.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 2 - Konzept der Halshöhenmessung\n","</p>\n","\n","Um Datenpunkte zu sammeln, gehen Sie mit einem Maßband auf das Feld und messen die Halshöhen einiger Schafe und Lamas. Sie legen zwei Kategorien fest: \"0\" für Schafe und \"1\" für Lamas. (Siehe Tabelle 1)\n","\n","Die meisten Lamas sind erwachsen und haben lange Hälse, aber es gibt auch einige junge Lamas mit kleineren Hälsen. Da ihre Hälse jedoch immer noch länger sind als die der Schafe, gehen Sie davon aus, dass dies kein Problem sein wird.\n","\n","|  Tier | Halshöhe  | Kategorie  |\n","|---------|--------------|-----------|\n","| Schaf #1| 0.20m        |0          |\n","| Schaf #2| 0.23m        |0          |\n","| Schaf #3| 0.28m        |0          |\n","| Schaf #4| 0.32m        |0          |\n","| Schaf #5| 0.35m        |0          |\n","| Lama #1| 0.55m        |1          |\n","| Lama #2| 0.68m        |1          |\n","| Lama #3| 0.74m        |1          |\n","| Lama #4| 0.83m        |1          |\n","| Lama #5| 0.95m        |1          |\n","\n","<p style=\"text-align: center;\">\n","    Tabelle. 1 - Ihre Data-Mining-Ergebnisse\n","</p>"],"metadata":{}},{"cell_type":"markdown","source":["#### Trainieren eines linearen Regressionsneurons von Hand\n","Der Einfachheit halber beginnen Sie damit, ein einzelnes Neuron als Klassifikator zu verwenden. Führen Sie die beiden folgenden Zellen aus, um die Data-Mining-Punkte zu definieren und ein Diagramm anzuzeigen."],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["# do not change\n","points_sheep = dict(\n","              x=[ 0.20, 0.23, 0.28, 0.32, 0.35],\n","              y=[ 0, 0, 0, 0, 0]\n","             )\n","\n","points_llamas = dict(\n","              x=[ 0.55, 0.68, 0.74, 0.83, 0.95],\n","              y=[ 1,  1, 1, 1, 1]\n","             )\n","\n","ranges = dict(x=[-0.1, 1.25], y=[-0.5, 1.4])\n","slider_layout = Layout(width=\"90%\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["# do not change\n","plot1 = Interactive2DPlot(points_sheep, points_llamas, ranges, loss_string=\"Mean Squared Loss\")\n","neuron1 = SimpleNeuron(plot1)\n","\n","interact(\n","    neuron1.set_values,\n","    weight=FloatSlider(min=-2, max=4, step=0.1, layout = slider_layout),\n","    bias=FloatSlider(min=-1, max=1, step=0.1, layout = slider_layout),\n",")\n","\n","plot1.plot"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.1:</b> Variieren Sie die obigen Schieberegler für Gewicht und Bias. Was ist eine Kombination aus Gewicht und Bias, die zu einem Verlust < 0,05 führt?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["***\n","#### Auf dem Weg zu einem diskreten Klassifikator\n","Nun wollen wir unser trainiertes Neuron verwenden, um neue Halshöhen zu klassifizieren. Dazu müssen wir ein Programm schreiben, das eine Halshöhe entgegennimmt und ausgibt, was das trainierte Neuron darüber denkt. Der Klassifikator wird auch die neue Halshöhe aufzeichnen. Führen Sie die folgende Box aus, um die Werte aus der vorherigen Aufgabe zu erhalten."],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["# do not change\n","# a duplicate of the last plot, so you don't have to scroll\n","plot2 = Interactive2DPlot(points_sheep, points_llamas, ranges, loss_string=\"Mean Squared Loss\") \n","neuron2 = SimpleNeuron(plot2)\n","neuron2.set_values(neuron1.get_weight(), neuron1.get_bias()) #get your values from last task\n","\n","plot2.plot"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.2:</b> Versuchen Sie, einen Klassifikator mit nur einem linearen Neuron zu implementieren. (Ja, eine fast aussichtslose Aufgabe, aber das wird später noch Sinn ergeben). <br> Vervollständigen Sie den folgenden Python-Code sodass Sie das Ergebnis der Klassifizierung als Variable <code>classification_result</code> erhalten.\n","<ul>\n","    <li> Das Klassifikationsergebnis soll die Ausgabe von neuron2 auf Basis einer neuen Halshöhe sein</li>\n","    <li> Sie sollten nicht mehr als 1 Zeile Code hinzufügen müssen </li>\n","    <li> Schauen Sie sich nach dem Ausführen den Stern im obigen Diagramm an. Er stellt die aktuelle Eingabe/Ausgabe für die neue Halslänge dar</li>\n","</ul>\n","\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["new_neck_height = 0.55  # this value shall be varied to answer the questions below\n","\n","#classification_result = ??\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","plot2.plot.data[3].x = [new_neck_height] #update plot\n","plot2.plot.data[3].y = [classification_result] \n","\n","print(\"Result:\", classification_result)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.3:</b> Welchen Klassifizierungswert hat das kleinste Lama? (führen Sie die Zelle oben aus und ändern Sie <code>new_neck_height</code>)  \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.4:</b> Welchen Klassifizierungswert hat ein Tier mit einer Halshöhe von 0,1m? \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.5:</b> Welchen Klassifizierungswert hat ein Tier mit einer Halshöhe von 0,9 m?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.6:</b> Warum ist der Klassifikationswert kontinuierlich, obwohl die Trainingsdaten nur zwei diskrete Werte hatten? \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.7:</b> Wie würden Sie diesen kontinuierlichen Klassifikationswert interpretieren? Versuchen Sie, ihn in wenigen Worten zu beschreiben, es gibt mehrere richtige Antworten.\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.8:</b> Ihr Neuron gibt einen kontinuierlichen Wert aus, aber wir brauchen eine diskrete Ausgabe, die eindeutig entweder \"Lama\" oder \"Schaf\" vorhersagt. Um das zu erreichen, fügen Sie der Ausgabe des Neurons eine einfache Entscheidung hinzu. Die Entscheidung sollte ungefähr genauso empfindlich gegenüber Lamas wie gegenüber Schafen sein. Welche Neuronenausgabe (y-Wert) würden Sie als Schwellenwert wählen und warum? (mehrere  richtige Antworten)\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.9:</b> Sie möchten mehr Daten zu Ihrem Modell hinzufügen, um dessen Performanz zu verbessern. Während Sie mehr Daten sammeln, finden Sie ein kleines Lama mit einer Halshöhe von 0,40 m in Ihrem Datensatz. Nachdem Sie Ihr Modell auf den neuen Daten trainiert haben, entscheidet Ihr diskreter Klassifikator, dass dieses kleine Lama ein Schaf ist. (Zur Erinnerung: die Entscheidung am Ende erhält nur den y-Wert). Warum ist es in diesem Fall problematisch, ein <b>lineares</b> Regressionsmodell für die diskrete Klassifikation zu verwenden? Welche Eigenschaft der Näherungsfunktion sollte anders sein?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.10:</b> Sie entscheiden, dass das manuelle Hinzufügen einer diskreten Entscheidung am Ende Ihres Netzes eine unpraktische Idee ist. Es wäre besser, das lineare Neuron zu verbessern, indem man eine Heaviside-Step-Funktion als Aktivierungsfunktion hinzufügt, so wie man eine ReLu-Funktion hinzufügt. Dann könnte das Training automatisiert werden und die richtige Schwelle automatisch gefunden werden. Was ist das Problem bei diesem Ansatz, wenn wir weiterhin den Backpropagation-Algorithmus verwenden wollen?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["***\n","### Logistische Regression\n","\n","Beim maschinellen Lernen ist die logistische Verteilung eine gängige Annahme für eine unbekannte Zwei-Klassen-Wahrscheinlichkeitsverteilung.[2]\n","Ihre kumulierte Funktion ist die logistische Funktion, von der die Sigmoidfunktion der am häufigsten verwendete Spezialfall ist (siehe Abb. 3).\n","Die Sigmoidfunktion ermöglicht es einem Modell, die meisten natürlich vorkommenden Wahrscheinlichkeitsverteilungen zu erfassen.[3] (Weiterführende Literatur: siehe Abschnitt \"Weiterführende Literatur\" am Ende des Dokuments)\n","\n","In der Einleitung zu Aufgabe 2.1 haben wir den Halslängen entsprechende Bezeichnungen gegeben. \"0\" für Schaf und \"1\" für Lama.\n","Hier können wir die Ausgabe des Neurons als die \"Lama-Wahrscheinlichkeit\" interpretieren. Zum Beispiel: Ein Ausgang von 1 bedeutet \"100%\" Lama-Wahrscheinlichkeit und ein Ausgang von 0,2 bedeutet \"20%\" Lama-Wahrscheinlichkeit und so weiter.\n","\n","<img src=\"images/sigmoid.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 3 - Sigmoid-Funktion\n","</p>\n"],"metadata":{}},{"cell_type":"markdown","source":["Führen Sie die folgende Zelle aus, um eine Sigmoidfunktion zu definieren."],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["# do not change\n","def sigmoid(x:float)->float:\n","    return 1 / (1 + np.exp(-x))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.11:</b> Vervollständigen Sie den Code und trainieren sie das Neuron. Modifizieren Sie die Klasse <code>SigmoidNeuron</code>, um eine Sigmoid-Funktion auf die endgültige Ausgabe anzuwenden.\n","\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["class SigmoidNeuron(SimpleNeuron): #inheriting from SimpleNeuron, \n","                                   #all functions stay the same unless they are specified here\n","\n","    def compute(self, x:float)->float:\n","        # STUDENT CODE HERE\n","\n","        # STUDENT CODE until HERE\n","        return self.activation"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["# do not change\n","classification_plot_sig = Interactive2DPlot(points_llamas, points_sheep, ranges, loss_string=\"Mean Squared Loss\")\n","\n","our_sig_neuron = SigmoidNeuron(classification_plot_sig)\n","\n","interact(\n","    our_sig_neuron.set_values,\n","    weight=FloatSlider(min=-50, max=200, step=0.1, layout = slider_layout),\n","    bias=FloatSlider(min=-50, max=50, step=0.1, layout = slider_layout),\n",")\n","\n","classification_plot_sig.plot"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.12:</b> Nennen Sie ein Beispiel für eine optimale Kombination aus Gewicht und Bias\n","</div>\n","\n","<div class=\"alert lock alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.13:</b> Welchen Vorteil hat ein Klassifikator, der auch eine Wahrscheinlichkeit ausgibt, im Vergleich zu einem Klassifikator, der nur einen binären Ja/Nein-Wert ausgibt? (ein paar Worte) \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.14:</b> Nennen Sie ein Beispiel, wie wir die zusätzlichen Wahrscheinlichkeitsinformationen nutzen können, um die Genauigkeit unseres Trennungsprozesses zu erhöhen \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["### Kreuzentropie/Logarithmischer Verlust (engl.  Cross Entropy/Logarithmic Loss):\n","Die gängigste Verlustfunktion für die Klassifizierung ist der Kreuzentropieverlust, auch logarithmischer Verlust genannt (im Kontext des maschinellen Lernens bezeichnen beide Begriffe das gängigste Gleiche). Im Spezialfall von zwei Kategorien wird der Verlust als binäre Kreuzentropie bezeichnet. Der binäre Kreuzentropieverlust zwischen einem tatsächlichen Datenwert $y$ und einem vorhergesagten Wert $p$ wird wie folgt berechnet:\n","\n","\\begin{align}\n","-[y \\cdot log(p)+(1-y)\\cdot log(1-p)]\n","\\end{align}\n","\n","Auf diese Weise wird der Durchschnitt aller Datenpunkte unter Berücksichtigung dieses Verlustes berechnet.\n","Es stellt sich heraus, dass die Ableitung eines logarithmischen Verlustes unter Verwendung einer \"One-Hot Kodierung\" (unten erklärt) einfach der Lösungsvektor subtrahiert von der Netzwerkausgabe ist, was die Arbeit damit sehr einfach macht.\n","**Hinweis:** Der Kreuzentropieverlust kann nur verwendet werden, wenn die Ausgabewerte zwischen 0 und 1 liegen.\n","\n","<img src=\"images/cross_entropy.png\" />\n","<p style=\"text-align: center;\">\n","        Abb. 4 - Logarithmische / Kreuzentropie-Verlustfunktion\n","\n","</p>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.15:</b> Berechnen Sie den quadratischen und den Kreuz-Entropieverlust. Kopieren Sie die Tabelle und füllen Sie das ??? als Antwort unten aus (Markdown ist gut geeignet, um die Tabelle darzustellen). Verwenden Sie die Zellen unten für die Berechnungen.\n","\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["\n","| Eingabe | Lama-Wahrscheinlichkeit | Quadratischer Verlust | Kreuzentropieverlust |\n","|---------------|--------------------|----------------------|----------------------|\n","| Lama(1) | 0.99 |??????                |????                  |\n","| Schafe(0) | 0.6 |????                  |????                  |\n","| sheep(0) | 0.95 |??????                |????                  |\n","| sheep(0) | 0.999999 |????????              |?????                 |\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["# do not change\n","def cross_entropy_loss(predictions:list, solutions:list) -> float:\n","    predictions += 1e-15 #in order to prevent log(0)\n","    total_loss = np.sum(-(solutions*np.log(predictions)+(1-solutions)*np.log(1-predictions)))\n","    avg_loss = total_loss/len(predictions)\n","    return avg_loss"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["predicted = np.array([0.1]) #insert here\n","actual = np.array([0.1]) #insert here\n","\n","\n","print(\"mean squared loss: {:0.4f}\".format(mean_squared_loss(predicted,actual)))\n","print(\"cross entropy loss: {:0.4f}\".format(cross_entropy_loss(predicted,actual)))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.16:</b> Wie unterscheiden sich die Ziele von Regression und Klassifikation generell? \n","</div>\n","\n","<div class=\"alert block alert-success\">\n","<b>Ihre Antwort:</b>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.17:</b> Was meinen Sie: Warum ist der Cross-Entropie-Verlust besser für Trainingsalgorithmen zur Klassifizierung geeignet?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["### One-Hot-Kodierung\n","Um eine Klassifizierung durchzuführen, müssen Kategorien in einer Weise dargestellt werden, die der Klassifikator verarbeiten kann. Neuronale Netze können Kategorien nicht direkt verstehen und benötigen eine numerische Darstellung.\n","\n","#### Nachteile der Integer-Kodierung\n","\n","Im Lama-Klassifikator wurde Lamas der Wert $1$ und Schafen der Wert $0$ zugewiesen. Ein einzelnes Ausgangsneuron würde \"feuern\", wenn ein Lama gefunden wurde, und nicht feuern, wenn ein Schaf gefunden wurde. Diese Art der Darstellung von Kategorien wird **ganzzahlige** (engl. integer) oder **Label-Kodierung** genannt.\n","\n","Für die binäre Klassifikation funktioniert das recht gut, aber was ist, wenn wir zwischen Schafen, Lamas und Schäferhunden unterscheiden wollen?\n","Dies mit nur einem Ausgangsneuron zu tun, würde zu Komplikationen führen: \n","- Hunde bräuchten ein Label, das numerisch höher oder niedriger ist (z.B. $2$), was eine Ordnung impliziert (Hunde > Lamas), wo es eigentlich keine gibt.\n","- man müsste aus einem Wert des Ausgangsneurons drei verschiedene Zustände interpretieren\n","\n","Ein weiterer Nachteil ist in der nächsten Frage zu sehen:"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.18:</b> Angenommen, die Kodierungen sind: 0 für Schafe, 1 für Lamas und 2 für Hunde. Sie haben heute 5 Schafe und 5 Hunde klassifiziert. Sie möchten, dass Ihr Klassifikator die durchschnittliche Klassifikation für heute ausgibt. Was wird der Klassifikator ausgeben?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["#### Zusammensetzung der One-Hot-Kodierung\n","\n","Die Lösung für die Mängel der Integer-Kodierung sieht wie folgt aus:\n","\n","| Eingabe | One-Hot-Encoding | \n","|---------------|--------------------|\n","| Schaf | [1,0,0] |\n","| Lama | [0,1,0] |\n","| Hund | [0,0,1] |\n","\n","\n","\n","Die Länge des Repräsentationsvektors ist immer gleich der Anzahl der Kategorien. Für jede Kategorie ist nur ein Element des Vektors 1 (\"one-hot\").\n","Mit dieser Kodierung können wir bequem 3 Ausgangsneuronen für 3 verschiedene Kategorien verwenden, so dass die Aktivierung jedes Ausgangsneurons den Klassifikationswert für diese Kategorie repräsentiert.\n","\n","#### Grenzen der One-Hot-Kodierung\n","Die One-Hot-Kodierung ist keine unverbesserliche Lösung zur Darstellung von Kategorien, sondern eher ein weiteres Werkzeug in unserer Toolbox, das zufällig für viele Probleme gut funktioniert, aber nicht für alle."],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.19:</b> Angenommen, Sie möchten ein neuronales Netzwerk zur Spracherkennung trainieren, das alle im Oxford English Dictionary enthaltenen englischen Wörter klassifizieren kann. Es muss nicht ganze Sätze klassifizieren, sondern nur einzelne Wörter. Was wäre ein Problem bei der Verwendung von One-Hot-Kodierung?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["### Softmax-Aktivierungsfunktion\n","\n","Die Sigmoid-Funktion funktioniert gut für ein \"Ja oder Nein\"-Problem, d. h. für binäre Entscheidungen. Meistens wollen wir aber zwischen mehr als zwei Kategorien unterscheiden. Dafür brauchen wir eine Funktion, die **mehrere** Neuronenaktivierungen aus der letzten Schicht eines Netzes aufnimmt und einen **Wahrscheinlichkeitsvektor** ausgibt, der die Wahrscheinlichkeiten für jede Kategorie enthält. \n","\n","Der Trick: **Jeder Eingang** dieser Funktion wird durch die anderen Eingänge **normalisiert**, so dass die Summe des Ausgangsvektors immer 1 ist. Diese Aktivierungsfunktion unterscheidet sich von ReLU oder Sigmoid, da sie immer für die gesamte Schicht gilt. In der Praxis ist sie nur als Aktivierungsfunktion für die Ausgabeschicht sinnvoll.  Abbildung 3 zeigt ein Beispielnetz.\n","\n","Wir können eine Softmax-Aktivierungsfunktion realisieren, indem wir jedes Element $x_i$ des Eingangsvektors nehmen, $exp(x_i)$ berechnen und diesen Wert dann normalisieren, indem wir ihn durch die Summe der $exp$-Ergebnisse aller einzelnen Elemente des Eingangsvektors dividieren. Streng genommen ist das $exp$ für diesen Effekt nicht notwendig, eine lineare Normalisierung, beschränkt auf nicht-negative Werte, könnte auch als Wahrscheinlichkeit interpretiert werden. Allerdings bietet die exponentielle Normalisierung Eigenschaften, die die Performanz verbessern (siehe \"Weiterführende Literatur\").\n","\n","\\begin{align}\n","\\phi_{\\text{Softmax}}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n","\\end{align}\n","\n","\n","<img src=\"images/softmax_example_network.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 3 - Softmax-Aktivierungsfunktion\n","</p>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.20:</b> In der \"logistischen Regression\" haben wir auch eine Wahrscheinlichkeit erhalten, indem wir eine Sigmoidfunktion auf die Ausgabe der letzten Schichten angewendet haben. Warum können wir nicht eine Sigmoid-Funktion auf jedes Ausgangsneuron dieses Netzes anstelle eines Softmax anwenden und einen Wahrscheinlichkeitsvektor erhalten?\n","</div>\n","\n","<div class=\"alert block alert-success\">\n","<b>Ihre Antwort:</b>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["***\n","## Automatisiertes Klassifizierungstraining\n","\n","### Einleitung\n","\n","Wir haben uns bereits im letzten Kapitel mit dem automatisierten Training mittels Backpropagation beschäftigt. Wir hatten einen Satz von Punkten, an die wir eine Funktion so gut wie möglich anpassen mussten. Beim Klassifikationstraining ist die Aufgabe ähnlich. Doch statt y-Koordinaten für Punkte haben wir nun diskrete Kategorien.\n","\n","Sie haben bereits einen Satz von Halslängen und die dazugehörigen Kategorien (siehe Tabelle 1). Im Bereich des maschinellen Lernens wird dieser Datensatz __Trainingsdaten__ genannt. Er spezifiziert das Verhalten, das das neuronale Netz haben soll. Wir werden Backpropagation verwenden, um die Gewichte und Verzerrungen des Netzes immer wieder anzupassen, bis das Netz für einen gegebenen Satz von Eingaben die gleichen Werte ausgibt wie in den Trainingsdaten. Während der Backpropagation \"lernt\" das Netz im übertragenen Sinne die Trainingsdaten. "],"metadata":{}},{"cell_type":"markdown","source":["***\n","### Realisieren eines XOR-Gatter mit einem neuronalen Netz\n","\n","Sie arbeiten als Ingenieur bei einer großen Firma, die elektronische Komponenten herstellt. Ihre Firma möchte den ersten XOR-Gatter-Chip herstellen, der mit künstlicher Intelligenz arbeitet. Sie erhalten die Trainingsdaten in Form einer Wahrheitstabelle:\n","\n","\n","| Eingang 1 | Eingang 2 | Ausgang |\n","|--------|----------|-----------|\n","| 0 | 0 |0 |\n","| 0 | 1 |1 |\n","| 1 | 0 |1 |\n","| 1 | 1 |0 |\n","\n","\n","<p style=\"text-align: center;\">\n","    Tabelle. 2 - XOR-Wahrheitstabelle\n","</p>\n","\n","\n","In dieser Aufgabe werden wir Arrays und Matrizen verwenden, um den Umgang mit den Daten und den Netzwerkparametern zu erleichtern. Wir werden auch ein neuronales Netzwerk ohne Biases verwenden, um den Algorithmus so einfach wie möglich zu gestalten.\n","Die Trainingsdaten bestehen aus einem 2D-Array mit allen möglichen Eingangszuständen und einem 1D-Array mit allen entsprechenden Ausgängen. "],"metadata":{}},{"cell_type":"markdown","source":["#### Aufgabe : Trainingsdaten erstellen\n","\n","Ein Trainingssatz besteht aus einem Eingabesatz und einem Lösungssatz. Beim überwachten Training wird das Netzwerk so lange angepasst, bis seine Vorhersagen für den Eingabesatz mit den entsprechenden vorgegebenen Lösungen übereinstimmen.\n","Vervollständigen Sie die Trainingsdaten unten mithilfe der Wahrheitstabelle"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.21:</b> Erstellen Sie die Trainingsdaten. Ein Trainingssatz besteht aus einem Eingabesatz und einem Lösungssatz. Beim überwachten Training wird das Netz so lange angepasst, bis seine Vorhersagen für den Eingabesatz mit den entsprechenden vorgegebenen Lösungen übereinstimmen (nicht immer, siehe: Overfitting, aber in diesem Fall). Vervollständigen Sie die untenstehenden Trainingsdaten unter Verwendung der obigen Groundtruth-Tabelle. Bitte initialisieren Sie auch den Lösungs-Array '2 dimensional'.\n","\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["#xor_input_set = np.array(tablegoeshere)\n","#xor_solution_set = np.array(tablegoeshere)\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["#### Initialisieren des Netzwerks\n","Als nächstes muss das Netzwerk definiert und initialisiert werden. Für diese Aufgabe verwenden wir ein Netz mit 3 versteckten Neuronen (siehe Abbildung 4).\n","\n","<img src=\"images/3x2_xor_network.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 4 - Neuronales Netzwerk \n","</p>\n","\n","Wir definieren $w_{01}, w_{02}, w_{03}, w_{10}, w_{11}, w_{12}$ auf einmal, indem wir einfach eine 2x3-Gewichtsmatrix $w_{l1}$ definieren und das gleiche für $w_{l2}$ tun. Die Matrizen werden mit Werten zwischen -1 und 1 initialisiert"],"metadata":{}},{"cell_type":"markdown","source":["Führen Sie die untenstehende Zelle aus, um die neuronale Netzwerkklasse zu definieren, die oben abgebildet ist."],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["# do not change\n","class NeuralNetwork:\n","    def __init__(self):\n","        self.hl_sum = [0, 0, 0]\n","        self.hl_activation = [0, 0, 0]\n","        self.ol_sum = [0]\n","        self.prediction = 0\n","        self.b = 0\n","        self.w_i = np.zeros((2, 3))\n","        self.w_o = np.zeros((3, 1))\n","        \n","    def set_conf(self, w_i:float, w_o:float, b:float):  # w_i and w_o are matrices here\n","        self.w_i = w_i\n","        self.w_o = w_o\n","        self.b = b\n","\n","    def get_conf(self)->dict:\n","        configuration = dict();\n","        configuration['w_i'] = self.w_i\n","        configuration['w_o'] = self.w_o\n","        configuration['b'] = self.b\n","        return configuration\n","\n","    def get_ex(self)->dict:\n","        excitations = dict();\n","        excitations['hl_sum'] = self.hl_sum\n","        excitations['hl_activation'] = self.hl_activation\n","        excitations['ol_sum'] = self.ol_sum\n","        return excitations\n","    \n","    \n","    def show_conf(self):\n","        print(\"weight matrix w_i:\")\n","        print(self.w_i)\n","        print(\"\\nweight matrix w_o:\")\n","        print(self.w_o)\n","        print(\"Bias\")\n","        print(self.b)\n","\n","    def compute(self, input_set:np.array)->float:\n","        self.hl_sum = input_set.dot(self.w_i)\n","        self.hl_activation = relu(self.hl_sum) \n","        self.ol_sum = relu(self.hl_activation).dot(self.w_o) + self.b\n","        self.prediction = sigmoid(self.ol_sum)\n","\n","        return self.prediction"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["# do not change\n","logic_gate_net = NeuralNetwork()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["# do not change\n","def initialize_network(net:NeuralNetwork):\n","    #np.random.seed(3)\n","    weight_matrix_i = np.random.rand(2,3)  # a 2x3 matrix of weights\n","    weight_matrix_o = np.random.rand(3,1)  # a 3x1 matrix of weights\n","    bias = np.random.randn()\n","    net.set_conf(weight_matrix_i,weight_matrix_o,bias)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["# do not change\n","initialize_network(logic_gate_net) #just a test initialization to illustrate the weight matrices\n","logic_gate_net.show_conf()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["#### Definieren des Trainingsprozesses\n","Führen Sie abschließend die folgenden Zellen aus, um einen Backpropagation-Algorithmus zu implementieren. Versuchen Sie, den Code zu verstehen. Siehe Abb. 4 zur Erklärung der Variablennamen."],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["# do not change\n","def sigmoid_prime(x:float)->float: #the derivative of sigmoid\n","    return sigmoid(x)*(1-sigmoid(x))"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":21,"source":["# do not change\n","def train(net:NeuralNetwork, input_set:np.array, solution_set:np.array, learning_rate:float, epochs:int):\n","    for t in range(epochs):\n","        # Forward pass: compute predicted solution_set\n","        predictions = net.compute(input_set)\n","        # Compute and print loss\n","        log_loss = cross_entropy_loss(predictions, solution_set)\n","        \n","        if (t % 5 == 0):  # only output every 5th epoch\n","            print(\"Loss after Epoch {}: {:0.4f}\".format(t, log_loss))\n","\n","        #unravel variables here for readability\n","        ol_sum = net.get_ex()['ol_sum']\n","        hl_activation = net.get_ex()['hl_activation']\n","        hl_sum = net.get_ex()['hl_sum']\n","        w_i = net.get_conf()['w_i']\n","        w_o = net.get_conf()['w_o']\n","        b = net.get_conf()['b']\n","        \n","        # Backpropagation to compute gradients of w_i and w_o with respect to loss\n","        # start from the loss at the end and then work towards the front\n","        grad_ol_sum = sigmoid_prime(ol_sum) * (predictions - xor_solution_set)\n","        grad_w_o = hl_activation.T.dot(grad_ol_sum)  # Gradient of Loss with respect to w_o\n","        grad_hl_activation = grad_ol_sum.dot(w_o.T)  # the second layer's error\n","        grad_hl_sum = hl_sum.copy()  # create a copy to work with\n","        grad_hl_sum[hl_sum < 0] = 0  # the derivate of ReLU\n","        grad_w_i = input_set.T.dot(grad_hl_sum * grad_hl_activation)  #\n","\n","        updated_weight_matrix_i = w_i - learning_rate * grad_w_i\n","        updated_weight_matrix_o = w_o - learning_rate * grad_w_o\n","        updated_bias = b - learning_rate * grad_ol_sum.sum()\n","        net.set_conf(updated_weight_matrix_i, updated_weight_matrix_o,\n","                       updated_bias)  # Apply updated weights to network"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.22:</b> Hyperparameter auswählen und trainieren\n","<ul>\n","<li> Wählen Sie eine optimale Lernrate und Anzahl der Epochen, indem Sie verschiedene Werte ausprobieren und die Zelle unten ausführen.\n","<li> Wenn Ihre Trainingsdaten korrekt waren, sollte das Netz nach dem Training einsatzbereit sein.\n","Ein erfolgreiches Training sollte zu einem Verlust kleiner als 0,02 führen.\n","                                                     \n","<li><b>Tipp:</b> Drücken Sie Umschalt+Eingabe auf der Zelle unten und dann die Pfeiltaste \"nach oben\", um das Training einfach zu wiederholen.\n","\n","</ul>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["#learning_rate = ??\n","#epochs = ??\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE\n","\n","initialize_network(logic_gate_net) #initialize again so you can just run this box and train a new network\n","train(logic_gate_net, xor_input_set, xor_solution_set,learning_rate,epochs)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.23:</b> Warum sind die Verluste bei jeder Ausführung der Zelle anders?\n","</div>\n","\n","<div class=\"alert block alert-success\">\n","<b>Ihre Antwort:</b>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.24:</b> Was ist eine gute Lernrate, die in den meisten Fällen einen Verlust < 0,02 in < 100 Epochen erreicht?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.25:</b> Klassifizierungstest. Führen Sie die Zelle unten aus, verändern Sie die Stellungen der Schieberegler und führen Sie eine Validierungsprüfung auf Ihr Logikgatter aus.\n","\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":23,"source":["# do not change\n","def change(input1:float, input2:float):\n","    input_vector = np.array([input1 * 1, input2 * 1])     # converting bool to float\n","    prediction = logic_gate_net.compute(input_vector)\n","    print(\"\\t input: {} \\t \\t output: {:0.9f}\".format(input_vector, prediction[0]))\n","\n","interact(\n","    change,\n","    input1=FloatSlider(min=0, max=1, step=1, layout=Layout(width=\"22%\")),\n","    input2=FloatSlider(min=0, max=1, step=1, layout=Layout(width=\"22%\")),\n",");"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.26:</b> Kontinuierlicher Eingangstest: Verändern Sie die Schieberegler Stellungen und beobachten Sie die Änderungen, wenn die Eingabe nicht binär, sondern kontinuierlich variiert wird.\n","\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":24,"source":["interact(change, input1=0.0, input2=0.0);"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.27:</b> Was können Sie beim Verändern der Schieberegler beobachten? Wie würden Sie den allgemeinen Zusammenhang zwischen den beiden Eingängen und dem Ausgang beschreiben (in wenigen Worten)\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.28:</b> Ändern Sie die Schieberegler auf die Werte der Trainingsdaten, z.B.(1.00, 1.00). Stimmt die Ausgabe genau mit den Trainingsdaten überein? Warum ist das der Fall?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.29:</b> Das neuronale Netz kann jetzt etwas mehr vorhersagen, als nur die Werte der Eingabemenge, die Sie ihm gegeben haben. Welche \"besondere Fähigkeit\" hat Ihr Netz automatisch erlangt? (<b>Hinweis:</b> Denken Sie an neuronale Netze im Allgemeinen, das XOR-Gatter ist nur ein Beispiel)\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.30:</b> Wie kann diese spezielle Fähigkeit bei der Anwendung neuronaler Netze auf selbstfahrende Fahrzeuge nützlich sein?\n","</div>\n","\n","<div class=\"alert block alert-success\">\n","<b>Ihre Antwort:</b>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 4.4.31:</b> Warum macht es diese Fähigkeit einfacher, ein neuronales Netz für selbstfahrende Fahrzeuge zu verwenden als die traditionelle regelbasierte Programmierung (ein pos. und neg. Aspekt)?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.32:</b> Erstellen Sie ein OR-Gatter. Ändern Sie den obigen Code, um ein OR-Netzwerk zu trainieren und überprüfen Sie Ihre Ergebnisse mit einem Test.\n","\n","</div>\n","\n","| Eingang 1 | Eingang 2 | Ausgang |\n","|--------|----------|-----------|\n","| 0 | 0 |0 |\n","| 0 | 1 |1 |\n","| 1 | 0 |1 |\n","| 1 | 1 |1 |\n","\n","\n","<p style=\"text-align: center;\">\n","    Tabelle. 3 - ODER-Wahrheitstabelle\n","</p>"],"metadata":{}},{"cell_type":"markdown","source":["### Training in Keras\n","\n","Nun soll das o.g. Beispiel in Keras implementiert werden.\n","Hierzu erstmals die benötigten Imports:"],"metadata":{}},{"cell_type":"code","execution_count":25,"source":["# benötigte Importe - nicht ändern\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation\n","from tensorflow.keras import optimizers, losses"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Als nächsten müssen die Daten für das Training vorbereitet werden.\n","Hierbei sollen zwei Listen entstehen, eine für die Datenpunkte (`train_data`) und eine für die dazugehörigen Labels (`train_labels`).\n","Beide Listen sollen die Daten von den Schaafen als auch der Lamas beinhalten. \n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.33:</b> Erstellen Sie eine Liste mit dem Namen `train_data` für die Trainingsdatenpunkte aka Nackenhöhe sowie eine Liste mit dem Namen `train_labels` für die zugehörigen Labels, der Nackenhöhe der Schaffe sowie Lamas.\n","    </div>"],"metadata":{}},{"cell_type":"code","execution_count":26,"source":["print('Schafe: {}'.format(points_sheep))\n","print('Lamas: {}'.format(points_llamas))\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE\n","print('Datenpunkte für Training: {}'.format(train_data))\n","print('Labels für Training: {}'.format(train_labels))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Zuletzt muss noch das Modell vorbereitet werden.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.34:</b> Erstellen Sie ein Model, bestehend aus zwei Dense Layern, wobei das erste drei Neuronen und das zweite ein Neuron besitzt und speichern dieses in einer Variablen mit dem Namen `model`. Als Aktivierungsfunktion soll ReLu und für die Ausgabe die Sigmoid-Funktion eingesetzt werden. Als Verlustfunktion soll der BinaryCrossentropy-Loss zum Einsatz kommen. Zuletzt soll RMSprop mit einer Lernrate von 0.01 als Optimierer verwendet werden.\n","\n","\n","_Hinweis: Verwenden Sie bei der Verlustfunktion <code>from_logits=False</code>_.\n","    </div>"],"metadata":{}},{"cell_type":"code","execution_count":27,"source":["model = Sequential()\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE\n","print(model.summary())"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","    <b>Aufgabe 4.4.35:</b> Rufen Sie nun die <code>compile</code> Methode des Modells auf. Geben Sie hierbei als Metrik <i>accuracy</i> an.\n","    </div>    "],"metadata":{}},{"cell_type":"code","execution_count":28,"source":["# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.4.36:</b> Starten Sie nun das Trainings ihres Models durch Aufruf der Fit-Funktion. Verwenden Sie hierbei eine  Batch Size von 2 und trainieren Sie 200 Epochen lang.\n","    </div>"],"metadata":{}},{"cell_type":"code","execution_count":29,"source":["# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":30,"source":["results = model.predict(train_data)\n","results = [1 if i > 0.5 else 0 for i in results]\n","correct_predicted = sum([1 if results[i] == train_labels[i] else 0 for i in range(len(results))])\n","false_predicted = len(results) - correct_predicted\n","\n","print('Korrekt: {}\\nNicht korrekt: {}'.format(correct_predicted, false_predicted))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Ausblick: Klassifizierungstests in der realen Welt\n","\n","Eine klassische Anwendung von neuronalen Netzen ist die Klassifizierung von Bildern. Ein häufig verwendeter Datensatz ist CIFAR-10, der aus folgenden Elementen besteht:  \n"," 1. Bilder von Flugzeugen, Autos, Vögeln, Katzen, Rehen, Hunden, Fröschen, Pferden, Schiffen und Lastwagen (10 Kategorien)\n"," 2. Labels, die an jedes Bild angehängt sind und das Bild kategorisieren\n"," \n","<img src=\"images/cifar10_plot.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 3 - CIFAR-10-Datensatz[4]\n","</p>\n","\n"," \n","Die Labels (auch Annotationen genannt) dienen als \"Lösung\" für den Trainingssatz. Jedes Element (Flugzeug, Auto...) ist eine eigene Kategorie. \n","Während des Trainings werden die Gewichte und Bias im Netzwerk genau so lange angepasst, bis das Modell die richtigen mathematischen Operationen ausführt, um die gegebenen Trainingsdaten korrekt zu klassifizieren. Nach dem Training kann das Netzwerk erkennen, ob es sich bei dem Bild um eine Katze, ein Flugzeug usw. handelt. Das funktioniert sogar bei Bildern, die das Netz noch nie gesehen hat. Wie neuronale Netze Bildklassifizierung durchführen, erfahren Sie in der nächsten Unterrichtseinheit."],"metadata":{}},{"cell_type":"markdown","source":["#### Quellen:\n","[1] Wikipedia, Statistical classification https://en.wikipedia.org/wiki/Statistical_classification, retrieved 01.05.2019\n","\n","[2]  Brownlee, Jason 2018. Machine Learning Algorithms From Scratch. p. 70\n","\n","[3]  Gibbs, M.N. (Nov 2000). \"Variational Gaussian process classifiers\". IEEE Transactions on Neural Networks. p. 1458–1464.\n","\n","[4] Cifar-10, Cifar-100 Dataset Introduction\n","Corochann - https://corochann.com/cifar-10-cifar-100-dataset-introduction-1258.html, retrieved 02.02.2019\n"],"metadata":{}},{"cell_type":"markdown","source":["#### Weiterführende Literatur:\n","\n","The Sigmoid Function in Logistic Regression: http://karlrosaen.com/ml/notebooks/logistic-regression-why-sigmoid/\n","\n","Why Softmax uses exponential function: https://stackoverflow.com/questions/17187507/why-use-softmax-as-opposed-to-standard-normalization"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
