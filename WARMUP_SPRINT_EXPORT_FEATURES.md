# ğŸš€ Warm-Up Sprint: Export-Features fÃ¼r Quiz-Plattformen

**Sprint-Typ:** Team-Building & Marktrecherche  
**Dauer:** 1 Woche (3h PrÃ¤senz + Online-Sprint)  
**Sprint-Ziel:** Technische und betriebswirtschaftliche Machbarkeitsstudie fÃ¼r Export-Funktionen zu 6 Quiz-Plattformen  
**Teams:** 3 Scrum-Teams (je 1 Plattform-Paar)  
**Format:** Hybrid (PrÃ¤senz-Kickoff + Online-Collaboration via BigBlueButton)

---

## ğŸ“‹ Product Owner Statement

> **"Als Dozent mÃ¶chte ich meine Fragensets aus der MC-Test-App in andere Quiz-Plattformen exportieren kÃ¶nnen, um die Reichweite zu erhÃ¶hen und verschiedene Lehr-Szenarien abzudecken (z.B. Live-Quizzes in der Vorlesung mit Kahoot, Karteikarten mit Anki, Hausaufgaben mit Quizlet)."**

---

## ğŸ¯ Sprint-Ziele

### GeschÃ¤ftsziele (BWL-Perspektive)
- ğŸ“Š **Marktanalyse:** Welche Plattformen dominieren den Bildungsmarkt?
- ğŸ’° **Business Case:** Welche Export-Features bringen den grÃ¶ÃŸten Nutzen?
- ğŸ¯ **Zielgruppen-Fit:** Welche Plattformen nutzen unsere Zielgruppen (MINT-Studierende, BWL, Dozenten)?
- ğŸ”„ **Competitive Advantage:** Wie differenzieren wir uns von der Konkurrenz?

### Technische Ziele
- ğŸ” **Format-Analyse:** Import-/Export-Formate der Plattformen (JSON, CSV, XML, etc.)
- ğŸ§ª **LaTeX-Support:** Welche Plattformen unterstÃ¼tzen mathematische Formeln?
- ğŸ› ï¸ **Implementierungs-KomplexitÃ¤t:** Aufwand-SchÃ¤tzung (Story Points)
- ğŸ“ **Spezifikation:** Klare Vorgaben fÃ¼r die Entwicklung

---

## ğŸ‘¥ Team-Aufteilung

### Team 1: "Flashcard Experts"
**Plattformen:** Anki + Quizlet  
**Use Case:** Karteikarten fÃ¼r Selbststudium

**Warum diese Kombination?**
- Beide fokussiert auf Spaced Repetition Learning
- Anki: Open-Source, Power-User, Desktop-first
- Quizlet: Kommerziell, Mainstream, Mobile-first

### Team 2: "Live Quiz Champions"
**Plattformen:** Kahoot + Socrative  
**Use Case:** Interaktive Live-Quizzes in der Vorlesung

**Warum diese Kombination?**
- Beide fokussiert auf Echtzeit-Audience-Response
- Kahoot: Gamification, kompetitiv, groÃŸer Markt
- Socrative: Education-fokussiert, formative Assessments

### Team 3: "Academic Tools Specialists"
**Plattformen:** Particify (ehem. ARSnova) + arsnova.click  
**Use Case:** Akademische Audience-Response-Systeme

**Warum diese Kombination?**
- Beide aus akademischem Kontext (Hochschulen)
- Particify: Enterprise-LÃ¶sung, DSGVO-konform
- arsnova.click: Schnell, datenschutzfreundlich, Open-Source

---

## ğŸ“ Aufgabenstellung pro Team

### Phase 1: Marktrecherche & Business-Analyse (Tag 2-3)

#### 1.1 Marktanalyse
**Deliverable:** Markdown-Dokument `MARKTANALYSE_[Plattform1]_[Plattform2].md`

**Zu recherchieren:**
- ğŸ“Š **Marktposition:**
  - Anzahl aktive Nutzer (weltweit, DACH-Region)
  - Marktanteil im Bildungssektor (SchÃ¤tzung)
  - Hauptzielgruppe (Schule, Hochschule, Unternehmensschulung)
  - Pricing-Modell (Freemium, Abo, Enterprise)

- ğŸ¯ **Zielgruppen-Fit:**
  - Welche unserer Personas nutzen diese Plattform? (MINT-Student, BWL-Student, Dozent)
  - Typische Nutzungsszenarien
  - Pain Points der Nutzer

- ğŸ’° **Business Case:**
  - Wie viele unserer Nutzer wÃ¼rden Export nutzen? (SchÃ¤tzung)
  - Welcher Mehrwert entsteht? (Zeit-Ersparnis, neue Use Cases)
  - PrioritÃ¤t: MUST-HAVE / SHOULD-HAVE / NICE-TO-HAVE

**Format:** 
```markdown
# Marktanalyse: [Plattform 1] & [Plattform 2]

## Executive Summary
- Empfehlung: Implementieren / ZurÃ¼ckstellen / Ablehnen
- BegrÃ¼ndung (3-5 SÃ¤tze)
- PrioritÃ¤t: HIGH / MEDIUM / LOW

## [Plattform 1]
### Marktposition
- Nutzer: [Zahl]
- Marktanteil: [%]
- Zielgruppe: [...]
- Pricing: [...]

### Zielgruppen-Fit
- [Persona 1]: [Beschreibung]
- Use Case: [...]

### Business Case
- Potenzielle Nutzer: [SchÃ¤tzung]
- Mehrwert: [...]
- ROI-SchÃ¤tzung: [qualitativ]

## [Plattform 2]
[Analog zu Plattform 1]

## Vergleich & Empfehlung
[2-3 AbsÃ¤tze]
```

#### 1.2 Competitive Analysis
**Deliverable:** Tabelle in MARKTANALYSE.md

**Fragen:**
- Welche MC-Test-Tools bieten Export zu diesen Plattformen an?
- Wie ist die User Experience? (Screenshots, wenn mÃ¶glich)
- Was kÃ¶nnen wir besser machen?

**Format:**
| Feature | Konkurrent A | Konkurrent B | MC-Test-App (geplant) |
|---------|--------------|--------------|------------------------|
| Export zu Plattform X | âœ… | âŒ | ğŸ¯ |
| LaTeX-Support | âŒ | âœ… | âœ… |
| Batch-Export | âœ… | âŒ | ğŸ¯ |
| ... | ... | ... | ... |

---

### Phase 2: Technische Analyse (Tag 4-5)

#### 2.1 Import-Format-Analyse
**Deliverable:** Markdown-Dokument `TECH_SPEC_[Plattform1]_[Plattform2].md`

**Zu untersuchen:**

**FÃ¼r jede Plattform:**

1. **Import-Formate:**
   - Welche Dateiformate werden unterstÃ¼tzt? (CSV, JSON, XML, GIFT, etc.)
   - Gibt es offizielle Import-Tools oder APIs?
   - Beispiel-Dateien herunterladen und analysieren

2. **Datenstruktur:**
   - Wie werden Fragen strukturiert?
   - Wie werden Antwortoptionen gespeichert?
   - Pflichtfelder vs. optionale Felder
   - Maximale Anzahl Antwortoptionen
   - Zeichenlimits

3. **LaTeX-Support:**
   - Werden mathematische Formeln unterstÃ¼tzt?
   - Syntax: `$...$`, `$$...$$`, MathJax, KaTeX, oder proprietÃ¤r?
   - Inline vs. Display-Formeln
   - Beispiel testen: `$E = mc^2$`, `$$\\int_{0}^{\\infty} e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2}$$`

4. **Metadaten-Support:**
   - Schwierigkeitsgrade / Gewichtung
   - Themen / Tags / Kategorien
   - ErklÃ¤rungen / Feedback
   - Bilder / Medien
   - Mini-Glossar (wenn relevant)

5. **Limitierungen:**
   - Was kann NICHT exportiert werden?
   - Workarounds oder Fallback-Optionen
   - Breaking Changes bei Updates?

**Format:**
```markdown
# Technische Spezifikation: [Plattform 1] & [Plattform 2]

## [Plattform 1]

### Import-Formate
- **UnterstÃ¼tzte Formate:** CSV, JSON, XML
- **Empfohlenes Format:** JSON (beste Feature-Coverage)
- **Offizielle Dokumentation:** [URL]

### Datenstruktur
```json
{
  "question": "Was ist die Hauptstadt von Deutschland?",
  "options": ["Berlin", "MÃ¼nchen", "Hamburg", "KÃ¶ln"],
  "correct": 0,
  "explanation": "Berlin ist seit 1990 die Hauptstadt.",
  "difficulty": 1,
  "tags": ["Geographie", "Deutschland"]
}
```

### LaTeX-Support
- âœ… **UnterstÃ¼tzt:** MathJax-Syntax `$...$` und `$$...$$`
- âš ï¸ **EinschrÃ¤nkung:** Nur Subset von LaTeX-Commands (keine TikZ, etc.)
- ğŸ§ª **Getestet:** $E = mc^2$ â†’ funktioniert âœ…

### Metadaten-Support
| Feature | Support | Mapping |
|---------|---------|---------|
| Gewichtung | âŒ | N/A |
| Themen | âœ… | `tags` |
| ErklÃ¤rungen | âœ… | `explanation` |
| Mini-Glossar | âŒ | Fallback: In ErklÃ¤rung integrieren |

### Limitierungen
- Max. 6 Antwortoptionen (MC-Test-App hat 4-5 â†’ OK)
- Keine extended_explanation â†’ ZusammenfÃ¼hren mit normaler ErklÃ¤rung
- Keine Bilder im JSON-Import â†’ SpÃ¤ter als Enhancement

## [Plattform 2]
[Analog zu Plattform 1]

## Implementierungs-Empfehlung
[...]
```

#### 2.2 Test-Export erstellen
**Deliverable:** Beispiel-Dateien im Format jeder Plattform

**Aufgabe:**
1. WÃ¤hlt 5 Fragen aus `questions_PDF_Test.json` (einfache Beispiele)
2. Konvertiert manuell in das Ziel-Format (CSV, JSON, etc.)
3. Importiert in die Plattform (sofern mÃ¶glich)
4. Dokumentiert Ergebnis mit Screenshots

**Ziel:** Proof-of-Concept, dass Mapping funktioniert

**Format:**
```
/export-examples/
  â”œâ”€â”€ anki_example.txt (Anki-Format)
  â”œâ”€â”€ quizlet_example.csv
  â”œâ”€â”€ kahoot_example.xlsx
  â”œâ”€â”€ socrative_example.csv
  â”œâ”€â”€ particify_example.json
  â””â”€â”€ arsnova_example.json
```

---

### Phase 3: Spezifikation & Priorisierung (Tag 5-6)

#### 3.1 Feature-Spezifikation
**Deliverable:** `FEATURE_SPEC_EXPORT.md`

**Inhalt:**

1. **User Stories** (pro Plattform):
```markdown
### User Story: Export zu [Plattform]

**Als** Dozent  
**mÃ¶chte ich** meine Fragensets zu [Plattform] exportieren  
**um** [Use Case zu erfÃ¼llen]

**Akzeptanzkriterien:**
- [ ] Export-Button im UI vorhanden
- [ ] Alle Fragen werden korrekt konvertiert
- [ ] LaTeX-Formeln werden Ã¼bernommen (falls unterstÃ¼tzt)
- [ ] Datei wird automatisch heruntergeladen
- [ ] Error-Handling bei ungÃ¼ltigen Fragen
- [ ] Success-Benachrichtigung nach Export

**Technische Anforderungen:**
- Input: `questions_*.json` (MC-Test-App-Format)
- Output: `[Plattform]_export.[format]`
- Mapping: [Link zu TECH_SPEC]
- Edge Cases: [...]

**Aufwand-SchÃ¤tzung:** [Story Points: 1, 2, 3, 5, 8, 13]

**PrioritÃ¤t:** MUST / SHOULD / COULD / WON'T
```

2. **Mapping-Tabelle** (MC-Test-App â†’ Plattform):

| MC-Test-App Feld | Plattform-Feld | Transformation | Fallback |
|------------------|----------------|----------------|----------|
| `frage` | `question` | Strip Numbering | - |
| `optionen` | `options` | Direct Mapping | - |
| `loesung` | `correct` | Index â†’ Index | - |
| `erklaerung` | `explanation` | Direct Mapping | - |
| `gewichtung` | `difficulty` | 1â†’Easy, 2â†’Medium, 3â†’Hard | Default: Medium |
| `thema` | `tags` | String â†’ Array | Default: ["General"] |
| `mini_glossary` | - | Append to explanation | - |
| `extended_explanation.content` | `explanation` | Merge with normal | Use normal only |

3. **UI-Mockup** (Text-basiert oder Skizze):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Export-Funktionen                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚ Aktuelles Fragenset:                 â”‚
â”‚ "Mathematik I" (25 Fragen)          â”‚
â”‚                                      â”‚
â”‚ Exportieren zu:                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ“š Anki (Flashcards)        â¬‡ï¸  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ“ Quizlet (Study Sets)     â¬‡ï¸  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ® Kahoot (Live Quiz)       â¬‡ï¸  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚
â”‚ [Weitere Optionen...]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.2 Priorisierung & Roadmap
**Deliverable:** Teil von `FEATURE_SPEC_EXPORT.md`

**Aufgabe:** Empfehlt Reihenfolge der Implementierung

**Kriterien:**
1. **Business Value:** Wie viele Nutzer profitieren?
2. **Technical Effort:** Aufwand in Story Points
3. **Dependencies:** Welche Features bauen aufeinander auf?
4. **Risk:** Technische Unsicherheiten

**Format:**

```markdown
## Priorisierung (MoSCoW-Methode)

### MUST HAVE (Sprint 1)
1. **Anki-Export** (8 SP)
   - BegrÃ¼ndung: GrÃ¶ÃŸte Zielgruppe (Selbststudium), einfaches Format
   - Risk: LOW (Plain-Text, gut dokumentiert)

2. **Quizlet-Export** (5 SP)
   - BegrÃ¼ndung: Mainstream-Plattform, hoher Nutzen
   - Risk: LOW (CSV-Format)

### SHOULD HAVE (Sprint 2)
3. **Kahoot-Export** (13 SP)
   - BegrÃ¼ndung: Live-Quiz-Szenarien, hoher Wow-Faktor
   - Risk: MEDIUM (proprietÃ¤res Format, ggf. API nÃ¶tig)

### COULD HAVE (Sprint 3)
4. **Socrative-Export** (8 SP)
5. **Particify-Export** (8 SP)

### WON'T HAVE (aktuell)
6. **arsnova.click-Export**
   - BegrÃ¼ndung: Nischen-Tool, geringe Nutzerbasis
   - SpÃ¤ter als Community-Feature?

## Roadmap

**Sprint 1 (2 Wochen):** Anki + Quizlet  
**Sprint 2 (2 Wochen):** Kahoot  
**Sprint 3 (2 Wochen):** Socrative + Particify  
**Future:** arsnova.click (Community-driven)
```

---

## ğŸ“Š AbschlussprÃ¤sentation (Tag 7 - PrÃ¤senz)

### Sprint Review (30 Min pro Team)

**Format:** PrÃ¤sentation vor Product Owner (KQC) + anderen Teams

**Agenda:**
1. **Executive Summary** (3 Min)
   - Kernaussage: Welche Plattformen sollten implementiert werden?
   - Top 3 Learnings

2. **Marktanalyse** (5 Min)
   - Marktposition der Plattformen
   - Zielgruppen-Fit
   - Business Case

3. **Technische Analyse** (10 Min)
   - Import-Formate & Datenstrukturen
   - LaTeX-Support (mit Live-Demo wenn mÃ¶glich)
   - Limitierungen

4. **Feature-Spezifikation** (7 Min)
   - User Stories
   - Mapping-Tabelle
   - Aufwand-SchÃ¤tzung

5. **Priorisierung** (3 Min)
   - MoSCoW-Kategorisierung
   - Roadmap-Empfehlung

6. **Q&A** (2 Min)

**Deliverables:**
- ğŸ“Š PrÃ¤sentations-Slides (PDF)
- ğŸ“ Alle Markdown-Dokumente im Repo
- ğŸ“‚ Beispiel-Export-Dateien
- ğŸ¥ Optional: Video-Demo eines Test-Imports

---

## ğŸ¯ Definition of Done

**Team-Level (pro Team):**
- [ ] MARKTANALYSE_[Plattformen].md vollstÃ¤ndig (auf GitHub gepusht)
- [ ] TECH_SPEC_[Plattformen].md vollstÃ¤ndig (mit JSON-Beispielen)
- [ ] FEATURE_SPEC_EXPORT.md mit User Stories & Mapping-Tabellen
- [ ] Beispiel-Export-Dateien fÃ¼r beide Plattformen erstellt (`/export-examples/`)
- [ ] Test-Import in Plattformen durchgefÃ¼hrt (Screenshots dokumentiert)
- [ ] PrÃ¤sentation vorbereitet (Slides PDF + Live-Demo)
- [ ] Sprint Review: 30-Min-PrÃ¤sentation gehalten
- [ ] Product Owner Acceptance erhalten

**Sprint-Level (alle Teams gemeinsam):**
- [ ] Alle 3 Teams haben ihre Deliverables abgeschlossen
- [ ] Sprint Review durchgefÃ¼hrt (90 Min, alle prÃ¤sentiert)
- [ ] MoSCoW-Voting durchgefÃ¼hrt (Foto dokumentiert)
- [ ] **EXPORT_ROADMAP.md** erstellt (finale Priorisierung)
- [ ] Sprint Retrospective durchgefÃ¼hrt (Start-Stop-Continue)
- [ ] **RETROSPECTIVE.md** erstellt (Action Items assigned)
- [ ] Teamfoto gemacht ğŸ“¸
- [ ] Celebration! ğŸ‰

---

## ğŸ› ï¸ Tools & Ressourcen

### Marktrecherche
- **Google Trends:** Vergleich der Suchvolumina
- **SimilarWeb:** Traffic-Analyse der Plattformen
- **G2/Capterra:** User-Reviews lesen
- **LinkedIn:** Job-Postings analysieren (Nachfrage-Indikator)

### Technische Analyse
- **Offizielle Dokumentation:** [Links werden bereitgestellt]
- **GitHub:** Suche nach `[Plattform] import format` fÃ¼r Community-Beispiele
- **ChatGPT/Claude:** Format-Conversion-Beispiele generieren lassen

### Kollaboration
- **GitHub Issues:** Ein Issue pro Team mit Checkliste
- **GitHub Discussions:** Fragen an PO und zwischen Teams
- **BigBlueButton (BBB):** Daily Standups + Arbeitssessions (Screen-Sharing)
- **Markdown-Editor:** VS Code mit Preview
- **Miro/Whiteboard:** Optional fÃ¼r Brainstorming (kann in BBB geteilt werden)

---

## ğŸ“š Hilfreiche Ressourcen

### Plattform-Dokumentation (Startpunkte)

**Anki:**
- Import-Format: https://docs.ankiweb.net/importing/text-files.html
- Suche: "Anki import format CSV"

**Quizlet:**
- Import-Format: https://help.quizlet.com/hc/en-us/articles/360029977151
- Suche: "Quizlet import spreadsheet"

**Kahoot:**
- Import-Format: https://support.kahoot.com/hc/en-us/articles/115002303908
- Suche: "Kahoot Excel import template"

**Socrative:**
- Import-Format: https://help.socrative.com/en/articles/369-how-do-i-import-questions
- Suche: "Socrative question import"

**Particify:**
- Dokumentation: https://particify.de/manual/
- Suche: "Particify ARSnova import"

**arsnova.click:**
- GitHub: https://github.com/thm-projects/arsnova.click-v2
- Suche: "arsnova.click API documentation"

### BWL-Methoden

**Marktanalyse:**
- Porter's Five Forces (Wettbewerbsanalyse)
- SWOT-Analyse (Strengths, Weaknesses, Opportunities, Threats)

**Priorisierung:**
- MoSCoW-Methode (Must, Should, Could, Won't)
- Value vs. Effort Matrix (2x2-Matrix)

**Business Case:**
- ROI-Kalkulation (qualitativ)
- Break-Even-Analyse

---

## â“ FAQs

**Q: Was, wenn eine Plattform keine Ã¶ffentliche API hat?**  
A: Dokumentiert das als "Limitierung". Empfehlt, mit proprietÃ¤ren Formaten zu arbeiten (z.B. CSV/Excel-Templates). Priorisierung dann niedriger.

**Q: Was, wenn wir keinen Account fÃ¼r eine Plattform haben?**  
A: Nutzt Free Trials oder erstellt kostenlose Accounts. Falls nicht mÃ¶glich: Recherche basierend auf Dokumentation + YouTube-Tutorials.

**Q: MÃ¼ssen wir alle Felder der MC-Test-App mappen?**  
A: Nein. Fokus auf Pflichtfelder (Frage, Optionen, LÃ¶sung). Nice-to-have: ErklÃ¤rungen, Themen, Gewichtung. Mini-Glossar und extended_explanation sind optional.

**Q: Was, wenn LaTeX nicht unterstÃ¼tzt wird?**  
A: Dokumentiert das klar. Schlagt Fallback vor (z.B. Formeln als Bilder exportieren, oder Text-Platzhalter wie "[Formel: E=mcÂ²]").

**Q: Wie detailliert muss die technische Spezifikation sein?**  
A: Detailliert genug, dass ein Entwickler (ich) die Implementierung ohne RÃ¼ckfragen starten kann. Beispiel-Mappings sind Pflicht!

---

## ğŸ–ï¸ Bonus-Challenges (Optional)

FÃ¼r Teams, die frÃ¼her fertig sind oder Extra-Punkte sammeln wollen:

1. **Competitive Teardown:**
   - Findet 3 konkurrierende MC-Test-Tools
   - Analysiert deren Export-Features
   - Erstellt Comparison-Matrix

2. **User Interview:**
   - Interviewt 2-3 Studierende oder Dozenten
   - Fragen: Welche Quiz-Plattformen nutzt ihr? WÃ¼rdet ihr Export nutzen?
   - Dokumentiert Insights

3. **Proof-of-Concept Code:**
   - Schreibt ein Python-Skript, das 1 Frage aus MC-Test-App-Format in Ziel-Format konvertiert
   - Zeigt das in der PrÃ¤sentation

4. **Video-Tutorial:**
   - Erstellt ein 2-Min-Video: "So importiert man Fragen in [Plattform]"
   - NÃ¼tzlich fÃ¼r Dokumentation spÃ¤ter

---

## ğŸ“… Zeitplan (1-Wochen-Sprint)

### **Tag 1: PrÃ¤senz-Kickoff (3 Stunden)**

**Ort:** Kursraum  
**Ziel:** Organisation, Team-Bildung, GitHub-Setup

| Zeit | AktivitÃ¤t | Details |
|------|-----------|--------|
| **0:00-0:30** | Sprint-Kickoff | Product Owner Statement, Ziele, Deliverables, Team-Aufteilung |
| **0:30-1:00** | GitHub-Setup | Issues erstellen, Kanban-Board einrichten, Checklisten |
| **1:00-2:00** | User Stories schreiben | Je Team: 2-3 User Stories fÃ¼r ihre Plattformen (mit Akzeptanzkriterien) |
| **2:00-2:30** | Tool-Accounts & Ressourcen | Accounts erstellen (Anki, Quizlet, etc.), Dokumentation sammeln |
| **2:30-3:00** | Sprint Planning | Aufgaben verteilen, BBB-Termine vereinbaren, Daily Standup planen |

**Output:** GitHub Issues mit User Stories, Kanban-Board, Sprint Backlog

---

### **Tag 2-6: Online-Sprint (BigBlueButton)**

**Format:** Asynchrone Arbeit + synchrone BBB-Sessions  
**Workload:** 2 Stunden pro Tag (1h BBB + 1h asynchron)

| Tag | BBB-Session (1h) | Asynchrone Arbeit (1h) |
|-----|------------------|------------------------|
| **Tag 2** | Daily Standup (15 Min) + Marktrecherche-Kick (45 Min) | Marktanalyse Plattform 1 (Nutzer, Pricing, Zielgruppe) |
| **Tag 3** | Daily Standup (15 Min) + Q&A (45 Min) | Marktanalyse Plattform 2 + Competitive Analysis |
| **Tag 4** | Daily Standup (15 Min) + Tech-Review (45 Min) | Technische Analyse: Import-Formate, Datenstruktur |
| **Tag 5** | Daily Standup (15 Min) + Mapping-Workshop (45 Min) | LaTeX-Tests, Metadaten-Mapping, Beispiel-Exports |
| **Tag 6** | Daily Standup (15 Min) + Priorisierung (45 Min) | User Stories finalisieren, MoSCoW, Slides vorbereiten |

**BBB-Sessions:**
- **Daily Standup (15 Min):** 3 Fragen: Was habe ich gestern gemacht? Was mache ich heute? Blocker?
- **Arbeitssession (45 Min):** Gemeinsam an Deliverables arbeiten, Screen-Sharing, Pair-Dokumentation

**Asynchrone Arbeit (1h):**
- EigenstÃ¤ndige Recherche (Plattform-Docs, User-Reviews, Format-Beispiele)
- Dokumentation in Markdown schreiben (GitHub)
- Screenshots, Test-Imports, Beispiel-Dateien erstellen

---

### **Tag 7: PrÃ¤senz-Abschluss (3 Stunden) - Scrum-Zeremonien**

**Ort:** Kursraum  
**Ziel:** Sprint Review, Sprint Retrospective, Increment-Abnahme, Lessons Learned

---

#### **Teil 1: Sprint Review (90 Min) - "Was haben wir gebaut?"**

**Scrum-Zeremonie:** PrÃ¤sentation des Increments an Stakeholder (Product Owner + andere Teams)

| Zeit | AktivitÃ¤t | Format | Erwartete Artefakte |
|------|-----------|--------|---------------------|
| **0:00-0:05** | Sprint Review Opening | PO begrÃ¼ÃŸt, erinnert an Sprint-Ziel | - |
| **0:05-0:35** | **Team 1 PrÃ¤sentation** | 30 Min Live-Demo + Q&A | âœ… MARKTANALYSE.md<br>âœ… TECH_SPEC.md<br>âœ… FEATURE_SPEC.md<br>âœ… Beispiel-Export-Dateien<br>âœ… Slides (PDF) |
| **0:35-1:05** | **Team 2 PrÃ¤sentation** | 30 Min Live-Demo + Q&A | (siehe oben) |
| **1:05-1:35** | **Team 3 PrÃ¤sentation** | 30 Min Live-Demo + Q&A | (siehe oben) |

**PrÃ¤sentationsstruktur pro Team (siehe unten: "AbschlussprÃ¤sentation")**

**Output Sprint Review:**
- âœ… Alle Deliverables vorgestellt und auf GitHub gepusht
- âœ… Feedback vom Product Owner dokumentiert
- âœ… Gemeinsames VerstÃ¤ndnis Ã¼ber technische Machbarkeit

---

#### **Teil 2: Priorisierungs-Voting (30 Min) - Product Backlog Refinement**

**Scrum-AktivitÃ¤t:** Gemeinsame Priorisierung fÃ¼r das Product Backlog

| Zeit | AktivitÃ¤t | Format | Erwartete Artefakte |
|------|-----------|--------|---------------------|
| **1:35-1:50** | **MoSCoW-Voting** | Jedes Team-Mitglied hat 3 Stimmen (Klebepunkte/Whiteboard) | âœ… Voting-Ergebnis (Foto) |
| **1:50-2:05** | **Roadmap-Entscheidung** | PO priorisiert basierend auf: Business Value + Voting + Aufwand | âœ… **EXPORT_ROADMAP.md** (finale Implementierungs-Reihenfolge) |

**MoSCoW-Voting-Regeln:**
- Jede Person: 3 Stimmen (kann mehrere auf 1 Plattform setzen)
- Product Owner hat **Veto-Recht** basierend auf Business Case
- Ergebnis: Priorisierte Liste aller 6 Plattformen

**Erwartetes Artefakt: `EXPORT_ROADMAP.md`**
```markdown
# Export-Feature Roadmap

## Entscheidung: [Datum]

### Sprint 1 (MUST HAVE)
1. **Anki** (Team 1) - 8 SP
   - BegrÃ¼ndung: Voting #1, einfaches Format, groÃŸe Zielgruppe
   
2. **Quizlet** (Team 1) - 5 SP
   - BegrÃ¼ndung: Mainstream, CSV-Format

### Sprint 2 (SHOULD HAVE)
3. **Kahoot** (Team 2) - 13 SP

### Sprint 3 (COULD HAVE)
4. **Socrative** (Team 2) - 8 SP
5. **Particify** (Team 3) - 8 SP

### Backlog (WON'T HAVE aktuell)
6. **arsnova.click** (Team 3)
   - BegrÃ¼ndung: Nischen-Tool, spÃ¤ter als Community-Feature

## Voting-Ergebnis
[Screenshot oder Tabelle]
```

---

#### **Teil 3: Sprint Retrospective (60 Min) - "Wie kÃ¶nnen wir besser werden?"**

**Scrum-Zeremonie:** Team-Reflexion zur Prozessverbesserung

| Zeit | AktivitÃ¤t | Format | Erwartete Artefakte |
|------|-----------|--------|---------------------|
| **2:05-2:20** | **Set the Stage** | Check-in: 1 Wort, wie fÃ¼hle ich mich? (Runde) | - |
| **2:20-2:35** | **Gather Data** | Timeline: Was ist passiert? (Whiteboard/Miro) | âœ… Timeline (Foto) |
| **2:35-2:50** | **Generate Insights** | Start-Stop-Continue (3 Spalten) | âœ… **RETROSPECTIVE.md** |
| **2:50-3:00** | **Decide What To Do** | Top 3 Action Items fÃ¼r nÃ¤chsten Sprint | âœ… Action Items (assigned) |
| **3:00** | **Celebration!** | Applaus, Teamfoto, High-Fives ğŸ‰ | âœ… Teamfoto |

**Retrospektive-Format: Start-Stop-Continue**

| ğŸŸ¢ START | ğŸ”´ STOP | ğŸ”µ CONTINUE |
|---------|---------|-------------|
| Was sollten wir anfangen? | Was sollten wir aufhÃ¶ren? | Was lief gut? |
| Z.B. "FrÃ¼her Docs lesen" | Z.B. "Meetings ohne Agenda" | Z.B. "Daily Standups" |
| Z.B. "Pair-Dokumentation" | Z.B. "Last-Minute-Arbeit" | Z.B. "Screen-Sharing in BBB" |
| ... | ... | ... |

**Erwartetes Artefakt: `RETROSPECTIVE.md`**

**Beispiel-Format:**

```markdown
# Sprint Retrospective: Export-Features Warm-Up

**Datum:** [Datum]  
**Teilnehmer:** Alle 3 Teams + Product Owner  
**Facilitator:** [Name]

## Check-In (1 Wort pro Person)
- Person 1: "Stolz"
- Person 2: "ErschÃ¶pft"
- ...

## Timeline (Was ist passiert?)
[Foto oder Bullet-Points]

## Start-Stop-Continue

### ğŸŸ¢ START (Anfangen)
1. FrÃ¼her Plattform-Dokumentation lesen (nicht erst Tag 4)
2. Pair-Dokumentation in BBB (nicht solo schreiben)
3. Templates fÃ¼r Markdown frÃ¼her bereitstellen

### ğŸ”´ STOP (AufhÃ¶ren)
1. Meetings ohne Agenda (Zeit verschwenden)
2. Alle Arbeit auf Tag 6 schieben (Stress)
3. Zu viele Chat-Nachrichten (lieber im Daily klÃ¤ren)

### ğŸ”µ CONTINUE (Weitermachen)
1. Daily Standups (super fÃ¼r Alignment!)
2. Screen-Sharing in BBB (technische Probleme schnell lÃ¶sen)
3. Cross-Team-Kommunikation via GitHub Discussions
4. User Stories am Tag 1 schreiben (praktisch!)

## Top 3 Action Items (fÃ¼r nÃ¤chsten Sprint)
1. **[Assigned to: PO]** Markdown-Templates 2 Tage vor Sprint bereitstellen
2. **[Assigned to: Teams]** Plattform-Docs am Tag 1 Ã¼berfliegen (nicht erst Tag 4)
3. **[Assigned to: Facilitator]** BBB-Sessions mit Agenda starten (5-Min-Rule)

## Celebration ğŸ‰
- Was hat uns stolz gemacht? [Antworten]
- Teamfoto: [Link]
```

---

### **Zusammenfassung: Erwartete Artefakte am Tag 7**

#### **Pro Team (3 Teams):**
1. âœ… **MARKTANALYSE_[Plattformen].md** (auf GitHub)
2. âœ… **TECH_SPEC_[Plattformen].md** (auf GitHub)
3. âœ… **FEATURE_SPEC_EXPORT.md** (User Stories, Mapping, Story Points)
4. âœ… **Beispiel-Export-Dateien** (`/export-examples/*.csv|.json|.txt`)
5. âœ… **PrÃ¤sentations-Slides** (PDF, 15-20 Slides)
6. âœ… **Live-Demo** (Import in Plattform, Screenshots)

#### **Gemeinsam (alle Teams):**
7. âœ… **EXPORT_ROADMAP.md** (priorisierte Implementierungs-Reihenfolge)
8. âœ… **RETROSPECTIVE.md** (Start-Stop-Continue, Action Items)
9. âœ… **Voting-Ergebnis** (Foto vom Whiteboard)
10. âœ… **Teamfoto** (Celebration!)

#### **Von Product Owner:**
11. âœ… **Sprint Review Feedback** (dokumentiert in GitHub Issues)
12. âœ… **Finale Roadmap-Entscheidung** (in EXPORT_ROADMAP.md)

---

### **Output Tag 7:**

âœ… **Product Backlog** ist priorisiert (Roadmap fÃ¼r Implementierung steht)  
âœ… **Increment** ist abgenommen (alle Deliverables reviewed)  
âœ… **Process Improvements** sind identifiziert (Retrospektive)  
âœ… **Team Motivation** ist hoch (Celebration, Teamfoto)  
âœ… **NÃ¤chste Schritte** sind klar (Action Items assigned)

---

### **Workload pro Person**

**PrÃ¤senz:** 2Ã— 3h = 6h  
**Online:** 5Ã— 2h = 10h (inkl. BBB-Sessions)  
**Total:** ~16 Stunden pro Person Ã¼ber 1 Woche

Bei 3er-Teams: ~48 Stunden pro Team (fokussiert auf Kernaufgaben)

---

## ğŸ“ Lernziele (fÃ¼r eure Reflexion)

Nach diesem Sprint kÃ¶nnt ihr:

**BWL-Skills:**
- âœ… Marktanalyse durchfÃ¼hren (Wettbewerb, Zielgruppen, Pricing)
- âœ… Business Cases bewerten (ROI, Value vs. Effort)
- âœ… Features priorisieren (MoSCoW, Roadmap)
- âœ… Stakeholder-Perspektiven einnehmen (Dozent, Student, Admin)

**Tech-Skills:**
- âœ… Import-/Export-Formate analysieren (CSV, JSON, XML)
- âœ… APIs und Dokumentationen lesen
- âœ… LaTeX-Support testen
- âœ… User Stories schreiben (Agile)
- âœ… Technical Specs erstellen

**Soft-Skills:**
- âœ… Im Team arbeiten (Scrum-Rollen)
- âœ… PrÃ¤sentieren (Sprint Review)
- âœ… Cross-Team-Kommunikation
- âœ… Feedbackkultur (Retrospective)

---

## ğŸ“ Support & Fragen

**Product Owner (KQC):**
- Erreichbar via GitHub Discussions: https://github.com/kqc-real/streamlit/discussions
- In BBB-Sessions: Daily Standup (Tag 2-6)
- Ad-hoc Fragen: GitHub Discussions oder BBB-Chat

**Zwischen Teams:**
- Nutzt GitHub Discussions fÃ¼r Cross-Team-Fragen
- Teilt Erkenntnisse frÃ¼hzeitig (z.B. "LaTeX funktioniert bei Plattform X nicht!")
- Screen-Sharing in BBB fÃ¼r technische Probleme

**Technische Hilfe:**
- KI-Tools nutzen (ChatGPT, Claude) fÃ¼r Format-Conversion-Beispiele
- GitHub Copilot fÃ¼r Code-Snippets (falls Bonus-Challenge)

---

## ğŸš€ Los geht's!

**Vorbereitung (vor Tag 1):**
1. âœ… GitHub-Account erstellen (falls noch nicht vorhanden)
2. âœ… Markdown-Editor installieren (VS Code empfohlen)
3. âœ… BigBlueButton-Link speichern (wird vom PO bereitgestellt)

**Tag 1 (PrÃ¤senz-Kickoff):**
1. âœ… Team-Namen wÃ¤hlen (kreativ! z.B. "Flashcard Ninjas")
2. âœ… GitHub Issues erstellen (1 pro Team mit Checkliste aus DoD)
3. âœ… User Stories schreiben (Template vom PO)
4. âœ… Accounts fÃ¼r eure Plattformen erstellen
5. âœ… Daily Standup Zeiten vereinbaren (BBB)

**Tag 2-6 (Online-Sprint):**
- ğŸ“… TÃ¤glich BBB-Session (1h) - Daily Standup + Arbeitssession
- ğŸ’» Asynchrone Arbeit (1h) - Recherche & Dokumentation
- ğŸ“ Total: 2h pro Tag, fokussiert auf Kernaufgaben
- ğŸ”„ Dokumentation tÃ¤glich in GitHub pushen

**Motto:** *"Learning by doing â€“ mit echtem Business-Impact!"*

Viel Erfolg! ğŸ‰

---

**Anhang:**
- [Link zu MC-Test-App JSON-Schema]
- [Link zu Beispiel-Fragensets]
- [Link zu CONTRIBUTING.md fÃ¼r Git-Workflow]
