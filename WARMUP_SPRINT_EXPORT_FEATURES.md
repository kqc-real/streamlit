# üöÄ Warm-Up Sprint: Export-Features f√ºr Quiz-Plattformen

**Sprint-Typ:** Team-Building & Marktrecherche  
**Dauer:** 1 Woche (3h Pr√§senz + Online-Sprint)  
**Sprint-Ziel:** Technische und betriebswirtschaftliche Machbarkeitsstudie f√ºr Export-Funktionen zu 6 Quiz-Plattformen  
**Teams:** 3 Scrum-Teams (je 1 Plattform-Paar)  
**Format:** Hybrid (Pr√§senz-Kickoff + Online-Collaboration via BigBlueButton)

---

## üìã Product Owner Statement

> Als Dozent m√∂chte ich meine Fragensets aus der MC-Test-App in andere Quiz-Plattformen exportieren k√∂nnen, um die Reichweite zu erh√∂hen und verschiedene Lehr-Szenarien abzudecken (z.B. Live-Quizzes in der Vorlesung mit Kahoot, Karteikarten mit Anki, Hausaufgaben mit Quizlet).

---

## üéØ Sprint-Ziele

### Gesch√§ftsziele (BWL-Perspektive)

- üìä **Marktanalyse:** Welche Plattformen dominieren den Bildungsmarkt?
- üí∞ **Business Case:** Welche Export-Features bringen den gr√∂√üten Nutzen?
- üéØ **Zielgruppen-Fit:** Welche Plattformen nutzen unsere Zielgruppen (MINT-Studierende, BWL, Dozenten)?
- üîÑ **Competitive Advantage:** Wie differenzieren wir uns von der Konkurrenz?

### Technische Ziele

- üîç **Format-Analyse:** Import-/Export-Formate der Plattformen (JSON, CSV, XML, etc.)
- üß™ **LaTeX-Support:** Welche Plattformen unterst√ºtzen mathematische Formeln?
- üõ†Ô∏è **Implementierungs-Komplexit√§t:** Aufwand-Sch√§tzung (Story Points)
- üìê **Spezifikation:** Klare Vorgaben f√ºr die Entwicklung

---

## üë• Team-Aufteilung

### Team A: "Flashcard Experts"

[BBB-Teamroom A](https://bbb.arsnova.eu/rooms/3rs-pkj-ygz-qd8/join)

**Plattformen:** Anki + Quizlet  
**Use Case:** Karteikarten f√ºr Selbststudium

**Warum diese Kombination?**
- Beide fokussiert auf Spaced Repetition Learning
- Anki: Open-Source, Power-User, Desktop-first
- Quizlet: Kommerziell, Mainstream, Mobile-first

### Team B: "Live Quiz Champions"

[BBB-Teamroom B](https://bbb.arsnova.eu/rooms/qhf-xtl-zlz-isr/join)

**Plattformen:** Kahoot + Socrative  
**Use Case:** Interaktive Live-Quizzes in der Vorlesung

**Warum diese Kombination?**
- Beide fokussiert auf Echtzeit-Audience-Response
- Kahoot: Gamification, kompetitiv, gro√üer Markt
- Socrative: Education-fokussiert, formative Assessments

### Team C: "Academic Tools Specialists"

[BBB-Teamroom C](https://bbb.arsnova.eu/rooms/whc-pxa-0if-tsx/join)

**Plattformen:** Particify (ehem. ARSnova) + arsnova.click  
**Use Case:** Akademische Audience-Response-Systeme

**Warum diese Kombination?**
- Beide aus akademischem Kontext (Hochschulen)
- Particify: Enterprise-L√∂sung, DSGVO-konform
- arsnova.click: Schnell, datenschutzfreundlich, Open-Source

---

## üìù Aufgabenstellung pro Team

### Phase 1: Marktrecherche & Business-Analyse (Tag 2-3)

#### 1.1 Marktanalyse

**Deliverable:** Markdown-Dokument MARKTANALYSE_Plattform1_Plattform2.md

**Zu recherchieren:**

**Marktposition:**
- Anzahl aktive Nutzer (weltweit, DACH-Region)
- Marktanteil im Bildungssektor (Sch√§tzung)
- Hauptzielgruppe (Schule, Hochschule, Unternehmensschulung)
- Pricing-Modell (Freemium, Abo, Enterprise)

**Zielgruppen-Fit:**
- Welche unserer Personas nutzen diese Plattform? (MINT-Student, BWL-Student, Dozent)
- Typische Nutzungsszenarien
- Pain Points der Nutzer

**Business Case:**
- Wie viele unserer Nutzer w√ºrden Export nutzen? (Sch√§tzung)
- Welcher Mehrwert entsteht? (Zeit-Ersparnis, neue Use Cases)
- Priorit√§t: MUST-HAVE / SHOULD-HAVE / NICE-TO-HAVE

**Das Dokument soll enthalten:**
- Executive Summary mit Empfehlung (Implementieren / Zur√ºckstellen / Ablehnen)
- Begr√ºndung (3-5 S√§tze)
- Priorit√§t: HIGH / MEDIUM / LOW
- Detaillierte Analyse f√ºr beide Plattformen
- Vergleich & Empfehlung (2-3 Abs√§tze)

#### 1.2 Competitive Analysis

**Deliverable:** Tabelle in MARKTANALYSE.md

**Fragen:**
- Welche MC-Test-Tools bieten Export zu diesen Plattformen an?
- Wie ist die User Experience? (Screenshots, wenn m√∂glich)
- Was k√∂nnen wir besser machen?

**Die Tabelle soll vergleichen:**

| Feature | Konkurrent A | Konkurrent B | MC-Test-App (geplant) |
|---------|--------------|--------------|------------------------|
| Export zu Plattform X | ‚úÖ | ‚ùå | üéØ |
| LaTeX-Support | ‚ùå | ‚úÖ | ‚úÖ |
| Batch-Export | ‚úÖ | ‚ùå | üéØ |

---

### Phase 2: Technische Analyse (Tag 4-5)

#### 2.1 Import-Format-Analyse

**Deliverable:** Markdown-Dokument TECH_SPEC_Plattform1_Plattform2.md

**F√ºr jede Plattform zu untersuchen:**

**1. Import-Formate:**
- Welche Dateiformate werden unterst√ºtzt? (CSV, JSON, XML, GIFT, etc.)
- Gibt es offizielle Import-Tools oder APIs?
- Beispiel-Dateien herunterladen und analysieren

**2. Datenstruktur:**
- Wie werden Fragen strukturiert?
- Wie werden Antwortoptionen gespeichert?
- Pflichtfelder vs. optionale Felder
- Maximale Anzahl Antwortoptionen
- Zeichenlimits

**3. LaTeX-Support:**
- Werden mathematische Formeln unterst√ºtzt?
- Welche Syntax wird verwendet?
- Inline vs. Display-Formeln
- Beispiel testen: E=mc¬≤ und komplexere Formeln

**4. Metadaten-Support:**
- Schwierigkeitsgrade / Gewichtung
- Themen / Tags / Kategorien
- Erkl√§rungen / Feedback
- Bilder / Medien
- Mini-Glossar (wenn relevant)

**5. Limitierungen:**
- Was kann NICHT exportiert werden?
- Workarounds oder Fallback-Optionen
- Breaking Changes bei Updates?

**Das Dokument soll enthalten:**
- √úbersicht aller unterst√ºtzten Import-Formate
- Empfohlenes Format mit Begr√ºndung
- Link zur offiziellen Dokumentation
- Beispiel-Datenstruktur (JSON oder CSV)
- Tabelle f√ºr Metadaten-Support mit Mapping
- Liste aller Limitierungen
- Implementierungs-Empfehlung

#### 2.2 Test-Export erstellen

**Deliverable:** Beispiel-Dateien im Format jeder Plattform

**Aufgabe:**
1. W√§hlt 5 Fragen aus questions_PDF_Test.json (einfache Beispiele)
2. Konvertiert manuell in das Ziel-Format (CSV, JSON, etc.)
3. Importiert in die Plattform (sofern m√∂glich)
4. Dokumentiert Ergebnis mit Screenshots

**Ziel:** Proof-of-Concept, dass Mapping funktioniert

**Erstellt einen Ordner export-examples mit:**
- anki_example.txt (Anki-Format)
- quizlet_example.csv
- kahoot_example.xlsx
- socrative_example.csv
- particify_example.json
- arsnova_example.json

---

### Phase 3: Spezifikation & Priorisierung (Tag 5-6)

#### 3.1 Feature-Spezifikation

**Deliverable:** FEATURE_SPEC_EXPORT.md

**Das Dokument soll enthalten:**

**1. User Stories (pro Plattform):**

Jede User Story beschreibt:
- Als wer m√∂chte ich was und warum
- Akzeptanzkriterien (Checkliste)
- Technische Anforderungen (Input/Output, Mapping)
- Aufwand-Sch√§tzung in Story Points
- Priorit√§t (MUST / SHOULD / COULD / WON'T)

**2. Mapping-Tabelle (MC-Test-App ‚Üí Plattform):**

Zeigt f√ºr jedes Feld:
- MC-Test-App Feldname
- Plattform-Feldname
- Transformation (z.B. "1‚ÜíEasy, 2‚ÜíMedium, 3‚ÜíHard")
- Fallback-Option

**3. UI-Mockup:**

Skizziert grob:
- Wo erscheint der Export-Button?
- Welche Optionen sieht der Nutzer?
- Wie sieht das Feedback aus?

#### 3.2 Priorisierung & Roadmap

**Deliverable:** Teil von FEATURE_SPEC_EXPORT.md

**Aufgabe:** Empfehlt Reihenfolge der Implementierung

**Kriterien:**
1. **Business Value:** Wie viele Nutzer profitieren?
2. **Technical Effort:** Aufwand in Story Points
3. **Dependencies:** Welche Features bauen aufeinander auf?
4. **Risk:** Technische Unsicherheiten

**Verwendet die MoSCoW-Methode:**
- **MUST HAVE:** Sprint 1 (z.B. Anki + Quizlet)
- **SHOULD HAVE:** Sprint 2 (z.B. Kahoot)
- **COULD HAVE:** Sprint 3 (z.B. Socrative + Particify)
- **WON'T HAVE:** Backlog (z.B. arsnova.click)

F√ºr jede Plattform angeben:
- Story Points
- Begr√ºndung
- Risk-Level (LOW / MEDIUM / HIGH)

**Am Ende steht eine Roadmap:**
- Sprint 1 (2 Wochen): Welche Plattformen?
- Sprint 2 (2 Wochen): Welche Plattformen?
- Sprint 3 (2 Wochen): Welche Plattformen?
- Future: Was kommt sp√§ter?

---

## üìä Abschlusspr√§sentation (Tag 7 - Pr√§senz)

### Sprint Review (30 Min pro Team)

**Format:** Pr√§sentation vor Product Owner (KQC) + anderen Teams

**Agenda:**

**1. Executive Summary (3 Min)**
- Kernaussage: Welche Plattformen sollten implementiert werden?
- Top 3 Learnings

**2. Marktanalyse (5 Min)**
- Marktposition der Plattformen
- Zielgruppen-Fit
- Business Case

**3. Technische Analyse (10 Min)**
- Import-Formate & Datenstrukturen
- LaTeX-Support (mit Live-Demo wenn m√∂glich)
- Limitierungen

**4. Feature-Spezifikation (7 Min)**
- User Stories
- Mapping-Tabelle
- Aufwand-Sch√§tzung

**5. Priorisierung (3 Min)**
- MoSCoW-Kategorisierung
- Roadmap-Empfehlung

**6. Q&A (2 Min)**

**Deliverables zur Pr√§sentation:**
- üìä Pr√§sentations-Slides (PDF)
- üìù Alle Markdown-Dokumente im Repo
- üìÇ Beispiel-Export-Dateien
- üé• Optional: Video-Demo eines Test-Imports

---

## üìÖ Zeitplan (1-Wochen-Sprint)

### Tag 1: Pr√§senz-Kickoff (3 Stunden)

**Ort:** Kursraum  
**Ziel:** Organisation, Team-Bildung, GitHub-Setup

| Zeit | Aktivit√§t | Details |
|------|-----------|---------|
| 0:00-0:30 | Sprint-Kickoff | Product Owner Statement, Ziele, Deliverables, Team-Aufteilung |
| 0:30-1:00 | GitHub-Setup | Issues erstellen, Kanban-Board einrichten, Checklisten |
| 1:00-2:00 | User Stories schreiben | Je Team: 2-3 User Stories f√ºr ihre Plattformen (mit Akzeptanzkriterien) |
| 2:00-2:30 | Tool-Accounts & Ressourcen | Accounts erstellen (Anki, Quizlet, etc.), Dokumentation sammeln |
| 2:30-3:00 | Sprint Planning | Aufgaben verteilen, BBB-Termine vereinbaren, Daily Standup planen |

**Output:** GitHub Issues mit User Stories, Kanban-Board, Sprint Backlog

---

### Tag 2-6: Online-Sprint (BigBlueButton)

**Format:** Asynchrone Arbeit + synchrone BBB-Sessions  
**Workload:** 2 Stunden pro Tag (1h BBB + 1h asynchron)

| Tag | BBB-Session (1h) | Asynchrone Arbeit (1h) |
|-----|------------------|------------------------|
| Tag 2 | Daily Standup (15 Min) + Marktrecherche-Kick (45 Min) | Marktanalyse Plattform 1 (Nutzer, Pricing, Zielgruppe) |
| Tag 3 | Daily Standup (15 Min) + Q&A (45 Min) | Marktanalyse Plattform 2 + Competitive Analysis |
| Tag 4 | Daily Standup (15 Min) + Tech-Review (45 Min) | Technische Analyse: Import-Formate, Datenstruktur |
| Tag 5 | Daily Standup (15 Min) + Mapping-Workshop (45 Min) | LaTeX-Tests, Metadaten-Mapping, Beispiel-Exports |
| Tag 6 | Daily Standup (15 Min) + Priorisierung (45 Min) | User Stories finalisieren, MoSCoW, Slides vorbereiten |

**BBB-Sessions:**
- **Daily Standup (15 Min):** 3 Fragen: Was habe ich gestern gemacht? Was mache ich heute? Blocker?
- **Arbeitssession (45 Min):** Gemeinsam an Deliverables arbeiten, Screen-Sharing, Pair-Dokumentation

**Asynchrone Arbeit (1h):**
- Eigenst√§ndige Recherche (Plattform-Docs, User-Reviews, Format-Beispiele)
- Dokumentation in Markdown schreiben (GitHub)
- Screenshots, Test-Imports, Beispiel-Dateien erstellen

---

### Tag 7: Pr√§senz-Abschluss (3 Stunden) - Scrum-Zeremonien

**Ort:** Kursraum  
**Ziel:** Sprint Review, Sprint Retrospective, Increment-Abnahme, Lessons Learned

---

#### Teil 1: Sprint Review (90 Min)

**Was haben wir gebaut?**

**Scrum-Zeremonie:** Pr√§sentation des Increments an Stakeholder (Product Owner + andere Teams)

| Zeit | Aktivit√§t | Format | Erwartete Artefakte |
|------|-----------|--------|---------------------|
| 0:00-0:05 | Sprint Review Opening | PO begr√º√üt, erinnert an Sprint-Ziel | - |
| 0:05-0:35 | Team 1 Pr√§sentation | 30 Min Live-Demo + Q&A | MARKTANALYSE.md, TECH_SPEC.md, FEATURE_SPEC.md, Beispiel-Export-Dateien, Slides (PDF) |
| 0:35-1:05 | Team 2 Pr√§sentation | 30 Min Live-Demo + Q&A | (siehe oben) |
| 1:05-1:35 | Team 3 Pr√§sentation | 30 Min Live-Demo + Q&A | (siehe oben) |

**Output Sprint Review:**
- ‚úÖ Alle Deliverables vorgestellt und auf GitHub gepusht
- ‚úÖ Feedback vom Product Owner dokumentiert
- ‚úÖ Gemeinsames Verst√§ndnis √ºber technische Machbarkeit

---

#### Teil 2: Priorisierungs-Voting (30 Min)

**Product Backlog Refinement**

**Scrum-Aktivit√§t:** Gemeinsame Priorisierung f√ºr das Product Backlog

| Zeit | Aktivit√§t | Format | Erwartete Artefakte |
|------|-----------|--------|---------------------|
| 1:35-1:50 | MoSCoW-Voting | Jedes Team-Mitglied hat 3 Stimmen (Klebepunkte/Whiteboard) | Voting-Ergebnis (Foto) |
| 1:50-2:05 | Roadmap-Entscheidung | PO priorisiert basierend auf: Business Value + Voting + Aufwand | EXPORT_ROADMAP.md (finale Implementierungs-Reihenfolge) |

**MoSCoW-Voting-Regeln:**
- Jede Person: 3 Stimmen (kann mehrere auf 1 Plattform setzen)
- Product Owner hat Veto-Recht basierend auf Business Case
- Ergebnis: Priorisierte Liste aller 6 Plattformen

**Die finale EXPORT_ROADMAP.md enth√§lt:**
- Datum der Entscheidung
- Sprint 1 (MUST HAVE): Welche Plattformen mit Story Points und Begr√ºndung
- Sprint 2 (SHOULD HAVE): Welche Plattformen
- Sprint 3 (COULD HAVE): Welche Plattformen
- Backlog (WON'T HAVE aktuell): Welche Plattformen mit Begr√ºndung
- Voting-Ergebnis (Screenshot oder Tabelle)

---

#### Teil 3: Sprint Retrospective (60 Min)

**Wie k√∂nnen wir besser werden?**

**Scrum-Zeremonie:** Team-Reflexion zur Prozessverbesserung

| Zeit | Aktivit√§t | Format | Erwartete Artefakte |
|------|-----------|--------|---------------------|
| 2:05-2:20 | Set the Stage | Check-in: 1 Wort, wie f√ºhle ich mich? (Runde) | - |
| 2:20-2:35 | Gather Data | Timeline: Was ist passiert? (Whiteboard/Miro) | Timeline (Foto) |
| 2:35-2:50 | Generate Insights | Start-Stop-Continue (3 Spalten) | RETROSPECTIVE.md |
| 2:50-3:00 | Decide What To Do | Top 3 Action Items f√ºr n√§chsten Sprint | Action Items (assigned) |
| 3:00 | Celebration! | Applaus, Teamfoto, High-Fives üéâ | Teamfoto |

**Retrospektive-Format: Start-Stop-Continue**

| üü¢ START | üî¥ STOP | üîµ CONTINUE |
|---------|---------|-------------|
| Was sollten wir anfangen? | Was sollten wir aufh√∂ren? | Was lief gut? |
| Z.B. "Fr√ºher Docs lesen" | Z.B. "Meetings ohne Agenda" | Z.B. "Daily Standups" |
| Z.B. "Pair-Dokumentation" | Z.B. "Last-Minute-Arbeit" | Z.B. "Screen-Sharing in BBB" |

**Die RETROSPECTIVE.md enth√§lt:**
- Datum und Teilnehmer
- Check-In (1 Wort pro Person)
- Timeline (Was ist passiert?)
- Start-Stop-Continue mit konkreten Beispielen
- Top 3 Action Items mit Verantwortlichen (Assigned to: PO / Teams / Facilitator)
- Celebration: Was hat uns stolz gemacht? + Teamfoto-Link

---

### Zusammenfassung: Erwartete Artefakte am Tag 7

**Pro Team (3 Teams):**
1. ‚úÖ MARKTANALYSE_Plattformen.md (auf GitHub)
2. ‚úÖ TECH_SPEC_Plattformen.md (auf GitHub)
3. ‚úÖ FEATURE_SPEC_EXPORT.md (User Stories, Mapping, Story Points)
4. ‚úÖ Beispiel-Export-Dateien im Ordner export-examples
5. ‚úÖ Pr√§sentations-Slides (PDF, 15-20 Slides)
6. ‚úÖ Live-Demo (Import in Plattform, Screenshots)

**Gemeinsam (alle Teams):**
7. ‚úÖ EXPORT_ROADMAP.md (priorisierte Implementierungs-Reihenfolge)
8. ‚úÖ RETROSPECTIVE.md (Start-Stop-Continue, Action Items)
9. ‚úÖ Voting-Ergebnis (Foto vom Whiteboard)
10. ‚úÖ Teamfoto (Celebration!)

**Von Product Owner:**
11. ‚úÖ Sprint Review Feedback (dokumentiert in GitHub Issues)
12. ‚úÖ Finale Roadmap-Entscheidung (in EXPORT_ROADMAP.md)

---

### Output Tag 7

‚úÖ **Product Backlog** ist priorisiert (Roadmap f√ºr Implementierung steht)  
‚úÖ **Increment** ist abgenommen (alle Deliverables reviewed)  
‚úÖ **Process Improvements** sind identifiziert (Retrospektive)  
‚úÖ **Team Motivation** ist hoch (Celebration, Teamfoto)  
‚úÖ **N√§chste Schritte** sind klar (Action Items assigned)

---

### Workload pro Person

**Pr√§senz:** 2√ó 3h = 6h  
**Online:** 5√ó 2h = 10h (inkl. BBB-Sessions)  
**Total:** 16 Stunden pro Person √ºber 1 Woche

Bei 3er-Teams: 48 Stunden pro Team (fokussiert auf Kernaufgaben)

---

## üéØ Definition of Done

### Team-Level (pro Team)

- [ ] MARKTANALYSE_Plattformen.md vollst√§ndig (auf GitHub gepusht)
- [ ] TECH_SPEC_Plattformen.md vollst√§ndig (mit JSON-Beispielen)
- [ ] FEATURE_SPEC_EXPORT.md mit User Stories & Mapping-Tabellen
- [ ] Beispiel-Export-Dateien f√ºr beide Plattformen erstellt (Ordner export-examples)
- [ ] Test-Import in Plattformen durchgef√ºhrt (Screenshots dokumentiert)
- [ ] Pr√§sentation vorbereitet (Slides PDF + Live-Demo)
- [ ] Sprint Review: 30-Min-Pr√§sentation gehalten
- [ ] Product Owner Acceptance erhalten

### Sprint-Level (alle Teams gemeinsam)

- [ ] Alle 3 Teams haben ihre Deliverables abgeschlossen
- [ ] Sprint Review durchgef√ºhrt (90 Min, alle pr√§sentiert)
- [ ] MoSCoW-Voting durchgef√ºhrt (Foto dokumentiert)
- [ ] EXPORT_ROADMAP.md erstellt (finale Priorisierung)
- [ ] Sprint Retrospective durchgef√ºhrt (Start-Stop-Continue)
- [ ] RETROSPECTIVE.md erstellt (Action Items assigned)
- [ ] Teamfoto gemacht üì∏
- [ ] Celebration! üéâ

---

## üõ†Ô∏è Tools & Ressourcen

### Marktrecherche

- **Google Trends:** Vergleich der Suchvolumina
- **SimilarWeb:** Traffic-Analyse der Plattformen
- **G2/Capterra:** User-Reviews lesen
- **LinkedIn:** Job-Postings analysieren (Nachfrage-Indikator)

### Technische Analyse

- **Offizielle Dokumentation:** Links werden bereitgestellt
- **GitHub:** Suche nach "Plattform import format" f√ºr Community-Beispiele
- **ChatGPT/Claude:** Format-Conversion-Beispiele generieren lassen

### Kollaboration

- **GitHub Issues:** Ein Issue pro Team mit Checkliste
- **GitHub Discussions:** Fragen an PO und zwischen Teams
- **BigBlueButton (BBB):** Daily Standups + Arbeitssessions (Screen-Sharing)
- **Markdown-Editor:** VS Code mit Preview
- **Miro/Whiteboard:** Optional f√ºr Brainstorming (kann in BBB geteilt werden)

---

## üìö Hilfreiche Ressourcen

### Plattform-Dokumentation (Startpunkte)

**Anki:**
- Import-Format: https://docs.ankiweb.net/importing/text-files.html
- Suche: "Anki import format CSV"

**Quizlet:**
- Import-Format: https://help.quizlet.com/hc/en-us/articles/360029977151
- Suche: "Quizlet import spreadsheet"

**Kahoot:**
- Import-Format: https://support.kahoot.com/hc/en-us/articles/115002303908
- Suche: "Kahoot Excel import template"

**Socrative:**
- Import-Format: https://help.socrative.com/en/articles/369-how-do-i-import-questions
- Suche: "Socrative question import"

**Particify:**
- Dokumentation: https://particify.de/manual/
- Suche: "Particify ARSnova import"

**arsnova.click:**
- GitHub: https://github.com/thm-projects/arsnova.click-v2
- Suche: "arsnova.click API documentation"

### BWL-Methoden

**Marktanalyse:**
- Porter's Five Forces (Wettbewerbsanalyse)
- SWOT-Analyse (Strengths, Weaknesses, Opportunities, Threats)

**Priorisierung:**
- MoSCoW-Methode (Must, Should, Could, Won't)
- Value vs. Effort Matrix (2x2-Matrix)

**Business Case:**
- ROI-Kalkulation (qualitativ)
- Break-Even-Analyse

---

## ‚ùì FAQs

**Q: Was, wenn eine Plattform keine √∂ffentliche API hat?**  
A: Dokumentiert das als "Limitierung". Empfehlt, mit propriet√§ren Formaten zu arbeiten (z.B. CSV/Excel-Templates). Priorisierung dann niedriger.

**Q: Was, wenn wir keinen Account f√ºr eine Plattform haben?**  
A: Nutzt Free Trials oder erstellt kostenlose Accounts. Falls nicht m√∂glich: Recherche basierend auf Dokumentation + YouTube-Tutorials.

**Q: M√ºssen wir alle Felder der MC-Test-App mappen?**  
A: Nein. Fokus auf Pflichtfelder (Frage, Optionen, L√∂sung). Nice-to-have: Erkl√§rungen, Themen, Gewichtung. Mini-Glossar und extended_explanation sind optional.

**Q: Was, wenn LaTeX nicht unterst√ºtzt wird?**  
A: Dokumentiert das klar. Schlagt Fallback vor (z.B. Formeln als Bilder exportieren, oder Text-Platzhalter wie "[Formel: E=mc¬≤]").

**Q: Wie detailliert muss die technische Spezifikation sein?**  
A: Detailliert genug, dass ein Entwickler (ich) die Implementierung ohne R√ºckfragen starten kann. Beispiel-Mappings sind Pflicht!

---

## üéì Lernziele (f√ºr eure Reflexion)

Nach diesem Sprint k√∂nnt ihr:

**BWL-Skills:**
- ‚úÖ Marktanalyse durchf√ºhren (Wettbewerb, Zielgruppen, Pricing)
- ‚úÖ Business Cases bewerten (ROI, Value vs. Effort)
- ‚úÖ Features priorisieren (MoSCoW, Roadmap)
- ‚úÖ Stakeholder-Perspektiven einnehmen (Dozent, Student, Admin)

**Tech-Skills:**
- ‚úÖ Import-/Export-Formate analysieren (CSV, JSON, XML)
- ‚úÖ APIs und Dokumentationen lesen
- ‚úÖ LaTeX-Support testen
- ‚úÖ User Stories schreiben (Agile)
- ‚úÖ Technical Specs erstellen

**Soft-Skills:**
- ‚úÖ Im Team arbeiten (Scrum-Rollen)
- ‚úÖ Pr√§sentieren (Sprint Review)
- ‚úÖ Cross-Team-Kommunikation
- ‚úÖ Feedbackkultur (Retrospective)

---

## üìû Support & Fragen

**Product Owner (KQC):**
- Erreichbar via GitHub Discussions: https://github.com/kqc-real/streamlit/discussions
- In BBB-Sessions: Daily Standup (Tag 2-6)
- Ad-hoc Fragen: GitHub Discussions oder BBB-Chat

**Zwischen Teams:**
- Nutzt GitHub Discussions f√ºr Cross-Team-Fragen
- Teilt Erkenntnisse fr√ºhzeitig (z.B. "LaTeX funktioniert bei Plattform X nicht!")
- Screen-Sharing in BBB f√ºr technische Probleme

**Technische Hilfe:**
- KI-Tools nutzen (ChatGPT, Claude) f√ºr Format-Conversion-Beispiele
- GitHub Copilot f√ºr Code-Snippets (falls Bonus-Challenge)

---

## üöÄ Los geht's!

**Vorbereitung (vor Tag 1):**
1. ‚úÖ GitHub-Account erstellen (falls noch nicht vorhanden)
2. ‚úÖ [Anleitung Markdown lesen](https://github.com/kqc-real/streamlit/blob/main/ANLEITUNG_MARKDOWN_BEARBEITEN.md)

**Tag 1 (Pr√§senz-Kickoff):**
2. ‚úÖ GitHub Issues erstellen
3. ‚úÖ User Stories schreiben
4. ‚úÖ Accounts f√ºr eure Plattformen erstellen
5. ‚úÖ Daily Standup Zeiten vereinbaren (BBB)

**Tag 2-6 (Online-Sprint):**
- üìÖ T√§glich BBB-Session (1h) - Daily Standup + Arbeitssession
- üíª Asynchrone Arbeit (1h) - Recherche & Dokumentation
- üìù Total: 2h pro Tag, fokussiert auf Kernaufgaben
- üîÑ Dokumentation t√§glich in GitHub pushen

**Motto:** *"Learning by doing ‚Äì mit echtem Business-Impact!"*

Viel Erfolg! üéâ
