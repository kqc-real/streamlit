{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86d38ff",
   "metadata": {},
   "source": [
    "# ü§ñ Modern NLP und Text Generation\n",
    "### Woche 7, Notebook 2: Von Transformers bis Deployment\n",
    "\n",
    "**Lernziele:**\n",
    "- üî§ **Modern NLP**: Transformer-basierte Modelle verstehen\n",
    "- ü§ó **Hugging Face**: Pre-trained Models nutzen\n",
    "- ‚úçÔ∏è **Text Generation**: GPT-Style Modelle anwenden\n",
    "- üåê **NLP APIs**: Text-Services f√ºr Produktion\n",
    "- üöÄ **Deployment**: NLP-Anwendungen bereitstellen\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **2025 Update**: Wir nutzen moderne Transformer-Modelle statt veralteter LSTM-Ans√§tze!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56900b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Modern NLP Setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Basis Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Modern NLP\n",
    "try:\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "    print(\"‚úÖ Transformers verf√ºgbar\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Transformers nicht installiert\")\n",
    "\n",
    "# API Framework\n",
    "try:\n",
    "    from fastapi import FastAPI\n",
    "    from pydantic import BaseModel\n",
    "    print(\"‚úÖ FastAPI verf√ºgbar\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è FastAPI nicht installiert\")\n",
    "\n",
    "print(f\"üöÄ Modern NLP Setup abgeschlossen - {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7d62d",
   "metadata": {},
   "source": [
    "## üî§ Modern NLP mit Transformers\n",
    "\n",
    "### Warum Transformers statt LSTM?\n",
    "\n",
    "| Aspekt | LSTM (Legacy) | Transformers (Modern) |\n",
    "|--------|---------------|----------------------|\n",
    "| **Performance** | Sequenziell, langsam | Parallel, schnell |\n",
    "| **Kontext** | Begrenzt | Unbegrenzt |\n",
    "| **Qualit√§t** | Gut | Exzellent |\n",
    "| **Pre-training** | Schwierig | Einfach |\n",
    "| **Deployment** | Komplex | Streamlined |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ó Hugging Face Text Generation Pipeline\n",
    "\n",
    "class ModernTextGenerator:\n",
    "    \"\"\"\n",
    "    Modern Text Generation mit Hugging Face Transformers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"distilgpt2\"):\n",
    "        self.model_name = model_name\n",
    "        print(f\"üì• Lade Modell: {model_name}...\")\n",
    "        \n",
    "        # Text Generation Pipeline\n",
    "        self.generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model_name,\n",
    "            tokenizer=model_name,\n",
    "            device=-1  # CPU\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Text Generator bereit!\")\n",
    "    \n",
    "    def generate_text(self, prompt, max_length=100, num_return_sequences=1, temperature=0.7):\n",
    "        \"\"\"\n",
    "        Text generieren basierend auf Prompt\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.generator(\n",
    "                prompt,\n",
    "                max_length=max_length,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                temperature=temperature,\n",
    "                pad_token_id=self.generator.tokenizer.eos_token_id,\n",
    "                do_sample=True\n",
    "            )\n",
    "            \n",
    "            generated_texts = [result['generated_text'] for result in results]\n",
    "            return generated_texts\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Generation Fehler: {str(e)}\")\n",
    "            return [f\"Fehler bei der Generierung: {str(e)}\"]\n",
    "\n",
    "# Text Generator initialisieren\n",
    "text_gen = ModernTextGenerator()\n",
    "\n",
    "# Test Generation\n",
    "test_prompt = \"Once upon a time in a magical forest\"\n",
    "generated = text_gen.generate_text(test_prompt, max_length=80)\n",
    "\n",
    "print(\"üß™ Test Generation:\")\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print(f\"Generated: {generated[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93373fc",
   "metadata": {},
   "source": [
    "### üéØ Verschiedene NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Multi-Task NLP Pipeline\n",
    "\n",
    "class NLPTaskSuite:\n",
    "    \"\"\"\n",
    "    Sammlung von NLP Tasks f√ºr praktische Anwendungen\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks = {}\n",
    "        self._init_pipelines()\n",
    "    \n",
    "    def _init_pipelines(self):\n",
    "        \"\"\"Initialisiert verschiedene NLP Pipelines\"\"\"\n",
    "        print(\"üîÑ Initialisiere NLP Pipelines...\")\n",
    "        \n",
    "        try:\n",
    "            # Sentiment Analysis\n",
    "            self.tasks['sentiment'] = pipeline(\"sentiment-analysis\")\n",
    "            print(\"‚úÖ Sentiment Analysis geladen\")\n",
    "            \n",
    "            # Text Summarization\n",
    "            self.tasks['summarization'] = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "            print(\"‚úÖ Summarization geladen\")\n",
    "            \n",
    "            # Question Answering\n",
    "            self.tasks['qa'] = pipeline(\"question-answering\")\n",
    "            print(\"‚úÖ Question Answering geladen\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Einige Pipelines konnten nicht geladen werden: {str(e)}\")\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        \"\"\"Sentiment Analysis\"\"\"\n",
    "        if 'sentiment' not in self.tasks:\n",
    "            return \"Sentiment Pipeline nicht verf√ºgbar\"\n",
    "        \n",
    "        result = self.tasks['sentiment'](text)[0]\n",
    "        return {\n",
    "            'label': result['label'],\n",
    "            'confidence': round(result['score'], 4)\n",
    "        }\n",
    "    \n",
    "    def summarize_text(self, text, max_length=130):\n",
    "        \"\"\"Text Summarization\"\"\"\n",
    "        if 'summarization' not in self.tasks:\n",
    "            return \"Summarization Pipeline nicht verf√ºgbar\"\n",
    "        \n",
    "        if len(text.split()) < 50:\n",
    "            return \"Text zu kurz f√ºr Zusammenfassung\"\n",
    "        \n",
    "        result = self.tasks['summarization'](text, max_length=max_length, min_length=30)\n",
    "        return result[0]['summary_text']\n",
    "    \n",
    "    def answer_question(self, context, question):\n",
    "        \"\"\"Question Answering\"\"\"\n",
    "        if 'qa' not in self.tasks:\n",
    "            return \"QA Pipeline nicht verf√ºgbar\"\n",
    "        \n",
    "        result = self.tasks['qa'](question=question, context=context)\n",
    "        return {\n",
    "            'answer': result['answer'],\n",
    "            'confidence': round(result['score'], 4)\n",
    "        }\n",
    "\n",
    "# NLP Suite initialisieren\n",
    "nlp_suite = NLPTaskSuite()\n",
    "\n",
    "# Tests\n",
    "print(\"\\nüß™ NLP Task Tests:\")\n",
    "\n",
    "# Sentiment Test\n",
    "sentiment_result = nlp_suite.analyze_sentiment(\"I love this modern NLP approach!\")\n",
    "print(f\"Sentiment: {sentiment_result}\")\n",
    "\n",
    "# QA Test\n",
    "context = \"Transformers are a type of neural network architecture that has revolutionized natural language processing.\"\n",
    "question = \"What has revolutionized NLP?\"\n",
    "qa_result = nlp_suite.answer_question(context, question)\n",
    "print(f\"QA: {qa_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e73a1d",
   "metadata": {},
   "source": [
    "### üåê NLP API Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ FastAPI NLP Service\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "# Pydantic Models f√ºr API\n",
    "class TextGenerationRequest(BaseModel):\n",
    "    prompt: str\n",
    "    max_length: Optional[int] = 100\n",
    "    temperature: Optional[float] = 0.7\n",
    "    num_sequences: Optional[int] = 1\n",
    "\n",
    "class SentimentRequest(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class QARequest(BaseModel):\n",
    "    question: str\n",
    "    context: str\n",
    "\n",
    "# FastAPI App\n",
    "app = FastAPI(\n",
    "    title=\"Modern NLP API\",\n",
    "    description=\"Production-ready NLP Services mit Transformers\",\n",
    "    version=\"2.0.0\"\n",
    ")\n",
    "\n",
    "# Global Services\n",
    "global_text_gen = None\n",
    "global_nlp_suite = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    global global_text_gen, global_nlp_suite\n",
    "    global_text_gen = text_gen\n",
    "    global_nlp_suite = nlp_suite\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"Modern NLP API\",\n",
    "        \"version\": \"2.0.0\",\n",
    "        \"services\": [\"text-generation\", \"sentiment\", \"qa\"],\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "async def generate_text(request: TextGenerationRequest):\n",
    "    \"\"\"Text Generation Endpoint\"\"\"\n",
    "    if not global_text_gen:\n",
    "        return {\"error\": \"Text Generator nicht verf√ºgbar\"}\n",
    "    \n",
    "    generated = global_text_gen.generate_text(\n",
    "        prompt=request.prompt,\n",
    "        max_length=request.max_length,\n",
    "        temperature=request.temperature,\n",
    "        num_return_sequences=request.num_sequences\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": request.prompt,\n",
    "        \"generated_texts\": generated,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.post(\"/sentiment\")\n",
    "async def analyze_sentiment(request: SentimentRequest):\n",
    "    \"\"\"Sentiment Analysis Endpoint\"\"\"\n",
    "    if not global_nlp_suite:\n",
    "        return {\"error\": \"NLP Suite nicht verf√ºgbar\"}\n",
    "    \n",
    "    result = global_nlp_suite.analyze_sentiment(request.text)\n",
    "    \n",
    "    return {\n",
    "        \"text\": request.text,\n",
    "        \"sentiment\": result,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.post(\"/qa\")\n",
    "async def question_answering(request: QARequest):\n",
    "    \"\"\"Question Answering Endpoint\"\"\"\n",
    "    if not global_nlp_suite:\n",
    "        return {\"error\": \"NLP Suite nicht verf√ºgbar\"}\n",
    "    \n",
    "    result = global_nlp_suite.answer_question(request.context, request.question)\n",
    "    \n",
    "    return {\n",
    "        \"question\": request.question,\n",
    "        \"context\": request.context[:100] + \"...\",\n",
    "        \"answer\": result,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Modern NLP API erstellt!\")\n",
    "print(\"üìù Endpoints:\")\n",
    "print(\"   POST /generate - Text Generation\")\n",
    "print(\"   POST /sentiment - Sentiment Analysis\")\n",
    "print(\"   POST /qa - Question Answering\")\n",
    "print(\"\\nüöÄ Starten mit: uvicorn main:app --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab13b2d",
   "metadata": {},
   "source": [
    "### üì± Streamlit NLP Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Streamlit NLP Dashboard erstellen\n",
    "\n",
    "streamlit_nlp_app = '''\n",
    "import streamlit as st\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Modern NLP Dashboard\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"ü§ñ Modern NLP Dashboard\")\n",
    "st.markdown(\"**Transformer-basierte NLP Services**\")\n",
    "\n",
    "# Sidebar\n",
    "st.sidebar.header(\"‚öôÔ∏è Konfiguration\")\n",
    "api_url = st.sidebar.text_input(\"NLP API URL\", \"http://localhost:8000\")\n",
    "\n",
    "# Main Content\n",
    "tab1, tab2, tab3 = st.tabs([\"‚úçÔ∏è Text Generation\", \"üòä Sentiment\", \"‚ùì Q&A\"])\n",
    "\n",
    "with tab1:\n",
    "    st.header(\"‚úçÔ∏è Text Generation\")\n",
    "    \n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        prompt = st.text_area(\"Prompt eingeben:\", \"Once upon a time\")\n",
    "        \n",
    "    with col2:\n",
    "        max_length = st.slider(\"Max Length\", 50, 200, 100)\n",
    "        temperature = st.slider(\"Temperature\", 0.1, 1.0, 0.7)\n",
    "        \n",
    "    if st.button(\"üöÄ Generate Text\", type=\"primary\"):\n",
    "        with st.spinner(\"Generiere Text...\"):\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    f\"{api_url}/generate\",\n",
    "                    json={\n",
    "                        \"prompt\": prompt,\n",
    "                        \"max_length\": max_length,\n",
    "                        \"temperature\": temperature\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    st.success(\"Text erfolgreich generiert!\")\n",
    "                    st.write(\"**Generated Text:**\")\n",
    "                    st.write(result[\"generated_texts\"][0])\n",
    "                else:\n",
    "                    st.error(f\"API Fehler: {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Verbindungsfehler: {str(e)}\")\n",
    "\n",
    "with tab2:\n",
    "    st.header(\"üòä Sentiment Analysis\")\n",
    "    \n",
    "    text_input = st.text_area(\"Text f√ºr Sentiment Analysis:\")\n",
    "    \n",
    "    if st.button(\"üîç Analyze Sentiment\", type=\"primary\"):\n",
    "        if text_input:\n",
    "            with st.spinner(\"Analysiere Sentiment...\"):\n",
    "                try:\n",
    "                    response = requests.post(\n",
    "                        f\"{api_url}/sentiment\",\n",
    "                        json={\"text\": text_input}\n",
    "                    )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        result = response.json()\n",
    "                        sentiment = result[\"sentiment\"]\n",
    "                        \n",
    "                        col1, col2 = st.columns(2)\n",
    "                        with col1:\n",
    "                            st.metric(\"Sentiment\", sentiment[\"label\"])\n",
    "                        with col2:\n",
    "                            st.metric(\"Confidence\", f\"{sentiment['confidence']:.2%}\")\n",
    "                            \n",
    "                        # Emoji basierend auf Sentiment\n",
    "                        emoji = \"üòä\" if sentiment[\"label\"] == \"POSITIVE\" else \"üòî\"\n",
    "                        st.write(f\"## {emoji} {sentiment['label']}\")\n",
    "                        \n",
    "                    else:\n",
    "                        st.error(f\"API Fehler: {response.status_code}\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Verbindungsfehler: {str(e)}\")\n",
    "        else:\n",
    "            st.warning(\"Bitte Text eingeben\")\n",
    "\n",
    "with tab3:\n",
    "    st.header(\"‚ùì Question Answering\")\n",
    "    \n",
    "    context = st.text_area(\"Kontext:\", height=150)\n",
    "    question = st.text_input(\"Frage:\")\n",
    "    \n",
    "    if st.button(\"üí° Answer Question\", type=\"primary\"):\n",
    "        if context and question:\n",
    "            with st.spinner(\"Beantworte Frage...\"):\n",
    "                try:\n",
    "                    response = requests.post(\n",
    "                        f\"{api_url}/qa\",\n",
    "                        json={\n",
    "                            \"context\": context,\n",
    "                            \"question\": question\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        result = response.json()\n",
    "                        answer = result[\"answer\"]\n",
    "                        \n",
    "                        st.success(\"Antwort gefunden!\")\n",
    "                        st.write(f\"**Antwort:** {answer['answer']}\")\n",
    "                        st.write(f\"**Confidence:** {answer['confidence']:.2%}\")\n",
    "                        \n",
    "                    else:\n",
    "                        st.error(f\"API Fehler: {response.status_code}\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Verbindungsfehler: {str(e)}\")\n",
    "        else:\n",
    "            st.warning(\"Bitte Kontext und Frage eingeben\")\n",
    "\n",
    "# Footer\n",
    "st.divider()\n",
    "st.caption(f\"Modern NLP Dashboard - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "'''\n",
    "\n",
    "# Streamlit App speichern\n",
    "with open('07_02_streamlit_nlp_dashboard.py', 'w') as f:\n",
    "    f.write(streamlit_nlp_app)\n",
    "\n",
    "print(\"üì± Streamlit NLP Dashboard erstellt!\")\n",
    "print(\"üìÑ Datei: 07_02_streamlit_nlp_dashboard.py\")\n",
    "print(\"\\nüöÄ Starten mit: streamlit run 07_02_streamlit_nlp_dashboard.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cff665",
   "metadata": {},
   "source": [
    "## üéØ Portfolio-Zusammenfassung: Modern NLP\n",
    "\n",
    "### üèÜ Erlernte F√§higkeiten\n",
    "\n",
    "1. **ü§ó Transformer Models** - State-of-the-art NLP mit Hugging Face\n",
    "2. **üî§ Multi-Task NLP** - Text Generation, Sentiment, Q&A\n",
    "3. **üåê NLP APIs** - Production-ready Services\n",
    "4. **üì± Interactive Dashboards** - User-friendly NLP Interfaces\n",
    "5. **üöÄ Modern Deployment** - Skalierbare NLP-Anwendungen\n",
    "\n",
    "### üìÅ Generierte Artefakte\n",
    "\n",
    "- **ü§ñ NLP Service Classes** - Wiederverwendbare Components\n",
    "- **üåê FastAPI Application** - REST API f√ºr NLP Tasks\n",
    "- **üì± Streamlit Dashboard** - Interactive NLP Interface\n",
    "\n",
    "### üöÄ Projektideen\n",
    "\n",
    "1. **üì∞ News Summarizer** - Automatische Artikel-Zusammenfassungen\n",
    "2. **üí¨ Chatbot Service** - Q&A System f√ºr Websites\n",
    "3. **üìä Social Media Monitor** - Sentiment Tracking\n",
    "4. **‚úçÔ∏è Creative Writing Assistant** - Text Generation Tool\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Portfolio-Tipp**: Modern NLP zeigt Ihre Kenntnisse aktueller AI-Technologien!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
