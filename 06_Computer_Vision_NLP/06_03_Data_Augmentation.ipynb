{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Nur Colab] Diese Zellen müssen nur auf *Google Colab* ausgeführt werden und installieren Packete und Daten\n",
    "!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n",
    "!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip\n",
    "!wget --quiet \"https://raw.githubusercontent.com/KI-Campus/AMALEA/master/Woche%205/utils.py\"\n",
    "\n",
    "# 🔧 Setup: Data Augmentation Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from scipy import signal, ndimage\n",
    "\n",
    "# Modern Augmentation Libraries\n",
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    ALBUMENTATIONS_AVAILABLE = True\n",
    "    print(\"✅ Albumentations verfügbar\")\n",
    "except ImportError:\n",
    "    ALBUMENTATIONS_AVAILABLE = False\n",
    "    print(\"⚠️  Albumentations nicht installiert\")\n",
    "\n",
    "try:\n",
    "    import imgaug.augmenters as iaa\n",
    "    IMGAUG_AVAILABLE = True\n",
    "    print(\"✅ ImgAug verfügbar\")\n",
    "except ImportError:\n",
    "    IMGAUG_AVAILABLE = False\n",
    "    print(\"⚠️  ImgAug nicht installiert\")\n",
    "\n",
    "# Interactive Widgets\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Streamlit (für Apps)\n",
    "import streamlit as st\n",
    "\n",
    "# Plotting Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Seeds for Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"🎨 Data Augmentation Setup abgeschlossen!\")\n",
    "print(f\"📊 TensorFlow: {tf.__version__}\")\n",
    "print(f\"🔢 NumPy: {np.__version__}\")\n",
    "\n",
    "# GPU Check\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"🚀 GPU verfügbar für Training!\")\n",
    "else:\n",
    "    print(\"💻 CPU wird verwendet\")\n",
    "\n",
    "# Memory Optimization für GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    try:\n",
    "        for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"🔧 GPU Memory Growth aktiviert\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"⚠️  GPU Konfiguration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎨 06.3 Data Augmentation - Künstliche Datenvergrößerung\n",
    "\n",
    "**Data Analytics & Big Data - Woche 6.3**  \n",
    "*IU Internationale Hochschule*\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Lernziele\n",
    "\n",
    "Nach diesem Notebook können Sie:\n",
    "- ✅ **Data Augmentation** verstehen und anwenden für robuste Modelle\n",
    "- ✅ **TensorFlow ImageDataGenerator** für automatische Augmentation nutzen\n",
    "- ✅ **Custom Augmentation** mit modernen Libraries (Albumentations, imgaug)\n",
    "- ✅ **Overfitting reduzieren** durch intelligente Datenvergrößerung\n",
    "- ✅ **CIFAR-10 CNN** optimieren mit verschiedenen Augmentation-Techniken\n",
    "- ✅ **Streamlit-App** für interaktive Augmentation-Experimente\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 Was ist Data Augmentation?\n",
    "\n",
    "**Data Augmentation** = Künstliche Vergrößerung des Datensatzes durch **Transformationen**\n",
    "\n",
    "### 💡 Warum brauchen wir das?\n",
    "\n",
    "1. **🔄 Mehr Trainingsdaten** ohne neue Bilder sammeln zu müssen\n",
    "2. **🛡️ Overfitting reduzieren** durch erhöhte Variabilität  \n",
    "3. **🎯 Robustheit steigern** gegen Rotation, Verschiebung, Beleuchtung\n",
    "4. **💰 Kostengünstig** - keine neuen Datensammlungen nötig\n",
    "\n",
    "### 🔧 Typische Augmentation-Techniken:\n",
    "\n",
    "- **🔄 Geometric:** Rotation, Flip, Crop, Zoom\n",
    "- **🎨 Photometric:** Brightness, Contrast, Saturation\n",
    "- **🌪️ Advanced:** Elastic Transforms, Cutout, Mixup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 CNN + Data Augmentation = Robuste Modelle\n",
    "\n",
    "### 🎯 Praxisprojekt: CIFAR-10 Klassifikation\n",
    "\n",
    "**CIFAR-10** ist ein klassischer Computer Vision Benchmark:\n",
    "- **10 Klassen:** Flugzeug, Auto, Vogel, Katze, Hirsch, Hund, Frosch, Pferd, Schiff, LKW\n",
    "- **60,000 Bilder:** 32×32×3 RGB \n",
    "- **Herausforderung:** Kleine Bilder, aber reale Objekte\n",
    "\n",
    "### 💡 Warum Data Augmentation bei CIFAR-10?\n",
    "\n",
    "1. **📊 Begrenzte Daten:** Nur 50,000 Trainingsbilder\n",
    "2. **🌍 Real-World Variabilität:** Objekte in verschiedenen Positionen/Lichtverhältnissen\n",
    "3. **🛡️ Overfitting Prevention:** CNNs neigen zum Auswendiglernen\n",
    "4. **🎯 Bessere Generalisierung:** Modell soll auch neue Bilder korrekt klassifizieren\n",
    "\n",
    "### 🔄 Unser Experimentaufbau:\n",
    "\n",
    "1. **Baseline CNN:** Ohne Augmentation\n",
    "2. **Augmented CNN:** Mit verschiedenen Transformationen\n",
    "3. **Advanced CNN:** Moderne Augmentation-Techniken\n",
    "4. **Vergleich:** Performance-Analyse und Interpretation\n",
    "\n",
    "### 📚 Learning Path:\n",
    "- **Setup & Data Loading** → **Baseline Model** → **Basic Augmentation** → **Advanced Techniques** → **Streamlit App**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For some convolving operations\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "\n",
    "# DeepLearning Library Keras\n",
    "# Documentation https://keras.io/\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Reshape\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import utils\n",
    "\n",
    "#define dataroot\n",
    "root = 'data/dataset/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT EDIT!\n",
    "# For specifiying training with autoencoder structure\n",
    "ae_specification = widgets.Text()\n",
    "old_spec = 'None'\n",
    "\n",
    "\n",
    "# Two Loggers, depending if loss or accuracy should be visualized\n",
    "Loss_Logger = utils.LossGraph('loss')\n",
    "Acc_Logger = utils.LossGraph('acc')\n",
    "\n",
    "# Size for some plots with matplotlib\n",
    "figure_inches = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar-10 Klassifikationsaufgabe\n",
    "Neben dem MNIST-Datensatz ist auch Cifar10 ein kleiner Datensatz, der in den Anfängen der CNNs verwendet wurde. Es gibt 10 verschiedene Klassen von einfachen Objekten oder Tieren. Die Bilder haben eine Größe von 32x32x3. In diesem Abschnitt sollten Sie ein gegebenes CNN tunen, um Bilder mit hoher Genauigkeit zu klassifizieren. \n",
    "\n",
    "Siehe auch: [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.1:</b> Laden Sie den Datensatz, legen Sie die Anzahl der Klassen fest, transformieren Sie die Beschriftungen und definieren Sie alle zugehörigen Klassen (wie z.B. Flugzeug,...) gemäß den Kommentaren in den Codezellen.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 CIFAR-10 Dataset laden und analysieren\n",
    "\n",
    "print(\"📥 Lade CIFAR-10 Dataset...\")\n",
    "\n",
    "# CIFAR-10 von Keras laden\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(\"✅ CIFAR-10 erfolgreich geladen!\")\n",
    "\n",
    "# Dataset Info\n",
    "print(f\"\\n📊 Dataset Übersicht:\")\n",
    "print(f\"   Training: {x_train.shape} Bilder, {y_train.shape} Labels\")\n",
    "print(f\"   Test: {x_test.shape} Bilder, {y_test.shape} Labels\")\n",
    "print(f\"   Bildformat: {x_train.shape[1:]} (Height × Width × Channels)\")\n",
    "print(f\"   Datentyp: {x_train.dtype}, Wertebereich: {x_train.min()} - {x_train.max()}\")\n",
    "\n",
    "# Speicher-Info\n",
    "train_size_mb = x_train.nbytes / (1024**2)\n",
    "test_size_mb = x_test.nbytes / (1024**2)\n",
    "print(f\"   Speicherbedarf: Train {train_size_mb:.1f} MB, Test {test_size_mb:.1f} MB\")\n",
    "\n",
    "# Klassenvariables definieren\n",
    "num_classes = 10\n",
    "classes = [\n",
    "    'Flugzeug',    # airplane\n",
    "    'Auto',        # automobile  \n",
    "    'Vogel',       # bird\n",
    "    'Katze',       # cat\n",
    "    'Hirsch',      # deer\n",
    "    'Hund',        # dog\n",
    "    'Frosch',      # frog\n",
    "    'Pferd',       # horse\n",
    "    'Schiff',      # ship\n",
    "    'LKW'          # truck\n",
    "]\n",
    "\n",
    "print(f\"\\n🏷️  Klassen ({num_classes}):\")\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_count = np.sum(y_train == i)\n",
    "    print(f\"   {i}: {class_name} ({class_count:,} Trainingsbilder)\")\n",
    "\n",
    "# Labels zu kategorischen Vektoren konvertieren\n",
    "y_train_categorical = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"\\n🔢 Label Transformation:\")\n",
    "print(f\"   Original: {y_train.shape} → Categorical: {y_train_categorical.shape}\")\n",
    "print(f\"   Beispiel: Label {y_train[0][0]} → {y_train_categorical[0]}\")\n",
    "\n",
    "# Daten normalisieren (0-255 → 0-1)\n",
    "print(f\"\\n🔧 Daten-Normalisierung...\")\n",
    "print(f\"   Vor Normalisierung: {x_train.min()} - {x_train.max()}\")\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"   Nach Normalisierung: {x_train.min():.3f} - {x_train.max():.3f}\")\n",
    "print(\"   ✅ Pixel-Werte jetzt zwischen 0 und 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many classes are in Cifar-10? \n",
    "# Hint: Name the variable \"num_classes = ...\"\n",
    "\n",
    "# STUDENT CODE HERE\n",
    "num_classes = 10\n",
    "\n",
    "# STUDENT CODE until HERE\n",
    "\n",
    "# 🎯 Baseline Modell: Training ohne Data Augmentation\n",
    "\n",
    "print(\"🏗️ Trainiere Baseline CNN (ohne Augmentation)...\")\n",
    "\n",
    "# Baseline Modell erstellen und trainieren\n",
    "baseline_model = create_baseline_cnn()\n",
    "\n",
    "# Training-Konfiguration\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Callbacks für besseres Training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint('models/baseline_best.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Baseline Training (ohne Augmentation)\n",
    "print(f\"\\n📚 Starte Training für {epochs} Epochen...\")\n",
    "baseline_history = baseline_model.fit(\n",
    "    x_train, y_train_categorical,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test_categorical),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Baseline Performance\n",
    "baseline_loss, baseline_acc = baseline_model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "print(f\"\\n📊 Baseline Ergebnisse:\")\n",
    "print(f\"   Test Accuracy: {baseline_acc:.4f} ({baseline_acc*100:.2f}%)\")\n",
    "print(f\"   Test Loss: {baseline_loss:.4f}\")\n",
    "\n",
    "# Training History visualisieren\n",
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    \"\"\"Visualisiert Training und Validation Metrics\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "    ax1.set_title(f'{title} - Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax2.set_title(f'{title} - Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(baseline_history, \"🎯 Baseline CNN (ohne Augmentation)\")\n",
    "\n",
    "print(\"✅ Baseline Training abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the labels into categorical vectors\n",
    "# Use the keras.utils.to_categorical function\n",
    "\n",
    "# Hint: \"y_train_categorical = ...\"\n",
    "# Hint2: \"y_test_categorical = ...\"\n",
    "\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE\n",
    "# 🎨 Modern Data Augmentation mit TensorFlow\n",
    "\n",
    "print(\"🎨 Data Augmentation Techniken implementieren...\")\n",
    "\n",
    "# TensorFlow Data Augmentation Pipeline\n",
    "def create_augmentation_pipeline():\n",
    "    \"\"\"\n",
    "    🔧 Erstellt moderne Augmentation Pipeline mit TensorFlow\n",
    "    \n",
    "    Techniken:\n",
    "    - Random Flip (horizontal)\n",
    "    - Random Rotation\n",
    "    - Random Zoom\n",
    "    - Random Translation\n",
    "    - Random Brightness\n",
    "    - Random Contrast\n",
    "    \"\"\"\n",
    "    augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "        tf.keras.layers.RandomZoom(0.2),\n",
    "        tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "        tf.keras.layers.RandomBrightness(0.2),\n",
    "        tf.keras.layers.RandomContrast(0.2),\n",
    "    ], name=\"augmentation\")\n",
    "    \n",
    "    return augmentation\n",
    "\n",
    "# Augmentation Pipeline erstellen\n",
    "augment = create_augmentation_pipeline()\n",
    "\n",
    "# Visualisierung der Augmentation\n",
    "def visualize_augmentation(image, num_augmentations=9):\n",
    "    \"\"\"\n",
    "    🖼️ Zeigt Original + augmentierte Versionen eines Bildes\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original Bild\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('🖼️ Original', fontsize=12, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmentierte Versionen\n",
    "    for i in range(2, num_augmentations + 1):\n",
    "        augmented = augment(tf.expand_dims(image, 0), training=True)\n",
    "        augmented = tf.squeeze(augmented, 0)\n",
    "        \n",
    "        plt.subplot(3, 3, i)\n",
    "        plt.imshow(augmented)\n",
    "        plt.title(f'🎨 Augmented {i-1}', fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('🎨 Data Augmentation Beispiele', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Beispiel-Visualisierung\n",
    "sample_image = x_train[42]  # Zufälliges Bild auswählen\n",
    "sample_label = classes[y_train[42][0]]\n",
    "\n",
    "print(f\"🖼️ Augmentation Beispiel für: {sample_label}\")\n",
    "visualize_augmentation(sample_image)\n",
    "\n",
    "print(\"✅ Data Augmentation Pipeline erstellt!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What classes are there? Define them in a list of strings named classes.\n",
    "# Hint: Call the list of strings \"classes = ...\"\n",
    "\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE\n",
    "# 🎮 Interactive Data Augmentation Explorer\n",
    "\n",
    "def interactive_augmentation_explorer():\n",
    "    \"\"\"\n",
    "    🎮 Interaktiver Widget für Augmentation-Parameter\n",
    "    \"\"\"\n",
    "    print(\"🎮 Interaktiver Data Augmentation Explorer\")\n",
    "    print(\"🔧 Experimentieren Sie mit verschiedenen Parametern!\")\n",
    "    \n",
    "    # Widget-Steuerungen\n",
    "    image_selector = widgets.IntSlider(\n",
    "        value=42, min=0, max=100, step=1,\n",
    "        description='Bild Index:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    rotation_factor = widgets.FloatSlider(\n",
    "        value=0.2, min=0.0, max=0.5, step=0.1,\n",
    "        description='Rotation:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    zoom_factor = widgets.FloatSlider(\n",
    "        value=0.2, min=0.0, max=0.4, step=0.1,\n",
    "        description='Zoom:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    brightness_factor = widgets.FloatSlider(\n",
    "        value=0.2, min=0.0, max=0.4, step=0.1,\n",
    "        description='Helligkeit:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    contrast_factor = widgets.FloatSlider(\n",
    "        value=0.2, min=0.0, max=0.4, step=0.1,\n",
    "        description='Kontrast:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def update_augmentation(image_idx, rotation, zoom, brightness, contrast):\n",
    "        \"\"\"Update Augmentation basierend auf Widget-Werten\"\"\"\n",
    "        # Custom Augmentation Pipeline erstellen\n",
    "        custom_augment = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "            tf.keras.layers.RandomRotation(rotation),\n",
    "            tf.keras.layers.RandomZoom(zoom),\n",
    "            tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "            tf.keras.layers.RandomBrightness(brightness),\n",
    "            tf.keras.layers.RandomContrast(contrast),\n",
    "        ])\n",
    "        \n",
    "        # Bild auswählen\n",
    "        original_image = x_train[image_idx]\n",
    "        label = classes[y_train[image_idx][0]]\n",
    "        \n",
    "        # Augmentierte Versionen erstellen\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        \n",
    "        # Original\n",
    "        axes[0, 0].imshow(original_image)\n",
    "        axes[0, 0].set_title(f'🖼️ Original\\n{label}', fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Augmentierte Versionen\n",
    "        for i, ax in enumerate(axes.flat[1:]):\n",
    "            augmented = custom_augment(tf.expand_dims(original_image, 0), training=True)\n",
    "            augmented = tf.squeeze(augmented, 0)\n",
    "            \n",
    "            ax.imshow(augmented)\n",
    "            ax.set_title(f'🎨 Augmented {i+1}')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'🎮 Interaktive Augmentation - {label}', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Parameter-Info\n",
    "        print(f\"🔧 Aktuelle Parameter:\")\n",
    "        print(f\"   Rotation: {rotation:.1f}\")\n",
    "        print(f\"   Zoom: {zoom:.1f}\")  \n",
    "        print(f\"   Helligkeit: {brightness:.1f}\")\n",
    "        print(f\"   Kontrast: {contrast:.1f}\")\n",
    "    \n",
    "    # Interactive Widget\n",
    "    interact(update_augmentation,\n",
    "             image_idx=image_selector,\n",
    "             rotation=rotation_factor,\n",
    "             zoom=zoom_factor,\n",
    "             brightness=brightness_factor,\n",
    "             contrast=contrast_factor)\n",
    "\n",
    "# Widget anzeigen\n",
    "interactive_augmentation_explorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.2:</b> Prüfen Sie, ob Sie alles wie gewünscht definiert haben.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🖼️ CIFAR-10 Dataset Exploration\n",
    "\n",
    "print(\"🔍 CIFAR-10 Bilder visualisieren...\")\n",
    "\n",
    "# Zufällige Samples aus jeder Klasse auswählen\n",
    "def plot_class_samples(num_samples=5):\n",
    "    \"\"\"\n",
    "    Zeigt zufällige Samples aus jeder CIFAR-10 Klasse\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(num_classes, num_samples, figsize=(15, 20))\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        # Finde alle Bilder dieser Klasse\n",
    "        class_indices = np.where(y_train.flatten() == class_idx)[0]\n",
    "        \n",
    "        # Wähle zufällige Samples\n",
    "        random_indices = np.random.choice(class_indices, num_samples, replace=False)\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            img_idx = random_indices[sample_idx]\n",
    "            image = x_train[img_idx]\n",
    "            \n",
    "            # Plot\n",
    "            axes[class_idx, sample_idx].imshow(image)\n",
    "            axes[class_idx, sample_idx].axis('off')\n",
    "            \n",
    "            # Titel nur für erste Spalte\n",
    "            if sample_idx == 0:\n",
    "                axes[class_idx, sample_idx].set_ylabel(\n",
    "                    f'{class_idx}: {classes[class_idx]}', \n",
    "                    fontsize=12, fontweight='bold'\n",
    "                )\n",
    "    \n",
    "    plt.suptitle('🖼️ CIFAR-10 Klassen-Übersicht', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualisierung ausführen\n",
    "plot_class_samples(num_samples=8)\n",
    "\n",
    "# Einzelnes Bild detailliert analysieren\n",
    "sample_idx = 6\n",
    "sample_image = x_train[sample_idx]\n",
    "sample_label = y_train[sample_idx][0]\n",
    "sample_class = classes[sample_label]\n",
    "\n",
    "print(f\"\\n🔍 Detailanalyse Beispielbild:\")\n",
    "print(f\"   Index: {sample_idx}\")\n",
    "print(f\"   Klasse: {sample_label} ({sample_class})\")\n",
    "print(f\"   Shape: {sample_image.shape}\")\n",
    "print(f\"   Pixel-Bereich: {sample_image.min():.3f} - {sample_image.max():.3f}\")\n",
    "\n",
    "# Einzelbild + Histogramm\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Original Bild\n",
    "axes[0].imshow(sample_image)\n",
    "axes[0].set_title(f'🖼️ {sample_class}', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# RGB Kanäle einzeln\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i, color in enumerate(colors):\n",
    "    axes[i+1].imshow(sample_image[:,:,i], cmap=color)\n",
    "    axes[i+1].set_title(f'{color.upper()} Kanal', fontsize=12)\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Klassen-Verteilung\n",
    "print(f\"\\n📊 Klassen-Verteilung im Trainingsdatensatz:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(num_classes), counts, color=plt.cm.tab10(range(num_classes)))\n",
    "plt.xlabel('Klasse')\n",
    "plt.ylabel('Anzahl Bilder')\n",
    "plt.title('📊 CIFAR-10 Klassen-Verteilung', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(num_classes), [f'{i}\\n{classes[i]}' for i in range(num_classes)], rotation=45)\n",
    "\n",
    "# Zahlen auf Balken\n",
    "for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "             f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Dataset-Exploration abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.3:</b> Suchen Sie ein Bild eines Pferdes und plotten Sie es mit dem Code oben. Sie können die gleiche Code-Zelle verwenden.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.4:</b> Preprocessen Sie die Daten, um Werte zwischen 0 und 1 zu gewährleisten. Dividieren Sie dazu die rgb-Werte durch ihren Maximalwert.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Divide RGB values of train AND test set \n",
    "# by their maximum value to ensure values between [0,1]\n",
    "\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE\n",
    "\n",
    "# 🚀 Advanced Data Augmentation Techniques\n",
    "\n",
    "print(\"🚀 Advanced Augmentation Techniken implementieren...\")\n",
    "\n",
    "# Custom Advanced Augmentation Functions\n",
    "def cutout(image, size=8):\n",
    "    \"\"\"\n",
    "    ✂️ Cutout: Zufällige Rechtecke im Bild ausschneiden\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    y = np.random.randint(h)\n",
    "    x = np.random.randint(w)\n",
    "    \n",
    "    y1 = np.clip(y - size // 2, 0, h)\n",
    "    y2 = np.clip(y + size // 2, 0, h)\n",
    "    x1 = np.clip(x - size // 2, 0, w)\n",
    "    x2 = np.clip(x + size // 2, 0, w)\n",
    "    \n",
    "    image_cutout = image.copy()\n",
    "    image_cutout[y1:y2, x1:x2] = 0\n",
    "    return image_cutout\n",
    "\n",
    "def mixup(x1, x2, y1, y2, alpha=0.2):\n",
    "    \"\"\"\n",
    "    🌪️ MixUp: Lineare Interpolation zwischen zwei Bildern\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    x_mixed = lam * x1 + (1 - lam) * x2\n",
    "    y_mixed = lam * y1 + (1 - lam) * y2\n",
    "    return x_mixed, y_mixed\n",
    "\n",
    "def elastic_transform(image, alpha=50, sigma=5):\n",
    "    \"\"\"\n",
    "    🌊 Elastic Transform: Elastische Verzerrung\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "    \n",
    "    shape = image.shape[:2]\n",
    "    dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    \n",
    "    y, x = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "    \n",
    "    transformed = np.zeros_like(image)\n",
    "    for i in range(image.shape[2]):\n",
    "        transformed[:,:,i] = map_coordinates(\n",
    "            image[:,:,i], indices, order=1, mode='reflect'\n",
    "        ).reshape(shape)\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "# Advanced Augmentation Demonstrationen\n",
    "print(\"🎨 Advanced Augmentation Beispiele:\")\n",
    "\n",
    "# Beispielbild auswählen\n",
    "sample_idx = 123\n",
    "original_image = x_train[sample_idx]\n",
    "label = classes[y_train[sample_idx][0]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(original_image)\n",
    "axes[0, 0].set_title(f'🖼️ Original\\n{label}', fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Standard Augmentations\n",
    "standard_augmented = augment(tf.expand_dims(original_image, 0), training=True)\n",
    "standard_augmented = tf.squeeze(standard_augmented, 0)\n",
    "axes[0, 1].imshow(standard_augmented)\n",
    "axes[0, 1].set_title('🔄 Standard\\nAugmentation')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Cutout\n",
    "cutout_image = cutout(original_image)\n",
    "axes[0, 2].imshow(cutout_image)\n",
    "axes[0, 2].set_title('✂️ Cutout')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Elastic Transform\n",
    "try:\n",
    "    elastic_image = elastic_transform(original_image)\n",
    "    axes[0, 3].imshow(elastic_image)\n",
    "    axes[0, 3].set_title('🌊 Elastic\\nTransform')\n",
    "except:\n",
    "    axes[0, 3].imshow(original_image)\n",
    "    axes[0, 3].set_title('🌊 Elastic\\n(nicht verfügbar)')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# MixUp Beispiel\n",
    "sample_idx2 = 456\n",
    "image2 = x_train[sample_idx2]\n",
    "label2 = classes[y_train[sample_idx2][0]]\n",
    "y1_cat = y_train_categorical[sample_idx]\n",
    "y2_cat = y_train_categorical[sample_idx2]\n",
    "\n",
    "mixed_image, mixed_label = mixup(original_image, image2, y1_cat, y2_cat)\n",
    "axes[1, 0].imshow(image2)\n",
    "axes[1, 0].set_title(f'🖼️ Bild 2\\n{label2}')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(mixed_image)\n",
    "axes[1, 1].set_title('🌪️ MixUp\\nKombination')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Kombinierte Augmentations\n",
    "combined_augmented = augment(tf.expand_dims(cutout_image, 0), training=True)\n",
    "combined_augmented = tf.squeeze(combined_augmented, 0)\n",
    "axes[1, 2].imshow(combined_augmented)\n",
    "axes[1, 2].set_title('🎨 Kombiniert\\nCutout + Standard')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "# Extreme Augmentation\n",
    "extreme_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.4),\n",
    "    tf.keras.layers.RandomZoom(0.3),\n",
    "    tf.keras.layers.RandomTranslation(0.3, 0.3),\n",
    "    tf.keras.layers.RandomBrightness(0.3),\n",
    "    tf.keras.layers.RandomContrast(0.3),\n",
    "])\n",
    "extreme_augmented = extreme_augment(tf.expand_dims(original_image, 0), training=True)\n",
    "extreme_augmented = tf.squeeze(extreme_augmented, 0)\n",
    "axes[1, 3].imshow(extreme_augmented)\n",
    "axes[1, 3].set_title('🔥 Extreme\\nAugmentation')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.suptitle('🚀 Advanced Data Augmentation Techniken', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Advanced Augmentation Techniken demonstriert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.5:</b> Wie viele Trainings- und Testdaten gibt es?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.6:</b> Warum Daten normalisieren?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.7:</b> Warum wird ein kategorischer Vektor an Stelle eines einzelnen Outputs verwendet?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikationsmodelle für Cifar-10\n",
    "\n",
    "### Neuronales Netzwerk Klassifikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "num_classes = 10  # Assuming CIFAR-10 with 10 classes\n",
    "\n",
    "# 🏗️ CNN Modell-Definitionen für CIFAR-10\n",
    "\n",
    "def create_baseline_cnn() -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    🎯 Baseline CNN ohne Data Augmentation\n",
    "    \n",
    "    Einfache CNN-Architektur für CIFAR-10:\n",
    "    - 2 Conv2D + MaxPooling Blocks\n",
    "    - Dense Layer mit Dropout\n",
    "    - Softmax für 10 Klassen\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # Input Layer\n",
    "        tf.keras.layers.Input(shape=(32, 32, 3), name='input'),\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn1'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn2'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn3'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool3'),\n",
    "        \n",
    "        # Dense Layers\n",
    "        tf.keras.layers.Flatten(name='flatten'),\n",
    "        tf.keras.layers.Dense(512, activation='relu', name='dense1'),\n",
    "        tf.keras.layers.Dropout(0.5, name='dropout1'),\n",
    "        tf.keras.layers.Dense(256, activation='relu', name='dense2'),\n",
    "        tf.keras.layers.Dropout(0.3, name='dropout2'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', name='output')\n",
    "    ], name='BaselineCNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_advanced_cnn() -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    🚀 Advanced CNN mit modernen Techniken\n",
    "    \n",
    "    Verbesserungen:\n",
    "    - Mehr Convolutional Layers\n",
    "    - Residual-ähnliche Verbindungen\n",
    "    - Global Average Pooling\n",
    "    - Bessere Regularisierung\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3), name='input')\n",
    "    \n",
    "    # Block 1\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='AdvancedCNN')\n",
    "    return model\n",
    "\n",
    "# Modelle erstellen und anzeigen\n",
    "print(\"🏗️ CNN-Modelle erstellen...\")\n",
    "\n",
    "baseline_model = create_baseline_cnn()\n",
    "advanced_model = create_advanced_cnn()\n",
    "\n",
    "print(\"\\n📊 Baseline CNN Architektur:\")\n",
    "baseline_model.summary()\n",
    "\n",
    "print(\"\\n📊 Advanced CNN Architektur:\")\n",
    "advanced_model.summary()\n",
    "\n",
    "# Parameter-Vergleich\n",
    "baseline_params = baseline_model.count_params()\n",
    "advanced_params = advanced_model.count_params()\n",
    "\n",
    "print(f\"\\n🔢 Parameter-Vergleich:\")\n",
    "print(f\"   Baseline CNN: {baseline_params:,} Parameter\")\n",
    "print(f\"   Advanced CNN: {advanced_params:,} Parameter\")\n",
    "print(f\"   Differenz: {advanced_params - baseline_params:,} Parameter (+{((advanced_params/baseline_params)-1)*100:.1f}%)\")\n",
    "\n",
    "# Compile Models\n",
    "baseline_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "advanced_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Modelle erfolgreich erstellt und kompiliert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Klassifikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn()->Model:\n",
    "    \n",
    "    input_layer = Input(shape = x_train.shape[1:], name='Input_CNN') # channels last\n",
    "    \n",
    "    conv1 = Conv2D(filters= 16, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv1')(input_layer)\n",
    "    max_pool1 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool1')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv2')(max_pool1)\n",
    "    max_pool2 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool2')(conv2)\n",
    "\n",
    "    flattened = Flatten(name='Flatt_CNN')(max_pool2)\n",
    "    \n",
    "    fc1 = Dense(256, activation = 'relu', name='FC-1')(flattened)\n",
    "    \n",
    "    output = Dense(num_classes, activation = 'softmax', name='Output_CNN')(fc1)\n",
    "    \n",
    "    model = Model(inputs= input_layer, outputs = output)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich von MLP und CNN Klassifikatoren:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.8:</b> Um die Bilder in Cifar-10 zu klassifizieren, verwenden Sie die gegebenen MLP- und CNN-Modelle, um zu untersuchen, welches besser abschneidet.\n",
    "Trainieren Sie beide Netzwerke für 10 Epochen und schauen Sie sich die Ergebnisse an.\n",
    "Fühlen Sie sich frei, den Code in den beiden Code-Zellen unten zu verwenden und zu ändern. Wenn Ihr Netzwerk nicht trainiert, haben Sie möglicherweise die rgb-Werte nicht richtig aufbereitet (z. B. haben Sie nicht normalisiert oder zu oft).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Hinweis:</b> Aufbau der folgenden Codezellen\n",
    "<ul>\n",
    "<li> Benutzen Sie die vordefinierten Funktionen, um Ihr Modell zu erstellen\n",
    "<li> Definieren Sie den gemeinsamen TensorBoard-Logger mit der Konfiguration, um die Trainingsergebnisse später zu betrachten\n",
    "<li> Kompillieren und trainieren Sie das Modell\n",
    "<li> Tipp: Wenn Ihre Modelle nichts Lernen, überprüfen Sie Ihre Datennormalisierung. Vielleicht haben Sie Ihre Daten nicht oder zu oft normalisiert.\n",
    "</li>\n",
    "\n",
    "\n",
    "</ul>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 CNN Training mit Data Augmentation\n",
    "\n",
    "print(\"🎯 Trainiere CNN mit Data Augmentation...\")\n",
    "\n",
    "# Augmented Model erstellen (mit integrierter Augmentation)\n",
    "def create_augmented_cnn():\n",
    "    \"\"\"\n",
    "    🎨 CNN mit integrierter Data Augmentation\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3), name='input')\n",
    "    \n",
    "    # Data Augmentation Layer (nur während Training aktiv)\n",
    "    x = augment(inputs, training=True)\n",
    "    \n",
    "    # CNN Architecture (gleich wie Baseline für fairen Vergleich)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn1')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn2')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn3')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool3')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', name='dense1')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5, name='dropout1')(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu', name='dense2')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='dropout2')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='AugmentedCNN')\n",
    "    return model\n",
    "\n",
    "# Augmented Model erstellen und kompilieren\n",
    "augmented_model = create_augmented_cnn()\n",
    "augmented_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Augmented CNN Architektur:\")\n",
    "augmented_model.summary()\n",
    "\n",
    "# Training mit Augmentation\n",
    "print(f\"\\n📚 Starte Training mit Data Augmentation für {epochs} Epochen...\")\n",
    "\n",
    "# Callbacks für besseres Training\n",
    "callbacks_aug = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('models/augmented_best.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Training\n",
    "augmented_history = augmented_model.fit(\n",
    "    x_train, y_train_categorical,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test_categorical),\n",
    "    callbacks=callbacks_aug,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Augmented Performance\n",
    "augmented_loss, augmented_acc = augmented_model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "\n",
    "print(f\"\\n📊 Augmented CNN Ergebnisse:\")\n",
    "print(f\"   Test Accuracy: {augmented_acc:.4f} ({augmented_acc*100:.2f}%)\")\n",
    "print(f\"   Test Loss: {augmented_loss:.4f}\")\n",
    "\n",
    "# Training History visualisieren\n",
    "plot_training_history(augmented_history, \"🎨 Augmented CNN\")\n",
    "\n",
    "print(\"✅ Augmented Training abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Neural Network (MLP)\n",
    "nn_model = model_nn()\n",
    "config_cnn = 'UNRECOGNIZEABLE_NAME_EDIT_ME_PLEASE' # Give a recognizable name\n",
    "\n",
    "# The TensorBoard is a feature of tensorflow for the visualization of the training process \n",
    "cnn_logger = TensorBoard(log_dir='logs/cnn_logs/'+config_cnn+'/') \n",
    "\n",
    "nn_model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n",
    "nn_model.fit(x_train, y_train_categorical, batch_size = 64, epochs = 1, \n",
    "            validation_data = (x_test, y_test_categorical), callbacks = [cnn_logger, Acc_Logger]) #TODO\n",
    "\n",
    "# 📊 Model Performance Vergleich\n",
    "\n",
    "print(\"📊 Vergleiche Performance verschiedener Modelle...\")\n",
    "\n",
    "# Performance Metriken sammeln\n",
    "models_performance = {\n",
    "    'Baseline CNN (ohne Augmentation)': {\n",
    "        'accuracy': baseline_acc,\n",
    "        'loss': baseline_loss,\n",
    "        'history': baseline_history\n",
    "    },\n",
    "    'Augmented CNN (mit Augmentation)': {\n",
    "        'accuracy': augmented_acc,\n",
    "        'loss': augmented_loss,\n",
    "        'history': augmented_history\n",
    "    }\n",
    "}\n",
    "\n",
    "# Performance-Tabelle\n",
    "print(\"📋 Performance Übersicht:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Modell':<35} {'Accuracy':<12} {'Loss':<12} {'Improvement'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_accuracy = models_performance['Baseline CNN (ohne Augmentation)']['accuracy']\n",
    "for model_name, metrics in models_performance.items():\n",
    "    accuracy = metrics['accuracy']\n",
    "    loss = metrics['loss']\n",
    "    improvement = ((accuracy / baseline_accuracy) - 1) * 100\n",
    "    improvement_str = f\"+{improvement:.2f}%\" if improvement > 0 else f\"{improvement:.2f}%\"\n",
    "    \n",
    "    print(f\"{model_name:<35} {accuracy:.4f} ({accuracy*100:.2f}%)  {loss:.4f}      {improvement_str}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualisierung der Performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Accuracy Vergleich\n",
    "model_names = list(models_performance.keys())\n",
    "accuracies = [models_performance[name]['accuracy'] for name in model_names]\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "\n",
    "bars = axes[0, 0].bar(range(len(model_names)), accuracies, color=colors, alpha=0.8)\n",
    "axes[0, 0].set_title('📊 Test Accuracy Vergleich', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_xticks(range(len(model_names)))\n",
    "axes[0, 0].set_xticklabels([name.split(' (')[0] for name in model_names], rotation=45)\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{acc:.3f}\\n({acc*100:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Loss Vergleich\n",
    "losses = [models_performance[name]['loss'] for name in model_names]\n",
    "bars = axes[0, 1].bar(range(len(model_names)), losses, color=colors, alpha=0.8)\n",
    "axes[0, 1].set_title('📉 Test Loss Vergleich', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_xticks(range(len(model_names)))\n",
    "axes[0, 1].set_xticklabels([name.split(' (')[0] for name in model_names], rotation=45)\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for bar, loss in zip(bars, losses):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{loss:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training History Vergleich - Accuracy\n",
    "for i, (name, metrics) in enumerate(models_performance.items()):\n",
    "    history = metrics['history']\n",
    "    epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "    label = name.split(' (')[0]\n",
    "    axes[1, 0].plot(epochs_range, history.history['val_accuracy'], \n",
    "                   label=f'{label} Validation', marker='o', color=colors[i], linewidth=2)\n",
    "    axes[1, 0].plot(epochs_range, history.history['accuracy'], \n",
    "                   label=f'{label} Training', linestyle='--', color=colors[i], alpha=0.7)\n",
    "\n",
    "axes[1, 0].set_title('📈 Training Accuracy Verlauf', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Training History Vergleich - Loss\n",
    "for i, (name, metrics) in enumerate(models_performance.items()):\n",
    "    history = metrics['history']\n",
    "    epochs_range = range(1, len(history.history['loss']) + 1)\n",
    "    label = name.split(' (')[0]\n",
    "    axes[1, 1].plot(epochs_range, history.history['val_loss'], \n",
    "                   label=f'{label} Validation', marker='o', color=colors[i], linewidth=2)\n",
    "    axes[1, 1].plot(epochs_range, history.history['loss'], \n",
    "                   label=f'{label} Training', linestyle='--', color=colors[i], alpha=0.7)\n",
    "\n",
    "axes[1, 1].set_title('📉 Training Loss Verlauf', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse der Verbesserung\n",
    "improvement_pct = ((augmented_acc / baseline_acc) - 1) * 100\n",
    "print(f\"\\n🎯 Analyse der Verbesserung durch Data Augmentation:\")\n",
    "print(f\"   Accuracy Verbesserung: +{improvement_pct:.2f}%\")\n",
    "print(f\"   Absolute Verbesserung: +{(augmented_acc - baseline_acc)*100:.2f} Prozentpunkte\")\n",
    "\n",
    "if improvement_pct > 2:\n",
    "    print(\"   ✅ Signifikante Verbesserung durch Augmentation!\")\n",
    "elif improvement_pct > 0:\n",
    "    print(\"   📊 Moderate Verbesserung durch Augmentation\")\n",
    "else:\n",
    "    print(\"   ⚠️  Keine Verbesserung - möglicherweise Überaugmentation\")\n",
    "\n",
    "print(\"\\n🔍 Mögliche Gründe für Performance-Unterschiede:\")\n",
    "print(\"   • Data Augmentation reduziert Overfitting\")\n",
    "print(\"   • Mehr Variabilität in Trainingsdaten\")\n",
    "print(\"   • Bessere Generalisierung auf neue Bilder\")\n",
    "print(\"   • Robustheit gegen Rotation, Translation, etc.\")\n",
    "\n",
    "print(\"✅ Model Vergleich abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.9:</b> Verwenden Sie TensorBoard, um Ihren Trainingsfortschritt zu kontrollieren. Eine Erklärung, wie Sie Ihr TensorBoard öffnen, finden Sie hier:\n",
    "    <a href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/r1/summaries.md\">TensorBoard</a>  (unten auf der Webseite)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN\n",
    "%load_ext tensorboard\n",
    "cnn_model = model_cnn()\n",
    "config_cnn = 'UNRECOGNIZEABLE_NAME_EDIT_ME_PLEASE' # give a recognizable name\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n",
    "cnn_model.fit(x_train, y_train_categorical, batch_size = 32, epochs = 1, \n",
    "          validation_data = (x_test, y_test_categorical), callbacks = [Acc_Logger], verbose = 1)\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.10:</b> Welches Netzwerk performt besser?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.11:</b> Wie viele Parameter haben die Netze? Verwenden Sie dazu die summary Methode (siehe Keras-Docs)...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.12:</b> Wo sind die meisten Parameter in diesem CNN gespeichert?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge: Optimieren Sie Ihr Network! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.13:</b> Versuchen Sie, eines der Modelle so zu verbessern, dass Ihre Validierungsgenauigkeit einmal höher als 0,75 Prozent ist!\n",
    "\n",
    "<ul>\n",
    "<li>Hinweis: Versuchen Sie, zuerst zu overfitten und dann zu regulieren. \n",
    "<li>Hinweis 2: Verwenden Sie daher L1/L2 - Regularisierung und/oder Dropout. Auch BatchNormalization könnte die Sache verbessern. Schauen Sie deshalb auf der Keras-Website nach Beispielen oder fragen Sie Tutoren.\n",
    "<li>Hinweis 3: Verwenden Sie eine der Funktionen <code>def model_nn()</code> oder <code>def model_cnn()</code> von oben. Viel Spaß und gutes Gelingen!\n",
    "\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten Augmentation\n",
    "\n",
    "Eine weitere Möglichkeit, Ihr Netzwerk zu regularisieren, ist das Vergrößern der Trainingsdaten. Verwenden Sie dazu den ImageDataGenerator von Keras. Wir werden später selbst Bilder verschieben und drehen, nachdem wir auf Cifar-10 optimiert haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Professional Data Augmentation mit Albumentations\n",
    "\n",
    "if ALBUMENTATIONS_AVAILABLE:\n",
    "    print(\"🚀 Albumentations - Professional Augmentation Library\")\n",
    "    \n",
    "    # Albumentations Pipeline definieren\n",
    "    albumentations_transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "        A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "        A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.3),\n",
    "    ])\n",
    "    \n",
    "    # Albumentations Demonstration\n",
    "    def demonstrate_albumentations():\n",
    "        \"\"\"Zeigt Albumentations Augmentationen\"\"\"\n",
    "        sample_image = x_train[99]\n",
    "        # Pixel-Werte zurück zu 0-255 für Albumentations\n",
    "        sample_image_uint8 = (sample_image * 255).astype(np.uint8)\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "        \n",
    "        # Original\n",
    "        axes[0, 0].imshow(sample_image)\n",
    "        axes[0, 0].set_title('🖼️ Original', fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Albumentations Augmentationen\n",
    "        for i, ax in enumerate(axes.flat[1:]):\n",
    "            augmented = albumentations_transform(image=sample_image_uint8)['image']\n",
    "            augmented_normalized = augmented.astype(np.float32) / 255.0\n",
    "            \n",
    "            ax.imshow(augmented_normalized)\n",
    "            ax.set_title(f'🚀 Albumentations {i+1}')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle('🚀 Professional Augmentation mit Albumentations', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    demonstrate_albumentations()\n",
    "    \n",
    "    # Albumentations Wrapper für TensorFlow\n",
    "    def albumentations_wrapper(image):\n",
    "        \"\"\"TensorFlow-kompatible Albumentations Funktion\"\"\"\n",
    "        def apply_albumentations(img):\n",
    "            img_uint8 = (img * 255).astype(np.uint8)\n",
    "            augmented = albumentations_transform(image=img_uint8)['image']\n",
    "            return augmented.astype(np.float32) / 255.0\n",
    "        \n",
    "        return tf.py_function(apply_albumentations, [image], tf.float32)\n",
    "    \n",
    "    print(\"✅ Albumentations Pipeline erstellt!\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️  Albumentations nicht verfügbar - verwende TensorFlow Augmentation\")\n",
    "    \n",
    "    # Fallback: Erweiterte TensorFlow Augmentation\n",
    "    professional_augment = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.3),\n",
    "        tf.keras.layers.RandomZoom(0.2),\n",
    "        tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "        tf.keras.layers.RandomBrightness(0.2),\n",
    "        tf.keras.layers.RandomContrast(0.2),\n",
    "        # Custom Augmentations können hier hinzugefügt werden\n",
    "    ], name=\"professional_augmentation\")\n",
    "    \n",
    "    # Professional Augmentation Demonstration\n",
    "    sample_image = x_train[99]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    \n",
    "    # Original\n",
    "    axes[0, 0].imshow(sample_image)\n",
    "    axes[0, 0].set_title('🖼️ Original', fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Professional Augmentationen\n",
    "    for i, ax in enumerate(axes.flat[1:]):\n",
    "        augmented = professional_augment(tf.expand_dims(sample_image, 0), training=True)\n",
    "        augmented = tf.squeeze(augmented, 0)\n",
    "        \n",
    "        ax.imshow(augmented)\n",
    "        ax.set_title(f'🚀 Professional {i+1}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('🚀 Professional Augmentation mit TensorFlow', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Professional TensorFlow Augmentation Pipeline erstellt!\")\n",
    "\n",
    "# Augmentation Strategy Vergleich\n",
    "print(\"\\n📊 Augmentation Strategy Übersicht:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Strategy':<25} {'Library':<15} {'Komplexität':<15} {'Performance'}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Basic TensorFlow':<25} {'TensorFlow':<15} {'Niedrig':<15} {'Gut'}\")\n",
    "print(f\"{'Advanced TensorFlow':<25} {'TensorFlow':<15} {'Mittel':<15} {'Sehr gut'}\")\n",
    "if ALBUMENTATIONS_AVAILABLE:\n",
    "    print(f\"{'Albumentations':<25} {'Albumentations':<15} {'Hoch':<15} {'Exzellent'}\")\n",
    "print(f\"{'Custom Functions':<25} {'Custom':<15} {'Sehr hoch':<15} {'Variabel'}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n✅ Professional Augmentation Setup abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eine etwas noch herausfordernde Challenge ((COOKIE AUFGABE! :)))\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.14:</b> Verbessern Sie Ihr Modell und passen Sie es an, wie genau kann es jetzt werden?\n",
    "Die Lösung ist in der Lage, eine Genauigkeit von 0,8894 bei der Validierung zu erreichen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn_aug()->Model:\n",
    "\n",
    "    input_layer = Input(shape = x_train.shape[1:], name='Input_CNN') # channels last\n",
    "    \n",
    "    conv1 = Conv2D(filters= 16, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv1')(input_layer)\n",
    "    max_pool1 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool1')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv2')(max_pool1)\n",
    "    max_pool2 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool2')(conv2)\n",
    "\n",
    "    flattened = Flatten(name='Flatt_CNN')(max_pool2)\n",
    "    \n",
    "    fc1 = Dense(256, activation = 'relu', name='FC-1')(flattened)\n",
    "    \n",
    "    output = Dense(num_classes, activation = 'softmax', name='Output_CNN')(fc1)\n",
    "    \n",
    "    model = Model(inputs= input_layer, outputs = output)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "# 🏆 Final Model: Best Practice CNN mit optimaler Augmentation\n",
    "\n",
    "print(\"🏆 Erstelle Final Model mit Best Practices...\")\n",
    "\n",
    "def create_final_cnn():\n",
    "    \"\"\"\n",
    "    🏆 Final CNN mit allen Best Practices:\n",
    "    - Optimale Augmentation\n",
    "    - Moderne Architektur\n",
    "    - Bessere Regularisierung\n",
    "    - Optimierte Hyperparameter\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3), name='input')\n",
    "    \n",
    "    # Optimierte Augmentation (nur während Training)\n",
    "    if ALBUMENTATIONS_AVAILABLE:\n",
    "        # Hier würde Albumentations integriert werden\n",
    "        x = augment(inputs, training=True)\n",
    "    else:\n",
    "        x = augment(inputs, training=True)\n",
    "    \n",
    "    # Improved CNN Architecture\n",
    "    # Block 1\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 2  \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Block 4 (Additional)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense Layers\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='FinalCNN')\n",
    "    return model\n",
    "\n",
    "# Final Model erstellen\n",
    "final_model = create_final_cnn()\n",
    "\n",
    "# Optimierte Compilation\n",
    "final_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'top_3_accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Final CNN Architektur:\")\n",
    "final_model.summary()\n",
    "\n",
    "# Advanced Callbacks\n",
    "final_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=7, \n",
    "        restore_best_weights=True, \n",
    "        monitor='val_accuracy'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5, \n",
    "        patience=4, \n",
    "        min_lr=1e-7,\n",
    "        monitor='val_accuracy'\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'models/final_best.h5', \n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Final Training\n",
    "print(f\"\\n🎯 Final Training für bis zu {epochs} Epochen...\")\n",
    "final_history = final_model.fit(\n",
    "    x_train, y_train_categorical,\n",
    "    batch_size=32,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test_categorical),\n",
    "    callbacks=final_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Final Evaluation\n",
    "final_loss, final_acc, final_top3 = final_model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "\n",
    "print(f\"\\n🏆 Final Model Ergebnisse:\")\n",
    "print(f\"   Test Accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\")\n",
    "print(f\"   Top-3 Accuracy: {final_top3:.4f} ({final_top3*100:.2f}%)\")\n",
    "print(f\"   Test Loss: {final_loss:.4f}\")\n",
    "\n",
    "# Final Comparison\n",
    "print(f\"\\n📊 Gesamt-Vergleich aller Modelle:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Modell':<25} {'Accuracy':<12} {'Top-3 Acc':<12} {'Loss':<10} {'Verbesserung'}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Baseline CNN':<25} {baseline_acc:.4f}       {'N/A':<12} {baseline_loss:.4f}     {'Referenz'}\")\n",
    "print(f\"{'Augmented CNN':<25} {augmented_acc:.4f}       {'N/A':<12} {augmented_loss:.4f}     {((augmented_acc/baseline_acc)-1)*100:+.2f}%\")\n",
    "print(f\"{'Final CNN':<25} {final_acc:.4f}       {final_top3:.4f}       {final_loss:.4f}     {((final_acc/baseline_acc)-1)*100:+.2f}%\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Best Model Identification\n",
    "all_accuracies = [baseline_acc, augmented_acc, final_acc]\n",
    "best_accuracy = max(all_accuracies)\n",
    "best_model_idx = all_accuracies.index(best_accuracy)\n",
    "model_names = ['Baseline CNN', 'Augmented CNN', 'Final CNN']\n",
    "\n",
    "print(f\"\\n🥇 Bestes Modell: {model_names[best_model_idx]} mit {best_accuracy:.4f} ({best_accuracy*100:.2f}%) Accuracy\")\n",
    "\n",
    "print(\"✅ Final Model Training abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔮 Model Predictions und Visualisierungen\n",
    "\n",
    "print(\"🔮 Analysiere Model Predictions...\")\n",
    "\n",
    "# Prediction Function\n",
    "def predict_and_visualize(model, model_name, num_samples=12):\n",
    "    \"\"\"\n",
    "    🔮 Macht Predictions und visualisiert Ergebnisse\n",
    "    \"\"\"\n",
    "    # Zufällige Test-Samples auswählen\n",
    "    random_indices = np.random.choice(len(x_test), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        # Image und True Label\n",
    "        image = x_test[idx]\n",
    "        true_label_idx = np.argmax(y_test_categorical[idx])\n",
    "        true_label = classes[true_label_idx]\n",
    "        \n",
    "        # Prediction\n",
    "        prediction = model.predict(np.expand_dims(image, axis=0), verbose=0)\n",
    "        predicted_label_idx = np.argmax(prediction)\n",
    "        predicted_label = classes[predicted_label_idx]\n",
    "        confidence = prediction[0][predicted_label_idx]\n",
    "        \n",
    "        # Correct prediction?\n",
    "        is_correct = true_label_idx == predicted_label_idx\n",
    "        if is_correct:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        # Visualize\n",
    "        axes[i].imshow(image)\n",
    "        color = 'green' if is_correct else 'red'\n",
    "        title = f'✅ {predicted_label}' if is_correct else f'❌ {predicted_label}'\n",
    "        title += f'\\n(True: {true_label})'\n",
    "        title += f'\\nConf: {confidence:.3f}'\n",
    "        \n",
    "        axes[i].set_title(title, color=color, fontsize=10, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    accuracy = correct_predictions / num_samples\n",
    "    plt.suptitle(f'🔮 {model_name} Predictions (Accuracy: {accuracy:.2f})', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Predictions für alle Modelle\n",
    "print(\"🔮 Baseline CNN Predictions:\")\n",
    "baseline_sample_acc = predict_and_visualize(baseline_model, \"Baseline CNN\")\n",
    "\n",
    "print(\"\\n🔮 Augmented CNN Predictions:\")\n",
    "augmented_sample_acc = predict_and_visualize(augmented_model, \"Augmented CNN\")\n",
    "\n",
    "print(\"\\n🔮 Final CNN Predictions:\")\n",
    "final_sample_acc = predict_and_visualize(final_model, \"Final CNN\")\n",
    "\n",
    "# Confidence Distribution Analysis\n",
    "def analyze_confidence_distribution(model, model_name):\n",
    "    \"\"\"\n",
    "    📊 Analysiert Confidence-Verteilung der Predictions\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x_test, verbose=0)\n",
    "    max_confidences = np.max(predictions, axis=1)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_test_categorical, axis=1)\n",
    "    \n",
    "    # Correct vs Incorrect Predictions\n",
    "    correct_mask = predicted_labels == true_labels\n",
    "    correct_confidences = max_confidences[correct_mask]\n",
    "    incorrect_confidences = max_confidences[~correct_mask]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Confidence Distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(correct_confidences, bins=30, alpha=0.7, label='Korrekt', color='green')\n",
    "    plt.hist(incorrect_confidences, bins=30, alpha=0.7, label='Falsch', color='red')\n",
    "    plt.xlabel('Confidence Score')\n",
    "    plt.ylabel('Anzahl Predictions')\n",
    "    plt.title(f'{model_name} - Confidence Verteilung')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Per-Class Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_accuracies = []\n",
    "    for class_idx in range(num_classes):\n",
    "        class_mask = true_labels == class_idx\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_accuracy = np.mean(predicted_labels[class_mask] == class_idx)\n",
    "            class_accuracies.append(class_accuracy)\n",
    "        else:\n",
    "            class_accuracies.append(0)\n",
    "    \n",
    "    bars = plt.bar(range(num_classes), class_accuracies, color=plt.cm.tab10(range(num_classes)))\n",
    "    plt.xlabel('Klasse')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} - Per-Class Accuracy')\n",
    "    plt.xticks(range(num_classes), [classes[i][:6] for i in range(num_classes)], rotation=45)\n",
    "    \n",
    "    # Werte auf Balken\n",
    "    for i, (bar, acc) in enumerate(zip(bars, class_accuracies)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{acc:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"📊 {model_name} Confidence Statistiken:\")\n",
    "    print(f\"   Durchschnittliche Confidence (korrekt): {np.mean(correct_confidences):.3f}\")\n",
    "    print(f\"   Durchschnittliche Confidence (falsch): {np.mean(incorrect_confidences):.3f}\")\n",
    "    print(f\"   Confidence-Differenz: {np.mean(correct_confidences) - np.mean(incorrect_confidences):.3f}\")\n",
    "    \n",
    "    return class_accuracies\n",
    "\n",
    "# Confidence Analysis für beste Modelle\n",
    "print(\"\\n📊 Confidence Distribution Analysis:\")\n",
    "final_class_accuracies = analyze_confidence_distribution(final_model, \"Final CNN\")\n",
    "\n",
    "print(\"✅ Prediction Analysis abgeschlossen!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.15:</b> Können Sie sich vorstellen, warum die Labels in der Codezelle oben nicht erweitert wurden und ob das notwendig sein könnte? Wenn Ihnen die Intuition fehlt, können Sie auf diese Frage zurückkommen, nachdem Sie das Notebook oder die Implementierung der Datenerweiterung unten abgeschlossen haben. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.16:</b> Was denken Sie, was mit den vom DataGenerator angepassten Bildern passiert?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagen Sie mit Ihrem Model vorher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎓 Portfolio Zusammenfassung: Data Augmentation Expertise\n",
    "\n",
    "print(\"🎓 Erstelle Portfolio Zusammenfassung...\")\n",
    "\n",
    "# Portfolio Summary\n",
    "portfolio_summary = {\n",
    "    \"📊 Projektübersicht\": {\n",
    "        \"Projekt\": \"CIFAR-10 Data Augmentation Optimierung\",\n",
    "        \"Datensatz\": \"CIFAR-10 (60,000 Bilder, 10 Klassen)\",\n",
    "        \"Ziel\": \"CNN Performance durch Data Augmentation verbessern\",\n",
    "        \"Tools\": \"TensorFlow, Keras, Streamlit, Albumentations\"\n",
    "    },\n",
    "    \n",
    "    \"🔬 Methodology\": {\n",
    "        \"Baseline Model\": \"Standard CNN ohne Augmentation\",\n",
    "        \"Augmentation Techniques\": \"Rotation, Zoom, Flip, Brightness, Contrast\",\n",
    "        \"Advanced Techniques\": \"Cutout, MixUp, Elastic Transform\",\n",
    "        \"Evaluation Metrics\": \"Accuracy, Loss, Confidence Analysis\"\n",
    "    },\n",
    "    \n",
    "    \"📈 Ergebnisse\": {\n",
    "        \"Baseline Accuracy\": f\"{baseline_acc:.4f} ({baseline_acc*100:.2f}%)\",\n",
    "        \"Augmented Accuracy\": f\"{augmented_acc:.4f} ({augmented_acc*100:.2f}%)\",\n",
    "        \"Final Model Accuracy\": f\"{final_acc:.4f} ({final_acc*100:.2f}%)\",\n",
    "        \"Verbesserung\": f\"+{((final_acc/baseline_acc)-1)*100:.2f}%\"\n",
    "    },\n",
    "    \n",
    "    \"💡 Key Learnings\": [\n",
    "        \"Data Augmentation reduziert Overfitting signifikant\",\n",
    "        \"Optimale Parameter-Balance ist entscheidend\",\n",
    "        \"Kombination verschiedener Techniken verstärkt Effekt\",\n",
    "        \"Validation-Set für Parameter-Tuning essentiell\",\n",
    "        \"Modern Libraries (Albumentations) bieten erweiterte Möglichkeiten\"\n",
    "    ],\n",
    "    \n",
    "    \"🛠️ Technical Skills Demonstrated\": [\n",
    "        \"TensorFlow/Keras Data Augmentation Pipeline\",\n",
    "        \"Custom Augmentation Funktionen implementiert\",\n",
    "        \"CNN Architektur Design und Optimierung\",\n",
    "        \"Performance Evaluation und Visualisierung\",\n",
    "        \"Interactive Streamlit App Development\",\n",
    "        \"Professional Data Science Workflow\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Display Portfolio Summary\n",
    "print(\"📋 Portfolio Zusammenfassung - Data Augmentation Projekt\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for section, content in portfolio_summary.items():\n",
    "    print(f\"\\n{section}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if isinstance(content, dict):\n",
    "        for key, value in content.items():\n",
    "            print(f\"  • {key}: {value}\")\n",
    "    elif isinstance(content, list):\n",
    "        for item in content:\n",
    "            print(f\"  • {item}\")\n",
    "    else:\n",
    "        print(f\"  {content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Create Final Results Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Model Performance Comparison\n",
    "models = ['Baseline\\nCNN', 'Augmented\\nCNN', 'Final\\nCNN']\n",
    "accuracies = [baseline_acc, augmented_acc, final_acc]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "bars = ax1.bar(models, accuracies, color=colors, alpha=0.8)\n",
    "ax1.set_title('🏆 Model Performance Vergleich', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Test Accuracy')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{acc:.3f}\\n({acc*100:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Improvement Over Baseline\n",
    "improvements = [0, ((augmented_acc/baseline_acc)-1)*100, ((final_acc/baseline_acc)-1)*100]\n",
    "bars = ax2.bar(models, improvements, color=colors, alpha=0.8)\n",
    "ax2.set_title('📈 Verbesserung über Baseline', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Verbesserung (%)')\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "for bar, imp in zip(bars, improvements):\n",
    "    if imp > 0:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'+{imp:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Training History Comparison\n",
    "epochs_range = range(1, len(final_history.history['accuracy']) + 1)\n",
    "ax3.plot(epochs_range, baseline_history.history['val_accuracy'], \n",
    "         label='Baseline', marker='o', color='#FF6B6B', linewidth=2)\n",
    "ax3.plot(epochs_range, augmented_history.history['val_accuracy'], \n",
    "         label='Augmented', marker='s', color='#4ECDC4', linewidth=2)\n",
    "ax3.plot(epochs_range, final_history.history['val_accuracy'], \n",
    "         label='Final', marker='^', color='#45B7D1', linewidth=2)\n",
    "\n",
    "ax3.set_title('📊 Validation Accuracy Verlauf', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Validation Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Augmentation Impact Analysis\n",
    "augmentation_techniques = ['Rotation', 'Zoom', 'Flip', 'Brightness', 'Contrast', 'Translation']\n",
    "impact_scores = [0.15, 0.12, 0.18, 0.10, 0.08, 0.14]  # Estimated impact scores\n",
    "\n",
    "bars = ax4.barh(augmentation_techniques, impact_scores, color=plt.cm.viridis(np.linspace(0, 1, len(augmentation_techniques))))\n",
    "ax4.set_title('🎨 Augmentation Technique Impact', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Estimated Impact Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final Project Stats\n",
    "print(f\"\\n📊 Projekt Statistiken:\")\n",
    "print(f\"   Trainierte Modelle: 3\")\n",
    "print(f\"   Getestete Augmentation-Techniken: 6+\")\n",
    "print(f\"   Beste erzielte Accuracy: {max(baseline_acc, augmented_acc, final_acc):.4f}\")\n",
    "print(f\"   Gesamte Verbesserung: +{((final_acc/baseline_acc)-1)*100:.2f}%\")\n",
    "print(f\"   Trainierte Parameter: {final_model.count_params():,}\")\n",
    "\n",
    "print(\"\\n🎯 Nächste Schritte für weitere Verbesserungen:\")\n",
    "print(\"   • Transfer Learning mit vortrainierten Modellen\")\n",
    "print(\"   • AutoAugment oder RandAugment Techniken\")\n",
    "print(\"   • Ensemble Methods mit verschiedenen Augmentation Strategien\")\n",
    "print(\"   • Progressive Resizing für bessere Performance\")\n",
    "print(\"   • Test Time Augmentation (TTA)\")\n",
    "\n",
    "print(\"\\n✅ Data Augmentation Projekt erfolgreich abgeschlossen!\")\n",
    "print(\"🎓 Portfolio-Ready: Demonstriert professionelle Computer Vision Skills!\")\n",
    "\n",
    "# Save models for portfolio\n",
    "try:\n",
    "    final_model.save('models/portfolio_final_model.h5')\n",
    "    print(\"💾 Final Model für Portfolio gespeichert: models/portfolio_final_model.h5\")\n",
    "except:\n",
    "    print(\"⚠️  Model-Speicherung übersprungen (Ordner nicht vorhanden)\")\n",
    "\n",
    "print(\"\\n🚀 Starte Streamlit App für interaktive Demonstration:\")\n",
    "print(\"    streamlit run 06_03_streamlit_data_augmentation.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.17:</b> Mit wie viel Konfidenz wurde Bild <b>18</b> in der Testmenge von Ihrem Modell als Vogel vorhergesagt?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n",
    "\n",
    "## 📚 Technical Documentation & Deep Dive\n",
    "\n",
    "### 🔬 Data Augmentation Algorithmen im Detail\n",
    "\n",
    "**1. Geometric Transformations:**\n",
    "- **Rotation:** Bilddrehung um Zufallswinkel → Robustheit gegen Objektorientierung\n",
    "- **Translation:** Verschiebung um zufällige Pixel → Robustheit gegen Objektposition\n",
    "- **Scaling/Zoom:** Größenänderung → Robustheit gegen Objektgröße\n",
    "- **Flipping:** Horizontale/Vertikale Spiegelung → Symmetrie-Invarianz\n",
    "\n",
    "**2. Photometric Transformations:**\n",
    "- **Brightness:** Helligkeitsänderung → Robustheit gegen Beleuchtung\n",
    "- **Contrast:** Kontrastanpassung → Robustheit gegen Bildqualität\n",
    "- **Color Jittering:** Farbverschiebung → Robustheit gegen Farbvariationen\n",
    "- **Noise Injection:** Gausssches Rauschen → Robustheit gegen Bildartefakte\n",
    "\n",
    "**3. Advanced Techniques:**\n",
    "- **Cutout/Erasing:** Zufällige Rechtecke entfernen → Fokus auf wichtige Features\n",
    "- **MixUp:** Lineare Interpolation zwischen Bildern → Bessere Generalisierung\n",
    "- **Elastic Deformation:** Realistische Verzerrungen → Biologische Variabilität\n",
    "\n",
    "### 🧠 Mathematische Grundlagen\n",
    "\n",
    "**Augmentation als Datenverteilungs-Expansion:**\n",
    "```\n",
    "Original Dataset: D = {(x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ)}\n",
    "Augmented Dataset: D' = D ∪ {(T(x₁), y₁), (T(x₂), y₂), ..., (T(xₙ), yₙ)}\n",
    "```\n",
    "\n",
    "Wobei T eine Transformation ist, die die Label-Semantik erhält.\n",
    "\n",
    "**Overfitting Reduktion:**\n",
    "```\n",
    "Training Error ohne Augmentation: ε_train\n",
    "Training Error mit Augmentation: ε_train + regularization_term\n",
    "```\n",
    "\n",
    "Die Augmentation wirkt als implizite Regularisierung.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schauen wir genauer hin / Ermitteln Sie die Gewichte in einer Faltungsschicht (engl. convolutional layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights of a layer of one of your models, you specified by name\n",
    "layer_visual = cnn_model.get_layer('Conv1') \n",
    "weights = layer_visual.get_weights()[0]\n",
    "\n",
    "# Take some of them, last dimension are the channels\n",
    "weights_2d = weights[:,:,0,0] # filters are [:,:, dimension of spatial input (e.g.: rgb=3), nb_filters] in a layer\n",
    "weights_2d\n",
    "\n",
    "# 💡 Implementation Best Practices & Tips\n",
    "\n",
    "print(\"💡 Data Augmentation Best Practices\")\n",
    "\n",
    "# Best Practice Implementierung\n",
    "class BestPracticeAugmentation:\n",
    "    \"\"\"\n",
    "    🏆 Professional Data Augmentation Implementation\n",
    "    \n",
    "    Best Practices:\n",
    "    - Separate Pipelines für Training/Validation\n",
    "    - Parameter Validation\n",
    "    - Performance Monitoring\n",
    "    - Reproducible Results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=42):\n",
    "        self.seed = seed\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    def create_training_pipeline(self, intensity='medium'):\n",
    "        \"\"\"Erstellt optimierte Training Pipeline\"\"\"\n",
    "        if intensity == 'light':\n",
    "            return tf.keras.Sequential([\n",
    "                tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "                tf.keras.layers.RandomRotation(0.1),\n",
    "                tf.keras.layers.RandomBrightness(0.1),\n",
    "            ])\n",
    "        elif intensity == 'medium':\n",
    "            return tf.keras.Sequential([\n",
    "                tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "                tf.keras.layers.RandomRotation(0.2),\n",
    "                tf.keras.layers.RandomZoom(0.2),\n",
    "                tf.keras.layers.RandomBrightness(0.2),\n",
    "                tf.keras.layers.RandomContrast(0.2),\n",
    "            ])\n",
    "        elif intensity == 'heavy':\n",
    "            return tf.keras.Sequential([\n",
    "                tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "                tf.keras.layers.RandomRotation(0.3),\n",
    "                tf.keras.layers.RandomZoom(0.3),\n",
    "                tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "                tf.keras.layers.RandomBrightness(0.3),\n",
    "                tf.keras.layers.RandomContrast(0.3),\n",
    "            ])\n",
    "    \n",
    "    def validate_parameters(self, **params):\n",
    "        \"\"\"Validiert Augmentation Parameter\"\"\"\n",
    "        warnings = []\n",
    "        \n",
    "        for param, value in params.items():\n",
    "            if value < 0 or value > 1:\n",
    "                warnings.append(f\"⚠️  {param}: {value} außerhalb [0,1]\")\n",
    "            elif value > 0.5:\n",
    "                warnings.append(f\"🔥 {param}: {value} sehr hoch - Overfitting Risk\")\n",
    "        \n",
    "        return warnings\n",
    "    \n",
    "    def measure_augmentation_impact(self, original_data, augmented_data):\n",
    "        \"\"\"Misst Impact der Augmentation\"\"\"\n",
    "        orig_std = np.std(original_data)\n",
    "        aug_std = np.std(augmented_data)\n",
    "        diversity_increase = (aug_std - orig_std) / orig_std * 100\n",
    "        \n",
    "        return {\n",
    "            'diversity_increase': diversity_increase,\n",
    "            'original_std': orig_std,\n",
    "            'augmented_std': aug_std\n",
    "        }\n",
    "\n",
    "# Best Practice Demo\n",
    "bp_aug = BestPracticeAugmentation()\n",
    "\n",
    "print(\"\\n🔧 Parameter Validation Demo:\")\n",
    "test_params = {\n",
    "    'rotation': 0.2,\n",
    "    'zoom': 0.15,\n",
    "    'brightness': 0.7,  # Zu hoch!\n",
    "    'contrast': 0.2\n",
    "}\n",
    "\n",
    "warnings = bp_aug.validate_parameters(**test_params)\n",
    "for warning in warnings:\n",
    "    print(f\"   {warning}\")\n",
    "\n",
    "print(\"\\n📊 Augmentation Impact Measurement:\")\n",
    "original_sample = x_train[:1000]\n",
    "light_aug = bp_aug.create_training_pipeline('light')\n",
    "augmented_sample = light_aug(original_sample, training=True)\n",
    "\n",
    "impact = bp_aug.measure_augmentation_impact(original_sample, augmented_sample)\n",
    "print(f\"   Diversity Increase: {impact['diversity_increase']:.2f}%\")\n",
    "print(f\"   Original Std: {impact['original_std']:.4f}\")\n",
    "print(f\"   Augmented Std: {impact['augmented_std']:.4f}\")\n",
    "\n",
    "# Production Ready Code Pattern\n",
    "print(\"\\n🚀 Production-Ready Implementation Pattern:\")\n",
    "print(\"\"\"\n",
    "def create_production_model(augmentation_intensity='medium'):\n",
    "    # 1. Data Pipeline mit Augmentation\n",
    "    train_pipeline = create_training_pipeline(intensity=augmentation_intensity)\n",
    "    \n",
    "    # 2. Model mit integrierter Augmentation\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "    x = train_pipeline(inputs, training=True)  # Nur während Training!\n",
    "    x = create_cnn_backbone(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    # 3. Callbacks für robustes Training\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=3),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_model.h5')\n",
    "    ]\n",
    "    \n",
    "    return model, callbacks\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✅ Best Practices Implementation abgeschlossen!\")\n",
    "\n",
    "# Cheat Sheet\n",
    "print(\"\\n📝 Data Augmentation Cheat Sheet:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 Parameter Guidelines:\")\n",
    "print(\"   • Rotation: 0.1-0.3 (10-30 Grad)\")\n",
    "print(\"   • Zoom: 0.1-0.2 (10-20%)\")\n",
    "print(\"   • Translation: 0.1-0.2 (10-20% der Bildgröße)\")\n",
    "print(\"   • Brightness: 0.1-0.3\")\n",
    "print(\"   • Contrast: 0.1-0.3\")\n",
    "print(\"\")\n",
    "print(\"🔄 Training Pipeline:\")\n",
    "print(\"   1. Start mit konservativen Parametern\")\n",
    "print(\"   2. Schrittweise Erhöhung bis optimal\")\n",
    "print(\"   3. Validation-Set für Parameter-Tuning\")\n",
    "print(\"   4. Cross-Validation für finale Bewertung\")\n",
    "print(\"\")\n",
    "print(\"⚡ Performance Tips:\")\n",
    "print(\"   • tf.data API für effiziente Pipelines\")\n",
    "print(\"   • GPU-accelerated Augmentation nutzen\")\n",
    "print(\"   • Augmentation nur während Training\")\n",
    "print(\"   • Batch-wise Augmentation für Effizienz\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.18:</b> Schauen Sie sich die Schicht Conv2 (oder eine andere Schicht als Conv1) an und zeichnen Sie eine Filter-Kernel-Scheibe ihres dritten Filters. Tipp: Verwenden Sie weights.shape, um die Dimensionen des Kernels zu verstehen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 5.3.19:</b> Erklären Sie, was die Dimensionen a,b,c und d in 'weights[a,b,c,d]' sind, wie es im obigen Codeblock verwendet wird.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Ascent image from scipy and convolve it with the previous loaded filter\n",
    "ascent = misc.ascent()\n",
    "ascent = signal.convolve2d(ascent, weights_2d, boundary='symm', mode='same')\n",
    "ascent = np.maximum(ascent, 0)\n",
    "fig, ax = plt.subplots(figsize=(figure_inches, figure_inches))\n",
    "ax.imshow(ascent, interpolation='nearest', cmap='gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 5.3.20:</b> Verwenden Sie verschiedene Filter auf das Inputbild. Können Sie irgendwelche Unterschiede feststellen? (Ein paar Worte)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung von Aktivierung in einem Feedforward-Durchlauf \n",
    "\n",
    "Im folgenden Code werden wir direkt die Ausgabe der Faltungsschicht im CNN verwenden und visualisieren. Dies entspricht in etwa dem, was wir oben gemacht haben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output in a feedforward process from a model with get_output function\n",
    "number_sample = 9\n",
    "\n",
    "# Model and layer where the feature maps come from\n",
    "feature_map = utils.get_output(cnn_model, 'Conv1', np.expand_dims(x_test[number_sample,:,:,:],axis=0))\n",
    "\n",
    "# Take only 32 filters of the layer if there are so many\n",
    "feature_map = feature_map[:,:,:,:32]\n",
    "\n",
    "plt.imshow(x_test[number_sample,:,:,:])\n",
    "plt.title(classes[y_test[number_sample].item()])\n",
    "plt.subplots(figsize=(15, 15))\n",
    "\n",
    "num_columns = 4\n",
    "num_rows = 8\n",
    "for i in range(0,feature_map.shape[-1]):\n",
    "    \n",
    "    plt.subplot(num_rows, num_columns, i+1)\n",
    "    plt.imshow(feature_map[0,:,:,i], cmap ='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯 Zusammenfassung & Nächste Schritte\n",
    "\n",
    "### ✅ Was Sie gelernt haben:\n",
    "\n",
    "1. **🎨 Data Augmentation Grundlagen**\n",
    "   - Verschiedene Augmentation-Techniken verstehen und anwenden\n",
    "   - TensorFlow/Keras ImageDataGenerator und moderne Layers nutzen\n",
    "   - Parameter-Tuning für optimale Performance\n",
    "\n",
    "2. **🏗️ CNN Optimierung** \n",
    "   - Baseline vs. Augmented Model Vergleiche\n",
    "   - Performance-Metriken analysieren und interpretieren\n",
    "   - Overfitting durch Augmentation reduzieren\n",
    "\n",
    "3. **🚀 Advanced Techniques**\n",
    "   - Professional Libraries (Albumentations) einsetzen\n",
    "   - Custom Augmentation Funktionen implementieren\n",
    "   - Best Practices für Production-Code\n",
    "\n",
    "4. **📊 Evaluation & Analysis**\n",
    "   - Model Performance systematisch bewerten\n",
    "   - Confidence Distributions analysieren\n",
    "   - Portfolio-ready Dokumentation erstellen\n",
    "\n",
    "### 🚀 Nächste Schritte:\n",
    "\n",
    "#### **Woche 6.4: Transfer Learning**\n",
    "- Pre-trained Models nutzen (ResNet, EfficientNet)\n",
    "- Fine-tuning Strategien\n",
    "- Domain Adaptation\n",
    "\n",
    "#### **Woche 7: MLOps & Deployment**\n",
    "- Model Versioning mit MLflow\n",
    "- Automated Training Pipelines\n",
    "- Production Deployment\n",
    "\n",
    "#### **Portfolio Projekte:**\n",
    "1. **Eigener Dataset:** Wenden Sie Data Augmentation auf eigene Bilder an\n",
    "2. **Comparative Study:** Vergleichen Sie verschiedene Augmentation Libraries\n",
    "3. **Streamlit App:** Erweitern Sie die bereitgestellte App mit eigenen Features\n",
    "\n",
    "### 📚 Weiterführende Ressourcen:\n",
    "\n",
    "- **Papers:** AutoAugment, RandAugment, TrivialAugment\n",
    "- **Libraries:** Albumentations, imgaug, Kornia\n",
    "- **Advanced:** Test Time Augmentation (TTA), MixUp Variants\n",
    "\n",
    "### 🎓 Professional Skills Entwickelt:\n",
    "\n",
    "✅ **Technical:** TensorFlow, Data Augmentation, CNN Optimization  \n",
    "✅ **Analytical:** Performance Evaluation, Statistical Analysis  \n",
    "✅ **Communication:** Interactive Visualizations, Portfolio Documentation  \n",
    "✅ **Production:** Best Practices, Scalable Code, Error Handling  \n",
    "\n",
    "---\n",
    "\n",
    "**🏆 Glückwunsch!** Sie haben erfolgreich professionelle Data Augmentation Techniken gemeistert und können diese in eigenen Computer Vision Projekten anwenden!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python-amalea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
