{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# [Nur Colab] Diese Zellen müssen nur auf *Google Colab* ausgeführt werden und installieren Packete und Daten\n","!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n","!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip\n","!wget --quiet \"https://raw.githubusercontent.com/KI-Campus/AMALEA/master/Woche%205/utils.py\""]},{"cell_type":"markdown","metadata":{},"source":["# Datenmangel? Copy & augmentated Paste"]},{"cell_type":"markdown","metadata":{},"source":["## CNN Übung\n","In diesem Notebook werden Sie mehrschichtige Perzeptronen (MLP, engl. Multilayer Perceptrons) mit Convolutional Neural Networks (CNN) vergleichen, um eine einfache Aufgabe wie die Erkennung von 10 verschiedenen Objekten aus Bildern zu lösen. Sie werden alles mit Keras programmieren und die Ergebnisse mit den bereits gelernten Metriken für die Klassifizierung vergleichen.\n","\n","### Importe"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from ipywidgets import widgets\n","from IPython.display import display\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# For some convolving operations\n","from scipy import signal\n","from scipy import misc\n","\n","# DeepLearning Library Keras\n","# Documentation https://keras.io/\n","import tensorflow.keras as keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Reshape\n","from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.datasets import cifar10\n","\n","import utils\n","\n","#define dataroot\n","root = 'data/dataset/'\n"]},{"cell_type":"markdown","metadata":{},"source":["### Definitionen"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#### DO NOT EDIT!\n","# For specifiying training with autoencoder structure\n","ae_specification = widgets.Text()\n","old_spec = 'None'\n","\n","\n","# Two Loggers, depending if loss or accuracy should be visualized\n","Loss_Logger = utils.LossGraph('loss')\n","Acc_Logger = utils.LossGraph('acc')\n","\n","# Size for some plots with matplotlib\n","figure_inches = 3"]},{"cell_type":"markdown","metadata":{},"source":["### Cifar-10 Klassifikationsaufgabe\n","Neben dem MNIST-Datensatz ist auch Cifar10 ein kleiner Datensatz, der in den Anfängen der CNNs verwendet wurde. Es gibt 10 verschiedene Klassen von einfachen Objekten oder Tieren. Die Bilder haben eine Größe von 32x32x3. In diesem Abschnitt sollten Sie ein gegebenes CNN tunen, um Bilder mit hoher Genauigkeit zu klassifizieren. \n","\n","Siehe auch: [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.1:</b> Laden Sie den Datensatz, legen Sie die Anzahl der Klassen fest, transformieren Sie die Beschriftungen und definieren Sie alle zugehörigen Klassen (wie z.B. Flugzeug,...) gemäß den Kommentaren in den Codezellen.\n","\n","</div>"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Load the dataset from Keras, Tip: cifar10 is already imported, train + test set required\n","# HINT: Load the dataset into this structure: \"(x_train, y_train), (x_test, y_test) = ...\"\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# How many classes are in Cifar-10? \n","# Hint: Name the variable \"num_classes = ...\"\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Transform the labels into categorical vectors\n","# Use the keras.utils.to_categorical function\n","\n","# Hint: \"y_train_categorical = ...\"\n","# Hint2: \"y_test_categorical = ...\"\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# What classes are there? Define them in a list of strings named classes.\n","# Hint: Call the list of strings \"classes = ...\"\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.2:</b> Prüfen Sie, ob Sie alles wie gewünscht definiert haben.\n","\n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Image in the training set\n","number_sample = 6  # test multiple ones\n","\n","fig, ax = plt.subplots(figsize=(figure_inches, figure_inches))\n","ax.set_title(classes[y_test[number_sample].item()]+' ?', fontsize = 15)\n","ax.imshow(x_test[number_sample,:,:,:], interpolation='nearest')\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.3:</b> Suchen Sie ein Bild eines Pferdes und plotten Sie es mit dem Code oben. Sie können die gleiche Code-Zelle verwenden.\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.4:</b> Preprocessen Sie die Daten, um Werte zwischen 0 und 1 zu gewährleisten. Dividieren Sie dazu die rgb-Werte durch ihren Maximalwert.\n","\n","</div>"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Data Preprocessing\n","# Divide RGB values of train AND test set \n","# by their maximum value to ensure values between [0,1]\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.5:</b> Wie viele Trainings- und Testdaten gibt es?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.6:</b> Warum Daten normalisieren?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.7:</b> Warum wird ein kategorischer Vektor an Stelle eines einzelnen Outputs verwendet?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Klassifikationsmodelle für Cifar-10\n","\n","### Neuronales Netzwerk Klassifikator:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def model_nn()->Model:\n","    \n","    input_layer = Input(shape = x_train.shape[1:], name='Input_MLP')\n","    \n","    flatten = Flatten(name='Flattening_MLP')(input_layer)\n","    \n","    hidden1 = Dense(256, activation = 'relu', name='Hidden1_NN')(flatten)\n","    hidden2 = Dense(256, activation = 'relu', name='Hidden2_NN')(hidden1)\n","    \n","    output = Dense(num_classes, activation = 'softmax', name='Output_NN')(hidden2)\n","    \n","    model = Model(inputs= input_layer, outputs = output)\n","    \n","    \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["### Convolutional Neural Network Klassifikator:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def model_cnn()->Model:\n","    \n","    input_layer = Input(shape = x_train.shape[1:], name='Input_CNN') # channels last\n","    \n","    conv1 = Conv2D(filters= 16, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv1')(input_layer)\n","    max_pool1 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool1')(conv1)\n","\n","    conv2 = Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv2')(max_pool1)\n","    max_pool2 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool2')(conv2)\n","\n","    flattened = Flatten(name='Flatt_CNN')(max_pool2)\n","    \n","    fc1 = Dense(256, activation = 'relu', name='FC-1')(flattened)\n","    \n","    output = Dense(num_classes, activation = 'softmax', name='Output_CNN')(fc1)\n","    \n","    model = Model(inputs= input_layer, outputs = output)\n","        \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["### Vergleich von MLP und CNN Klassifikatoren:\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.8:</b> Um die Bilder in Cifar-10 zu klassifizieren, verwenden Sie die gegebenen MLP- und CNN-Modelle, um zu untersuchen, welches besser abschneidet.\n","Trainieren Sie beide Netzwerke für 10 Epochen und schauen Sie sich die Ergebnisse an.\n","Fühlen Sie sich frei, den Code in den beiden Code-Zellen unten zu verwenden und zu ändern. Wenn Ihr Netzwerk nicht trainiert, haben Sie möglicherweise die rgb-Werte nicht richtig aufbereitet (z. B. haben Sie nicht normalisiert oder zu oft).\n","</div>\n","\n","<div class=\"alert alert-block alert-info\">\n","<b>Hinweis:</b> Aufbau der folgenden Codezellen\n","<ul>\n","<li> Benutzen Sie die vordefinierten Funktionen, um Ihr Modell zu erstellen\n","<li> Definieren Sie den gemeinsamen TensorBoard-Logger mit der Konfiguration, um die Trainingsergebnisse später zu betrachten\n","<li> Kompillieren und trainieren Sie das Modell\n","<li> Tipp: Wenn Ihre Modelle nichts Lernen, überprüfen Sie Ihre Datennormalisierung. Vielleicht haben Sie Ihre Daten nicht oder zu oft normalisiert.\n","</li>\n","\n","\n","</ul>\n","\n","\n","</div>"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":[" # Train the Neural Network (MLP)\n","nn_model = model_nn()\n","config_nn = 'UNRECOGNIZEABLE_NAME_EDIT_ME_PLEASE' # Give a recognizable name\n","\n","# The TensorBoard is a feature of tensorflow for the visualization of the training process \n","nn_logger = TensorBoard(log_dir='logs/nn_logs/'+config_nn+'/')\n","\n","nn_model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n","nn_model.fit(x_train, y_train_categorical, batch_size = 32, epochs = 1, \n","            validation_data = (x_test, y_test_categorical), callbacks = [nn_logger, Acc_Logger], verbose = 1) #TODO"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Train the Neural Network (MLP)\n","nn_model = model_nn()\n","config_cnn = 'UNRECOGNIZEABLE_NAME_EDIT_ME_PLEASE' # Give a recognizable name\n","\n","# The TensorBoard is a feature of tensorflow for the visualization of the training process \n","cnn_logger = TensorBoard(log_dir='logs/cnn_logs/'+config_cnn+'/') \n","\n","nn_model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n","nn_model.fit(x_train, y_train_categorical, batch_size = 64, epochs = 1, \n","            validation_data = (x_test, y_test_categorical), callbacks = [cnn_logger, Acc_Logger]) #TODO"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.9:</b> Verwenden Sie TensorBoard, um Ihren Trainingsfortschritt zu kontrollieren. Eine Erklärung, wie Sie Ihr TensorBoard öffnen, finden Sie hier:\n","    <a href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/r1/summaries.md\">TensorBoard</a>  (unten auf der Webseite)\n","</div>"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Train the CNN\n","%load_ext tensorboard\n","cnn_model = model_cnn()\n","config_cnn = 'UNRECOGNIZEABLE_NAME_EDIT_ME_PLEASE' # give a recognizable name\n","\n","cnn_model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n","cnn_model.fit(x_train, y_train_categorical, batch_size = 32, epochs = 1, \n","          validation_data = (x_test, y_test_categorical), callbacks = [Acc_Logger], verbose = 1)\n","%tensorboard --logdir logs"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.10:</b> Welches Netzwerk performt besser?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.11:</b> Wie viele Parameter haben die Netze? Verwenden Sie dazu die summary Methode (siehe Keras-Docs)...\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.12:</b> Wo sind die meisten Parameter in diesem CNN gespeichert?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Challenge: Optimieren Sie Ihr Network! "]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.13:</b> Versuchen Sie, eines der Modelle so zu verbessern, dass Ihre Validierungsgenauigkeit einmal höher als 0,75 Prozent ist!\n","\n","<ul>\n","<li>Hinweis: Versuchen Sie, zuerst zu overfitten und dann zu regulieren. \n","<li>Hinweis 2: Verwenden Sie daher L1/L2 - Regularisierung und/oder Dropout. Auch BatchNormalization könnte die Sache verbessern. Schauen Sie deshalb auf der Keras-Website nach Beispielen oder fragen Sie Tutoren.\n","<li>Hinweis 3: Verwenden Sie eine der Funktionen <code>def model_nn()</code> oder <code>def model_cnn()</code> von oben. Viel Spaß und gutes Gelingen!\n","\n","</li>\n","</ul>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["### Daten Augmentation\n","\n","Eine weitere Möglichkeit, Ihr Netzwerk zu regularisieren, ist das Vergrößern der Trainingsdaten. Verwenden Sie dazu den ImageDataGenerator von Keras. Wir werden später selbst Bilder verschieben und drehen, nachdem wir auf Cifar-10 optimiert haben."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Keras ImageDataGenerator\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,\n","    featurewise_std_normalization=False,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True)"]},{"cell_type":"markdown","metadata":{},"source":["#### Eine etwas noch herausfordernde Challenge ((COOKIE AUFGABE! :)))\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.14:</b> Verbessern Sie Ihr Modell und passen Sie es an, wie genau kann es jetzt werden?\n","Die Lösung ist in der Lage, eine Genauigkeit von 0,8894 bei der Validierung zu erreichen.\n","</div>"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def model_cnn_aug()->Model:\n","\n","    input_layer = Input(shape = x_train.shape[1:], name='Input_CNN') # channels last\n","    \n","    conv1 = Conv2D(filters= 16, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv1')(input_layer)\n","    max_pool1 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool1')(conv1)\n","\n","    conv2 = Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu', name='Conv2')(max_pool1)\n","    max_pool2 = MaxPooling2D(pool_size = (2,2), strides = (2,2), padding='valid', name='Pool2')(conv2)\n","\n","    flattened = Flatten(name='Flatt_CNN')(max_pool2)\n","    \n","    fc1 = Dense(256, activation = 'relu', name='FC-1')(flattened)\n","    \n","    output = Dense(num_classes, activation = 'softmax', name='Output_CNN')(fc1)\n","    \n","    model = Model(inputs= input_layer, outputs = output)\n","    \n","    \n","    return model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Train your model that makes use of data augmentation\n","# Fit the training data to the data-generator\n","datagen.fit(x_train)\n","\n","# Train your CNN_augmentation model:\n","cnn_aug_model = model_cnn_aug()\n","cnn_aug_model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n","config_cnn_aug = 'None' # give a recognizable name\n","cnn_logger = TensorBoard(log_dir='logs/cnn_aug_logs/'+config_cnn_aug+'/') \n","\n","cnn_aug_model.fit(datagen.flow(x_train, y_train_categorical, batch_size = 5),\n","                            epochs=1, validation_data=(x_test, y_test_categorical),\n","                            callbacks=[Acc_Logger, cnn_logger], verbose=1, steps_per_epoch=10000)\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.15:</b> Können Sie sich vorstellen, warum die Labels in der Codezelle oben nicht erweitert wurden und ob das notwendig sein könnte? Wenn Ihnen die Intuition fehlt, können Sie auf diese Frage zurückkommen, nachdem Sie das Notebook oder die Implementierung der Datenerweiterung unten abgeschlossen haben. \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.16:</b> Was denken Sie, was mit den vom DataGenerator angepassten Bildern passiert?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Sagen Sie mit Ihrem Model vorher"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Get the probabilities of one image prediction\n","x_tester = x_test[1,:,:,:]  \n","\n","# Use numpy expand_dims before predicting with your model\n","# Print your predicted classes for the first test image (x_test[0,:,:,:])\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.17:</b> Mit wie viel Konfidenz wurde Bild <b>18</b> in der Testmenge von Ihrem Modell als Vogel vorhergesagt?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Schauen wir genauer hin / Ermitteln Sie die Gewichte in einer Faltungsschicht (engl. convolutional layer)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Get the weights of a layer of one of your models, you specified by name\n","layer_visual = cnn_model.get_layer('Conv1') \n","weights = layer_visual.get_weights()[0]\n","\n","# Take some of them, last dimension are the channels\n","weights_2d = weights[:,:,0,0] # filters are [:,:, dimension of spatial input (e.g.: rgb=3), nb_filters] in a layer\n","weights_2d"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.18:</b> Schauen Sie sich die Schicht Conv2 (oder eine andere Schicht als Conv1) an und zeichnen Sie eine Filter-Kernel-Scheibe ihres dritten Filters. Tipp: Verwenden Sie weights.shape, um die Dimensionen des Kernels zu verstehen.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 5.3.19:</b> Erklären Sie, was die Dimensionen a,b,c und d in 'weights[a,b,c,d]' sind, wie es im obigen Codeblock verwendet wird.\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["#Load Ascent image from scipy and convolve it with the previous loaded filter\n","ascent = misc.ascent()\n","ascent = signal.convolve2d(ascent, weights_2d, boundary='symm', mode='same')\n","ascent = np.maximum(ascent, 0)\n","fig, ax = plt.subplots(figsize=(figure_inches, figure_inches))\n","ax.imshow(ascent, interpolation='nearest', cmap='gray')\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 5.3.20:</b> Verwenden Sie verschiedene Filter auf das Inputbild. Können Sie irgendwelche Unterschiede feststellen? (Ein paar Worte)\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisierung von Aktivierung in einem Feedforward-Durchlauf \n","\n","Im folgenden Code werden wir direkt die Ausgabe der Faltungsschicht im CNN verwenden und visualisieren. Dies entspricht in etwa dem, was wir oben gemacht haben.  "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Get the output in a feedforward process from a model with get_output function\n","number_sample = 9\n","\n","# Model and layer where the feature maps come from\n","feature_map = utils.get_output(cnn_model, 'Conv1', np.expand_dims(x_test[number_sample,:,:,:],axis=0))\n","\n","# Take only 32 filters of the layer if there are so many\n","feature_map = feature_map[:,:,:,:32]\n","\n","plt.imshow(x_test[number_sample,:,:,:])\n","plt.title(classes[y_test[number_sample].item()])\n","plt.subplots(figsize=(15, 15))\n","\n","num_columns = 4\n","num_rows = 8\n","for i in range(0,feature_map.shape[-1]):\n","    \n","    plt.subplot(num_rows, num_columns, i+1)\n","    plt.imshow(feature_map[0,:,:,i], cmap ='gray')\n","    plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
