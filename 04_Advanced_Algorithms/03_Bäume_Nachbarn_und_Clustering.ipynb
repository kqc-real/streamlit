{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e16a4d",
   "metadata": {},
   "source": [
    "# 🌳 Woche 3: Bäume, Nachbarn und Clustering - AMALEA Kernkonzepte\n",
    "\n",
    "**Integration der ursprünglichen AMALEA-Notebooks:**\n",
    "- \"Willkommen in der Baumschule!\" → Decision Trees\n",
    "- \"Schöne Nachbarschaft\" → K-Nearest Neighbors  \n",
    "- \"K-Means-Clustering\" → Unsupervised Learning\n",
    "\n",
    "## 📚 Was du heute lernst\n",
    "\n",
    "- **Decision Trees** 🌳 - Wie Computer Entscheidungen treffen\n",
    "- **K-Nearest Neighbors (KNN)** 👥 - Lernen von den Nachbarn\n",
    "- **K-Means Clustering** 🎯 - Gruppen in Daten finden\n",
    "- **Supervised vs. Unsupervised Learning** unterscheiden\n",
    "- **Streamlit-Apps** für alle drei Algorithmen erstellen\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Kernkonzepte aus dem ursprünglichen AMALEA-Kurs\n",
    "\n",
    "### Decision Trees 🌳\n",
    "> **Idee**: Wie Menschen Entscheidungen treffen - durch eine Serie von Ja/Nein-Fragen\n",
    "\n",
    "**Beispiel aus dem ursprünglichen Kurs:**\n",
    "```\n",
    "Ist es sonnig?\n",
    "├─ JA → Gehe spazieren\n",
    "└─ NEIN → Ist es regnerisch?\n",
    "    ├─ JA → Bleibe zu Hause\n",
    "    └─ NEIN → Gehe joggen\n",
    "```\n",
    "\n",
    "**Vorteile:**\n",
    "- ✅ Leicht interpretierbar\n",
    "- ✅ Keine Daten-Normalisierung nötig\n",
    "- ✅ Arbeitet mit kategorialen und numerischen Daten\n",
    "\n",
    "**Nachteile:**\n",
    "- ❌ Kann zu Overfitting neigen\n",
    "- ❌ Instabil bei kleinen Datenänderungen\n",
    "\n",
    "### K-Nearest Neighbors (KNN) 👥\n",
    "> **Idee**: \"Sage mir, wer deine Nachbarn sind, und ich sage dir, wer du bist\"\n",
    "\n",
    "**Funktionsweise:**\n",
    "1. Finde die k nächsten Nachbarn\n",
    "2. Schaue, welche Klasse am häufigsten ist\n",
    "3. Treffe Vorhersage basierend auf Mehrheit\n",
    "\n",
    "**Parameter k:**\n",
    "- k=1: Sehr flexibel, aber anfällig für Noise\n",
    "- k=groß: Glatter, aber weniger Details\n",
    "- k=ungerade: Vermeidet Unentschieden\n",
    "\n",
    "### K-Means Clustering 🎯\n",
    "> **Idee**: Finde natürliche Gruppen in den Daten (ohne Labels!)\n",
    "\n",
    "**Unterschied zu Supervised Learning:**\n",
    "- **Supervised** (Decision Trees, KNN): Haben Labels/Targets\n",
    "- **Unsupervised** (K-Means): Keine Labels, finde Muster selbst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088791a7",
   "metadata": {},
   "source": [
    "## 🎬 Original AMALEA Videos: Advanced Algorithms Deep-Dive\n",
    "\n",
    "**Diese drei Algorithmus-Videos sind Klassiker und perfekt für das tiefe Verständnis! 🌳**\n",
    "\n",
    "### 📹 **Video 1: \"Willkommen in der Baumschule!\" (Decision Trees)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4`\n",
    "- **Dauer:** ~20 Minuten\n",
    "- **Inhalt:** Decision Trees, Entropy, Information Gain, Pruning\n",
    "- **Warum wichtig:** Versteht, wie Entscheidungsbäume \"denken\"\n",
    "- **Fun Fact:** Der Titel ist Kult! 🌳\n",
    "\n",
    "### 📹 **Video 2: \"Schöne Nachbarschaft\" (K-Nearest Neighbors)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4`\n",
    "- **Dauer:** ~15 Minuten\n",
    "- **Inhalt:** KNN-Algorithmus, Distance Metrics, k-Wahl\n",
    "- **Warum wichtig:** Einfachster ML-Algorithmus, aber mächtig!\n",
    "- **Quote:** \"Sag mir wer deine Nachbarn sind...\" 🏠\n",
    "\n",
    "### 📹 **Video 3: \"K-Means-Clustering\"**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4`\n",
    "- **Dauer:** ~18 Minuten\n",
    "- **Inhalt:** Unsupervised Learning, Centroids, Elbow Method\n",
    "- **Warum wichtig:** Findet versteckte Muster in Daten\n",
    "- **Anwendung:** Customer Segmentation, Market Research\n",
    "\n",
    "> **🎯 Pro-Tipp:** Die Videos erklären die Algorithmen besser als jedes Lehrbuch. Schaut sie → dann implementiert sie unten!\n",
    "\n",
    "**Diese Algorithmen sind die Basis für viele moderne ML-Systeme. Versteht ihr sie, versteht ihr ML! 💪**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36022f9",
   "metadata": {},
   "source": [
    "## 🎬 Ergänzende Videos: Advanced Algorithms\n",
    "\n",
    "**📼 Original AMALEA Video-Serie (KIT 2021):**\n",
    "\n",
    "### 🌳 Video 1: Willkommen in der Baumschule! (Decision Trees)  \n",
    "`Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4` (~25 min)\n",
    "- Wie Decision Trees \"denken\"\n",
    "- Gini Impurity vs. Information Gain\n",
    "- Random Forest als Ensemble-Methode\n",
    "\n",
    "### 👥 Video 2: Schöne Nachbarschaft (K-Nearest Neighbors)  \n",
    "`Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4` (~20 min)\n",
    "- K-Nearest Neighbors (KNN) Algorithmus\n",
    "- Curse of Dimensionality\n",
    "- Distance Metrics: Euclidean vs. Manhattan\n",
    "\n",
    "### 🎯 Video 3: K-Means Clustering  \n",
    "`Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4` (~30 min)\n",
    "- Unsupervised Learning in Aktion\n",
    "- Lloyd's Algorithm Schritt für Schritt\n",
    "- Elbow-Method für optimales K\n",
    "\n",
    "💡 **Tipp:** Diese 3 Algorithmen sind die \"Big 3\" des Machine Learning - verstehst du sie, verstehst du 80% aller ML-Projekte!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
