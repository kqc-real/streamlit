{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e16a4d",
   "metadata": {},
   "source": [
    "# 🌳 Woche 3: Bäume, Nachbarn und Clustering - AMALEA Kernkonzepte\n",
    "\n",
    "**Integration der ursprünglichen AMALEA-Notebooks:**\n",
    "- \"Willkommen in der Baumschule!\" → Decision Trees\n",
    "- \"Schöne Nachbarschaft\" → K-Nearest Neighbors  \n",
    "- \"K-Means-Clustering\" → Unsupervised Learning\n",
    "\n",
    "## 📚 Was du heute lernst\n",
    "\n",
    "- **Decision Trees** 🌳 - Wie Computer Entscheidungen treffen\n",
    "- **K-Nearest Neighbors (KNN)** 👥 - Lernen von den Nachbarn\n",
    "- **K-Means Clustering** 🎯 - Gruppen in Daten finden\n",
    "- **Supervised vs. Unsupervised Learning** unterscheiden\n",
    "- **Streamlit-Apps** für alle drei Algorithmen erstellen\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Kernkonzepte aus dem ursprünglichen AMALEA-Kurs\n",
    "\n",
    "### Decision Trees 🌳\n",
    "> **Idee**: Wie Menschen Entscheidungen treffen - durch eine Serie von Ja/Nein-Fragen\n",
    "\n",
    "**Beispiel aus dem ursprünglichen Kurs:**\n",
    "```\n",
    "Ist es sonnig?\n",
    "├─ JA → Gehe spazieren\n",
    "└─ NEIN → Ist es regnerisch?\n",
    "    ├─ JA → Bleibe zu Hause\n",
    "    └─ NEIN → Gehe joggen\n",
    "```\n",
    "\n",
    "**Vorteile:**\n",
    "- ✅ Leicht interpretierbar\n",
    "- ✅ Keine Daten-Normalisierung nötig\n",
    "- ✅ Arbeitet mit kategorialen und numerischen Daten\n",
    "\n",
    "**Nachteile:**\n",
    "- ❌ Kann zu Overfitting neigen\n",
    "- ❌ Instabil bei kleinen Datenänderungen\n",
    "\n",
    "### K-Nearest Neighbors (KNN) 👥\n",
    "> **Idee**: \"Sage mir, wer deine Nachbarn sind, und ich sage dir, wer du bist\"\n",
    "\n",
    "**Funktionsweise:**\n",
    "1. Finde die k nächsten Nachbarn\n",
    "2. Schaue, welche Klasse am häufigsten ist\n",
    "3. Treffe Vorhersage basierend auf Mehrheit\n",
    "\n",
    "**Parameter k:**\n",
    "- k=1: Sehr flexibel, aber anfällig für Noise\n",
    "- k=groß: Glatter, aber weniger Details\n",
    "- k=ungerade: Vermeidet Unentschieden\n",
    "\n",
    "### K-Means Clustering 🎯\n",
    "> **Idee**: Finde natürliche Gruppen in den Daten (ohne Labels!)\n",
    "\n",
    "**Unterschied zu Supervised Learning:**\n",
    "- **Supervised** (Decision Trees, KNN): Haben Labels/Targets\n",
    "- **Unsupervised** (K-Means): Keine Labels, finde Muster selbst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088791a7",
   "metadata": {},
   "source": [
    "## 🎬 Original AMALEA Videos: Advanced Algorithms Deep-Dive\n",
    "\n",
    "**Diese drei Algorithmus-Videos sind Klassiker und perfekt für das tiefe Verständnis! 🌳**\n",
    "\n",
    "### 📹 **Video 1: \"Willkommen in der Baumschule!\" (Decision Trees)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4`\n",
    "- **Dauer:** ~20 Minuten\n",
    "- **Inhalt:** Decision Trees, Entropy, Information Gain, Pruning\n",
    "- **Warum wichtig:** Versteht, wie Entscheidungsbäume \"denken\"\n",
    "- **Fun Fact:** Der Titel ist Kult! 🌳\n",
    "\n",
    "### 📹 **Video 2: \"Schöne Nachbarschaft\" (K-Nearest Neighbors)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4`\n",
    "- **Dauer:** ~15 Minuten\n",
    "- **Inhalt:** KNN-Algorithmus, Distance Metrics, k-Wahl\n",
    "- **Warum wichtig:** Einfachster ML-Algorithmus, aber mächtig!\n",
    "- **Quote:** \"Sag mir wer deine Nachbarn sind...\" 🏠\n",
    "\n",
    "### 📹 **Video 3: \"K-Means-Clustering\"**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4`\n",
    "- **Dauer:** ~18 Minuten\n",
    "- **Inhalt:** Unsupervised Learning, Centroids, Elbow Method\n",
    "- **Warum wichtig:** Findet versteckte Muster in Daten\n",
    "- **Anwendung:** Customer Segmentation, Market Research\n",
    "\n",
    "> **🎯 Pro-Tipp:** Die Videos erklären die Algorithmen besser als jedes Lehrbuch. Schaut sie → dann implementiert sie unten!\n",
    "\n",
    "**Diese Algorithmen sind die Basis für viele moderne ML-Systeme. Versteht ihr sie, versteht ihr ML! 💪**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36022f9",
   "metadata": {},
   "source": [
    "## 🎬 Video-Serie: Original AMALEA Advanced Algorithms\n",
    "\n",
    "**📼 Diese Video-Trilogie stammt aus dem Original AMALEA-Kurs (KIT 2021) und erklärt die wichtigsten ML-Algorithmen!**\n",
    "\n",
    "---\n",
    "\n",
    "### 🌳 Video 1: Willkommen in der Baumschule! (Decision Trees)\n",
    "**📁 Datei:** `../Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4`  \n",
    "**⏱️ Dauer:** ~25 Minuten  \n",
    "**🎯 Algorithmus:** Decision Trees & Random Forest\n",
    "\n",
    "**📚 Was lernst du:**\n",
    "- Wie Decision Trees \"denken\"\n",
    "- Gini Impurity vs. Information Gain\n",
    "- Pruning - Warum weniger manchmal mehr ist\n",
    "- Random Forest als Ensemble-Methode\n",
    "- Overfitting bei Bäumen vermeiden\n",
    "\n",
    "**🌟 Highlight:** Visualisierung von Entscheidungsbäumen - endlich verstehen, wie sie funktionieren!\n",
    "\n",
    "---\n",
    "\n",
    "### 👥 Video 2: Schöne Nachbarschaft (K-Nearest Neighbors)\n",
    "**📁 Datei:** `../Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4`  \n",
    "**⏱️ Dauer:** ~20 Minuten  \n",
    "**🎯 Algorithmus:** K-Nearest Neighbors (KNN)\n",
    "\n",
    "**📚 Was lernst du:**\n",
    "- Das einfachste ML-Algorithmus der Welt?\n",
    "- Curse of Dimensionality verstehen\n",
    "- Wie wähle ich das richtige K?\n",
    "- Distance Metrics: Euclidean vs. Manhattan\n",
    "- Lazy Learning vs. Eager Learning\n",
    "\n",
    "**💡 Fun Fact:** KNN ist so einfach, dass es schon 1951 erfunden wurde!\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Video 3: K-Means Clustering\n",
    "**📁 Datei:** `../Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4`  \n",
    "**⏱️ Dauer:** ~30 Minuten  \n",
    "**🎯 Algorithmus:** K-Means & Clustering-Methoden\n",
    "\n",
    "**📚 Was lernst du:**\n",
    "- Unsupervised Learning in Aktion\n",
    "- Lloyd's Algorithm Schritt für Schritt\n",
    "- Elbow-Method für optimales K\n",
    "- Silhouette Score verstehen\n",
    "- Clustering vs. Classification\n",
    "\n",
    "**🚀 Anwendung:** Customer Segmentation, Datenexploration, Anomaly Detection\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Empfohlene Lernstrategie:\n",
    "\n",
    "### 📋 **Option A: Video-First Approach**\n",
    "1. **🎬 Alle 3 Videos schauen** (~75 Minuten)\n",
    "2. **💻 Notebook durcharbeiten** \n",
    "3. **🔬 Eigene Experimente starten**\n",
    "\n",
    "### 📋 **Option B: Interaktives Lernen**\n",
    "1. **🎬 Video 1 → 💻 Decision Tree Code**\n",
    "2. **🎬 Video 2 → 💻 KNN Code**  \n",
    "3. **🎬 Video 3 → 💻 K-Means Code**\n",
    "\n",
    "### 📋 **Option C: Deep Dive**\n",
    "1. **🎬 Alle Videos**\n",
    "2. **💻 Code verstehen**\n",
    "3. **📊 Eigene Daten testen**\n",
    "4. **🎬 Videos nochmal für Details**\n",
    "\n",
    "---\n",
    "\n",
    "> 🏆 **Pro-Tipp:** Diese 3 Algorithmen sind die \"Big 3\" des Machine Learning! Verstehst du sie, verstehst du 80% aller ML-Projekte.\n",
    "\n",
    "---\n",
    "\n",
    "> 🎓 **Akademische Qualität:** Original KIT-Produktion bedeutet Uni-Level Erklärungen - perfekt für IU Informatik!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
