{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n","!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip"]},{"cell_type":"markdown","metadata":{},"source":["# Oh sorry, das war ein Falsch-Positiv"]},{"cell_type":"markdown","metadata":{},"source":["## Klassifizierungsmetriken\n","Um zu verstehen, wie wir die Performanz eines Klassifikators messen können, werden wir zunächst ein einfaches Zwei-Klassen-Problem betrachten und analysieren, wie es richtig oder falsch klassifiziert werden kann. Auf Grundlage dessen werden wir später in der Lage sein, weitere, spezifischere Metriken abzuleiten.\n","\n","Die Wahl der Metriken, die Sie für die Bewertung Ihrer maschinellen Lernalgorithmen verwenden, ist sehr wichtig, da sie beeinflusst, wie die Performanz gemessen und verglichen wird. Die ausgewählten Metriken beeinflussen somit, wie Sie die Wichtigkeit verschiedener Merkmale in den Ergebnissen gewichten und welchen Algorithmus Sie schlussendlich wählen. In diesem Abschnitt werden Sie erfahren, wie Sie in Python verschiedene Performanzmetriken des maschinellen Lernens mit scikit-learn auswählen und verwenden können.\n","\n","Das ist wichtig, da Sie so in der Lage sind, Unterschiede zu erkennen und eine Auswahl zu treffen:\n","- Unterschiedliche Transformationen der Daten, die zum Trainieren desselben maschinellen Lernmodells verwendet werden.\n","- Unterschiedliche maschinelle Lernmodelle, die auf denselben Daten trainiert wurden.\n","- Unterschiedliche Konfigurationen von maschinellen Lernmodellen, die auf denselben Daten trainiert wurde.  \n","\n","https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\n"]},{"cell_type":"markdown","metadata":{},"source":["### Wahrheitsmatrix  (engl. Confusion Matrix)\n","\n","![FalsePositive-300x225.png](images/FalsePositive-300x225.png)\n","\n","\n","Eine reale Bedingung kann entweder \"der Fall\" (positiv) oder \"nicht der Fall\" (negativ) sein. Unabhängig von den realen Bedingungen kann ein Klassifikator diese Bedingung basierend auf den Daten ebenfalls entweder als \"der Fall\" oder \"nicht der Fall\" klassifizieren. Daraus ergeben sich vier verschiedene Klassifikationsmöglichkeiten, die durch die Wahrheitsmatrix dargestellt werden.\n","\n","\n","Zur Veranschaulichung wollen wir das Beispiel einer medizinischen Diagnose einer Herzerkrankung betrachten. Stellen Sie sich vor, wir verfügen über bereits vorhandene medizinische Daten sowie klinische Messungen und möchten ein maschinelles Lernverfahren auf diese anwenden, um vorherzusagen, ob jemand eine Herzerkrankung entwickeln wird. Wie entscheiden wir, welches Modell am besten mit unseren Daten funktioniert?\n","\n","Die beiden Spalten in dieser Wahrheitsmatrix entsprechen dem, was der maschinelle Lernalgorithmus vorhergesagt hat, und die Zeilen entsprechen der Grundwahrheit.\n","In diesem speziellen Fall handelt es sich um ein binäres Klassifikationsproblem, da nur zwei Kategorien zur Auswahl stehen: _Herzkrankheit_ oder _hat keine Herzkrankheit._ Wahrheitsmatrizen können auch für mehr als zwei Kategorien verwendet werden.\n","\n","Jedes Mal, wenn ein neuer Patient klassifiziert wird, wird die Wahrheitsmatrix aktualisiert und ein weiteres Klassifizierungsergebnis wird zu einem der vier Felder hinzugefügt. Wir werden diese Felder verwenden, um die Häufigkeit jedes Klassifikationsergebnisses zu zählen.\n","\n","![confusion_matrix.png](images/confusion_matrix.png)\n","\n","\n","\n","Die obere linke Ecke enthält <font color=darkgreen>__richtig Positive__</font> (engl. true positives), das sind Patienten, die eine Herzerkrankung hatten und vom Algorithmus korrekt identifiziert wurden.  \n","Die rechte untere Ecke enthält <font color=darkgreen>__richtig Negative__</font> (engl. true negatives), dies sind Patienten, die keine Herzerkrankung hatten und vom Algorithmus korrekt identifiziert wurden.  \n","Die untere linke Ecke enthält <font color=darkred>__falsch Negative__</font> (engl. false negatives), dies sind Patienten, die eine Herzerkrankung haben, der Algorithmus dies aber nicht erkannte.  \n","Die rechte obere Ecke enthält schließlich <font color=darkred>__falsch Positive__</font> (engl. false positives), das sind Patienten, die keine Herzkrankheit haben, der Algorithmus dies aber dennoch behauptet.\n","\n","Diese Gedächtnisstütze könnte nützlich sein: Das erste Wort gibt an, ob die Vermutung richtig war oder nicht. Das zweite Wort gibt an, wie die Vorhersage lautete.\n","\n","Wir wollen so viele richtig-positive und so viele richtig-negative Vorhersagen wie möglich haben, während wir gleichzeitig so wenig falsch-negative und falsch-positive Vorhersagen wie möglich anstreben. Das ist eine Gratwanderung, denn wenn man den Klassifikator empfindlicher für Herzerkrankungen macht, führt das unweigerlich zu mehr falsch-positiven Vorhersagen, bei denen der Klassifikator eine Herzerkrankung \"erkennt\", wo eigentlich gar keine ist.\n","\n","\n","\n","Der Falsch-Positiv-Anteil/Fall-Out ist definiert als: \n","\n","$ \\frac{\\sum \\textrm{FP}}{\\sum \\textrm{FP+TN}} = 1 - \\frac{\\sum \\textrm{TN}}{\\sum \\textrm{FP+TN}} $\n","\n","Die zweite Möglichkeit, die auf der Spezifität basiert, ist für mehr als zwei Klassen oder Dimensionen der Matrix einfacher zu berechnen.\n","\n","\n","Der _richtig-positiv-Anteil_ und der _falsch-positiv-Anteil_ sind Konzepte, die eng mit der ROC verwandt sind. Mehr dazu später."]},{"cell_type":"markdown","metadata":{},"source":["Nachdem das Modell gelernt hat, Herzkrankheiten zu klassifizieren, testen wir es mit einem Datensatz mit echten Patientendaten. Die Diagnosen werden im Datensatzes als eine Liste von 0en (keine Herzerkrankung) und 1en (Herzerkrankung) dargestellt. Das bedeutet zum Beispiel, dass die ersten 5 Patienten in diesem Datensatz tatsächlich keine Herzerkrankung hatten, während die letzten 5 Patienten eine hatten.\n","\n","$$ground\\_truth \\ \\ = \\ \\ \\ [0,0,0,0,0,1,1,1,1,1]$$\n","\n","\n","Wenn wir den Datensatz in das Modell einspeisen, erhalten wir diese Diagnosevorhersagen:\n","\n","$$Vorhersage \\ \\ \\ \\ \\ \\ = \\ \\ \\ [0,1,1,0,0,1,0,1,1,1]$$\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe/Frage 2.3.1:</b> Füllen Sie die folgende Wahrheitsmatrix aus, ersetzen Sie a, b, c und d durch die entsprechenden Anzahlen. Sie müssen dazu den Code der Markdown-Zelle bearbeiten. \n","</div>\n","\n","\n","<table class=\"tg table-condensed table-bordered\">\n","  <tr>\n","    <th class=\"tg-c3ow\" colspan=\"2\" rowspan=\"2\"></th>\n","    <th class=\"tg-7btt\" colspan=\"2\">Wahrer Zustand (Realität)</th>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-c3ow\">Herzerkrankung</td>\n","    <td class=\"tg-c3ow\">Keine Herzerkrankung</td>\n","  </tr>\n","  <tr>\n","      <td class=\"tg-7btt\" rowspan=\"2\"><b>Vorhergesagte Erkrankung</b></td>\n","    <td class=\"tg-c3ow\">Herzerkrankung</td>\n","    <td class=\"tg-c3ow\">a</td>\n","    <td class=\"tg-c3ow\">b</td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-c3ow\">Keine Herzerkrankung</td>\n","    <td class=\"tg-c3ow\">c</td>\n","    <td class=\"tg-c3ow\">d</td>\n","  </tr>\n","</table>\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe/Fragestellung 2.3.2:</b> Nun wollen wir das Gleiche wie zuvor tun. Statt eines binären Klassifikationsproblem liegt diesmal ein Problem mit 3 verschiedenen Labels vor: Katze(Cat), Hund(Dog) und Affe(Mon). Füllen Sie die Tabelle aus.\n","</div>\n","\n","$$actual =    \n","[Dog, Mon, Mon, Mon, Cat]$$\n","$$predicted =  \n","[Cat, Dog, Mon, Mon, Mon]$$ \n","\n","<style type=\"text/css\">\n",".tg  {border-collapse:collapse;border-spacing:0;}\n",".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",".tg .tg-baqh{text-align:center;vertical-align:top}\n",".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",".tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}\n","</style>\n","<table class=\"tg table-condensed table-bordered\">\n","  <tr>\n","    <th class=\"tg-c3ow\" colspan=\"2\" rowspan=\"2\"></th>\n","    <th class=\"tg-7btt\" colspan=\"3\">Wahrer Zustand (Realität)</th>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-c3ow\">Tatsächliche Katze</td>\n","    <td class=\"tg-c3ow\">Tatsächlicher Hund</td>\n","    <td class=\"tg-baqh\">Tatsächlicher Affe</td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-7btt\" rowspan=\"3\">Vorhergesagte Bedingung</td>\n","    <td class=\"tg-c3ow\">Vorhergesagte Katze</td>\n","    <td class=\"tg-c3ow\">a</td>\n","    <td class=\"tg-c3ow\">b</td>\n","    <td class=\"tg-baqh\">c</td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-c3ow\">Vorhergesagter Hund</td>\n","    <td class=\"tg-c3ow\">d</td>\n","    <td class=\"tg-c3ow\">e</td>\n","    <td class=\"tg-baqh\">f</td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-baqh\">Vorhergesagter Affe</td>\n","    <td class=\"tg-baqh\">g</td>\n","    <td class=\"tg-baqh\">h</td>\n","    <td class=\"tg-baqh\">i</td>\n","  </tr>\n","</table>\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.3.3:</b> \n","Bestätigen Sie Ihr Ergebnis mit der Confusion-Matrix Funktion von scikitlearn. Werfen Sie einen Blick in die <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\">Dokumentation</a> und wenden Sie diese Funktion auf die Daten der Übung 2.2.1.a an. Der Code sollte eine Matrix in der gleichen Form wie in der Tabelle oben ausgeben. Dazu ist am Ende ein kleiner zusätzlicher Schritt notwendig, den Sie selbst herausfinden sollen.\n","</div>"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.3.4:</b> Bestätigen Sie auch Ihre Ergebnisse zu Übung 2.2.1.b. (zweite Tabelle Katze, Hund, Affe)\n","</div>"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.3.5:</b> Berechnen Sie die Confusion-Matrix für den pima-indians-diabetes-Datensatz mit train_test_split, Testgröße 0,33, Seed 7 und logistischer Regression.\n","Beachten Sie, dass die letzten Spalte des Datensatzes angibt, ob die Person Diabetes hat oder nicht.  \n","1: positiv auf Diabetes getestet,  \n","0: negativ auf Diabetes getestet\n","<ul>\n","<li>Hinweis: Sie können das LogisticRegression Modell verwenden, indem Sie die Methoden fit und predict verwenden. Schauen Sie sich dazu auch die Dokumentationen von sklearn an.\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Cross Validation Classification Confusion Matrix\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","\n","filename = 'data/pima-indians-diabetes.data.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","\n","test_size = 0.33\n","seed = 7\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(\"Number of people with diabetes: \")\n","print(\"Number of people without diabetes: \")\n","\n","\n","print(\"True positives: \")\n","print(\"True negatives: \") \n","print(\"False positives: \")\n","print(\"False negatives: \")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Korrektklassifikationsrate (engl. accuracy)\n","Ein einfacher Metrik, um einen Satz von Vorhersagen zu einem Klassifizierungsproblem zu bewerten, ist die Korrektklassifikationsrate.\n","Siet ist das Verhältnis zwischen der Anzahl der richtigen Vorhersagen und der Anzahl aller getroffenen Vorhersagen. Normalerweise wird die Korrektklassifikationsrate als Prozentsatz zwischen 0 % für die schlechtestmögliche Genauigkeit und 100 % für die bestmögliche Genauigkeit angegeben.\n","\n","\n","$$ \\textrm{Korrektklassifikationsrate} = \\frac{\\textrm{richtige Vorhersagen}}{\\textrm{alle Vorhersagen}} = \\frac{ \\color{darkgreen}{\\textrm{TP} + \\textrm{TN}}}{\\color{darkgreen}{\\textrm{TP} + \\textrm{TN}} +\\color{darkred}{\\textrm{FP} + \\textrm{FN}}}$$"]},{"cell_type":"markdown","metadata":{},"source":["Angenommen, wir haben einen Datensatz mit Herzkrankheitsfällen von Erwachsenen mittleren Alters. 10 % der Personen in diesem Datensatz haben eine Herzerkrankung, während 90 % keine haben. Nun trainieren wir einen sehr einfachen Klassifikator auf diesem Datensatz. Es stellt sich heraus, dass der Klassifikator eine genial einfache, aber dennoch genaue Strategie entwickelt hat: Er ignoriert die Daten, die Sie ihm geben, komplett und sagt einfach immer \"keine Herzerkrankung\" voraus.  "]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.3.6:</b> Welche Korrektklassifikationsrate hat dieser Klassifikator auf diesem Datensatz?\n","</div>\n","\n","<div class=\"alert block alert-success\">\n","\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.3.7:</b> Beschreiben Sie, wie der Datensatz aussehen muss, damit die Korrektklassifikationsrate eine potenziell nützliche Metrik ist? (Eine vage Beschreibung ist ausreichend)\n","</div>\n","\n","<div class=\"alert block alert-success\">\n","\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert block alert-success\">\n","<b>Aufgabe 2.3.8:</b> Implementieren Sie eine Funktion, die die Korrektklassifikationsrate  berechnet. Mit Ihrem bisherigen Kenntnisstand sollte Ihnen das leicht fallen.\n","</div>"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Example of calculating classification accuracy\n","# Calculate accuracy percentage between two lists\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","\n","# Test accuracy\n","true = [0,0,0,0,0,1,1,1,1,1]\n","predicted = [0,1,0,0,0,1,0,1,1,1]\n","accuracy = accuracy_metric(true, predicted)\n","print(accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.3.9:</b> Nun wollen wir die Korrektklassifikationsrate berechnen, aber mit Funktionen der Bibliothek sklearn und einem Datensatz. Parameter der Aufgabe sind:\n","<ul>\n","<li>Datensatz: pima-indians-diabetes\n","<li> Resampling-Methode: k-fold, 10 Faltungen.\n","<li> Modell: Logistische Regression, Solver: liblinear.\n","<li> Hinweis: Die beiden folgenden Links könnten hilfreich sein:\n","<UL>\n","    <li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html</a>,\n","     <li><a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\">https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values</a>\n","</ul>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","\n","<b>Hinweis:</b> Alle Scores werden so ausgegeben, dass sie in aufsteigender Reihenfolge sortiert werden können (der größte Score ist der beste).  \n","Einige Bewertungsmetriken (wie der mittlere quadratische Fehler oder der logarithmische Verlust) sind von Natur aus absteigende Scores (der kleinste Score ist der beste) und werden als solche von der Funktion cross validation.cross val score() negativ ausgegeben.  \n","Das ist wichtig zu beachten, da einige Scores so negativ werden, die per Definition niemals negativ sein können.\n","</div>"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from pandas import read_csv\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["### Positiver Vorhersagewert, Sensitivität  (engl. precision, recall)\n","\n","Der __positive Vorhersagewert__ (engl. precision) kann als ein Maß dafür gesehen werden, wie sehr Sie dem Klassifikator vertrauen können, wenn er \"positiv\" ausgibt. Wenn der Klassifikator einen deutlichen Hinweis benötigt, bevor er eine Herzerkrankung klassifiziert, gibt es eine geringe Anzahl von falsch-positiven Ergebnissen im Verhältnis zu den richtig-positiven Ergebnissen, was zu einem hohen positiven Vorhersagewert führt.\n","\n","Wenn ein sehr präziser Klassifikator (mit einem hohen positiven Vorhersagewert) sagt, dass ein Patient eine Herzerkrankung hat, dann wird dies wahrscheinlich der Fall sein. Da der präzise Klassifikator jedoch einen starken Indikator benötigt, bleiben viele Patienten mit Herzerkrankungen unerkannt.\n","\n","$$ \\textrm{Positiver Vorhersagewert} = \\frac{\\textrm{richtig Positive}}{\\textrm{vorhergesagte Positive}} = \\frac{ \\color{darkgreen}{\\textrm{TP} }}{\\color{darkgreen}{\\textrm{TP}} +\\color{darkred}{\\textrm{FP}}}$$\n","\n","\n","__Sensitivität__ oder Recall beschreibt, wie gut der Klassifikator im Erkennen von Positiven ist. Wenn der Klassifikator sehr dünnhäutig ist und bereits auf winzige Unterschiede reagiert, wird er die meisten tatsächlichen Positiven in den Daten entdecken und nur sehr wenige falsch Negative übrig lassen. Wenn ein sehr empfindlicher Klassifikator sagt, dass ein Patient eine Herzerkrankung hat, kann es sehr gut sein, dass dies nicht der Fall ist. Ein empfindlicher Klassifikator wird jedoch bei fast allen Patienten, die tatsächlich eine Herzerkrankung haben, eine solche erkennen. \n","\n","$$ \\textrm{Sensitivität} = \\frac{\\textrm{richtig Positive}}{\\textrm{tatsächlich Positive}} = \\frac{ \\color{darkgreen}{\\textrm{TP} }}{\\color{darkgreen}{\\textrm{TP}} +\\color{darkred}{\\textrm{FN}}}$$\n","\n","Daraus lässt sich schließen, dass die Klassifizierung immer ein Balanceakt ist. "]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.3.10:</b> Angenommen, ein Screening auf Herzkrankheiten soll für eine breite Population junger und scheinbar gesunder Menschen entwickelt werden, um unbekannte Fälle von Herzkrankheiten aufzudecken. Wäre ein guter Positiver Vorhersagewert oder eine gute Sensitivität wichtiger?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","\n","<b>Ihre Antwort:</b>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.3.11:</b> Es ist gegeben, dass von 100 Personen 2 Personen eine Herzerkrankung haben (positiv). Welcher Positive Vorhersagewert und welche Sensitivität würden sich aus einem Klassifikator ergeben, der immer \"Herzkrankheit\" ausgibt?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","\n","<b>Ihre Antwort:</b></div>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["![metrics.jpg](images/metrics.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Klassifikationsbericht (engl. Classification Report)\n","\n","Die scikit-learn Bibliothek bietet im Umgang mit Klassifizierungsproblemen einen komfortablen Bericht, der Ihnen einen schnellen Überblick über die Genauigkeit eines Modells anhand einer Reihe von Maßen gibt.  \n","Die Funktion classification_report() berechnet für jede Klasse: \n","- positiver Vorhersagewert (precision): $ \\frac{\\sum \\textrm{richtig Positive}}{\\sum \\textrm{vorhergesagte Positive}} $ <br><br>\n","- Sensitivität (recall): $ \\frac{\\sum \\textrm{richtig Positive}}{\\sum \\textrm{tatsächlich Positive}} $ <br><br>\n","- F1-Score: ist ein weiteres Maß für die Performanz eines Tests. Er berücksichtigt sowohl den Positiven Vorhersagewert als auch die Sensitivität des Tests. Der F1-Score erreicht seinen besten Wert bei 1 (perfekter Positiver Vorhersagewert und Sensitivität) und den schlechtesten bei 0. <br><br>  \n","- Support: Der Support zählt das Auftreten jeder Klasse in den gegebenen Daten. Im nächsten Beispiel wäre z.B. 162 richtig Positive(141) + falsch Negative(21) und 92 richtig Negative(51) + falsch Positive(41).\n","\n","Das folgende Beispiel demonstriert den Bericht für ein binäres Klassifizierungsproblem."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Cross Validation Classification Report\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","filename = 'data/pima-indians-diabetes.data.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","\n","test_size = 0.33\n","seed = 7\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","model = LogisticRegression(solver = 'liblinear')\n","model.fit(X_train, Y_train)\n","predicted = model.predict(X_test)\n","report = classification_report(Y_test, predicted)\n","\n","print(report)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.3.12:</b> Was können Sie über das Modell sagen? Ist es ein gutes Modell? Und warum?\n","</div>\n","\n","<div class=\"alert block alert-success\">\n","\n","<b>Ihre Antwort:</b></div>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Logarithmischer Verlust\n","\n","Verlustfunktionen sind für Klassifikationsaufgaben genauso wichtig wie für die Regression. Obwohl die Wahrheitsmatrix (engl. Confusion Matrix) und die daraus abgeleiteten Metriken nützliche Informationen über die Performanz von Methoden des maschinellen Lernens liefern können, basieren sie auf diskreten Ereignissen und sind somit nicht kontinuierlich. Backpropagation-Algorithmen benötigen aber eine differenzierbare (und damit kontinuierliche) Funktion. \n","\n","Für Klassifizierungsprobleme können wir die gleichen Algorithmen wie für Regressionsprobleme verwenden, wenn wir ihnen dazu einen zu minimierenden Verlust geben. Bei der Klassifikation ist die am meisten verwendete Verlustfunktion der logarithmische Verlust (oder logloss). Er bewertet die Vorhersagen der Wahrscheinlichkeiten der Klassenzugehörigkeit.  \n","Die skalare Wahrscheinlichkeit zwischen 0 und 1 kann als ein Maß für das Vertrauen in eine Vorhersage eines Algorithmus verstanden werden. \n","Ein kleinerer Logloss ist besser, wobei 0 einen perfekten Logloss darstellt.\n","\n","Zusätzlich werden Vorhersagen, die nicht korrekt sind, in Abhängigkeit von der Sicherheit der Vorhersage bestraft. Wenn das Modell vorhersagt, dass das Eintreten einer Bedingung sehr unwahrscheinlich ist (vorhergesagte Wahrscheinlichkeit < 0,1), wird der Verlust sehr hoch, wenn die Bedingung tatsächlich eingetreten ist. (Siehe Abb. )\n","\n","\n","![Imagen K-fold](images/Log_loss_graph.png)"]},{"cell_type":"markdown","metadata":{},"source":["## Letzte Aufgabe:\n","\n","In dieser Aufgabe haben Sie ein Klassifikationsproblem, bei dem Sie entscheiden sollen, welches Modell Sie verwenden wollen. Glücklicherweise hat bereits jemand Code geschrieben, der den bekannten Iris-Datensatz analysiert (https://en.wikipedia.org/wiki/Iris_flower_data_set). Die Analyse beinhaltet eine Datenvisualisierung und erstellt die folgenden sechs Modelle (auch hier gilt das \"No Free Lunch Theorem\"!)\n","\n","- Logistische Regression\n","- Lineare Diskriminanzanalyse\n","- k-nearest Neighbors\n","- Entscheidungsbaum-Klassifikator\n","- Gaußsche Naive Bayes\n","- C-Support-Vektor-Klassifikation\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.3.13:</b> Führen Sie den Code aus und untersuchen Sie die Ausgabe\n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Load libraries\n","from pandas import read_csv\n","from pandas.plotting import scatter_matrix\n","from matplotlib import pyplot\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","\n","# Load dataset\n","filename = 'data/iris.data.csv'\n","names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n","dataset = read_csv(filename, names=names)\n","\n","# Summarize Data\n","\n","# Descriptive statistics\n","# shape\n","print(dataset.shape)\n","# head\n","print(dataset.head(20))\n","# descriptions\n","print(dataset.describe())\n","# class distribution\n","print(dataset.groupby('class').size())\n","\n","# Data visualizations\n","\n","# box and whisker plots\n","dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n","pyplot.show()\n","# histograms\n","dataset.hist()\n","pyplot.show()\n","# scatter plot matrix\n","scatter_matrix(dataset)\n","pyplot.show()\n","\n","# Prepare Data\n","\n","# Split-out validation dataset\n","array = dataset.values\n","X = array[:,0:4]\n","Y = array[:,4]\n","validation_size = 0.20\n","seed = 7\n","X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed, shuffle=True)\n","\n","# Spot-Check Algorithms\n","models = []\n","models.append(('LR', LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial', max_iter=200))) #These parameters are set to prevent warnings.\n","models.append(('LDA', LinearDiscriminantAnalysis()))\n","models.append(('KNN', KNeighborsClassifier()))\n","models.append(('CART', DecisionTreeClassifier()))\n","models.append(('NB', GaussianNB()))\n","models.append(('SVM', SVC(gamma = 'auto'))) #Parameter set to prevent warnings.\n","\n","# evaluate each model in turn and prints Accuracy\n","results = []\n","names = []\n","for name, model in models:\n","\tkfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n","\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n","\tresults.append(cv_results)\n","\tnames.append(name)\n","\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","\tprint(msg) # Prints accuracy\n","\n","# Compare Algorithms\n","fig = pyplot.figure()\n","fig.suptitle('Algorithm Comparison')\n","ax = fig.add_subplot(111)\n","pyplot.boxplot(results)\n","ax.set_xticklabels(names)\n","pyplot.show()\n","\n","for name, model in models:\n","    model.fit(X_train, Y_train)\n","    predictions= model.predict(X_validation)\n","    print(\"Model %s: Accuracy: %f \" % (name, accuracy_score(Y_validation, predictions)))\n","    print(\"Model: \" + name)\n","    print(confusion_matrix(Y_validation, predictions))\n","    print(\"Classification Report: \" + name)\n","    print(classification_report(Y_validation, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.3.14:</b> Welchen Algorithmus würden sie wählen? Erklären Sie Ihre Antwort! \n","</div>\n","\n","<div class=\"alert block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Literatur\n","- https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
